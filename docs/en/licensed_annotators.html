<!DOCTYPE html><html lang="en">
  <head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">

<!-- Google Tag Manager MAIN -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-59JLR64');</script>
<!-- End Google Tag Manager --><title>Enterprise NLP Annotators</title><meta property="og:title" content="Spark NLP | John Snow Labs"/>

<meta name="description" content="High Performance NLP with Apache Spark
">
<!-- <link rel="canonical" href="/docs/en/licensed_annotators"> -->
<link rel="canonical" href="/docs/en/licensed_annotators"><link rel="alternate" type="application/rss+xml" title="Spark NLP" href="/feed.xml"><!-- start favicons snippet, use https://realfavicongenerator.net/ -->
<!---->
<!-- <link rel="apple-touch-icon" sizes="180x180" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="32x32" href="/fav.ico"> -->

<!---->
<!-- <link rel="icon" type="image/png" sizes="16x16" href="/fav.ico"> -->

<!---->
<!-- <link rel="manifest" href="/fav.ico"> --><link rel="mask-icon" href="/fav.ico" color="#fc4d50"><link rel="shortcut icon" href="/fav.ico">

<meta name="msapplication-TileColor" content="#ffc40d"><meta name="msapplication-config" content="/assets/browserconfig.xml">

<meta name="theme-color" content="#ffffff">
<!-- end favicons snippet --><link rel="stylesheet" href="/assets/css/main.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" >
<link rel="stylesheet" href="/static/models.css" /><!-- start custom head snippets -->
<meta http-equiv="Content-Security-Policy" content="img-src * data: nlp.johnsnowlabs.com; 
style-src 'self' 'unsafe-inline' buttons.github.io nlp.johnsnowlabs.com sparknlp.org fonts.googleapis.com use.fontawesome.com; 
script-src 'self' 'unsafe-inline' 'unsafe-eval' search.modelshub.johnsnowlabs.com nlp.johnsnowlabs.com www.googletagmanager.com www.youtube.com ajax.googleapis.com code.jquery.com www.google-analytics.com search.modelshub.johnsnowlabs.com sparknlp.org cdn.bootcss.com buttons.github.io; 
font-src 'self' data: buttons.github.io fonts.gstatic.com use.fontawesome.com; 
connect-src 'self' data: api.github.com sparknlp.org search.modelshub.johnsnowlabs.com www.google-analytics.com www.youtube.com nlp.johnsnowlabs.com;">

 <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700;800&display=swap" rel="stylesheet"> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
 <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro&display=swap" rel="stylesheet"> 
<!-- end custom head snippets -->
<script>(function() {
  window.isArray = function(val) {
    return Object.prototype.toString.call(val) === '[object Array]';
  };
  window.isString = function(val) {
    return typeof val === 'string';
  };

  window.decodeUrl = function(str) {
    return str ? decodeURIComponent(str.replace(/\+/g, '%20')) : '';
  };

  window.hasEvent = function(event) {
    return 'on'.concat(event) in window.document;
  };

  window.isOverallScroller = function(node) {
    return node === document.documentElement || node === document.body || node === window;
  };

  window.isFormElement = function(node) {
    var tagName = node.tagName;
    return tagName === 'INPUT' || tagName === 'SELECT' || tagName === 'TEXTAREA';
  };

  window.pageLoad = (function () {
    var loaded = false, cbs = [];
    window.addEventListener('load', function () {
      var i;
      loaded = true;
      if (cbs.length > 0) {
        for (i = 0; i < cbs.length; i++) {
          cbs[i]();
        }
      }
    });
    return {
      then: function(cb) {
        cb && (loaded ? cb() : (cbs.push(cb)));
      }
    };
  })();
})();
(function() {
  window.throttle = function(func, wait) {
    var args, result, thisArg, timeoutId, lastCalled = 0;

    function trailingCall() {
      lastCalled = new Date;
      timeoutId = null;
      result = func.apply(thisArg, args);
    }
    return function() {
      var now = new Date,
        remaining = wait - (now - lastCalled);

      args = arguments;
      thisArg = this;

      if (remaining <= 0) {
        clearTimeout(timeoutId);
        timeoutId = null;
        lastCalled = now;
        result = func.apply(thisArg, args);
      } else if (!timeoutId) {
        timeoutId = setTimeout(trailingCall, remaining);
      }
      return result;
    };
  };
})();
(function() {
  var Set = (function() {
    var add = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (data[i] === item) {
          return;
        }
      }
      this.size ++;
      data.push(item);
      return data;
    };

    var Set = function(data) {
      this.size = 0;
      this._data = [];
      var i;
      if (data.length > 0) {
        for (i = 0; i < data.length; i++) {
          add.call(this, data[i]);
        }
      }
    };
    Set.prototype.add = add;
    Set.prototype.get = function(index) { return this._data[index]; };
    Set.prototype.has = function(item) {
      var i, data = this._data;
      for (i = 0; i < data.length; i++) {
        if (this.get(i) === item) {
          return true;
        }
      }
      return false;
    };
    Set.prototype.is = function(map) {
      if (map._data.length !== this._data.length) { return false; }
      var i, j, flag, tData = this._data, mData = map._data;
      for (i = 0; i < tData.length; i++) {
        for (flag = false, j = 0; j < mData.length; j++) {
          if (tData[i] === mData[j]) {
            flag = true;
            break;
          }
        }
        if (!flag) { return false; }
      }
      return true;
    };
    Set.prototype.values = function() {
      return this._data;
    };
    return Set;
  })();

  window.Lazyload = (function(doc) {
    var queue = {js: [], css: []}, sources = {js: {}, css: {}}, context = this;
    var createNode = function(name, attrs) {
      var node = doc.createElement(name), attr;
      for (attr in attrs) {
        if (attrs.hasOwnProperty(attr)) {
          node.setAttribute(attr, attrs[attr]);
        }
      }
      return node;
    };
    var end = function(type, url) {
      var s, q, qi, cbs, i, j, cur, val, flag;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        s[url] = true;
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (cur.urls.has(url)) {
            qi = cur, val = qi.urls.values();
            qi && (cbs = qi.callbacks);
            for (flag = true, j = 0; j < val.length; j++) {
              cur = val[j];
              if (!s[cur]) {
                flag = false;
              }
            }
            if (flag && cbs && cbs.length > 0) {
              for (j = 0; j < cbs.length; j++) {
                cbs[j].call(context);
              }
              qi.load = true;
            }
          }
        }
      }
    };
    var load = function(type, urls, callback) {
      var s, q, qi, node, i, cur,
        _urls = typeof urls === 'string' ? new Set([urls]) : new Set(urls), val, url;
      if (type === 'js' || type ==='css') {
        s = sources[type], q = queue[type];
        for (i = 0; i < q.length; i++) {
          cur = q[i];
          if (_urls.is(cur.urls)) {
            qi = cur;
            break;
          }
        }
        val = _urls.values();
        if (qi) {
          callback && (qi.load || qi.callbacks.push(callback));
          callback && (qi.load && callback());
        } else {
          q.push({
            urls: _urls,
            callbacks: callback ? [callback] : [],
            load: false
          });
          for (i = 0; i < val.length; i++) {
            node = null, url = val[i];
            if (s[url] === undefined) {
              (type === 'js' ) && (node = createNode('script', { src: url }));
              (type === 'css') && (node = createNode('link', { rel: 'stylesheet', href: url }));
              if (node) {
                node.onload = (function(type, url) {
                  return function() {
                    end(type, url);
                  };
                })(type, url);
                (doc.head || doc.body).appendChild(node);
                s[url] = false;
              }
            }
          }
        }
      }
    };
    return {
      js: function(url, callback) {
        load('js', url, callback);
      },
      css: function(url, callback) {
        load('css', url, callback);
      }
    };
  })(this.document);
})();
</script><script>
  (function() {
    var TEXT_VARIABLES = {
      version: '2.2.4',
      sources: {
        font_awesome: 'https://use.fontawesome.com/releases/v5.0.13/css/all.css',
        jquery: 'https://code.jquery.com/jquery-3.1.1.min.js',
        leancloud_js_sdk: '//cdn1.lncld.net/static/js/3.4.1/av-min.js',
        chart: 'https://cdn.bootcss.com/Chart.js/2.7.2/Chart.bundle.min.js',
        gitalk: {
          js: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.js',
          css: 'https://cdn.bootcss.com/gitalk/1.2.2/gitalk.min.css'
        },
        valine: 'https://unpkg.com/valine/dist/Valine.min.js',
        mathjax: 'https://cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML',
        mermaid: 'https://cdn.bootcss.com/mermaid/8.0.0-rc.8/mermaid.min.js'
      },
      site: {
        toc: {
          selectors: 'h1,h2,h3'
        }
      },
      paths: {
        search_js: '/assets/search.js'
      }
    };
    window.TEXT_VARIABLES = TEXT_VARIABLES;
  })();
</script></head>
  <body>
    <div class="root" data-is-touch="false">
      <div class="layout--page layout--page--sidebar clearfix js-page-root&nbsp; layout--page--aside">
  <div class="page__mask d-print-none js-page-mask js-sidebar-hide"></div>
  <div class="page__viewport">
    <div class="page__actions d-print-none">
      <div class="js-sidebar-show">
        <i class="fas fa-bars icon--show"></i>
      </div>
    </div>

    <div class="grid page__grid">

      <div class="page__sidebar d-print-none"><a title="High Performance NLP with Apache Spark
" href="/">
    <!--<svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
-->
</a><div class="sidebar-toc"><ul class="toc toc--navigator"><li class="toc-h1">All Enterprise libraries</li><li class="toc-h2"><a href="/docs/en/license_getting_started">Getting Started</a></li><li class="toc-h1">Healthcare NLP</li><li class="toc-h2"><a href="/docs/en/licensed_install">Installation</a></li><li class="toc-h2 active"><a href="/docs/en/licensed_annotators">Annotators</a></li><li class="toc-h2"><a href="/docs/en/licensed_training">Training</a></li><li class="toc-h2"><a href="/docs/en/evaluation">Evaluation</a></li><li class="toc-h2"><a href="/docs/en/healthcare_risk_adjustments_score_calculation">Risk Adjustments Score Calculation</a></li><li class="toc-h2"><a href="/docs/en/utility_helper_modules">Utility & Helper Modules</a></li><li class="toc-h2"><a href="/docs/en/licensed_serving_spark_nlp_via_api_synapseml">Serving Spark NLP&#58 SynapseML</a></li><li class="toc-h2"><a href="/docs/en/licensed_serving_spark_nlp_via_api_fastapi">Serving Spark NLP&#58 FastAPI</a></li><li class="toc-h2"><a href="/licensed/api/">Scala API (Scaladoc)</a></li><li class="toc-h2"><a href="/licensed/api/python">Python API (Sphinx)</a></li><li class="toc-h2"><a href="/docs/en/wiki">Wiki</a></li><li class="toc-h2"><a href="/docs/en/benchmark">Benchmarks</a></li><li class="toc-h2"><a href="/docs/en/benchmark-llm">Benchmarks LLM</a></li><li class="toc-h2"><a href="/docs/en/best_practices_pretrained_models">Best Practices Using Pretrained Models Together</a></li><li class="toc-h2"><a href="/docs/en/spark_nlp_healthcare_versions/licensed_release_notes">Release Notes</a></li><li class="toc-h2"><a href="/models?edition=Spark+NLP+for+Healthcare">Healthcare Models</a></li><li class="toc-h2"><a href="/docs/en/licensed_version_compatibility">Version Compatibility</a></li><li class="toc-h1">Visual NLP</li><li class="toc-h2"><a href="/docs/en/ocr">Getting Started</a></li><li class="toc-h2"><a href="/docs/en/ocr_install">Installation</a></li><li class="toc-h2"><a href="/docs/en/version_compatibility">Version Compatibility</a></li><li class="toc-h2"><a href="/docs/en/ocr_pipeline_components">Pipeline components</a></li><li class="toc-h2"><a href="/docs/en/ocr_table_recognition">Table recognition</a></li><li class="toc-h2"><a href="/docs/en/ocr_visual_document_understanding">Visual document understanding</a></li><li class="toc-h2"><a href="/docs/en/ocr_object_detection">Object detection</a></li><li class="toc-h2"><a href="/docs/en/ocr_structures">Structures and helpers</a></li><li class="toc-h2"><a href="/docs/en/ocr_benchmark">Speed benchmarks</a></li><li class="toc-h2"><a href="/docs/en/spark_ocr_versions/ocr_release_notes">Release notes</a></li><li class="toc-h1">Finance NLP</li><li class="toc-h2"><a href="/docs/en/financial_release_notes">Release Notes</a></li><li class="toc-h2"><a href="/models?edition=Spark+NLP+for+Finance">Financial Models</a></li><li class="toc-h2"><a href="/docs/en/financial_version_compatibility">Version Compatibility</a></li><li class="toc-h1">Legal NLP</li><li class="toc-h2"><a href="/docs/en/legal_release_notes">Release Notes</a></li><li class="toc-h2"><a href="/models?edition=Spark+NLP+for+Legal">Legal Models</a></li><li class="toc-h2"><a href="/docs/en/legal_version_compatibility">Version Compatibility</a></li></ul></div></div><div class="page__main js-page-main has-aside cell cell--auto">

      <div class="page__main-inner"><div class="page__header d-print-none"><!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-59JLR64"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
  <header class="header">
    <div class="main">
      <div class="header__title">
        <a class="responsive_btn" href="#" id="responsive_menu">          
        <i class="fas fa-bars"></i>
        <i class="fas fa-times"></i>
        </a>
        <div class="header__brand">
          <a title="High Performance NLP with Apache Spark
" href="https://www.johnsnowlabs.com" target="_blank"><svg width="187" height="50" viewBox="0 0 187 50" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M38.6212 18.6877H42.3588V29.0697C42.3588 33.7209 40.1163 35.382 36.5448 35.382C35.7143 35.382 34.5515 35.2159 33.804 34.9668L34.2192 31.9767C34.7176 32.1428 35.382 32.3089 36.1295 32.3089C37.7076 32.3089 38.6212 31.6445 38.6212 29.0697V18.6877Z" fill="#3E4095"/>
<path d="M55.2325 28.9867C55.2325 33.3056 52.1594 35.299 48.9202 35.299C45.4319 35.299 42.774 32.9734 42.774 29.1528C42.774 25.3322 45.2657 22.8405 49.0863 22.8405C52.7408 22.8405 55.2325 25.4153 55.2325 28.9867ZM46.5946 29.0698C46.5946 31.1462 47.4252 32.6412 49.0033 32.6412C50.4152 32.6412 51.3289 31.2292 51.3289 29.0698C51.3289 27.3256 50.6644 25.4983 49.0033 25.4983C47.2591 25.4983 46.5946 27.3256 46.5946 29.0698Z" fill="#3E4095"/>
<path d="M55.6478 17.774H59.3854V24.5847H59.4684C59.8837 24.0863 60.382 23.6711 60.9634 23.3388C61.4618 23.0066 62.2093 22.8405 62.8737 22.8405C65.1993 22.8405 67.0266 24.5016 67.0266 28.0731V35.0498H63.289V28.4883C63.289 26.9103 62.7907 25.8305 61.3787 25.8305C60.382 25.8305 59.8006 26.495 59.5515 27.1594C59.4684 27.4086 59.4684 27.7408 59.4684 27.99V35.0498H55.6478V17.774Z" fill="#3E4095"/>
<path d="M68.1064 26.9103C68.1064 25.4153 68.0233 24.1694 68.0233 23.0897H71.2625L71.4286 24.7508C71.927 24.0033 73.0898 22.8405 75.0831 22.8405C77.4917 22.8405 79.319 24.4186 79.319 27.907V34.9668H75.5814V28.4053C75.5814 26.9103 75.0831 25.8305 73.6711 25.8305C72.6745 25.8305 72.01 26.495 71.7609 27.2425C71.6778 27.4917 71.5947 27.8239 71.5947 28.1561V35.0498H68.1064V26.9103Z" fill="#3E4095"/>
<path d="M83.887 31.2292C84.8836 31.7275 86.3787 32.2259 87.9567 32.2259C89.6179 32.2259 90.5315 31.5614 90.5315 30.4817C90.5315 29.485 89.784 28.9036 87.7906 28.1561C85.0497 27.2425 83.3056 25.6644 83.3056 23.3388C83.3056 20.5149 85.6311 18.4385 89.5348 18.4385C91.362 18.4385 92.774 18.8538 93.6876 19.269L92.8571 22.2591C92.1926 21.9268 91.0298 21.5116 89.4517 21.5116C87.8737 21.5116 87.0431 22.2591 87.0431 23.0896C87.0431 24.1694 87.9567 24.5847 90.1162 25.4152C93.0232 26.495 94.3521 27.99 94.3521 30.3156C94.3521 33.0564 92.2757 35.382 87.7076 35.382C85.7973 35.382 83.97 34.8837 83.0564 34.3853L83.887 31.2292Z" fill="#3E4095"/>
<path d="M94.9336 26.9103C94.9336 25.4153 94.8505 24.1694 94.8505 23.0897H98.0897L98.2558 24.7508H98.3389C98.8372 24.0033 100 22.8405 101.993 22.8405C104.402 22.8405 106.229 24.4186 106.229 27.907V34.9668H102.492V28.4053C102.492 26.9103 101.993 25.8305 100.581 25.8305C99.5847 25.8305 98.9203 26.495 98.6711 27.2425C98.5881 27.4917 98.505 27.8239 98.505 28.1561V35.0498H94.7675V26.9103H94.9336Z" fill="#3E4095"/>
<path d="M119.103 28.9867C119.103 33.3056 116.03 35.299 112.791 35.299C109.302 35.299 106.645 32.9734 106.645 29.1528C106.645 25.3322 109.136 22.8405 112.957 22.8405C116.694 22.8405 119.103 25.4153 119.103 28.9867ZM110.465 29.0698C110.465 31.1462 111.296 32.6412 112.874 32.6412C114.286 32.6412 115.199 31.2292 115.199 29.0698C115.199 27.3256 114.535 25.4983 112.874 25.4983C111.13 25.4983 110.465 27.3256 110.465 29.0698Z" fill="#3E4095"/>
<path d="M121.927 23.1727L122.841 28.0731C123.09 29.3189 123.339 30.6478 123.505 31.9767H123.588C123.837 30.6478 124.17 29.2359 124.502 28.0731L125.748 23.1727H128.655L129.817 27.9069C130.15 29.2359 130.482 30.5648 130.731 31.9767H130.814C130.98 30.6478 131.229 29.2359 131.478 27.9069L132.475 23.1727H136.13L132.475 35.0498H128.987L127.907 30.897C127.575 29.7342 127.409 28.6545 127.16 27.1594H127.076C126.827 28.6545 126.578 29.7342 126.329 30.897L125.166 35.0498H121.678L118.189 23.1727H121.927Z" fill="#3E4095"/>
<path d="M143.023 18.9369H145.1V32.8073H152.575V34.5515H143.023V18.9369Z" fill="#0098DA"/>
<path d="M155.399 29.5681L153.571 34.5515H151.329L157.226 18.9369H159.801L165.781 34.5515H163.455L161.545 29.5681H155.399ZM161.213 27.99L159.468 23.3389C159.136 22.3422 158.804 21.5116 158.555 20.6811H158.472C158.223 21.5116 157.973 22.3422 157.641 23.2558L155.897 27.99H161.213Z" fill="#0098DA"/>
<path d="M165.864 19.186C166.777 19.0199 168.355 18.8538 169.933 18.8538C172.176 18.8538 173.505 19.186 174.502 20.0166C175.332 20.6811 175.914 21.5947 175.914 22.8405C175.914 24.3355 174.834 25.6644 173.173 26.2458V26.3289C174.502 26.6611 176.495 27.8239 176.495 30.2326C176.495 31.5615 175.914 32.6412 175.083 33.3887C173.92 34.3854 172.093 34.8837 169.269 34.8837C167.774 34.8837 166.611 34.8007 165.864 34.7176V19.186ZM168.023 25.5814H170.183C172.508 25.5814 173.754 24.5017 173.754 23.0066C173.754 21.0963 172.176 20.4319 170.1 20.4319C169.02 20.4319 168.355 20.5149 168.023 20.598V25.5814ZM168.023 32.9734C168.521 33.0565 169.103 33.0565 169.933 33.0565C172.093 33.0565 174.252 32.392 174.252 29.9834C174.252 27.8239 172.342 26.9934 169.933 26.9934H167.94V32.9734H168.023Z" fill="#0098DA"/>
<path d="M176.91 31.9768C177.907 32.6412 179.402 33.1396 180.98 33.1396C183.223 33.1396 184.468 32.0598 184.468 30.4818C184.468 28.9867 183.638 28.1562 181.229 27.4087C178.239 26.495 176.661 25.1661 176.661 22.9236C176.661 20.4319 178.821 18.6047 182.06 18.6047C183.887 18.6047 185.133 19.02 185.963 19.4352L185.382 21.0964C184.884 20.7641 183.638 20.2658 182.06 20.2658C179.734 20.2658 178.821 21.5947 178.821 22.5914C178.821 24.0033 179.817 24.7509 182.226 25.4984C185.133 26.412 186.628 27.6578 186.628 30.1495C186.628 32.4751 184.884 34.7176 180.814 34.7176C179.153 34.7176 177.325 34.2193 176.412 33.6379L176.91 31.9768Z" fill="#0098DA"/>
<path d="M22.5083 35.6312C22.5083 40.1163 18.8538 43.7708 14.3688 43.7708C9.88372 43.7708 6.22924 40.1163 6.22924 35.6312V12.2093L0 11.4618V35.6312C0 43.6047 6.4784 50 14.3688 50C22.2591 50 28.7375 43.5216 28.7375 35.6312V11.4618L22.5083 12.2093V35.6312Z" fill="#0098DA"/>
<path d="M16.1129 17.7741H8.63786C8.13952 17.7741 7.72424 17.3588 7.72424 16.8604V9.38536C7.72424 8.88702 8.13952 8.47174 8.63786 8.47174H16.1129C16.6113 8.47174 17.0266 8.88702 17.0266 9.38536V16.8604C17.0266 17.3588 16.6113 17.7741 16.1129 17.7741Z" fill="#3E4095"/>
<path d="M20.515 22.7575H15.2824C14.7841 22.7575 14.3688 22.3422 14.3688 21.8439V16.6113C14.3688 16.113 14.7841 15.6977 15.2824 15.6977H20.515C21.0133 15.6977 21.4286 16.113 21.4286 16.6113V21.8439C21.4286 22.4253 21.0133 22.7575 20.515 22.7575Z" fill="#3E4095"/>
<path d="M19.8505 9.71762H16.113C15.6146 9.71762 15.1993 9.30233 15.1993 8.80399V5.06645C15.1993 4.56811 15.6146 4.15283 16.113 4.15283H19.8505C20.3488 4.15283 20.7641 4.56811 20.7641 5.06645V8.80399C20.6811 9.30233 20.3488 9.71762 19.8505 9.71762Z" fill="#3E4095"/>
<path d="M13.6213 3.48837H11.8771C11.3788 3.48837 10.9635 3.07309 10.9635 2.57475V0.913621C10.9635 0.415282 11.3788 0 11.8771 0H13.6213C14.1196 0 14.5349 0.415282 14.5349 0.913621V2.65781C14.5349 3.15615 14.1196 3.48837 13.6213 3.48837Z" fill="#3E4095"/>
<path d="M20.2658 41.196H8.38867V41.3622H20.2658V41.196Z" fill="#ECF9FF"/>
<path d="M20.2658 40.9469H8.38867V41.113H20.2658V40.9469Z" fill="#EBF9FF"/>
<path d="M20.2658 40.7808H8.38867V40.9469H20.2658V40.7808Z" fill="#EAF8FF"/>
<path d="M20.2658 40.6146H8.38867V40.7807H20.2658V40.6146Z" fill="#E9F8FF"/>
<path d="M20.2658 40.3655H8.38867V40.5316H20.2658V40.3655Z" fill="#E8F8FF"/>
<path d="M20.2658 40.1993H8.38867V40.3655H20.2658V40.1993Z" fill="#E7F7FF"/>
<path d="M20.2658 40.0333H8.38867V40.1994H20.2658V40.0333Z" fill="#E6F7FF"/>
<path d="M20.2658 39.8671H8.38867V40.0332H20.2658V39.8671Z" fill="#E5F7FF"/>
<path d="M20.2658 39.618H8.38867V39.7841H20.2658V39.618Z" fill="#E4F6FE"/>
<path d="M20.2658 39.4518H8.38867V39.618H20.2658V39.4518Z" fill="#E3F6FE"/>
<path d="M20.2658 39.2858H8.38867V39.4519H20.2658V39.2858Z" fill="#E2F5FE"/>
<path d="M20.2658 39.0366H8.38867V39.2027H20.2658V39.0366Z" fill="#E1F5FE"/>
<path d="M20.2658 38.8705H8.38867V39.0366H20.2658V38.8705Z" fill="#E0F5FE"/>
<path d="M20.2658 38.7043H8.38867V38.8705H20.2658V38.7043Z" fill="#DFF4FE"/>
<path d="M20.2658 38.4552H8.38867V38.6213H20.2658V38.4552Z" fill="#DEF4FE"/>
<path d="M20.2658 38.2891H8.38867V38.4552H20.2658V38.2891Z" fill="#DDF4FE"/>
<path d="M20.2658 38.1229H8.38867V38.289H20.2658V38.1229Z" fill="#DCF3FE"/>
<path d="M20.2658 37.8738H8.38867V38.0399H20.2658V37.8738Z" fill="#DBF3FE"/>
<path d="M20.2658 37.7077H8.38867V37.8738H20.2658V37.7077Z" fill="#DAF3FE"/>
<path d="M20.2658 37.5416H8.38867V37.7077H20.2658V37.5416Z" fill="#D9F2FE"/>
<path d="M20.2658 37.3754H8.38867V37.5415H20.2658V37.3754Z" fill="#D8F2FE"/>
<path d="M20.2658 37.1263H8.38867V37.2924H20.2658V37.1263Z" fill="#D7F2FE"/>
<path d="M20.2658 36.9601H8.38867V37.1263H20.2658V36.9601Z" fill="#D6F1FE"/>
<path d="M20.2658 36.7941H8.38867V36.9602H20.2658V36.7941Z" fill="#D5F1FE"/>
<path d="M20.2658 36.5449H8.38867V36.711H20.2658V36.5449Z" fill="#D4F1FD"/>
<path d="M20.2658 36.3788H8.38867V36.5449H20.2658V36.3788Z" fill="#D3F0FD"/>
<path d="M20.2658 36.2126H8.38867V36.3788H20.2658V36.2126Z" fill="#D2F0FD"/>
<path d="M20.2658 35.9635H8.38867V36.1296H20.2658V35.9635Z" fill="#D1F0FD"/>
<path d="M20.2658 35.7974H8.38867V35.9635H20.2658V35.7974Z" fill="#D0EFFD"/>
<path d="M20.2658 35.6313H8.38867V35.7974H20.2658V35.6313Z" fill="#CFEFFD"/>
<path d="M20.2658 35.3821H8.38867V35.5482H20.2658V35.3821Z" fill="#CEEEFD"/>
<path d="M20.2658 35.216H8.38867V35.3821H20.2658V35.216Z" fill="#CDEEFD"/>
<path d="M20.2658 35.0499H8.38867V35.216H20.2658V35.0499Z" fill="#CCEEFD"/>
<path d="M20.2658 34.8837H8.38867V35.0498H20.2658V34.8837Z" fill="#CBEDFD"/>
<path d="M20.2658 34.6346H8.38867V34.8007H20.2658V34.6346Z" fill="#CAEDFD"/>
<path d="M20.2658 34.4684H8.38867V34.6346H20.2658V34.4684Z" fill="#C9EDFD"/>
<path d="M20.2658 34.3024H8.38867V34.4685H20.2658V34.3024Z" fill="#C8ECFD"/>
<path d="M20.2658 34.0532H8.38867V34.2193H20.2658V34.0532Z" fill="#C7ECFD"/>
<path d="M20.2658 33.8871H8.38867V34.0532H20.2658V33.8871Z" fill="#C6ECFD"/>
<path d="M20.2658 33.7209H8.38867V33.8871H20.2658V33.7209Z" fill="#C4EBFC"/>
<path d="M20.2658 33.4718H8.38867V33.6379H20.2658V33.4718Z" fill="#C3EBFC"/>
<path d="M20.2658 33.3057H8.38867V33.4718H20.2658V33.3057Z" fill="#C2EBFC"/>
<path d="M20.2658 33.1396H8.38867V33.3057H20.2658V33.1396Z" fill="#C1EAFC"/>
<path d="M20.2658 32.8904H8.38867V33.0565H20.2658V32.8904Z" fill="#C0EAFC"/>
<path d="M20.2658 32.7242H8.38867V32.8904H20.2658V32.7242Z" fill="#BFEAFC"/>
<path d="M20.2658 32.5582H8.38867V32.7243H20.2658V32.5582Z" fill="#BEE9FC"/>
<path d="M20.2658 32.392H8.38867V32.5581H20.2658V32.392Z" fill="#BDE9FC"/>
<path d="M20.2658 32.1429H8.38867V32.309H20.2658V32.1429Z" fill="#BCE9FC"/>
<path d="M20.2658 31.9768H8.38867V32.1429H20.2658V31.9768Z" fill="#BBE8FC"/>
<path d="M20.2658 31.8107H8.38867V31.9768H20.2658V31.8107Z" fill="#BAE8FC"/>
<path d="M20.2658 31.5615H8.38867V31.7276H20.2658V31.5615Z" fill="#B9E7FC"/>
<path d="M20.2658 31.3954H8.38867V31.5615H20.2658V31.3954Z" fill="#B8E7FC"/>
<path d="M20.2658 31.2292H8.38867V31.3954H20.2658V31.2292Z" fill="#B7E7FC"/>
<path d="M20.2658 30.9801H8.38867V31.1462H20.2658V30.9801Z" fill="#B6E6FC"/>
<path d="M20.2658 30.814H8.38867V30.9801H20.2658V30.814Z" fill="#B5E6FB"/>
<path d="M20.2658 30.6479H8.38867V30.814H20.2658V30.6479Z" fill="#B4E6FB"/>
<path d="M20.2658 30.3987H8.38867V30.5648H20.2658V30.3987Z" fill="#B3E5FB"/>
<path d="M20.2658 30.2326H8.38867V30.3987H20.2658V30.2326Z" fill="#B2E5FB"/>
<path d="M20.2658 30.0665H8.38867V30.2326H20.2658V30.0665Z" fill="#B1E5FB"/>
<path d="M20.2658 29.9004H8.38867V30.0665H20.2658V29.9004Z" fill="#B0E4FB"/>
<path d="M20.2658 29.6512H8.38867V29.8173H20.2658V29.6512Z" fill="#AFE4FB"/>
<path d="M20.2658 29.4851H8.38867V29.6512H20.2658V29.4851Z" fill="#AEE4FB"/>
<path d="M20.2658 29.319H8.38867V29.4851H20.2658V29.319Z" fill="#ADE3FB"/>
<path d="M20.2658 29.0698H8.38867V29.2359H20.2658V29.0698Z" fill="#ACE3FB"/>
<path d="M20.2658 28.9037H8.38867V29.0698H20.2658V28.9037Z" fill="#ABE3FB"/>
<path d="M20.2658 28.7375H8.38867V28.9037H20.2658V28.7375Z" fill="#AAE2FB"/>
<path d="M20.2658 28.4884H8.38867V28.6545H20.2658V28.4884Z" fill="#A9E2FB"/>
<path d="M20.2658 28.3223H8.38867V28.4884H20.2658V28.3223Z" fill="#A8E2FB"/>
<path d="M20.2658 28.1562H8.38867V28.3223H20.2658V28.1562Z" fill="#A7E1FB"/>
<path d="M20.2658 27.907H8.38867V28.0731H20.2658V27.907Z" fill="#A6E1FB"/>
<path d="M20.2658 27.7409H8.38867V27.907H20.2658V27.7409Z" fill="#A5E0FA"/>
<path d="M20.2658 27.5748H8.38867V27.7409H20.2658V27.5748Z" fill="#A4E0FA"/>
<path d="M20.2658 27.4087H8.38867V27.5748H20.2658V27.4087Z" fill="#A3E0FA"/>
<path d="M20.2658 27.1595H8.38867V27.3256H20.2658V27.1595Z" fill="#A2DFFA"/>
<path d="M20.2658 26.9934H8.38867V27.1595H20.2658V26.9934Z" fill="#A1DFFA"/>
<path d="M20.2658 26.8273H8.38867V26.9934H20.2658V26.8273Z" fill="#A0DFFA"/>
<path d="M20.2658 26.5781H8.38867V26.7442H20.2658V26.5781Z" fill="#9FDEFA"/>
<path d="M20.2658 26.412H8.38867V26.5781H20.2658V26.412Z" fill="#9EDEFA"/>
</svg>
</a></div></div><nav class="navigation top_navigation">
        <ul class="top-menu"><li class="navigation__item "><a href="/">Home</a></li><li class="navigation__item navigation__item--active"><a href="/docs">Docs</a></li><li class="navigation__item "><a href="/learn">Learn</a></li><li class="navigation__item "><a href="/models">Models</a></li><li class="navigation__item "><a href="/demos">Demo</a></li><li class="navigation__item "><a href="/search"><span style="color: #FF8A00;"><i class = "fas fa-search fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://github.com/JohnSnowLabs/spark-nlp"><span style="color: #FF8A00;"><i class = "fab fa-github fa-2x"></i></span></a></li><li class="navigation__item "><a href="https://join.slack.com/t/spark-nlp/shared_invite/zt-198dipu77-L3UWNe_AJ8xqDk0ivmih5Q"><span style="color: #FF8A00;"><i class="fab fa-slack-hash fa-2x"></i></span></a></li></ul>
      </nav><a class="responsive_btn" href="#" id="aside_menu">          
        <i class="fas fa-bars"></i><i class="fas fa-times"></i>
      </a>
    </div>
  </header>
</div><div class="page__content "><div class ="main"><div class="grid grid--reverse">

              <div class="col-aside d-print-none js-col-aside"><aside class="page__aside js-page-aside"><div class="toc-aside js-toc-root"></div></aside></div>

              <div class="col-main cell cell--auto"><!-- start custom main top snippet -->

<!-- end custom main top snippet --><article itemscope itemtype="https://schema.org/Article"><script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script>
  /*!
  * Search
  * Licensed under the MIT License.
  */


'use strict'

function fetchAndPopulate() {
  // Fetch JSON data
  fetch('search.json')
      .then(response => response.json())
      .then(data => {
          // Process the JSON data
          populateHTML(data);
          // Now that data is loaded, add input event listener for searching
          document.getElementById('search-input').addEventListener('input', search);
      })
      .catch(error => console.error('Error fetching JSON:', error));
}



function populateHTML(data) {
  // Iterate through the data and create HTML elements
  const container = document.getElementById('results-container');
  container.innerHTML = ''; // Clear previous content

  data.forEach(item => {
      const element = document.createElement('li');
      element.innerHTML = `${item.demopage}<a href="${item.url}">${item.title}</a><div class="sr_seotitle">${item.seotitle}</div><em>${item.content}</em>`;
      container.appendChild(element);
  });
}



function search() {
  const searchTerm = document.getElementById('search-input').value.toLowerCase(),
        resultsContainer = document.getElementById('results-container'),
        itemsTitle = document.querySelectorAll('#results-container a'), 
        itemsContent = document.querySelectorAll('#results-container em'), 
        items = document.querySelectorAll('#results-container li'); 

        if(searchTerm.length > 3) {
          itemsTitle.forEach(item => {
            wrapWordInSpan(item, searchTerm);
          });
  
          itemsContent.forEach(item => {
            wrapWordInSpan(item, searchTerm);
          });
        }

      items.forEach(item => {
      
      const text = item.innerText.toLowerCase();
      
      if (text.includes(searchTerm) && searchTerm.length > 3) {        
          resultsContainer.style.display = 'block';
          item.style.display = 'block';
      } else {
          item.style.display = 'none';
      }
      if (searchTerm == "" || searchTerm == null) {
        resultsContainer.style.display = 'none';
    }
  });
  

}

function wrapWordInSpan(data, wordToWrap) {

  var dataText = data.textContent;

  var regex = new RegExp('(' + wordToWrap.replace(/[.*+?^${}()|[\]\\]/g, '\\$&') + ')', 'gi');


  var newText = dataText.replace(regex, '<span class="hightitle">$1</span>');

  // Замена содержимого элемента с новым текстом
  return data.innerHTML = newText;
}




</script><div class="article__header"><div class="header-nav"><div class="main-docs">
  <ul class="breadcrambs">
    <li><a href="/docs">Documentation</a></li>
    <li>Enterprise NLP Annotators</li>
  </ul>
</div></div><header class="main-docs have_subtitle">
          <h1>Enterprise NLP Annotators</h1><div class="top-subtitle mont"></div></header><span class="split-space">&nbsp;</span>
          <a class="edit-on-github"
            title="Edit on Github"
            href="https://github.com/johnsnowlabs/johnsnowlabs/tree/master/docs/en/licensed_annotators.md">
            <i class="far fa-edit"></i></a></div><meta itemprop="headline" content="Enterprise NLP Annotators"><meta itemprop="author" content=""/><div class="js-article-content"><div class="docs-wrapper">
<div class="layout--article"><!-- start custom article top snippet -->

<!-- end custom article top snippet --><div class="article__content" itemprop="articleBody"><div class="h3-box">

  <p>A Spark NLP Enterprise license includes access to unique annotators.
At the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings">Spark NLP Workshop</a> you can see different types of annotators in action.</p>

  <p>By clicking on any annotator, you will see different sections:</p>
  <ul>
    <li>The <code class="language-plaintext highlighter-rouge">Approach</code>, or class to train models.</li>
    <li>The <code class="language-plaintext highlighter-rouge">Model</code>, to infer using pretrained models.</li>
  </ul>

  <p>Also, for most of the annotators, you will find examples for the different enterprise libraries:</p>
  <ul>
    <li>Healthcare NLP</li>
    <li>Finance NLP</li>
    <li>Legal NLP</li>
  </ul>

  <p>Check out the <a href="https://nlp.johnsnowlabs.com/docs/en/annotators">Spark NLP Annotators page</a> for more information on how to read this page.</p>

</div>
<div class="h3-box">

  <h2 id="available-annotators">Available Annotators</h2>

  <table class="table-model-big">
    <thead>
      <tr>
        <th>Annotators</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a href="#annotationmerger">AnnotationMerger</a></td>
        <td>Merge annotations from different pipeline steps that have the same annotation type into a unified annotation.</td>
      </tr>
      <tr>
        <td><a href="#assertionchunkconverter">AssertionChunkConverter</a></td>
        <td>AssertionChunkConverter annotator uses both begin and end indices of the tokens as input to add a more robust metadata to the chunk column in a way that improves the reliability of the indices and avoid loss of data.</td>
      </tr>
      <tr>
        <td><a href="#assertiondl">AssertionDL</a></td>
        <td>AssertionDL is a deep Learning based approach used to extract Assertion Status from extracted entities and text.</td>
      </tr>
      <tr>
        <td><a href="#assertionfilterer">AssertionFilterer</a></td>
        <td>Filters entities coming from ASSERTION type annotations and returns the CHUNKS.</td>
      </tr>
      <tr>
        <td><a href="#assertionlogreg">AssertionLogReg</a></td>
        <td>Logistic Regression is used to extract Assertion Status from extracted entities and text.</td>
      </tr>
      <tr>
        <td><a href="#assertionmerger">AssertionMerger</a></td>
        <td>Merges variety assertion columns coming from Assertion annotators</td>
      </tr>
      <tr>
        <td><a href="#averageembeddings">AverageEmbeddings</a></td>
        <td>Computes the mean of vector embeddings for two sentences of equal size, producing a unified representation</td>
      </tr>
      <tr>
        <td><a href="#bertforsequenceclassification">BertForSequenceClassification</a></td>
        <td>Can load Bert Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</td>
      </tr>
      <tr>
        <td><a href="#bertfortokenclassifier">BertForTokenClassifier</a></td>
        <td>Can load Bert Models with a token classification head on top (a linear layer on top of the hidden-states output) for Named-Entity-Recognition (NER) tasks.</td>
      </tr>
      <tr>
        <td><a href="#bertsentencechunkembeddings">BertSentenceChunkEmbeddings</a></td>
        <td>This annotator combines sentence and NER chunk embeddings to enhance resolution codes, leveraging contextual information in the embeddings for more precise results. It takes sentence context and NER chunks as input and produces embeddings for each chunk, facilitating input for the resolution model.</td>
      </tr>
      <tr>
        <td><a href="#chunk2token">Chunk2Token</a></td>
        <td>A feature transformer that converts the input array of strings (annotatorType CHUNK) into an array of chunk-based tokens (annotatorType TOKEN).</td>
      </tr>
      <tr>
        <td><a href="#chunkconverter">ChunkConverter</a></td>
        <td>This annotator merges NER-detected entities with RegexMatcher-based rules for unified processing in the pipeline.</td>
      </tr>
      <tr>
        <td><a href="#chunkentityresolver">ChunkEntityResolver</a></td>
        <td>Returns a normalized entity for a particular trained ontology / curated dataset (e.g. clinical ICD-10, RxNorm, SNOMED; financial SEC’s EDGAR database,  etc).</td>
      </tr>
      <tr>
        <td><a href="#chunkfilterer">ChunkFilterer</a></td>
        <td>Filters entities coming from CHUNK annotations.</td>
      </tr>
      <tr>
        <td><a href="#chunkkeyphraseextraction">ChunkKeyPhraseExtraction</a></td>
        <td>Uses Bert Sentence Embeddings to determine the most relevant key phrases describing a text.</td>
      </tr>
      <tr>
        <td><a href="#chunkmapper">ChunkMapper</a></td>
        <td>We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries.</td>
      </tr>
      <tr>
        <td><a href="#chunkmapperfilterer">ChunkMapperFilterer</a></td>
        <td>Annotator to be used after <code class="language-plaintext highlighter-rouge">ChunkMapper</code> that allows to filter chunks based on the results of the mapping, whether it was successful or failed.</td>
      </tr>
      <tr>
        <td><a href="#chunkmerge">ChunkMerge</a></td>
        <td>Merges entities coming from different CHUNK annotations.</td>
      </tr>
      <tr>
        <td><a href="#chunksentencesplitter">ChunkSentenceSplitter</a></td>
        <td>Annotator can split the documents into chunks according to separators given as <code class="language-plaintext highlighter-rouge">CHUNK</code> columns. It is useful when you need to perform different models or analysis in different sections of your document</td>
      </tr>
      <tr>
        <td><a href="#contextualassertion">ContextualAssertion</a></td>
        <td>This model identifies  contextual cues within text data, such as negation, uncertainty etc.It annotates text chunks with assertions based on configurable rules, prefix and suffix patterns, and exception patterns.</td>
      </tr>
      <tr>
        <td><a href="#contextualentityfilterer">ContextualEntityFilterer</a></td>
        <td>ContextualEntityFilterer can filter chunks coming from CHUNK annotations based on entity(identifier,field) info in metadata and contextual cues.</td>
      </tr>
      <tr>
        <td><a href="#contextualentityruler">ContextualEntityRuler</a></td>
        <td>ContextualEntityRuler is an annotator that updates chunks based on contextual rules.</td>
      </tr>
      <tr>
        <td><a href="#contextualparser">ContextualParser</a></td>
        <td>Extracts entity from a document based on user defined rules.</td>
      </tr>
      <tr>
        <td><a href="#contextsplitassembler">ContextSplitAssembler</a></td>
        <td>Converts and assembles <code class="language-plaintext highlighter-rouge">VECTOR_SIMILARITY_RANKINGS</code> type annotations into <code class="language-plaintext highlighter-rouge">DOCUMENT</code> type.</td>
      </tr>
      <tr>
        <td><a href="#datenormalizer">DateNormalizer</a></td>
        <td>This annotator transforms date mentions to a common standard format: YYYY/MM/DD. It is useful when using data from different sources, some times from different countries that has different formats to represent dates.</td>
      </tr>
      <tr>
        <td><a href="#deidentification">DeIdentification</a></td>
        <td>Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS.</td>
      </tr>
      <tr>
        <td><a href="#distilbertforsequenceclassification">DistilBertForSequenceClassification</a></td>
        <td>Can load DistilBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</td>
      </tr>
      <tr>
        <td><a href="#doc2chunkinternal">Doc2ChunkInternal</a></td>
        <td>Converts <code class="language-plaintext highlighter-rouge">DOCUMENT</code>, <code class="language-plaintext highlighter-rouge">TOKEN</code> typed annotations into <code class="language-plaintext highlighter-rouge">CHUNK</code> type with the contents of a <code class="language-plaintext highlighter-rouge">chunkCol</code>.</td>
      </tr>
      <tr>
        <td><a href="#docmapper">DocMapper</a></td>
        <td>Uses the text representation of document annotations to map clinical codes to other codes or relevant information.</td>
      </tr>
      <tr>
        <td><a href="#documentfiltererbyclassifier">DocumentFiltererByClassifier</a></td>
        <td>This annotator sorts documents based on classifier results. It uses white and black lists, allowing or blocking specific outcomes. It can be case-sensitive or case-insensitive for broader matching. This tool efficiently organizes documents based on classifier outcomes.</td>
      </tr>
      <tr>
        <td><a href="#documentfiltererbyner">DocumentFiltererByNER</a></td>
        <td>This annotator returns sentences containing the entity chunks you have filtered, allowing you to see only the sentences with the entities you want.</td>
      </tr>
      <tr>
        <td><a href="#documenthashcoder">DocumentHashCoder</a></td>
        <td>This annotator swaps dates in a document column with hash codes from another column, creating a new column with shifted day information. The subsequent <code class="language-plaintext highlighter-rouge">DeIdentification</code> annotator anonymizes the document, incorporating the altered dates.</td>
      </tr>
      <tr>
        <td><a href="#documentlogregclassifier">DocumentLogRegClassifier</a></td>
        <td>Classifies documents with a Logarithmic Regression algorithm.</td>
      </tr>
      <tr>
        <td><a href="#documentmlclassifier">DocumentMLClassifier</a></td>
        <td>classifies documents with a Logarithmic Regression algorithm.</td>
      </tr>
      <tr>
        <td><a href="#drugnormalizer">DrugNormalizer</a></td>
        <td>Annotator which normalizes raw text from documents, e.g. scraped web pages or xml documents.</td>
      </tr>
      <tr>
        <td><a href="#entitychunkembeddings">EntityChunkEmbeddings</a></td>
        <td>Entity Chunk Embeddings uses BERT Sentence embeddings to compute a weighted average vector represention of related entity chunks.</td>
      </tr>
      <tr>
        <td><a href="#entityrulerinternal">EntityRulerInternal</a></td>
        <td>This annotator match exact strings or regex patterns provided in a file against a Document and assigns them an named entity.</td>
      </tr>
      <tr>
        <td><a href="#featuresassembler">FeaturesAssembler</a></td>
        <td>Collects features from different columns.</td>
      </tr>
      <tr>
        <td><a href="#fewshotclassifier">FewShotClassifier</a></td>
        <td>This Annotator specifically target few-shot classification tasks, which involve training a model to make accurate predictions with limited labeled data.</td>
      </tr>
      <tr>
        <td><a href="#fewshotassertionclassifiermodel">FewShotAssertionClassifierModel</a></td>
        <td>assertion classification using large (LLMS based) few shot classifiers based on the SetFit approach.</td>
      </tr>
      <tr>
        <td><a href="#fewshotassertionsentenceclassifier">FewShotAssertionSentenceClassifier</a></td>
        <td>It is a util annotator that is used in some datasets to train a new FewShotAssertionClassifierModel.</td>
      </tr>
      <tr>
        <td><a href="#flattener">Flattener</a></td>
        <td><code class="language-plaintext highlighter-rouge">Flattener</code> annotator in Spark NLP converts annotation results into a simplified DataFrame format for easier analysis and interpretation.</td>
      </tr>
      <tr>
        <td><a href="#genericclassifier">GenericClassifier</a></td>
        <td>Creates a generic single-label classifier which uses pre-generated Tensorflow graphs.</td>
      </tr>
      <tr>
        <td><a href="#genericlogregclassifier">GenericLogRegClassifier</a></td>
        <td>Is a derivative of GenericClassifier which implements a multinomial logistic regression.</td>
      </tr>
      <tr>
        <td><a href="#genericsvmclassifier">GenericSVMClassifier</a></td>
        <td>Creates a generic single-label classifier which uses pre-generated Tensorflow graphs.</td>
      </tr>
      <tr>
        <td><a href="#internaldocumentsplitter">InternalDocumentSplitter</a></td>
        <td>This annotator splits large documents into small documents.</td>
      </tr>
      <tr>
        <td><a href="#iobtagger">IOBTagger</a></td>
        <td>Merges token tags and NER labels from chunks in the specified format.</td>
      </tr>
      <tr>
        <td><a href="#largefewshotclassifier">LargeFewShotClassifier</a></td>
        <td>This annotator is designed to work effectively with minimal labeled data, offering flexibility and adaptability to new, unseen classes.</td>
      </tr>
      <tr>
        <td><a href="#lightdeidentification">LightDeIdentification</a></td>
        <td>Light version of DeIdentification.</td>
      </tr>
      <tr>
        <td><a href="#llmloader">LLMLoader</a></td>
        <td>LLMLoader is designed to interact with a LLMs that are converted into gguf format. This module allows using John Snow Labs’ licensed LLMs at various sizes that are finetuned on medical context for certain tasks.</td>
      </tr>
      <tr>
        <td><a href="#mapper2chunk">Mapper2Chunk</a></td>
        <td>This annotator converts ‘LABELED_DEPENDENCY’ type annotations coming from ChunkMapper into ‘CHUNK’ type to create new chunk-type column</td>
      </tr>
      <tr>
        <td><a href="#medicalllm">MedicalLLM</a></td>
        <td>MedicalLLM was designed to load and run large language models (LLMs) in GGUF format with scalable performance.</td>
      </tr>
      <tr>
        <td><a href="#multichunk2doc">MultiChunk2Doc</a></td>
        <td>Merges a given chunks to create a document.</td>
      </tr>
      <tr>
        <td><a href="#namechunkobfuscator">NameChunkObfuscator</a></td>
        <td>This annotator allows to transform a dataset with an Input Annotation of type CHUNK, into its obfuscated version of by obfuscating the given CHUNKS.</td>
      </tr>
      <tr>
        <td><a href="#nerchunker">NerChunker</a></td>
        <td>Extracts phrases that fits into a known pattern using the NER tags.</td>
      </tr>
      <tr>
        <td><a href="#nerconverterinternal">NerConverterInternal</a></td>
        <td>Converts a IOB or IOB2 representation of NER to a user-friendly one, by associating the tokens of recognized entities and their label.</td>
      </tr>
      <tr>
        <td><a href="#nerdisambiguator">NerDisambiguator</a></td>
        <td>Links words of interest, such as names of persons, locations and companies, from an input text document to a corresponding unique entity in a target Knowledge Base (KB).</td>
      </tr>
      <tr>
        <td><a href="#nermodel">NerModel</a></td>
        <td>This Named Entity recognition annotator is a generic NER model based on Neural Networks.</td>
      </tr>
      <tr>
        <td><a href="#nerquestiongenerator">NerQuestionGenerator</a></td>
        <td>This annotator takes an NER chunk (obtained by, e.g., <code class="language-plaintext highlighter-rouge">NerConverterInternal</code>) and generates a questions based on two entity types, a pronoun and a strategy.</td>
      </tr>
      <tr>
        <td><a href="#questionanswering">QuestionAnswering</a></td>
        <td>GPT-based model for answering questions given a context.</td>
      </tr>
      <tr>
        <td><a href="#pretrainedzeroshotner">PretrainedZeroShotNER</a></td>
        <td>it makes easy to identify specific entities in text without needing pre-labeled datasets.</td>
      </tr>
      <tr>
        <td><a href="#regexmatcherinternal">RegexMatcherInternal</a></td>
        <td><code class="language-plaintext highlighter-rouge">RegexMatcherInternal</code> matches predefined regex patterns with entities in text, allowing for flexible entity recognition based on user-defined rules.</td>
      </tr>
      <tr>
        <td><a href="#reidentification">ReIdentification</a></td>
        <td>Reidentifies obfuscated entities by DeIdentification.</td>
      </tr>
      <tr>
        <td><a href="#relationextraction">RelationExtraction</a></td>
        <td>Extracts and classifies instances of relations between named entities.</td>
      </tr>
      <tr>
        <td><a href="#relationextractiondl">RelationExtractionDL</a></td>
        <td>Extracts and classifies instances of relations between named entities.</td>
      </tr>
      <tr>
        <td><a href="#rechunkmerger">REChunkMerger</a></td>
        <td>Merges relation chunks to create a new chunk.</td>
      </tr>
      <tr>
        <td><a href="#renerchunksfilter">RENerChunksFilter</a></td>
        <td>Filters and outputs combinations of relations between extracted entities, for further processing.</td>
      </tr>
      <tr>
        <td><a href="#replacer">Replacer</a></td>
        <td>This annotator allows to replace entities in the original text with the ones extracted by the annotators <code class="language-plaintext highlighter-rouge">NameChunkObfuscatorApproach</code> or <code class="language-plaintext highlighter-rouge">DateNormalizer</code>.</td>
      </tr>
      <tr>
        <td><a href="#resolution2chunk">Resolution2Chunk</a></td>
        <td>This annotator is responsible for converting the annotations generated by entity resolver models (typically labeled as ENTITY) into a format compatible with subsequent stages of the pipeline, such as the ChunkMapperModel.</td>
      </tr>
      <tr>
        <td><a href="#resolvermerger">ResolverMerger</a></td>
        <td>This annotator is provide the ability to merge sentence enitity resolver and chunk mapper model output columns.</td>
      </tr>
      <tr>
        <td><a href="#router">Router</a></td>
        <td>This annotator is provide the ability to split an output of an annotator for a selected metadata field and the value for that field.</td>
      </tr>
      <tr>
        <td><a href="#sentenceentityresolver">SentenceEntityResolver</a></td>
        <td>Returns the normalized entity for a particular trained ontology / curated dataset (e.g. clinical ICD-10, RxNorm, SNOMED; financial SEC’s EDGAR database,  etc) based on sentence embeddings.</td>
      </tr>
      <tr>
        <td><a href="#structuredjsonconverter">StructuredJsonConverter</a></td>
        <td>StructuredJsonConverter is a transformer that converts the output of the pipeline into a structured JSON format.</td>
      </tr>
      <tr>
        <td><a href="#summarizer">Summarizer</a></td>
        <td>Helps to quickly summarize complex medical information.</td>
      </tr>
      <tr>
        <td><a href="#textgenerator">TextGenerator</a></td>
        <td>Uses the basic BioGPT model to perform various tasks related to medical text abstraction.</td>
      </tr>
      <tr>
        <td><a href="#textmatcherinternal">TextMatcherInternal</a></td>
        <td>This annotator match exact phrases provided in a file against a Document.</td>
      </tr>
      <tr>
        <td><a href="#tfgraphbuilder">TFGraphBuilder</a></td>
        <td>Creates Tensorflow graphs.</td>
      </tr>
      <tr>
        <td><a href="#vectordbpostprocessor">VectorDBPostProcessor</a></td>
        <td>VectorDBPostProcessor is used to filter and sort the annotations from the :class:<code class="language-plaintext highlighter-rouge">sparknlp_jsl.annotator.resolution.VectorDBModel</code>.</td>
      </tr>
      <tr>
        <td><a href="#windowedsentencemodel">WindowedSentenceModel</a></td>
        <td>This annotator that helps you to merge the previous and following sentences of a given piece of text, so that you add the context surrounding them.</td>
      </tr>
      <tr>
        <td><a href="#zeroshotnermodel">ZeroShotNerModel</a></td>
        <td>This is a zero-shot named entity recognition using <code class="language-plaintext highlighter-rouge">RoBertaForQuestionAnswering</code>. It identifies entities across diverse data without domain-specific fine-tuning.</td>
      </tr>
      <tr>
        <td><a href="#zeroshotrelationextractionmodel">ZeroShotRelationExtractionModel</a></td>
        <td>This annotator implements zero-shot binary relations extraction by utilizing <code class="language-plaintext highlighter-rouge">BERT</code> transformer models trained on the NLI (Natural Language Inference) task.</td>
      </tr>
    </tbody>
  </table>

</div>

<script> /* jQuery(document).ready(function () {
    $(".model-button").click(function () {
        $(this).closest(".tabs-box").find(".model-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        //remove  active class from all other buttons
        $(this).closest(".tabs-box").find(".approach-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".h3-box.approach-content").hide()
        $(this.parentNode).siblings(".h3-box.model-content").show()
    });

    $(".approach-button").click(function () {
        //set current button to active class and remove unactive class
        $(this).closest(".tabs-box").find(".approach-button").removeClass('code-selector-un-active').addClass("code-selector-active");

        //remove  active class from all other buttons
        $(this).closest(".tabs-box").find(".model-button").removeClass('code-selector-active').addClass('code-selector-un-active');

        //toggle content
        $(this.parentNode).siblings(".h3-box.model-content").hide()
        $(this.parentNode).siblings(".h3-box.approach-content").show()
    });
});
 */ </script>

<div class="tabs-model-aproach">

  <h2 id="annotationmerger">AnnotationMerger</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Merge annotations from different pipeline steps that have the same annotation type into a unified annotation. Possible annotations that can be merged include:</p>
    <ul>
      <li>document (e.g., output of <code class="language-plaintext highlighter-rouge">DocumentAssembler</code> annotator)</li>
      <li>token (e.g., output of <code class="language-plaintext highlighter-rouge">Tokenizer</code> annotator)</li>
      <li>word_embeddings (e.g., output of <code class="language-plaintext highlighter-rouge">WordEmbeddingsModel</code> annotator)</li>
      <li>sentence_embeddings (e.g., output of <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> annotator)</li>
      <li>category (e.g., output of <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code> annotator)</li>
      <li>date (e.g., output of <code class="language-plaintext highlighter-rouge">DateMatcher</code> annotator)</li>
      <li>sentiment (e.g., output of <code class="language-plaintext highlighter-rouge">SentimentDLModel</code> annotator)</li>
      <li>pos (e.g., output of <code class="language-plaintext highlighter-rouge">PerceptronModel</code> annotator)</li>
      <li>chunk (e.g., output of <code class="language-plaintext highlighter-rouge">NerConverter</code> annotator)</li>
      <li>named_entity (e.g., output of <code class="language-plaintext highlighter-rouge">NerDLModel</code> annotator)</li>
      <li>regex (e.g., output of <code class="language-plaintext highlighter-rouge">RegexTokenizer</code> annotator)</li>
      <li>dependency (e.g., output of <code class="language-plaintext highlighter-rouge">DependencyParserModel</code> annotator)</li>
      <li>language (e.g., output of <code class="language-plaintext highlighter-rouge">LanguageDetectorDL</code> annotator)</li>
      <li>keyword (e.g., output of <code class="language-plaintext highlighter-rouge">YakeModel</code> annotator)</li>
    </ul>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">inputType</code>: The type of the annotations that you want to merge. Possible values.</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">ANY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ANY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/annotation_merger/index.html#sparknlp_jsl.annotator.annotation_merger.AnnotationMerger">AnnotationMerger</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/annotator/AnnotationMerger.html">AnnotationMerger</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/AnnotationMerger.ipynb">AnnotationMerger</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># Create the pipeline with two RE models
</span><span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">pos_ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_pos"</span><span class="p">)</span>

<span class="n">pos_ner_chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_pos"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_ner_chunks"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">pos_reModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"posology_re"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"pos_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">ade_ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_ade_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ade_ner_tags"</span><span class="p">)</span>  

<span class="n">ade_ner_chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ade_ner_tags"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ade_ner_chunks"</span><span class="p">)</span>

<span class="n">ade_reModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_ade_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ade_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ade_relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"drug-ade, ade-drug"</span><span class="p">])</span>

<span class="n">annotation_merger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AnnotationMerger</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ade_relations"</span><span class="p">,</span> <span class="s">"pos_relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputType</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"all_relations"</span><span class="p">)</span>

<span class="n">merger_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span> 
    <span class="n">words_embedder</span><span class="p">,</span> 
    <span class="n">pos_tagger</span><span class="p">,</span> 
    <span class="n">pos_ner_tagger</span><span class="p">,</span>
    <span class="n">pos_ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">pos_reModel</span><span class="p">,</span>
    <span class="n">ade_ner_tagger</span><span class="p">,</span>
    <span class="n">ade_ner_chunker</span><span class="p">,</span>
    <span class="n">ade_reModel</span><span class="p">,</span>
    <span class="n">annotation_merger</span>
<span class="p">])</span>

<span class="c1"># Show example result
</span><span class="n">text</span> <span class="o">=</span> <span class="s">"""
The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.. 
"""</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">merger_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"pos_relations.result as PosologyRelation"</span><span class="p">,</span> 
                  <span class="s">"ade_relations.result as AdeRelation"</span><span class="p">,</span> 
                  <span class="s">"all_relations.result as MergedRelation"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------------------------------------------------------+-----------+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">PosologyRelation</span>                                         <span class="o">|</span><span class="n">AdeRelation</span><span class="o">|</span><span class="n">MergedRelation</span>                                                 <span class="o">|</span>
<span class="o">+---------------------------------------------------------+-----------+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span><span class="p">,</span> <span class="n">DRUG</span><span class="o">-</span><span class="n">DURATION</span><span class="p">,</span> <span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span><span class="p">,</span> <span class="n">DRUG</span><span class="o">-</span><span class="n">FREQUENCY</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span><span class="p">,</span> <span class="n">DRUG</span><span class="o">-</span><span class="n">DURATION</span><span class="p">,</span> <span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span><span class="p">,</span> <span class="n">DRUG</span><span class="o">-</span><span class="n">FREQUENCY</span><span class="p">]</span><span class="o">|</span>
<span class="o">+---------------------------------------------------------+-----------+---------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># Create the pipeline with two RE models
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">TextSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model_date</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_sec_dates"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_dates"</span><span class="p">)</span>

<span class="n">ner_converter_date</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_dates"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_date"</span><span class="p">)</span>

<span class="n">ner_model_org</span><span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_orgs"</span><span class="p">)</span>

<span class="n">ner_converter_org</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_orgs"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_org"</span><span class="p">)</span>\

<span class="n">chunk_merger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'ner_chunk_org'</span><span class="p">,</span> <span class="s">"ner_chunk_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner_chunk'</span><span class="p">)</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">re_filter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"ORG-ORG"</span><span class="p">,</span> <span class="s">"ORG-DATE"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">reDL</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finre_acquisitions_subsidiaries_md'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'finance/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations_acq"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">reDL_alias</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finre_org_prod_alias'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'finance/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations_alias"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">annotation_merger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AnnotationMerger</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"relations_acq"</span><span class="p">,</span> <span class="s">"relations_alias"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputType</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">text_splitter</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model_date</span><span class="p">,</span>
        <span class="n">ner_converter_date</span><span class="p">,</span>
        <span class="n">ner_model_org</span><span class="p">,</span>
        <span class="n">ner_converter_org</span><span class="p">,</span>
        <span class="n">chunk_merger</span><span class="p">,</span>
        <span class="n">pos</span><span class="p">,</span>
        <span class="n">dependency_parser</span><span class="p">,</span>
        <span class="n">re_filter</span><span class="p">,</span>
        <span class="n">reDL</span><span class="p">,</span>
        <span class="n">reDL_alias</span><span class="p">,</span>
        <span class="n">annotation_merger</span><span class="p">])</span>


<span class="c1"># Show example result
</span><span class="n">text</span> <span class="o">=</span><span class="s">"""Definite-lived intangible assets acquired with Cadence’s fiscal 2021 acquisitions were as follows:
 
Acquisition Date Fair Value
Weighted Average Amortization Period
 
(In thousands)
 (in years)
Existing technology
$
59,100 
13.7 years
Agreements and relationships
28,900 
13.7 years
Tradenames, trademarks and patents
4,600 
14.3 years
Total acquired intangibles with definite lives
$
92,600 
13.7 years
2020 Acquisitions
In fiscal 2020, Cadence acquired all of the outstanding equity of AWR Corporation ("AWR") and Integrand Software, Inc. ("Integrand"). These acquisitions enhanced Cadence’s technology portfolio to address growing radio frequency design activity, driven by expanding use of 5G communications.
The aggregate cash consideration for these acquisitions was $195.6 million, after taking into account cash acquired of $1.5 million. The total purchase consideration was allocated to the assets acquired and liabilities assumed based on their respective estimated fair values on the acquisition dates. Cadence will also make payments to certain employees, subject to continued employment and other performance-based conditions, through the first quarter of fiscal 2023.
 With its acquisitions of AWR and Integrand, Cadence recorded $101.3 million of definite-lived intangible assets with a weighted average amortization period of approximately nine years. The definite-lived intangible assets related primarily to existing technology and customer agreements and relationships. Cadence also recorded $119.4 million of goodwill and $25.1 million of net liabilities, consisting primarily of deferred tax liabilities, assumed deferred revenue and trade accounts receivable. The recorded goodwill was primarily related to the acquired assembled workforce and expected synergies from combining operations of the acquired companies with Cadence. None of the goodwill related to the acquisitions of AWR and Integrand is deductible for tax purposes.
Cadence completed one additional acquisition during fiscal 2020 that was not material to the consolidated financial statements. 
Pro Forma Financial Information
Cadence has not presented pro forma financial information for any of the businesses it acquired during fiscal 2021 and fiscal 2020 because the results of operations for these businesses are not material to Cadence’s consolidated financial statements.
Acquisition-Related Transaction Costs
Transaction costs associated with acquisitions, which consist of professional fees and administrative costs, were not material during fiscal 2021, 2020 or 2019 and were expensed as incurred in Cadence’s consolidated income statements.
NOTE 7. GOODWILL AND ACQUIRED INTANGIBLES
Goodwill
The changes in the carrying amount of goodwill during fiscal 2021 and 2020 were as follows:
 
Gross CarryingAmount
 
(In thousands)
Balance as of December 28, 2019
$
661,856 
Goodwill resulting from acquisitions
120,564 
Effect of foreign currency translation
(333)
Balance as of January 2, 2021
782,087 
Goodwill resulting from acquisitions
154,362 
Effect of foreign currency translation
(8,091)
Balance as of January 1, 2022
$
928,358 
Cadence completed its annual goodwill impairment test during the third quarter of fiscal 2021 and determined that the fair value of Cadence’s single reporting unit exceeded the carrying amount of its net assets and that no impairment existed.
65"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="c1"># Show the results 
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"relations_acq.result as AcqRelation"</span><span class="p">,</span> 
                  <span class="s">"relations_alias.result as AliasRelation"</span><span class="p">,</span> 
                  <span class="s">"relations.result as MergedRelation"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">AcqRelation</span>                                                                                     <span class="o">|</span><span class="n">AliasRelation</span>                                                                           <span class="o">|</span><span class="n">MergedRelation</span>                                                                                                                                                                          <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">has_acquisition_date</span><span class="p">,</span> <span class="n">was_acquired_by</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">has_acquisition_date</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">other</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">has_acquisition_date</span><span class="p">,</span> <span class="n">was_acquired_by</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">has_acquisition_date</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">,</span> <span class="n">has_alias</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># Create the pipeline with two RE models
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">TextSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span><span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model_date</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_parties"</span><span class="p">)</span>

<span class="n">ner_converter_date</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_parties"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_parties"</span><span class="p">)</span>

<span class="n">ner_model_org</span><span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_whereas_md"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_whereas"</span><span class="p">)</span>

<span class="n">ner_converter_org</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_whereas"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_whereas"</span><span class="p">)</span>\

<span class="n">chunk_merger</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'ner_chunk_whereas'</span><span class="p">,</span> <span class="s">"ner_chunk_parties"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner_chunk'</span><span class="p">)</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">re_filter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">reDL</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legre_contract_doc_parties_md"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations_parties"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">reDL_alias</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legre_whereas"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations_whereas"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">annotation_merger</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AnnotationMerger</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"relations_parties"</span><span class="p">,</span> <span class="s">"relations_whereas"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputType</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">text_splitter</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model_date</span><span class="p">,</span>
        <span class="n">ner_converter_date</span><span class="p">,</span>
        <span class="n">ner_model_org</span><span class="p">,</span>
        <span class="n">ner_converter_org</span><span class="p">,</span>
        <span class="n">chunk_merger</span><span class="p">,</span>
        <span class="n">pos</span><span class="p">,</span>
        <span class="n">dependency_parser</span><span class="p">,</span>
        <span class="n">re_filter</span><span class="p">,</span>
        <span class="n">reDL</span><span class="p">,</span>
        <span class="n">reDL_alias</span><span class="p">,</span>
        <span class="n">annotation_merger</span><span class="p">])</span>


<span class="c1"># Show example result
</span><span class="n">text</span> <span class="o">=</span> <span class="s">"""
WHEREAS, the Company Entities own certain Copyrights and Know-How which may be used in the Arizona Field, and in connection with the transactions contemplated by the Stock Purchase Agreement, Arizona desires to obtain a license from the Company Entities to use such Intellectual Property on the terms and subject to the conditions set forth herein.
"""</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show the results 
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"relations_parties.result as PartiesRelation"</span><span class="p">,</span> 
                  <span class="s">"relations_whereas.result as WhereasRelation"</span><span class="p">,</span> 
                  <span class="s">"relations.result as MergedRelation"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------+--------------------------------------+-------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">PartiesRelation</span>              <span class="o">|</span><span class="n">WhereasRelation</span>                       <span class="o">|</span><span class="n">MergedRelation</span>                                                     <span class="o">|</span>
<span class="o">+-----------------------------+--------------------------------------+-------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">signed_by</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">signed_by</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">has_subject</span><span class="p">,</span> <span class="n">has_subject</span><span class="p">,</span> <span class="n">has_object</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">signed_by</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">signed_by</span><span class="p">,</span> <span class="n">has_subject</span><span class="p">,</span> <span class="n">has_subject</span><span class="p">,</span> <span class="n">has_object</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------+--------------------------------------+-------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Create the pipeline with two RE models</span>
<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_ner_tagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_pos"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_ner_chunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_reModel</span> <span class="k">=</span> <span class="nv">RelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"posology_re"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"pos_ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_relations"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ade_ner_tagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_ade_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ade_ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ade_ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ade_ner_tags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ade_ner_chunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ade_reModel</span> <span class="k">=</span> <span class="nv">RelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"re_ade_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"ade_ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ade_relations"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"drug-ade"</span><span class="o">,</span> <span class="s">"ade-drug"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">annotation_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AnnotationMerger</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ade_relations"</span><span class="o">,</span> <span class="s">"pos_relations"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setInputType</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"all_relations"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">merger_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documenter</span><span class="o">,</span>
  <span class="n">sentencer</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">words_embedder</span><span class="o">,</span>
  <span class="n">pos_tagger</span><span class="o">,</span>
  <span class="n">pos_ner_tagger</span><span class="o">,</span>
  <span class="n">pos_ner_chunker</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">pos_reModel</span><span class="o">,</span>
  <span class="n">ade_ner_tagger</span><span class="o">,</span>
  <span class="n">ade_ner_chunker</span><span class="o">,</span>
  <span class="n">ade_reModel</span><span class="o">,</span>
  <span class="n">annotation_merger</span>
<span class="o">))</span>


<span class="c1">// Show example result</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span>
  <span class="s">"""
The patient was prescribed 1 unit of naproxen for 5 days after meals for chronic low back pain. The patient was also given 1 unit of oxaprozin daily for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands..
"""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">merger_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+---------------------------------------------------------+-----------+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">PosologyRelation</span>                                         <span class="o">|</span><span class="nc">AdeRelation</span><span class="o">|</span><span class="nc">MergedRelation</span>                                                 <span class="o">|</span>
<span class="o">+---------------------------------------------------------+-----------+---------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">DOSAGE-DRUG</span>, <span class="kt">DRUG-DURATION</span>, <span class="kt">DOSAGE-DRUG</span>, <span class="kt">DRUG-FREQUENCY</span><span class="o">]|[</span><span class="err">1</span>, <span class="err">1</span><span class="o">]</span>     <span class="o">|[</span><span class="err">1</span>, <span class="err">1</span>, <span class="kt">DOSAGE-DRUG</span>, <span class="kt">DRUG-DURATION</span>, <span class="kt">DOSAGE-DRUG</span>, <span class="kt">DRUG-FREQUENCY</span><span class="o">]|</span>
<span class="o">+---------------------------------------------------------+-----------+---------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Create the pipeline with two RE models</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">text_splitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextSplitter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model_date</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_sec_dates"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_dates"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_date</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_dates"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_date"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model_org</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_orgs"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_org</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_orgs"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_org"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk_org"</span><span class="o">,</span> <span class="s">"ner_chunk_date"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PerceptronModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DependencyParserModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RelationExtractionModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ORG-ORG"</span><span class="o">,</span> <span class="s">"ORG-DATE"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reDL</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RelationExtractionModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finre_acquisitions_subsidiaries_md"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations_acq"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reDL_alias</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RelationExtractionModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finre_org_prod_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations_alias"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">annotation_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AnnotationMerger</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"relations_acq"</span><span class="o">,</span> <span class="s">"relations_alias"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputType</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">text_splitter</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model_date</span><span class="o">,</span>
  <span class="n">ner_converter_date</span><span class="o">,</span>
  <span class="n">ner_model_org</span><span class="o">,</span>
  <span class="n">ner_converter_org</span><span class="o">,</span>
  <span class="n">chunk_merger</span><span class="o">,</span>
  <span class="n">pos</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">re_filter</span><span class="o">,</span>
  <span class="n">reDL</span><span class="o">,</span>
  <span class="n">reDL_alias</span><span class="o">,</span>
  <span class="n">annotation_merger</span>
<span class="o">))</span>

<span class="c1">// Show example result</span>
<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""
Definite-lived intangible assets acquired with Cadence’s fiscal 2021 acquisitions were as follows:
 
Acquisition Date Fair Value
Weighted Average Amortization Period
 
(In thousands)
 (in years)
Existing technology
$
59,100 
13.7 years
Agreements and relationships
28,900 
13.7 years
Tradenames, trademarks and patents
4,600 
14.3 years
Total acquired intangibles with definite lives
$
92,600 
13.7 years
2020 Acquisitions
In fiscal 2020, Cadence acquired all of the outstanding equity of AWR Corporation ("AWR") and Integrand Software, Inc. ("Integrand"). These acquisitions enhanced Cadence’s technology portfolio to address growing radio frequency design activity, driven by expanding use of 5G communications.
The aggregate cash consideration for these acquisitions was $195.6 million, after taking into account cash acquired of $1.5 million. The total purchase consideration was allocated to the assets acquired and liabilities assumed based on their respective estimated fair values on the acquisition dates. Cadence will also make payments to certain employees, subject to continued employment and other performance-based conditions, through the first quarter of fiscal 2023.
 With its acquisitions of AWR and Integrand, Cadence recorded $101.3 million of definite-lived intangible assets with a weighted average amortization period of approximately nine years. The definite-lived intangible assets related primarily to existing technology and customer agreements and relationships. Cadence also recorded $119.4 million of goodwill and $25.1 million of net liabilities, consisting primarily of deferred tax liabilities, assumed deferred revenue and trade accounts receivable. The recorded goodwill was primarily related to the acquired assembled workforce and expected synergies from combining operations of the acquired companies with Cadence. None of the goodwill related to the acquisitions of AWR and Integrand is deductible for tax purposes.
Cadence completed one additional acquisition during fiscal 2020 that was not material to the consolidated financial statements. 
Pro Forma Financial Information
Cadence has not presented pro forma financial information for any of the businesses it acquired during fiscal 2021 and fiscal 2020 because the results of operations for these businesses are not material to Cadence’s consolidated financial statements.
Acquisition-Related Transaction Costs
Transaction costs associated with acquisitions, which consist of professional fees and administrative costs, were not material during fiscal 2021, 2020 or 2019 and were expensed as incurred in Cadence’s consolidated income statements.
NOTE 7. GOODWILL AND ACQUIRED INTANGIBLES
Goodwill
The changes in the carrying amount of goodwill during fiscal 2021 and 2020 were as follows:
 
Gross CarryingAmount
 
(In thousands)
Balance as of December 28, 2019
$
661,856 
Goodwill resulting from acquisitions
120,564 
Effect of foreign currency translation
(333)
Balance as of January 2, 2021
782,087 
Goodwill resulting from acquisitions
154,362 
Effect of foreign currency translation
(8,091)
Balance as of January 1, 2022
$
928,358 
Cadence completed its annual goodwill impairment test during the third quarter of fiscal 2021 and determined that the fair value of Cadence’s single reporting unit exceeded the carrying amount of its net assets and that no impairment existed.
65
"""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">AcqRelation</span>                                                                                     <span class="o">|</span><span class="nc">AliasRelation</span>                                                                           <span class="o">|</span><span class="nc">MergedRelation</span>                                                                                                                                                                          <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">has_acquisition_date</span>, <span class="kt">was_acquired_by</span>, <span class="kt">other</span>, <span class="kt">other</span>, <span class="kt">other</span>, <span class="kt">has_acquisition_date</span>, <span class="kt">other</span>, <span class="kt">other</span><span class="o">]|[</span><span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span><span class="o">]|[</span><span class="kt">has_acquisition_date</span>, <span class="kt">was_acquired_by</span>, <span class="kt">other</span>, <span class="kt">other</span>, <span class="kt">other</span>, <span class="kt">has_acquisition_date</span>, <span class="kt">other</span>, <span class="kt">other</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span>, <span class="kt">has_alias</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Create the pipeline with two RE models</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">text_splitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextSplitter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model_date</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_parties"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_date</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_parties"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_parties"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model_org</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_whereas_md"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_whereas"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_org</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_whereas"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_whereas"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk_whereas"</span><span class="o">,</span> <span class="s">"ner_chunk_parties"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PerceptronModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DependencyParserModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RelationExtractionModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reDL</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RelationExtractionModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legre_contract_doc_parties_md"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations_parties"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reDL_alias</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RelationExtractionModel</span><span class="o">()</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legre_whereas"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations_whereas"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">annotation_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AnnotationMerger</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"relations_parties"</span><span class="o">,</span> <span class="s">"relations_whereas"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputType</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">text_splitter</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model_date</span><span class="o">,</span>
  <span class="n">ner_converter_date</span><span class="o">,</span>
  <span class="n">ner_model_org</span><span class="o">,</span>
  <span class="n">ner_converter_org</span><span class="o">,</span>
  <span class="n">chunk_merger</span><span class="o">,</span>
  <span class="n">pos</span><span class="o">,</span>
  <span class="n">dependency_parser</span><span class="o">,</span>
  <span class="n">re_filter</span><span class="o">,</span>
  <span class="n">reDL</span><span class="o">,</span>
  <span class="n">reDL_alias</span><span class="o">,</span>
  <span class="n">annotation_merger</span>
<span class="o">))</span>

<span class="c1">// Show example result</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""WHEREAS, the Company Entities own certain Copyrights and Know-How which may be used in the Arizona Field, and in connection with the transactions contemplated by the Stock Purchase Agreement, Arizona desires to obtain a license from the Company Entities to use such Intellectual Property on the terms and subject to the conditions set forth herein.
"""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------+--------------------------------------+-------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">PartiesRelation</span>              <span class="o">|</span><span class="nc">WhereasRelation</span>                       <span class="o">|</span><span class="nc">MergedRelation</span>                                                     <span class="o">|</span>
<span class="o">+-----------------------------+--------------------------------------+-------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">signed_by</span>, <span class="kt">other</span>, <span class="kt">signed_by</span><span class="o">]|[</span><span class="kt">has_subject</span>, <span class="kt">has_subject</span>, <span class="kt">has_object</span><span class="o">]|[</span><span class="kt">signed_by</span>, <span class="kt">other</span>, <span class="kt">signed_by</span>, <span class="kt">has_subject</span>, <span class="kt">has_subject</span>, <span class="kt">has_object</span><span class="o">]|</span>
<span class="o">+-----------------------------+--------------------------------------+-------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="assertionchunkconverter">AssertionChunkConverter</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator creates a <code class="language-plaintext highlighter-rouge">CHUNK</code> column with metadata useful for training an Assertion Status Detection model (see <a href="https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#assertiondl">AssertionDL</a>).</p>

    <p>In some cases, there may be issues while creating the chunk column when using token indices that can lead to loss of data to train assertion status models.</p>

    <p>The <code class="language-plaintext highlighter-rouge">AssertionChunkConverter</code> annotator uses both the begin and end indices of the tokens as input to add more robust metadata to the chunk column in a way that improves the reliability of the indices and avoids loss of data.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">chunkBeginCol</code>: (Str) The column containing the start index of the chunk.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">chunkEndCol</code>: (Str) The column containing the end index of the chunk.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">chunkTextCol</code>: (Str) The column containing the text chunk.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputTokenBeginCol</code>: (Str)  The column containing the selected token start.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputTokenEndCol</code>: (Str) The column containing the selected token end index.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">metadataFields</code>:  (Dict) The dictionary of of metadata fields to be added to the chunk column</p>
      </li>
    </ul>

    <blockquote>
      <p><em>NOTE</em>: Chunk begin and end indices in the assertion status model training dataframe can be populated using the new version of the ALAB module.</p>
    </blockquote>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertion_chunk_converter/index.html#sparknlp_jsl.annotator.assertion.assertion_chunk_converter.AssertionChunkConverter">AssertionChunkConverter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/AssertionChunkConverter.html">AssertionChunkConverter</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/AssertionChunkConverter.ipynb">AssertionChunkConverterNootebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionChunkConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkTextCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkBeginCol</span><span class="p">(</span><span class="s">"char_begin"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkEndCol</span><span class="p">(</span><span class="s">"char_end"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputTokenBeginCol</span><span class="p">(</span><span class="s">"token_begin"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputTokenEndCol</span><span class="p">(</span><span class="s">"token_end"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">(</span>
    <span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> 
     <span class="n">sentenceDetector</span><span class="p">,</span> 
     <span class="n">tokenizer</span><span class="p">,</span> 
     <span class="n">converter</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized."</span><span class="p">,</span><span class="s">"Minnie"</span><span class="p">,</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">64</span><span class="p">,],</span>
    <span class="p">[</span><span class="s">"After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation"</span><span class="p">,</span><span class="s">"PCP"</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">34</span><span class="p">,],</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">,</span> <span class="s">"char_begin"</span><span class="p">,</span> <span class="s">"char_end"</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"target"</span><span class="p">,</span>
    <span class="s">"char_begin"</span><span class="p">,</span>
    <span class="s">"char_end"</span><span class="p">,</span>
    <span class="s">"token_begin"</span><span class="p">,</span>
    <span class="s">"token_end"</span><span class="p">,</span>
    <span class="s">"tokens[token_begin].result"</span><span class="p">,</span>
    <span class="s">"tokens[token_end].result"</span><span class="p">,</span>
    <span class="s">"target"</span><span class="p">,</span>
    <span class="s">"chunk"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">target</span><span class="o">|</span><span class="n">char_begin</span><span class="o">|</span><span class="n">char_end</span><span class="o">|</span><span class="n">token_begin</span><span class="o">|</span><span class="n">token_end</span><span class="o">|</span><span class="n">tokens</span><span class="p">[</span><span class="n">token_begin</span><span class="p">].</span><span class="n">result</span><span class="o">|</span><span class="n">tokens</span><span class="p">[</span><span class="n">token_end</span><span class="p">].</span><span class="n">result</span><span class="o">|</span><span class="n">target</span><span class="o">|</span><span class="n">chunk</span>                                         <span class="o">|</span>
<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">Minnie</span><span class="o">|</span><span class="mi">57</span>        <span class="o">|</span><span class="mi">64</span>      <span class="o">|</span><span class="mi">10</span>         <span class="o">|</span><span class="mi">10</span>       <span class="o">|</span><span class="n">Minnie</span>                    <span class="o">|</span><span class="n">Minnie</span>                  <span class="o">|</span><span class="n">Minnie</span><span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">57</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="n">Minnie</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span><span class="o">|</span>
<span class="o">|</span><span class="n">PCP</span>   <span class="o">|</span><span class="mi">31</span>        <span class="o">|</span><span class="mi">34</span>      <span class="o">|</span><span class="mi">5</span>          <span class="o">|</span><span class="mi">5</span>        <span class="o">|</span><span class="n">PCP</span>                       <span class="o">|</span><span class="n">PCP</span>                     <span class="o">|</span><span class="n">PCP</span>   <span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="n">PCP</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span>   <span class="o">|</span>
<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionChunkConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkTextCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkBeginCol</span><span class="p">(</span><span class="s">"char_begin"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkEndCol</span><span class="p">(</span><span class="s">"char_end"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputTokenBeginCol</span><span class="p">(</span><span class="s">"token_begin"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputTokenEndCol</span><span class="p">(</span><span class="s">"token_end"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">(</span>
    <span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> 
     <span class="n">sentenceDetector</span><span class="p">,</span> 
     <span class="n">tokenizer</span><span class="p">,</span> 
     <span class="n">converter</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"Tom Martin worked as Cadence's CTO until 2010"</span><span class="p">,</span><span class="s">"Cadence's CTO"</span><span class="p">,</span><span class="mi">21</span><span class="p">,</span><span class="mi">33</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Mrs. Charles was before Managing Director at a big consultancy company"</span><span class="p">,</span><span class="s">"Managing Director"</span><span class="p">,</span><span class="mi">24</span><span class="p">,</span><span class="mi">40</span><span class="p">],</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">,</span> <span class="s">"char_begin"</span><span class="p">,</span> <span class="s">"char_end"</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"target"</span><span class="p">,</span>
    <span class="s">"char_begin"</span><span class="p">,</span>
    <span class="s">"char_end"</span><span class="p">,</span>
    <span class="s">"token_begin"</span><span class="p">,</span>
    <span class="s">"token_end"</span><span class="p">,</span>
    <span class="s">"tokens[token_begin].result"</span><span class="p">,</span>
    <span class="s">"tokens[token_end].result"</span><span class="p">,</span>
    <span class="s">"target"</span><span class="p">,</span>
    <span class="s">"chunk"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------+----------+--------+-----------+---------+--------------------------+------------------------+-----------------+---------------------------------------------------------+</span>
<span class="o">|</span><span class="n">target</span>           <span class="o">|</span><span class="n">char_begin</span><span class="o">|</span><span class="n">char_end</span><span class="o">|</span><span class="n">token_begin</span><span class="o">|</span><span class="n">token_end</span><span class="o">|</span><span class="n">tokens</span><span class="p">[</span><span class="n">token_begin</span><span class="p">].</span><span class="n">result</span><span class="o">|</span><span class="n">tokens</span><span class="p">[</span><span class="n">token_end</span><span class="p">].</span><span class="n">result</span><span class="o">|</span><span class="n">target</span>           <span class="o">|</span><span class="n">chunk</span>                                                    <span class="o">|</span>
<span class="o">+-----------------+----------+--------+-----------+---------+--------------------------+------------------------+-----------------+---------------------------------------------------------+</span>
<span class="o">|</span><span class="n">Cadence</span><span class="s">'s CTO    |21        |33      |4          |4        |Cadence'</span><span class="n">s</span>                 <span class="o">|</span><span class="n">Cadence</span><span class="s">'s               |Cadence'</span><span class="n">s</span> <span class="n">CTO</span>    <span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="n">Cadence</span><span class="s">'s CTO, {sentence -&gt; 0}, []}]    |
|Managing Director|24        |40      |5          |5        |Managing                  |Managing                |Managing Director|[{chunk, 24, 31, Managing Director, {sentence -&gt; 0}, []}]|
+-----------------+----------+--------+-----------+---------+--------------------------+------------------------+-----------------+---------------------------------------------------------+
</span></code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionChunkConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkTextCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkBeginCol</span><span class="p">(</span><span class="s">"char_begin"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setChunkEndCol</span><span class="p">(</span><span class="s">"char_end"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputTokenBeginCol</span><span class="p">(</span><span class="s">"token_begin"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputTokenEndCol</span><span class="p">(</span><span class="s">"token_end"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">(</span>
    <span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span>
     <span class="n">sentenceDetector</span><span class="p">,</span>
     <span class="n">tokenizer</span><span class="p">,</span> 
     <span class="n">converter</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"This Agreement may be executed by different parties hereto"</span><span class="p">,</span><span class="s">"parties"</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span><span class="mi">50</span><span class="p">,],</span>
    <span class="p">[</span><span class="s">"The Administrative Agent will determine the Dollar Equivalent amount"</span><span class="p">,</span><span class="s">"Agent"</span><span class="p">,</span><span class="mi">19</span><span class="p">,</span><span class="mi">23</span><span class="p">,],</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">,</span> <span class="s">"char_begin"</span><span class="p">,</span> <span class="s">"char_end"</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"target"</span><span class="p">,</span>
    <span class="s">"char_begin"</span><span class="p">,</span>
    <span class="s">"char_end"</span><span class="p">,</span>
    <span class="s">"token_begin"</span><span class="p">,</span>
    <span class="s">"token_end"</span><span class="p">,</span>
    <span class="s">"tokens[token_begin].result"</span><span class="p">,</span>
    <span class="s">"tokens[token_end].result"</span><span class="p">,</span>
    <span class="s">"target"</span><span class="p">,</span>
    <span class="s">"chunk"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-------+----------+--------+-----------+---------+--------------------------+------------------------+-------+-----------------------------------------------+</span>
<span class="o">|</span><span class="n">target</span> <span class="o">|</span><span class="n">char_begin</span><span class="o">|</span><span class="n">char_end</span><span class="o">|</span><span class="n">token_begin</span><span class="o">|</span><span class="n">token_end</span><span class="o">|</span><span class="n">tokens</span><span class="p">[</span><span class="n">token_begin</span><span class="p">].</span><span class="n">result</span><span class="o">|</span><span class="n">tokens</span><span class="p">[</span><span class="n">token_end</span><span class="p">].</span><span class="n">result</span><span class="o">|</span><span class="n">target</span> <span class="o">|</span><span class="n">chunk</span>                                          <span class="o">|</span>
<span class="o">+-------+----------+--------+-----------+---------+--------------------------+------------------------+-------+-----------------------------------------------+</span>
<span class="o">|</span><span class="n">parties</span><span class="o">|</span><span class="mi">44</span>        <span class="o">|</span><span class="mi">50</span>      <span class="o">|</span><span class="mi">7</span>          <span class="o">|</span><span class="mi">6</span>        <span class="o">|</span><span class="n">parties</span>                   <span class="o">|</span><span class="n">different</span>               <span class="o">|</span><span class="n">parties</span><span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="n">parties</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span><span class="o">|</span>
<span class="o">|</span><span class="n">Agent</span>  <span class="o">|</span><span class="mi">19</span>        <span class="o">|</span><span class="mi">23</span>      <span class="o">|</span><span class="mi">2</span>          <span class="o">|</span><span class="mi">1</span>        <span class="o">|</span><span class="n">Agent</span>                     <span class="o">|</span><span class="n">Administrative</span>          <span class="o">|</span><span class="n">Agent</span>  <span class="o">|</span><span class="p">[{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">Agent</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span>  <span class="o">|</span>
<span class="o">+-------+----------+--------+-----------+---------+--------------------------+------------------------+-------+-----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionChunkConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkTextCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkBeginCol</span><span class="o">(</span><span class="s">"char_begin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkEndCol</span><span class="o">(</span><span class="s">"char_end"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputTokenBeginCol</span><span class="o">(</span><span class="s">"token_begin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputTokenEndCol</span><span class="o">(</span><span class="s">"token_end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                              <span class="n">document_assembler</span><span class="o">,</span> 
                                              <span class="n">sentenceDetector</span><span class="o">,</span> 
                                              <span class="n">tokenizer</span><span class="o">,</span> 
                                              <span class="n">converter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="o">(</span><span class="s">"An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized."</span><span class="o">,</span> <span class="s">"Minnie"</span><span class="o">,</span><span class="mi">57</span><span class="o">,</span><span class="mi">64</span><span class="o">,),</span>
    <span class="o">(</span><span class="s">"After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation"</span><span class="o">,</span> <span class="s">"PCP"</span><span class="o">,</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">34</span><span class="o">,)</span>
<span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"target"</span><span class="o">,</span> <span class="s">"char_begin"</span><span class="o">,</span> <span class="s">"char_end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">target</span><span class="o">|</span><span class="n">char_begin</span><span class="o">|</span><span class="n">char_end</span><span class="o">|</span><span class="n">token_begin</span><span class="o">|</span><span class="n">token_end</span><span class="o">|</span><span class="n">tokens</span><span class="o">[</span><span class="kt">token_begin</span><span class="o">].</span><span class="py">result</span><span class="o">|</span><span class="n">tokens</span><span class="o">[</span><span class="kt">token_end</span><span class="o">].</span><span class="py">result</span><span class="o">|</span><span class="n">target</span><span class="o">|</span><span class="n">chunk</span>                                         <span class="o">|</span>
<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
<span class="o">|</span><span class="nc">Minnie</span><span class="o">|</span><span class="mi">57</span>        <span class="o">|</span><span class="mi">64</span>      <span class="o">|</span><span class="mi">10</span>         <span class="o">|</span><span class="mi">10</span>       <span class="o">|</span><span class="nc">Minnie</span>                    <span class="o">|</span><span class="nc">Minnie</span>                  <span class="o">|</span><span class="nc">Minnie</span><span class="o">|[{</span><span class="kt">chunk</span>, <span class="err">57</span>, <span class="err">62</span>, <span class="kt">Minnie</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]|</span>
<span class="o">|</span><span class="nc">PCP</span>   <span class="o">|</span><span class="mi">31</span>        <span class="o">|</span><span class="mi">34</span>      <span class="o">|</span><span class="mi">5</span>          <span class="o">|</span><span class="mi">5</span>        <span class="o">|</span><span class="nc">PCP</span>                       <span class="o">|</span><span class="nc">PCP</span>                     <span class="o">|</span><span class="nc">PCP</span>   <span class="o">|[{</span><span class="kt">chunk</span>, <span class="err">31</span>, <span class="err">33</span>, <span class="kt">PCP</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]</span>   <span class="o">|</span>
<span class="o">+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionChunkConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkTextCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkBeginCol</span><span class="o">(</span><span class="s">"char_begin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkEndCol</span><span class="o">(</span><span class="s">"char_end"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputTokenBeginCol</span><span class="o">(</span><span class="s">"token_begin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputTokenEndCol</span><span class="o">(</span><span class="s">"token_end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                              <span class="n">document_assembler</span><span class="o">,</span> 
                                              <span class="n">sentenceDetector</span><span class="o">,</span> 
                                              <span class="n">tokenizer</span><span class="o">,</span> 
                                              <span class="n">converter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="o">(</span><span class="s">"Tom Martin worked as Cadence's CTO until 2010"</span><span class="o">,</span><span class="s">"Cadence's CTO"</span><span class="o">,</span><span class="mi">21</span><span class="o">,</span><span class="mi">33</span><span class="o">,),</span>
    <span class="o">(</span><span class="s">"Mrs. Charles was before Managing Director at a big consultancy company"</span><span class="o">,</span> <span class="s">"Managing Director"</span><span class="o">,</span><span class="mi">24</span><span class="o">,</span> <span class="mi">40</span><span class="o">,)</span>
<span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"target"</span><span class="o">,</span> <span class="s">"char_begin"</span><span class="o">,</span> <span class="s">"char_end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------+----------+--------+-----------+---------+-----+----+------------+----------+-------------------+</span>
<span class="o">|</span><span class="n">target</span>           <span class="o">|</span><span class="n">char_begin</span><span class="o">|</span><span class="n">char_end</span><span class="o">|</span><span class="n">token_begin</span><span class="o">|</span><span class="n">token_end</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span> <span class="o">|</span><span class="n">begin_result</span><span class="o">|</span><span class="n">end_result</span><span class="o">|</span><span class="n">result</span>             <span class="o">|</span>
<span class="o">+-----------------+----------+--------+-----------+---------+-----+----+------------+----------+-------------------+</span>
<span class="o">|</span><span class="nc">Cadence</span><span class="ss">'s</span> <span class="nc">CTO</span>    <span class="o">|</span><span class="mi">21</span>        <span class="o">|</span><span class="mi">33</span>      <span class="o">|</span><span class="mi">4</span>          <span class="o">|</span><span class="mi">4</span>        <span class="o">|[</span><span class="err">21</span><span class="o">]</span> <span class="o">|[</span><span class="err">29</span><span class="o">]|</span><span class="nc">Cadence</span><span class="ss">'s</span>   <span class="o">|</span><span class="nc">Cadence</span><span class="ss">'s</span> <span class="o">|[</span><span class="kt">Cadence's</span> <span class="kt">CTO</span><span class="o">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="nc">Managing</span> <span class="nc">Director</span><span class="o">|</span><span class="mi">24</span>        <span class="o">|</span><span class="mi">40</span>      <span class="o">|</span><span class="mi">5</span>          <span class="o">|</span><span class="mi">5</span>        <span class="o">|[</span><span class="err">24</span><span class="o">]</span> <span class="o">|[</span><span class="err">31</span><span class="o">]|</span><span class="nc">Managing</span>    <span class="o">|</span><span class="nc">Managing</span>  <span class="o">|[</span><span class="kt">Managing</span> <span class="kt">Director</span><span class="o">]|</span>
<span class="o">+-----------------+----------+--------+-----------+---------+-----+----+------------+----------+-------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionChunkConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkTextCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkBeginCol</span><span class="o">(</span><span class="s">"char_begin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkEndCol</span><span class="o">(</span><span class="s">"char_end"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputTokenBeginCol</span><span class="o">(</span><span class="s">"token_begin"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputTokenEndCol</span><span class="o">(</span><span class="s">"token_end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                              <span class="n">document_assembler</span><span class="o">,</span> 
                                              <span class="n">sentenceDetector</span><span class="o">,</span> 
                                              <span class="n">tokenizer</span><span class="o">,</span> 
                                              <span class="n">converter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="o">(</span><span class="s">"Tom Martin worked as Cadence's CTO until 2010"</span><span class="o">,</span><span class="s">"Cadence's CTO"</span><span class="o">,</span> <span class="mi">21</span><span class="o">,</span><span class="mi">33</span><span class="o">,),</span>
    <span class="o">(</span><span class="s">"Mrs. Charles was before Managing Director at a big consultancy company"</span><span class="o">,</span><span class="s">"Managing Director"</span><span class="o">,</span><span class="mi">24</span><span class="o">,</span><span class="mi">40</span><span class="o">,)</span>
<span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"target"</span><span class="o">,</span> <span class="s">"char_begin"</span><span class="o">,</span> <span class="s">"char_end"</span><span class="o">)</span>
 
<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-------+----------+--------+-----------+---------+--------------------------+------------------------+-------+-----------------------------------------------+</span>
<span class="o">|</span><span class="n">target</span> <span class="o">|</span><span class="n">char_begin</span><span class="o">|</span><span class="n">char_end</span><span class="o">|</span><span class="n">token_begin</span><span class="o">|</span><span class="n">token_end</span><span class="o">|</span><span class="n">tokens</span><span class="o">[</span><span class="kt">token_begin</span><span class="o">].</span><span class="py">result</span><span class="o">|</span><span class="n">tokens</span><span class="o">[</span><span class="kt">token_end</span><span class="o">].</span><span class="py">result</span><span class="o">|</span><span class="n">target</span> <span class="o">|</span><span class="n">chunk</span>                                          <span class="o">|</span>
<span class="o">+-------+----------+--------+-----------+---------+--------------------------+------------------------+-------+-----------------------------------------------+</span>
<span class="o">|</span><span class="n">parties</span><span class="o">|</span><span class="mi">44</span>        <span class="o">|</span><span class="mi">50</span>      <span class="o">|</span><span class="mi">7</span>          <span class="o">|</span><span class="mi">6</span>        <span class="o">|</span><span class="n">parties</span>                   <span class="o">|</span><span class="n">different</span>               <span class="o">|</span><span class="n">parties</span><span class="o">|[{</span><span class="kt">chunk</span>, <span class="err">44</span>, <span class="err">42</span>, <span class="kt">parties</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]|</span>
<span class="o">|</span><span class="nc">Agent</span>  <span class="o">|</span><span class="mi">19</span>        <span class="o">|</span><span class="mi">23</span>      <span class="o">|</span><span class="mi">2</span>          <span class="o">|</span><span class="mi">1</span>        <span class="o">|</span><span class="nc">Agent</span>                     <span class="o">|</span><span class="nc">Administrative</span>          <span class="o">|</span><span class="nc">Agent</span>  <span class="o">|[{</span><span class="kt">chunk</span>, <span class="err">19</span>, <span class="err">17</span>, <span class="kt">Agent</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]</span>  <span class="o">|</span>
<span class="o">+-------+----------+--------+-----------+---------+--------------------------+------------------------+-------+-----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="assertiondl">AssertionDL</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>AssertionDL is a deep Learning based approach used to extract Assertion Status
from extracted entities and text. AssertionDLModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type
annotator inputs, which can be obtained by e.g a
<a href="/docs/en/annotators#documentassembler">DocumentAssembler</a>,
<a href="/docs/en/annotators#nerconverter">NerConverter</a>
and <a href="/docs/en/annotators#wordembeddings">WordEmbeddingsModel</a>.
The result is an assertion status annotation for each recognized entity.
Possible values include <code class="language-plaintext highlighter-rouge">“present”,“absent”,“hypothetical”,“conditional”,“associated_with_other_person”</code> etc.</p>

    <p>Parameters:</p>
    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: Gets current column names of input annotations.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: Gets output column name of annotations.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ScopeWindow</code>: Sets the scope of the window of the assertion expression.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">EntityAssertionCaseSensitive</code>: Sets the case sensitivity of entities and assertion labels.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">DoExceptionHandling</code>: If it is set as True, the annotator tries to process as usual and ff exception-causing data (e.g. corrupted record/ document) is passed to the annotator, an exception warning is emitted which has the exception message.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">datasetInfo</code> <em>(Str)</em>: Descriptive information about the dataset being used.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">blackList</code> <em>(list[str])</em>: If defined, list of entities to ignore. The rest will be processed.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">whiteList</code> <em>(list[str])</em>:  If defined, list of entities to process. The rest will be ignored. Do not include IOB prefix on labels.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">caseSensitive</code> <em>(Bool)</em>: Determines whether the definitions of the white listed and black listed entities are case sensitive. Default: True.</p>
      </li>
    </ul>

    <p>For pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Assertion+Status">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertionDL/index.html#sparknlp_jsl.annotator.assertion.assertionDL.AssertionDLModel">AssertionDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/dl/AssertionDLModel.html">AssertionDLModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/AssertionDLModel.ipynb">AssertionDLModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="c1"># Define pipeline stages to extract NER chunks first
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">nerModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Then a pretrained AssertionDLModel is used to extract the assertion status
</span><span class="n">clinicalAssertion</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"assertion_dl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">nerModel</span><span class="p">,</span>
  <span class="n">nerConverter</span><span class="p">,</span>
  <span class="n">clinicalAssertion</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">[</span><span class="s">"Patient with severe fever and sore throat"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"Patient shows no stomach pain"</span><span class="p">],</span>
  <span class="p">[</span><span class="s">"She was maintained on an epidural and PCA for pain control."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>


<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"ner_chunk.result as chunk_result"</span><span class="p">,</span> <span class="s">"assertion.result as assertion_result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="n">chunk_result</span>                    <span class="o">|</span><span class="n">assertion_result</span>                <span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">severe</span> <span class="n">fever</span><span class="p">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">]</span>              <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">stomach</span> <span class="n">pain</span><span class="p">]</span>                  <span class="o">|</span><span class="p">[</span><span class="n">absent</span><span class="p">]</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">an</span> <span class="n">epidural</span><span class="p">,</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">pain</span> <span class="n">control</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">present</span><span class="p">,</span> <span class="n">present</span><span class="p">,</span> <span class="n">hypothetical</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\

<span class="n">assertion</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finassertion_competitors"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>
    
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span> 
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">assertion</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>


<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">assertion</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sent_id"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-------+------------+---------+----------+</span>
<span class="o">|</span><span class="n">sent_id</span><span class="o">|</span><span class="n">chunk</span>       <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">assertion</span> <span class="o">|</span>
<span class="o">+-------+------------+---------+----------+</span>
<span class="o">|</span><span class="mi">0</span>      <span class="o">|</span><span class="n">McAfee</span> <span class="n">LLC</span>  <span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span><span class="n">COMPETITOR</span><span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>      <span class="o">|</span><span class="n">Broadcom</span> <span class="n">Inc</span><span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span><span class="n">COMPETITOR</span><span class="o">|</span>
<span class="o">+-------+------------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings_ner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings_ner"</span><span class="p">)</span>\

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'legner_contract_doc_parties'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'legal/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings_ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DOC"</span><span class="p">,</span> <span class="s">"EFFDATE"</span><span class="p">,</span> <span class="s">"PARTY"</span><span class="p">])</span>

<span class="n">embeddings_ass</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings_ass"</span><span class="p">)</span>

<span class="n">assertion</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legassertion_time"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings_ass"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
            <span class="n">document_assembler</span><span class="p">,</span> 
            <span class="n">sentence_detector</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">embeddings_ner</span><span class="p">,</span>
            <span class="n">ner_model</span><span class="p">,</span>
            <span class="n">ner_converter</span><span class="p">,</span>
            <span class="n">embeddings_ass</span><span class="p">,</span>
            <span class="n">assertion</span>
            <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>


<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>  
                                     <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">begin</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">end</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">assertion</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"begin"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"end"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['4']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-------------------------------+-----+---+---------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                          <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">assertion</span><span class="o">|</span>
<span class="o">+-------------------------------+-----+---+---------+---------+</span>
<span class="o">|</span><span class="n">Intellectual</span> <span class="n">Property</span> <span class="n">Agreement</span><span class="o">|</span><span class="mi">11</span>   <span class="o">|</span><span class="mi">41</span> <span class="o">|</span><span class="n">DOC</span>      <span class="o">|</span><span class="n">PRESENT</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">Amazon</span> <span class="n">Inc</span>                     <span class="o">|</span><span class="mi">51</span>   <span class="o">|</span><span class="mi">60</span> <span class="o">|</span><span class="n">PARTY</span>    <span class="o">|</span><span class="n">PRESENT</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">Atlantic</span> <span class="n">Inc</span>                   <span class="o">|</span><span class="mi">67</span>   <span class="o">|</span><span class="mi">78</span> <span class="o">|</span><span class="n">PARTY</span>    <span class="o">|</span><span class="n">PRESENT</span>  <span class="o">|</span>
<span class="o">+-------------------------------+-----+---+---------+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="c1">// Define pipeline stages to extract NER chunks first</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="c1">// Then a pretrained AssertionDLModel is used to extract the assertion status</span>
<span class="k">val</span> <span class="nv">clinicalAssertion</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"assertion_dl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">clinicalAssertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Patient with severe fever and sore throat"</span><span class="o">,</span>
  <span class="s">"Patient shows no stomach pain"</span><span class="o">,</span>
  <span class="s">"She was maintained on an epidural and PCA for pain control."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  

<span class="c1">// Show results</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|</span><span class="n">chunk_result</span>                    <span class="o">|</span><span class="n">assertion_result</span>                <span class="o">|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
<span class="o">|[</span><span class="kt">severe</span> <span class="kt">fever</span>, <span class="kt">sore</span> <span class="kt">throat</span><span class="o">]</span>     <span class="o">|[</span><span class="kt">present</span>, <span class="kt">present</span><span class="o">]</span>              <span class="o">|</span>
<span class="o">|[</span><span class="kt">stomach</span> <span class="kt">pain</span><span class="o">]</span>                  <span class="o">|[</span><span class="kt">absent</span><span class="o">]</span>                        <span class="o">|</span>
<span class="o">|[</span><span class="kt">an</span> <span class="kt">epidural</span>, <span class="kt">PCA</span>, <span class="kt">pain</span> <span class="kt">control</span><span class="o">]|[</span><span class="kt">present</span>, <span class="kt">present</span>, <span class="kt">hypothetical</span><span class="o">]|</span>
<span class="o">+--------------------------------+--------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span>  <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finassertion_competitors"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
    
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">assertion</span>
    <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>


<span class="c1">// Show results</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-------+------------+---------+----------+</span>
<span class="o">|</span><span class="n">sent_id</span><span class="o">|</span><span class="n">chunk</span>       <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">assertion</span> <span class="o">|</span>
<span class="o">+-------+------------+---------+----------+</span>
<span class="o">|</span><span class="mi">0</span>      <span class="o">|</span><span class="nc">McAfee</span> <span class="nc">LLC</span>  <span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span><span class="nc">COMPETITOR</span><span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>      <span class="o">|</span><span class="nc">Broadcom</span> <span class="nc">Inc</span><span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span><span class="nc">COMPETITOR</span><span class="o">|</span>
<span class="o">+-------+------------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings_ner</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'legner_contract_doc_partie</span><span class="n">s</span><span class="o">',</span> <span class="ss">'e</span><span class="n">n</span><span class="o">',</span> <span class="ss">'legal</span><span class="o">/</span><span class="n">models</span><span class="o">')</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings_ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"DOC"</span><span class="o">,</span> <span class="s">"EFFDATE"</span><span class="o">,</span> <span class="s">"PARTY"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">embeddings_ass</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings_ass"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legassertion_time"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings_ass"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
    
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings_ner</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">embeddings_ass</span><span class="o">,</span>
    <span class="n">assertion</span>
    <span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>


<span class="c1">// Show results</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-------------------------------+-----+---+---------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                          <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">assertion</span><span class="o">|</span>
<span class="o">+-------------------------------+-----+---+---------+---------+</span>
<span class="o">|</span><span class="nc">Intellectual</span> <span class="nc">Property</span> <span class="nc">Agreement</span><span class="o">|</span><span class="mi">11</span>   <span class="o">|</span><span class="mi">41</span> <span class="o">|</span><span class="nc">DOC</span>      <span class="o">|</span><span class="nc">PRESENT</span>  <span class="o">|</span>
<span class="o">|</span><span class="nc">Amazon</span> <span class="nc">Inc</span>                     <span class="o">|</span><span class="mi">51</span>   <span class="o">|</span><span class="mi">60</span> <span class="o">|</span><span class="nc">PARTY</span>    <span class="o">|</span><span class="nc">PRESENT</span>  <span class="o">|</span>
<span class="o">|</span><span class="nc">Atlantic</span> <span class="nc">Inc</span>                   <span class="o">|</span><span class="mi">67</span>   <span class="o">|</span><span class="mi">78</span> <span class="o">|</span><span class="nc">PARTY</span>    <span class="o">|</span><span class="nc">PRESENT</span>  <span class="o">|</span>
<span class="o">+-------------------------------+-----+---+---------+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Trains AssertionDL, a deep Learning based approach used to extract Assertion Status
from extracted entities and text.
Contains all the methods for training an AssertionDLModel.
For pretrained models please use AssertionDLModel and see the
<a href="https://nlp.johnsnowlabs.com/models?task=Assertion+Status">Models Hub</a> for available models.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: Gets current column names of input annotations.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: Gets output column name of annotations.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ScopeWindow</code>: Sets the scope of the window of the assertion expression.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">StartCol</code>: Set a column that contains the token number for the start of the target.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">datasetInfo</code> <em>(Str)</em>: Descriptive information about the dataset being used.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertionDL/index.html#sparknlp_jsl.annotator.assertion.assertionDL.AssertionDLApproach">AssertionDLApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/dl/AssertionDLApproach.html">AssertionDLApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/AssertionDLApproach.ipynb">AssertionDLApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStartColByTokenIndex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setFailOnMissing</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLowerCase</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Define AssertionDLApproach with parameters and start training
</span><span class="n">assertionStatus</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.012</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.015</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSentLen</span><span class="p">(</span><span class="mi">250</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">assertionStatus</span>
<span class="p">])</span>

<span class="n">assertionResults</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Define AssertionDLApproach with parameters and start training
</span><span class="n">assertionStatus</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionDLApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.012</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.015</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochs</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSentLen</span><span class="p">(</span><span class="mi">250</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">assertionStatus</span>
<span class="p">])</span>

<span class="n">assertionResults</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"doc_chunk"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'token'</span><span class="p">)</span>

<span class="n">roberta_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="c1"># Define AssertionDLApproach with parameters and start training
</span><span class="n">assertionStatus</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionDLApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"assertion_label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"doc_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEpochs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"tkn_start"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"tkn_end"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentLen</span><span class="p">(</span><span class="mi">1200</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEnableOutputLogs</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">'training_logs/'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">graph_folder</span><span class="si">}</span><span class="s">/assertion_graph.pb"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTestDataset</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">"test_data.parquet"</span><span class="p">,</span> <span class="n">read_as</span><span class="o">=</span><span class="s">'SPARK'</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s">'format'</span><span class="p">:</span> <span class="s">'parquet'</span><span class="p">})</span>\
    <span class="p">.</span><span class="n">setScopeWindow</span><span class="p">(</span><span class="n">scope_window</span><span class="p">)</span>
    <span class="c1">#.setValidationSplit(0.2)\    
</span>    <span class="c1">#.setDropout(0.1)\    
</span>
<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">roberta_embeddings</span><span class="p">,</span>
    <span class="n">assertionStatus</span>
<span class="p">])</span>

<span class="n">assertionResults</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Define AssertionDLApproach with parameters and start training</span>
<span class="k">val</span> <span class="nv">assertionStatus</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.012</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.015</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSentLen</span><span class="o">(</span><span class="mi">250</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">assertionStatus</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionResults</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="c1">// First, pipeline stages for pre-processing the dataset (containing columns for text and label) are defined.</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Define AssertionDLApproach with parameters and start training</span>
<span class="k">val</span> <span class="nv">assertionStatus</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionDLApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.012</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.015</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochs</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSentLen</span><span class="o">(</span><span class="mi">250</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">assertionStatus</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionResults</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"doc_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"tkn_start"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setStartColByTokenIndex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setFailOnMissing</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLowerCase</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="ss">'documen</span><span class="n">t</span><span class="o">'))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="ss">'toke</span><span class="n">n</span><span class="o">')</span>

<span class="k">val</span> <span class="nv">roberta_embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMaxSentenceLength</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span>

<span class="k">#</span> <span class="nc">Define</span> <span class="nc">AssertionDLApproach</span> <span class="k">with</span> <span class="n">parameters</span> <span class="n">and</span> <span class="n">start</span> <span class="n">training</span>
<span class="k">val</span> <span class="nv">assertionStatus</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionDLApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"assertion_label"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"doc_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.001</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEpochs</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"tkn_start"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"tkn_end"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxSentLen</span><span class="o">(</span><span class="mi">1200</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEnableOutputLogs</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="ss">'training_logs</span><span class="o">/')</span>
    <span class="o">.</span><span class="py">setGraphFolder</span><span class="o">(</span><span class="n">graph_folder</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setGraphFile</span><span class="o">(</span><span class="n">f</span><span class="s">"{graph_folder}/assertion_graph.pb"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setTestDataset</span><span class="o">(</span><span class="n">path</span><span class="o">=</span><span class="s">"test_data.parquet"</span><span class="o">,</span> <span class="n">read_as</span><span class="o">='</span><span class="nc">SPARK</span><span class="o">',</span> <span class="n">options</span><span class="o">={</span><span class="ss">'forma</span><span class="n">t</span><span class="o">':</span> <span class="ss">'parque</span><span class="n">t</span><span class="o">'})</span>
    <span class="o">.</span><span class="py">setScopeWindow</span><span class="o">(</span><span class="n">scope_window</span><span class="o">)</span>
    <span class="o">#.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document</span><span class="o">,</span>
  <span class="n">chunk</span><span class="o">,</span>
  <span class="n">token</span><span class="o">,</span>
  <span class="n">roberta_embeddings</span><span class="o">,</span>
  <span class="n">assertionStatus</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionResults</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="assertionfilterer">AssertionFilterer</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Filters entities coming from ASSERTION type annotations and returns the CHUNKS.
Filters can be set via a white list on the extracted chunk, the assertion or a regular expression.
White list for assertion is enabled by default. To use chunk white list, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">"isin"</code>.
For regex, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">"regex"</code>.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">whiteList</code>: (list) If defined, list of entities to process. The rest will be ignored.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">CaseSensitive</code>: (bool) Determines whether the definitions of the white listed entities are case sensitive.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">regex</code>: (list) List of dash-separated pairs of named entities.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">criteria</code>: (list)  Set tag representing what is the criteria to filter the chunks. possibles values (assertion,isIn,regex). <em>assertion</em>: Filter by the assertion, <em>isIn</em> : Filter by the chunk, <em>regex</em> : Filter using a regex.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">entitiesConfidence</code>: (Str) Entity pairs to remove based on the confidence level.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, ASSERTION</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/assertion_filterer/index.html#sparknlp_jsl.annotator.chunker.assertion_filterer.AssertionFilterer">AssertionFilterer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/AssertionFilterer.html">AssertionFilterer</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/AssertionFilterer.ipynb">AssertionFiltererNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 

<span class="c1"># Annotator that transforms a text column from dataframe into an Annotation ready for NLP
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="c1"># Sentence Detector annotator, processes various sentences per line
</span><span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Clinical word embeddings trained on PubMED dataset
</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="c1">#.setIncludeAllConfidenceScores(False)
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PROBLEM"</span><span class="p">,</span> <span class="s">"TEST"</span><span class="p">,</span><span class="s">"TREATMENT"</span><span class="p">])</span>

<span class="n">clinical_assertion</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"assertion_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>

<span class="n">assertion_filterer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionFilterer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"assertion"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_filtered"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Present"</span><span class="p">])</span>
<span class="c1">#or .setBlackList([["absent"]])
</span>
<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>
      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">clinical_assertion</span><span class="p">,</span>
      <span class="n">assertion_filterer</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. Alopecia noted. She denies pain."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results:
</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"ner_chunk.result as ner_chunk"</span><span class="p">,</span> <span class="s">"assertion.result as assertion"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>                                       <span class="o">|</span><span class="n">assertion</span>                                         <span class="o">|</span>
<span class="o">+------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">headache</span><span class="p">,</span> <span class="n">a</span> <span class="n">head</span> <span class="n">CT</span><span class="p">,</span> <span class="n">anxious</span><span class="p">,</span> <span class="n">Alopecia</span><span class="p">,</span> <span class="n">pain</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">Present</span><span class="p">,</span> <span class="n">Hypothetical</span><span class="p">,</span> <span class="n">Possible</span><span class="p">,</span> <span class="n">Present</span><span class="p">,</span> <span class="n">Absent</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------+--------------------------------------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"filtered.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+----------------------+</span>
<span class="o">|</span><span class="n">result</span>                <span class="o">|</span>
<span class="o">+----------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">headache</span><span class="p">,</span> <span class="n">Alopecia</span><span class="p">]</span><span class="o">|</span>
<span class="o">+----------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\

<span class="n">assertion</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finassertion_competitors"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>

<span class="n">assertion_filterer</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionFilterer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"assertion"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_filtered"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Competitor"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">assertion</span><span class="p">,</span>
    <span class="n">assertion_filterer</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="c1"># Show results
</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"ner_chunk.result as ner_chunk"</span><span class="p">,</span> <span class="s">"assertion.result as assertion"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------+------------------------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>                 <span class="o">|</span><span class="n">assertion</span>               <span class="o">|</span>
<span class="o">+--------------------------+------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">McAfee</span> <span class="n">LLC</span><span class="p">,</span> <span class="n">Broadcom</span> <span class="n">Inc</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">COMPETITOR</span><span class="p">,</span> <span class="n">COMPETITOR</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------+------------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"assertion_filtered.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------+</span>
<span class="o">|</span><span class="n">result</span>                    <span class="o">|</span>
<span class="o">+--------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">McAfee</span> <span class="n">LLC</span><span class="p">,</span> <span class="n">Broadcom</span> <span class="n">Inc</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings_ner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings_ner"</span><span class="p">)</span>\

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'legner_contract_doc_parties'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'legal/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings_ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DOC"</span><span class="p">,</span> <span class="s">"EFFDATE"</span><span class="p">,</span> <span class="s">"PARTY"</span><span class="p">])</span>

<span class="n">embeddings_ass</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings_ass"</span><span class="p">)</span>

<span class="n">assertion</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legassertion_time"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"embeddings_ass"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>

<span class="n">assertion_filterer</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionFilterer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">,</span><span class="s">"assertion"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_filtered"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Present"</span><span class="p">])</span>


<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
            <span class="n">document_assembler</span><span class="p">,</span>
            <span class="n">sentence_detector</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">embeddings_ner</span><span class="p">,</span>
            <span class="n">ner_model</span><span class="p">,</span>
            <span class="n">ner_converter</span><span class="p">,</span>
            <span class="n">embeddings_ass</span><span class="p">,</span>
            <span class="n">assertion</span><span class="p">,</span>
            <span class="n">assertion_filterer</span>
            <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="c1"># Show results
</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"ner_chunk.result as ner_chunk"</span><span class="p">,</span> <span class="s">"assertion.result as assertion"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------+---------------------------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>                                                  <span class="o">|</span><span class="n">assertion</span>                  <span class="o">|</span>
<span class="o">+-----------------------------------------------------------+---------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Intellectual</span> <span class="n">Property</span> <span class="n">Agreement</span><span class="p">,</span> <span class="n">Amazon</span> <span class="n">Inc</span><span class="p">,</span> <span class="n">Atlantic</span> <span class="n">Inc</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">PRESENT</span><span class="p">,</span> <span class="n">PRESENT</span><span class="p">,</span> <span class="n">PRESENT</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------+---------------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"assertion_filtered.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                     <span class="o">|</span>
<span class="o">+-----------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Intellectual</span> <span class="n">Property</span> <span class="n">Agreement</span><span class="p">,</span> <span class="n">Amazon</span> <span class="n">Inc</span><span class="p">,</span> <span class="n">Atlantic</span> <span class="n">Inc</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Annotator that transforms a text column from dataframe into an Annotation ready for NLP</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="c1">// Sentence Detector annotator, processes various sentences per line</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="c1">// Tokenizer splits words in a relevant format for NLP</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Clinical word embeddings trained on PubMED dataset</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
    <span class="c1">//.setIncludeAllConfidenceScores(false)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"PROBLEM"</span><span class="o">,</span> <span class="s">"TEST"</span><span class="o">,</span><span class="s">"TREATMENT"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">clinical_assertion</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"assertion_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion_filterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionFilterer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"assertion"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_filtered"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"Present"</span><span class="o">))</span>
<span class="c1">//or .setBlackList(Array("absent"))</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">word_embeddings</span><span class="o">,</span>
      <span class="n">clinical_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">clinical_assertion</span><span class="o">,</span>
      <span class="n">assertion_filterer</span>
<span class="o">))</span>


<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. Alopecia noted. She denies pain."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>

<span class="o">+------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>                                       <span class="o">|</span><span class="n">assertion</span>                                         <span class="o">|</span>
<span class="o">+------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">a</span> <span class="kt">headache</span>, <span class="kt">a</span> <span class="kt">head</span> <span class="kt">CT</span>, <span class="kt">anxious</span>, <span class="kt">Alopecia</span>, <span class="kt">pain</span><span class="o">]|[</span><span class="kt">Present</span>, <span class="kt">Hypothetical</span>, <span class="kt">Possible</span>, <span class="kt">Present</span>, <span class="kt">Absent</span><span class="o">]|</span>
<span class="o">+------------------------------------------------+--------------------------------------------------+</span>

<span class="o">+----------------------+</span>
<span class="o">|</span><span class="n">result</span>                <span class="o">|</span>
<span class="o">+----------------------+</span>
<span class="o">|[</span><span class="kt">a</span> <span class="kt">headache</span>, <span class="kt">Alopecia</span><span class="o">]|</span>
<span class="o">+----------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Annotator that transforms a text column from dataframe into an Annotation ready for NLP</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="c1">// Sentence Detector annotator, processes various sentences per line</span>
<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="c1">// Tokenizer splits words in a relevant format for NLP</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Clinical word embeddings trained on PubMED dataset</span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finassertion_competitors"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion_filterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionFilterer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"assertion"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_filtered"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"Competitor"</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
        <span class="n">document_assembler</span><span class="o">,</span>
        <span class="n">sentence_detector</span><span class="o">,</span>
        <span class="n">tokenizer</span><span class="o">,</span>
        <span class="n">embeddings</span><span class="o">,</span>
        <span class="n">ner_model</span><span class="o">,</span>
        <span class="n">ner_converter</span><span class="o">,</span>
        <span class="n">assertion</span><span class="o">,</span>
        <span class="n">assertion_filterer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>
<span class="o">+--------------------------+------------------------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>                 <span class="o">|</span><span class="n">assertion</span>               <span class="o">|</span>
<span class="o">+--------------------------+------------------------+</span>
<span class="o">|[</span><span class="kt">McAfee</span> <span class="kt">LLC</span>, <span class="kt">Broadcom</span> <span class="kt">Inc</span><span class="o">]|[</span><span class="kt">COMPETITOR</span>, <span class="kt">COMPETITOR</span><span class="o">]|</span>
<span class="o">+--------------------------+------------------------+</span>

<span class="o">+--------------------------+</span>
<span class="o">|</span><span class="n">result</span>                    <span class="o">|</span>
<span class="o">+--------------------------+</span>
<span class="o">|[</span><span class="kt">McAfee</span> <span class="kt">LLC</span>, <span class="kt">Broadcom</span> <span class="kt">Inc</span><span class="o">]|</span>
<span class="o">+--------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Annotator that transforms a text column from dataframe into an Annotation ready for NLP</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="c1">// Sentence Detector annotator, processes various sentences per line</span>
<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="c1">// Tokenizer splits words in a relevant format for NLP</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Clinical word embeddings trained on PubMED dataset</span>
<span class="k">val</span> <span class="nv">embeddings_ner</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'legner_contract_doc_partie</span><span class="n">s</span><span class="o">',</span> <span class="ss">'e</span><span class="n">n</span><span class="o">',</span> <span class="ss">'legal</span><span class="o">/</span><span class="n">models</span><span class="o">')</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings_ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
    <span class="c1">//.setIncludeAllConfidenceScores(false)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"DOC"</span><span class="o">,</span> <span class="s">"EFFDATE"</span><span class="o">,</span> <span class="s">"PARTY"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">embeddings_ass</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings_ass"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"assertion_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"embeddings_ass"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion_filterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionFilterer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"assertion"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_filtered"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"Present"</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">document_assembler</span><span class="o">,</span>
      <span class="n">sentence_detector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings_ner</span><span class="o">,</span>
      <span class="n">ner_model</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">embeddings_ass</span><span class="o">,</span>
      <span class="n">assertion</span><span class="o">,</span>
      <span class="n">assertion_filterer</span>
<span class="o">))</span>


<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>
<span class="o">+-----------------------------------------------------------+---------------------------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>                                                  <span class="o">|</span><span class="n">assertion</span>                  <span class="o">|</span>
<span class="o">+-----------------------------------------------------------+---------------------------+</span>
<span class="o">|[</span><span class="kt">Intellectual</span> <span class="kt">Property</span> <span class="kt">Agreement</span>, <span class="kt">Amazon</span> <span class="kt">Inc</span>, <span class="kt">Atlantic</span> <span class="kt">Inc</span><span class="o">]|[</span><span class="kt">PRESENT</span>, <span class="kt">PRESENT</span>, <span class="kt">PRESENT</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------+---------------------------+</span>

<span class="o">+-----------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                     <span class="o">|</span>
<span class="o">+-----------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Intellectual</span> <span class="kt">Property</span> <span class="kt">Agreement</span>, <span class="kt">Amazon</span> <span class="kt">Inc</span>, <span class="kt">Atlantic</span> <span class="kt">Inc</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="assertionlogreg">AssertionLogReg</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This is a main class in AssertionLogReg family. Logarithmic Regression is used to extract Assertion Status from extracted entities and text. AssertionLogRegModel requires DOCUMENT, CHUNK and WORD_EMBEDDINGS type annotator inputs, which can be obtained by e.g a <a href="/docs/en/annotators#documentassembler">DocumentAssembler</a>, <a href="/docs/en/annotators#nerconverter">NerConverter</a> and <a href="/docs/en/annotators#wordembeddings">WordEmbeddingsModel</a>. The result is an assertion status annotation for each recognized entity.
Possible values are <code class="language-plaintext highlighter-rouge">"Negated", "Affirmed" and "Historical"</code>.</p>

    <p>Unlike the DL Model, this class does not extend AnnotatorModel. Instead it extends the RawAnnotator, that’s why the main point of interest is method transform().</p>

    <p>At the moment there are no pretrained models available for this class. Please refer to AssertionLogRegApproach to train your own model.</p>

    <p>Parametres:</p>
    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setAfter(Int)</code>: Length of the context after the target (Default: 13)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setBefore(Int)</code>: Length of the context before the target (Default: 11)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setEndCol(String)</code>: Column that contains the token number for the end of the target</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setStartCol(String)</code>: Column that contains the token number for the start of the target</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertion_dl_reg/index.html#sparknlp_jsl.annotator.assertion.assertion_dl_reg.AssertionLogRegModel">AssertionLogRegModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/logreg/AssertionLogRegModel.html">AssertionLogRegModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/AssertionLogRegModel.ipynb">AssertionLogRegModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Trains a classification method, which uses the Logarithmic Regression Algorithm. It is used to extract Assertion Status
from extracted entities and text.
Contains all the methods for training a AssertionLogRegModel, together with trainWithChunk, trainWithStartEnd.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">label</code> : Column with label per each token</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxIter</code>: This specifies the maximum number of iterations to be performed in the model’s training, default: 26</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">regParam</code> : This specifies the regularization parameter. Regularization helps to control the complexity of the model, aiding in preventing the issue of overfitting.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">eNetParam</code> : Elastic net parameter</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">beforeParam</code> : Length of the context before the target</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">afterParam</code> : Length of the context after the target</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">startCol</code> : Column that contains the token number for the start of the target</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">endCol</code> : Column that contains the token number for the end of the target</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertion_dl_reg/index.html#sparknlp_jsl.annotator.assertion.assertion_dl_reg.AssertionLogRegApproach">AssertionLogRegApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/logreg/AssertionLogRegApproach.html">AssertionLogRegApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/AssertionLogRegApproach.ipynb">AssertionLogRegApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># First define pipeline stages to extract embeddings and text chunks
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">glove</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="c1"># Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.
</span><span class="n">assertion</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionLogRegApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReg</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBefore</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAfter</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerModel</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">assertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># First define pipeline stages to extract embeddings and text chunks
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">glove</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="c1"># Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.
</span><span class="n">assertion</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">AssertionLogRegApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReg</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBefore</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAfter</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerModel</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">assertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># First define pipeline stages to extract embeddings and text chunks
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">glove</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="c1"># Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.
</span><span class="n">assertion</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">AssertionLogRegApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReg</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBefore</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAfter</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setStartCol</span><span class="p">(</span><span class="s">"start"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEndCol</span><span class="p">(</span><span class="s">"end"</span><span class="p">)</span>

<span class="n">assertionPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">nerModel</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">assertion</span>
<span class="p">])</span>

<span class="n">assertionModel</span> <span class="o">=</span> <span class="n">assertionPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// First define pipeline stages to extract embeddings and text chunks</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">glove</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="c1">// Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.</span>
<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionLogRegApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReg</span><span class="o">(</span><span class="mf">0.01</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBefore</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAfter</span><span class="o">(</span><span class="mi">13</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">assertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// First define pipeline stages to extract embeddings and text chunks</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">glove</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="c1">// Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.</span>
<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionLogRegApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReg</span><span class="o">(</span><span class="mf">0.01</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBefore</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAfter</span><span class="o">(</span><span class="mi">13</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">assertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// First define pipeline stages to extract embeddings and text chunks</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">glove</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="c1">// Then the AssertionLogRegApproach model is defined. Label column is needed in the dataset for training.</span>
<span class="k">val</span> <span class="nv">assertion</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionLogRegApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReg</span><span class="o">(</span><span class="mf">0.01</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBefore</span><span class="o">(</span><span class="mi">11</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAfter</span><span class="o">(</span><span class="mi">13</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStartCol</span><span class="o">(</span><span class="s">"start"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEndCol</span><span class="o">(</span><span class="s">"end"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">assertion</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">assertionModel</span> <span class="k">=</span> <span class="nv">assertionPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="assertionmerger">AssertionMerger</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Merges variety assertion columns coming from Assertion annotators like <code class="language-plaintext highlighter-rouge">sparknlp_jsl.annotator.assertion.AssertionDLModel</code>.
AssertionMerger can filter, prioritize and merge assertion annotations by using proper parameters.
See Also: <code class="language-plaintext highlighter-rouge">sparknlp_jsl.annotator.WhiteBlackListParams</code> for filtering options.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">mergeOverlapping</code> <em>(Bool)</em>: Whether to merge overlapping matched assertions.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">applyFilterBeforeMerge</code> <em>(Bool)</em>: Whether to apply filtering before merging.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">assertionsConfidence</code> <em>(dict[str, float])</em>: Pairs (assertion,confidenceThreshold) to filter assertions which have confidence lower than the confidence threshold.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">orderingFeatures</code> <em>(list[str])</em>: Specifies the ordering features to use for overlapping entities.
Possible values include: ‘begin’, ‘end’, ‘length’, ‘source’, ‘confidence’.
Default: [‘begin’, ‘length’, ‘source’]</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">selectionStrategy</code> <em>(str)</em>: Determines the strategy for selecting annotations.
Annotations can be selected either sequentially based on their order (Sequential) or using a more diverse strategy (DiverseLonger).
Currently, only Sequential and DiverseLonger options are available. Default: Sequential.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">defaultConfidence</code> <em>(float)</em>: When the confidence value is included in the orderingFeatures and a given annotation does not have any confidence,
this parameter determines the value to be used. The default value is 0.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">assertionSourcePrecedence</code> <em>(str)</em>: Specifies the assertion sources to use for prioritizing overlapping annotations when the ‘source’ ordering feature is utilized.
This parameter contains a comma-separated list of assertion sources that drive the prioritization.
Annotations will be prioritized based on the order of the given string.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">sortByBegin</code> <em>(Bool)</em>: Whether to sort the annotations by begin at the end of the merge and filter process. Default: False.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">blackList</code> <em>(list[str])</em>: If defined, list of entities to ignore. The rest will be processed.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">whiteList</code> <em>(list[str])</em>:  If defined, list of entities to process. The rest will be ignored. Do not include IOB prefix on labels.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">caseSensitive</code> <em>(Bool)</em>: Determines whether the definitions of the white listed and black listed entities are case sensitive. Default: True.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">majorityVoting</code> <em>(Bool)</em>: Whether to use majority voting to resolve conflicts. Default: False.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/assertion_merger/index.html">AssertionMerger</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/merger/AssertionMerger.html">AssertionMerger</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_jsl</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">)</span>\
    <span class="c1">#.setIncludeAllConfidenceScores(False)
</span>
<span class="n">ner_jsl_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_jsl"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_jsl_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"SYMPTOM"</span><span class="p">,</span><span class="s">"VS_FINDING"</span><span class="p">,</span><span class="s">"DISEASE_SYNDROME_DISORDER"</span><span class="p">,</span><span class="s">"ADMISSION_DISCHARGE"</span><span class="p">,</span><span class="s">"PROCEDURE"</span><span class="p">])</span>

<span class="n">assertion_jsl</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"assertion_jsl_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_jsl_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_jsl"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEntityAssertionCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">ner_clinical</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">)</span>\
    <span class="c1">#.setIncludeAllConfidenceScores(False)
</span>
<span class="n">ner_clinical_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_clinical"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_clinical_chunk"</span><span class="p">)</span>\

<span class="n">assertion_dl</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"assertion_dl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_clinical_chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_dl"</span><span class="p">)</span>

<span class="n">assertion_merger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AssertionMerger</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"assertion_jsl"</span><span class="p">,</span> <span class="s">"assertion_dl"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_merger"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMergeOverlapping</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setSelectionStrategy</span><span class="p">(</span><span class="s">"sequential"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAssertionSourcePrecedence</span><span class="p">(</span><span class="s">"assertion_dl, assertion_jsl"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAssertionsConfidence</span><span class="p">({</span><span class="s">"past"</span><span class="p">:</span> <span class="mf">0.70</span><span class="p">})</span> \
    <span class="p">.</span><span class="n">setOrderingFeatures</span><span class="p">([</span><span class="s">"length"</span><span class="p">,</span> <span class="s">"source"</span><span class="p">,</span> <span class="s">"confidence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setDefaultConfidence</span><span class="p">(</span><span class="mf">0.50</span><span class="p">)</span>\
    <span class="c1">#.setBlackList(["HYPothetical"])
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span> <span class="n">stages</span> <span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span>
                              <span class="n">sentence_detector</span><span class="p">,</span>
                              <span class="n">tokenizer</span><span class="p">,</span>
                              <span class="n">word_embeddings</span><span class="p">,</span>
                              <span class="n">ner_jsl</span><span class="p">,</span>
                              <span class="n">ner_jsl_converter</span><span class="p">,</span>
                              <span class="n">assertion_jsl</span><span class="p">,</span>
                              <span class="n">ner_clinical</span><span class="p">,</span>
                              <span class="n">ner_clinical_converter</span><span class="p">,</span>
                              <span class="n">assertion_dl</span><span class="p">,</span>
                              <span class="n">assertion_merger</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
                        <span class="s">"""Patient had a headache for the last 2 weeks, and appears anxious when she walks fast. No alopecia noted. She denies pain. Her father is paralyzed and it is a stressor for her. She got antidepressant. We prescribed sleeping pills for her current insomnia."""</span><span class="p">],</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>


<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">coalesce</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">withColumn</span><span class="p">(</span><span class="s">"idx"</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="n">monotonically_increasing_id</span><span class="p">())</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+---+--------------+-----+---+---------+---------+----------------+----------+</span>
<span class="o">|</span><span class="n">idx</span><span class="o">|</span><span class="n">ner_chunk</span>     <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">assertion</span><span class="o">|</span><span class="n">assertion_source</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+---+--------------+-----+---+---------+---------+----------------+----------+</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">headache</span>      <span class="o">|</span><span class="mi">14</span>   <span class="o">|</span><span class="mi">21</span> <span class="o">|</span><span class="n">Symptom</span>  <span class="o">|</span><span class="n">Past</span>     <span class="o">|</span><span class="n">assertion_jsl</span>   <span class="o">|</span><span class="mf">0.9999</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">anxious</span>       <span class="o">|</span><span class="mi">57</span>   <span class="o">|</span><span class="mi">63</span> <span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">present</span>  <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.9392</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">alopecia</span>      <span class="o">|</span><span class="mi">89</span>   <span class="o">|</span><span class="mi">96</span> <span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span>   <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.9992</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">pain</span>          <span class="o">|</span><span class="mi">116</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span>   <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.9884</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">paralyzed</span>     <span class="o">|</span><span class="mi">136</span>  <span class="o">|</span><span class="mi">144</span><span class="o">|</span><span class="n">Symptom</span>  <span class="o">|</span><span class="n">Family</span>   <span class="o">|</span><span class="n">assertion_jsl</span>   <span class="o">|</span><span class="mf">0.9995</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">stressor</span>      <span class="o">|</span><span class="mi">158</span>  <span class="o">|</span><span class="mi">165</span><span class="o">|</span><span class="n">Symptom</span>  <span class="o">|</span><span class="n">Family</span>   <span class="o">|</span><span class="n">assertion_jsl</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">antidepressant</span><span class="o">|</span><span class="mi">184</span>  <span class="o">|</span><span class="mi">197</span><span class="o">|</span><span class="n">TREATMENT</span><span class="o">|</span><span class="n">present</span>  <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.9628</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">sleeping</span> <span class="n">pills</span><span class="o">|</span><span class="mi">214</span>  <span class="o">|</span><span class="mi">227</span><span class="o">|</span><span class="n">TREATMENT</span><span class="o">|</span><span class="n">present</span>  <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.998</span>     <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">insomnia</span>      <span class="o">|</span><span class="mi">245</span>  <span class="o">|</span><span class="mi">252</span><span class="o">|</span><span class="n">Symptom</span>  <span class="o">|</span><span class="n">Past</span>     <span class="o">|</span><span class="n">assertion_jsl</span>   <span class="o">|</span><span class="mf">0.9862</span>    <span class="o">|</span>
<span class="o">+---+--------------+-----+---+---------+---------+----------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_jsl</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">)</span>
    <span class="c1">//.setIncludeAllConfidenceScores(false)</span>

<span class="k">val</span> <span class="nv">ner_jsl_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_jsl"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_jsl_chunk"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"SYMPTOM"</span><span class="o">,</span> <span class="s">"VS_FINDING"</span><span class="o">,</span> <span class="s">"DISEASE_SYNDROME_DISORDER"</span><span class="o">,</span> <span class="s">"ADMISSION_DISCHARGE"</span><span class="o">,</span> <span class="s">"PROCEDURE"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">assertion_jsl</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"assertion_jsl_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_jsl_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_jsl"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setEntityAssertionCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_clinical</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">)</span>
    <span class="c1">//.setIncludeAllConfidenceScores(false)</span>

<span class="k">val</span> <span class="nv">ner_clinical_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_clinical"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_clinical_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion_dl</span> <span class="k">=</span> <span class="nv">AssertionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"assertion_dl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_clinical_chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_dl"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertion_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AssertionMerger</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"assertion_jsl"</span><span class="o">,</span> <span class="s">"assertion_dl"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_merger"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setMergeOverlapping</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setSelectionStrategy</span><span class="o">(</span><span class="s">"sequential"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setAssertionSourcePrecedence</span><span class="o">(</span><span class="s">"assertion_dl, assertion_jsl"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setAssertionsConfidence</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"past"</span><span class="o">-&gt;</span> <span class="mf">0.70f</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOrderingFeatures</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"length"</span><span class="o">,</span> <span class="s">"source"</span><span class="o">,</span> <span class="s">"confidence"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setDefaultConfidence</span><span class="o">(</span><span class="mf">0.50f</span><span class="o">)</span>
     <span class="c1">// .setBlackList(("HYPothetical"))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document_assembler</span><span class="o">,</span>
          <span class="n">sentence_detector</span><span class="o">,</span>
          <span class="n">tokenizer</span><span class="o">,</span>
          <span class="n">word_embeddings</span><span class="o">,</span>
          <span class="n">ner_jsl</span><span class="o">,</span>
          <span class="n">ner_jsl_converter</span><span class="o">,</span>
          <span class="n">assertion_jsl</span><span class="o">,</span>
          <span class="n">ner_clinical</span><span class="o">,</span>
          <span class="n">ner_clinical_converter</span><span class="o">,</span>
          <span class="n">assertion_dl</span><span class="o">,</span>
          <span class="n">assertion_merger</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"Patient had a headache for the last 2 weeks, and appears anxious when she walks fast. No alopecia noted. She denies pain. Her father is paralyzed and it is a stressor for her. She got antidepressant. We prescribed sleeping pills for her current insomnia."</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="c1">//val data = data.coalesce(1).withColumn("idx", F.monotonically_increasing_id())</span>

<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Result</span>

<span class="o">+---+--------------+-----+---+---------+---------+----------------+----------+</span>
<span class="o">|</span><span class="n">idx</span><span class="o">|</span><span class="n">ner_chunk</span>     <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">assertion</span><span class="o">|</span><span class="n">assertion_source</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+---+--------------+-----+---+---------+---------+----------------+----------+</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">headache</span>      <span class="o">|</span><span class="mi">14</span>   <span class="o">|</span><span class="mi">21</span> <span class="o">|</span><span class="nc">Symptom</span>  <span class="o">|</span><span class="nc">Past</span>     <span class="o">|</span><span class="n">assertion_jsl</span>   <span class="o">|</span><span class="mf">0.9999</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">anxious</span>       <span class="o">|</span><span class="mi">57</span>   <span class="o">|</span><span class="mi">63</span> <span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">present</span>  <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.9392</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">alopecia</span>      <span class="o">|</span><span class="mi">89</span>   <span class="o">|</span><span class="mi">96</span> <span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span>   <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.9992</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">pain</span>          <span class="o">|</span><span class="mi">116</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span>   <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.9884</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">paralyzed</span>     <span class="o">|</span><span class="mi">136</span>  <span class="o">|</span><span class="mi">144</span><span class="o">|</span><span class="nc">Symptom</span>  <span class="o">|</span><span class="nc">Family</span>   <span class="o">|</span><span class="n">assertion_jsl</span>   <span class="o">|</span><span class="mf">0.9995</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">stressor</span>      <span class="o">|</span><span class="mi">158</span>  <span class="o">|</span><span class="mi">165</span><span class="o">|</span><span class="nc">Symptom</span>  <span class="o">|</span><span class="nc">Family</span>   <span class="o">|</span><span class="n">assertion_jsl</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">antidepressant</span><span class="o">|</span><span class="mi">184</span>  <span class="o">|</span><span class="mi">197</span><span class="o">|</span><span class="nc">TREATMENT</span><span class="o">|</span><span class="n">present</span>  <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.9628</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">sleeping</span> <span class="n">pills</span><span class="o">|</span><span class="mi">214</span>  <span class="o">|</span><span class="mi">227</span><span class="o">|</span><span class="nc">TREATMENT</span><span class="o">|</span><span class="n">present</span>  <span class="o">|</span><span class="n">assertion_dl</span>    <span class="o">|</span><span class="mf">0.998</span>     <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>  <span class="o">|</span><span class="n">insomnia</span>      <span class="o">|</span><span class="mi">245</span>  <span class="o">|</span><span class="mi">252</span><span class="o">|</span><span class="nc">Symptom</span>  <span class="o">|</span><span class="nc">Past</span>     <span class="o">|</span><span class="n">assertion_jsl</span>   <span class="o">|</span><span class="mf">0.9862</span>    <span class="o">|</span>
<span class="o">+---+--------------+-----+---+---------+---------+----------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="averageembeddings">AverageEmbeddings</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">AverageEmbeddings</code> computes the mean of vector embeddings for two sentences of equal size, producing a unified representation.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS, SENTENCE_EMBEDDINGS, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">EMBEDDINGS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/embeddings/average_embeddings/index.html#sparknlp_jsl.annotator.embeddings.average_embeddings.AverageEmbeddings">AverageEmbeddings</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/embeddings/AverageEmbeddings.html">AverageEmbeddings</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/AverageEmbeddings.ipynb">AverageEmbeddingsNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">doc2Chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setIsArray</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">sbiobert_base_cased_mli</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">)</span>

<span class="n">sent_biobert_clinical_base_cased</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_biobert_clinical_base_cased"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sent_biobert_clinical_base_cased"</span><span class="p">)</span>

<span class="n">avg_embeddings</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AverageEmbeddings</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sent_biobert_clinical_base_cased"</span><span class="p">,</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">"chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">doc2Chunk</span><span class="p">,</span>
        <span class="n">sbiobert_base_cased_mli</span><span class="p">,</span>
        <span class="n">sent_biobert_clinical_base_cased</span><span class="p">,</span>
        <span class="n">avg_embeddings</span>
    <span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">" The patient was prescribed 1 capsule of Advil for 5 days "</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result_df</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                                 <span class="n">result</span><span class="p">.</span><span class="n">chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span>
                                                 <span class="n">result</span><span class="p">.</span><span class="n">sentence</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                                 <span class="n">result</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">embeddings</span><span class="p">,</span>
                                                 <span class="n">result</span><span class="p">.</span><span class="n">sent_biobert_clinical_base_cased</span><span class="p">.</span><span class="n">embeddings</span><span class="p">,</span>
                                                 <span class="n">result</span><span class="p">.</span><span class="n">sbiobert_base_cased_mli</span><span class="p">.</span><span class="n">embeddings</span><span class="p">,)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
                  <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence_metadata"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['4']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sent_biobert_clinical_base_cased"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['5']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">))</span>

<span class="n">result_df</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+--------------------------------------------------+---------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span>                                          <span class="n">sentence</span><span class="o">|</span>          <span class="n">sentence_metadata</span><span class="o">|</span>                                             <span class="n">chunk</span><span class="o">|</span>                                        <span class="n">embeddings</span><span class="o">|</span>                  <span class="n">sent_biobert_clinical_base_cased</span><span class="o">|</span>                           <span class="n">sbiobert_base_cased_mli</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">prescribed</span> <span class="mi">1</span> <span class="n">capsule</span> <span class="n">of</span> <span class="n">Advil</span> <span class="n">f</span><span class="p">...</span><span class="o">|</span><span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">}</span><span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">prescribed</span> <span class="mi">1</span> <span class="n">capsule</span> <span class="n">of</span> <span class="n">Advil</span> <span class="n">f</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="mf">0.32466835</span><span class="p">,</span> <span class="mf">0.12497781</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.20237188</span><span class="p">,</span> <span class="mf">0.3716198</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.07857181</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.061015874</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.020198729</span><span class="p">,</span> <span class="mf">0.177</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="mf">0.7279085</span><span class="p">,</span> <span class="mf">0.3109715</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.38454503</span><span class="p">,</span> <span class="mf">0.5657965</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">doc2Chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setIsArray</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sbiobert_base_cased_mli</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sent_biobert_clinical_base_cased</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_biobert_clinical_base_cased"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sent_biobert_clinical_base_cased"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">avg_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AverageEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sent_biobert_clinical_base_cased"</span><span class="o">,</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span> 
    <span class="n">doc2Chunk</span><span class="o">,</span> 
    <span class="n">sbiobert_base_cased_mli</span><span class="o">,</span> 
    <span class="n">sent_biobert_clinical_base_cased</span><span class="o">,</span> 
    <span class="n">avg_embeddings</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">" The patient was prescribed 1 capsule of Advil for 5 days"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>
<span class="o">+--------------------------------------------------+---------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span>                                          <span class="n">sentence</span><span class="o">|</span>          <span class="n">sentence_metadata</span><span class="o">|</span>                                             <span class="n">chunk</span><span class="o">|</span>                                        <span class="n">embeddings</span><span class="o">|</span>                  <span class="n">sent_biobert_clinical_base_cased</span><span class="o">|</span>                           <span class="n">sbiobert_base_cased_mli</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">prescribed</span> <span class="mi">1</span> <span class="n">capsule</span> <span class="n">of</span> <span class="nc">Advil</span> <span class="n">f</span><span class="o">...|{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">}|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">prescribed</span> <span class="mi">1</span> <span class="n">capsule</span> <span class="n">of</span> <span class="nc">Advil</span> <span class="n">f</span><span class="o">...|[</span><span class="err">0</span><span class="kt">.</span><span class="err">32466835</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12497781</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">20237188</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3716198</span><span class="kt">...|</span><span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07857181</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">061015874</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">020198729</span>, <span class="err">0</span><span class="kt">.</span><span class="err">177</span><span class="kt">...|</span><span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">7279085</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3109715</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">38454503</span>, <span class="err">0</span><span class="kt">.</span><span class="err">5657965</span>, <span class="kt">...|</span>
<span class="kt">+--------------------------------------------------+---------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="bertforsequenceclassification">BertForSequenceClassification</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">BertForSequenceClassification</code>  can load Bert Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">batchSize</code>’:  Size of every batch (default: 8).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">coalesceSentences</code>’: Instead of 1 class per sentence (if inputCols is “sentence” output 1 class per document by averaging probabilities in all sentences (default: False).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxSentenceLength</code>’: Max sentence length to process (default: 128).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">caseSensitive</code>’: Whether to ignore case in tokens for embeddings matching (default: True)</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/medical_bert_for_sequence_classification/index.html#">BertForSequenceClassification</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/MedicalBertForSequenceClassification.html">BertForSequenceClassification</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
 
<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">BertForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_sequence_classifier_ade"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"classes"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>


<span class="n">text</span> <span class="o">=</span><span class="p">[[</span><span class="s">"Right inguinal hernia repair in childhood Cervical discectomy 3 years ago Umbilical hernia repair 2137. Retired schoolteacher, now substitutes. Lives with wife in location 1439. Has a 27 yo son and a 25 yo daughter. Name (NI) past or present smoking hx, no EtOH."</span><span class="p">],</span>
     <span class="p">[</span><span class="s">"Atrial Septal Defect with Right Atrial Thrombus Pulmonary Hypertension Obesity, Obstructive Sleep Apnea. Denies tobacco and ETOH. Works as cafeteria worker."</span><span class="p">]]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">text</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"classes.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="o">|</span> <span class="n">text</span>                                                                                           <span class="o">|</span> <span class="n">result</span> <span class="o">|</span>
<span class="o">|------------------------------------------------------------------------------------------------|-------|</span>
<span class="o">|</span> <span class="n">Right</span> <span class="n">inguinal</span> <span class="n">hernia</span> <span class="n">repair</span> <span class="ow">in</span> <span class="n">childhood</span> <span class="n">Cervical</span> <span class="n">discectomy</span> <span class="mi">3</span> <span class="n">years</span> <span class="n">ago</span> <span class="n">Umbilical</span> <span class="n">hernia</span> <span class="n">repair</span><span class="p">...</span> <span class="o">|</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">Atrial</span> <span class="n">Septal</span> <span class="n">Defect</span> <span class="k">with</span> <span class="n">Right</span> <span class="n">Atrial</span> <span class="n">Thrombus</span> <span class="n">Pulmonary</span> <span class="n">Hypertension</span> <span class="n">Obesity</span><span class="p">,</span> <span class="n">Obstructive</span> <span class="n">Sleep</span><span class="p">...</span> <span class="o">|</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span> <span class="o">|</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">MedicalBertForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_sequence_classifier_ade"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"classes"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">sequenceClassifier</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="nc">List</span><span class="o">(</span>
  <span class="nc">List</span><span class="o">(</span><span class="s">"Right inguinal hernia repair in childhood Cervical discectomy 3 years ago Umbilical hernia repair 2137. Retired schoolteacher, now substitutes. Lives with wife in location 1439. Has a 27 yo son and a 25 yo daughter. Name (NI) past or present smoking hx, no EtOH."</span><span class="o">),</span>
  <span class="nc">List</span><span class="o">(</span><span class="s">"Atrial Septal Defect with Right Atrial Thrombus Pulmonary Hypertension Obesity, Obstructive Sleep Apnea. Denies tobacco and ETOH. Works as cafeteria worker."</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">|</span> <span class="n">text</span>                                                                                           <span class="o">|</span> <span class="n">result</span> <span class="o">|</span>
<span class="o">|------------------------------------------------------------------------------------------------|-------|</span>
<span class="o">|</span> <span class="nc">Right</span> <span class="n">inguinal</span> <span class="n">hernia</span> <span class="n">repair</span> <span class="n">in</span> <span class="n">childhood</span> <span class="nc">Cervical</span> <span class="n">discectomy</span> <span class="mi">3</span> <span class="n">years</span> <span class="n">ago</span> <span class="nc">Umbilical</span> <span class="n">hernia</span> <span class="n">repair</span><span class="o">...</span> <span class="o">|</span> <span class="o">[</span><span class="kt">False</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|</span> <span class="nc">Atrial</span> <span class="nc">Septal</span> <span class="nc">Defect</span> <span class="k">with</span> <span class="nc">Right</span> <span class="nc">Atrial</span> <span class="nc">Thrombus</span> <span class="nc">Pulmonary</span> <span class="nc">Hypertension</span> <span class="nc">Obesity</span><span class="o">,</span> <span class="nc">Obstructive</span> <span class="nc">Sleep</span><span class="o">...</span> <span class="o">|</span> <span class="o">[</span><span class="kt">False</span><span class="o">]</span> <span class="o">|</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="bertfortokenclassifier">BertForTokenClassifier</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">BertForTokenClassifier</code> can load Bert Models with a token classification head on top (a linear layer on top of the hidden-states output) for Named-Entity-Recognition (NER) tasks.\</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">CaseSensitive</code> <em>(Boolean)</em>: Whether to lowercase tokens or not (Default: False).</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/medical_bert_for_token_classifier/index.html">BertForTokenClassifier</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/MedicalBertForTokenClassifier.html">BertForTokenClassifier</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
 
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">BertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_token_classifier_ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">tokenClassifier</span><span class="p">,</span>
    <span class="n">ner_converter</span>
    <span class="p">])</span>


<span class="n">text</span> <span class="o">=</span> <span class="s">"""A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .
Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection .
She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation .
Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity .
Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 .
Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia .
The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission .
However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L .
The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again .
The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours .
Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use .
The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day .
It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge ."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">res</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">begin</span><span class="p">,</span> <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">end</span><span class="p">,</span> <span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
   <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence_id"</span><span class="p">),</span>
           <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
           <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"end"</span><span class="p">),</span>
           <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">))</span>\
   <span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="s">"ner_label!='O'"</span><span class="p">)</span>\
   <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">## Result
</span><span class="o">+-----------+-----------------------------+---+---------+</span>
<span class="o">|</span><span class="n">sentence_id</span><span class="o">|</span><span class="n">chunk</span>                        <span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-----------+-----------------------------+---+---------+</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">gestational</span> <span class="n">diabetes</span> <span class="n">mellitus</span><span class="o">|</span><span class="mi">67</span> <span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="nb">type</span> <span class="n">two</span> <span class="n">diabetes</span> <span class="n">mellitus</span>   <span class="o">|</span><span class="mi">153</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">T2DM</span>                         <span class="o">|</span><span class="mi">160</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">HTG</span><span class="o">-</span><span class="n">induced</span> <span class="n">pancreatitis</span>     <span class="o">|</span><span class="mi">209</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">an</span> <span class="n">acute</span> <span class="n">hepatitis</span>           <span class="o">|</span><span class="mi">280</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">obesity</span>                      <span class="o">|</span><span class="mi">294</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">a</span> <span class="n">body</span> <span class="n">mass</span> <span class="n">index</span>            <span class="o">|</span><span class="mi">317</span><span class="o">|</span><span class="n">TEST</span>     <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">BMI</span>                          <span class="o">|</span><span class="mi">323</span><span class="o">|</span><span class="n">TEST</span>     <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">polyuria</span>                     <span class="o">|</span><span class="mi">387</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">polydipsia</span>                   <span class="o">|</span><span class="mi">400</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">poor</span> <span class="n">appetite</span>                <span class="o">|</span><span class="mi">416</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">vomiting</span>                     <span class="o">|</span><span class="mi">431</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">1</span>          <span class="o">|</span><span class="n">amoxicillin</span>                  <span class="o">|</span><span class="mi">521</span><span class="o">|</span><span class="n">TREATMENT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">1</span>          <span class="o">|</span><span class="n">a</span> <span class="n">respiratory</span> <span class="n">tract</span> <span class="n">infection</span><span class="o">|</span><span class="mi">555</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">2</span>          <span class="o">|</span><span class="n">metformin</span>                    <span class="o">|</span><span class="mi">578</span><span class="o">|</span><span class="n">TREATMENT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">2</span>          <span class="o">|</span><span class="n">glipizide</span>                    <span class="o">|</span><span class="mi">590</span><span class="o">|</span><span class="n">TREATMENT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">2</span>          <span class="o">|</span><span class="n">dapagliflozin</span>                <span class="o">|</span><span class="mi">610</span><span class="o">|</span><span class="n">TREATMENT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">2</span>          <span class="o">|</span><span class="n">T2DM</span>                         <span class="o">|</span><span class="mi">619</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">2</span>          <span class="o">|</span><span class="n">atorvastatin</span>                 <span class="o">|</span><span class="mi">636</span><span class="o">|</span><span class="n">TREATMENT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">2</span>          <span class="o">|</span><span class="n">gemfibrozil</span>                  <span class="o">|</span><span class="mi">652</span><span class="o">|</span><span class="n">TREATMENT</span><span class="o">|</span>
<span class="o">+-----------+-----------------------------+---+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">MedicalBertForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_token_classifier_ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">True</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">tokenClassifier</span><span class="o">,</span> 
    <span class="n">ner_converter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting .
Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection .
She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation .
Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity .
Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 .
Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia .
The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission .
However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L .
The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again .
The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours .
Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use .
The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day .
It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge ."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Result</span>

<span class="o">+-----------+-----------------------------+---+---------+</span>
<span class="o">|</span><span class="n">sentence_id</span><span class="o">|</span><span class="n">chunk</span>                        <span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-----------+-----------------------------+---+---------+</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="n">gestational</span> <span class="n">diabetes</span> <span class="n">mellitus</span><span class="o">|</span><span class="mi">67</span> <span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">0</span>          <span class="o">|</span><span class="k">type</span> <span class="kt">two</span> <span class="kt">diabetes</span> <span class="kt">mellitus</span>   <span class="kt">|</span><span class="err">153</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|T2DM</span>                         <span class="kt">|</span><span class="err">160</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|HTG-induced</span> <span class="kt">pancreatitis</span>     <span class="kt">|</span><span class="err">209</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|an</span> <span class="kt">acute</span> <span class="kt">hepatitis</span>           <span class="kt">|</span><span class="err">280</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|obesity</span>                      <span class="kt">|</span><span class="err">294</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|a</span> <span class="kt">body</span> <span class="kt">mass</span> <span class="kt">index</span>            <span class="kt">|</span><span class="err">317</span><span class="kt">|TEST</span>     <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|BMI</span>                          <span class="kt">|</span><span class="err">323</span><span class="kt">|TEST</span>     <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|polyuria</span>                     <span class="kt">|</span><span class="err">387</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|polydipsia</span>                   <span class="kt">|</span><span class="err">400</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|poor</span> <span class="kt">appetite</span>                <span class="kt">|</span><span class="err">416</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span>          <span class="kt">|vomiting</span>                     <span class="kt">|</span><span class="err">431</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">1</span>          <span class="kt">|amoxicillin</span>                  <span class="kt">|</span><span class="err">521</span><span class="kt">|TREATMENT|</span>
<span class="kt">|</span><span class="err">1</span>          <span class="kt">|a</span> <span class="kt">respiratory</span> <span class="kt">tract</span> <span class="kt">infection|</span><span class="err">555</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">2</span>          <span class="kt">|metformin</span>                    <span class="kt">|</span><span class="err">578</span><span class="kt">|TREATMENT|</span>
<span class="kt">|</span><span class="err">2</span>          <span class="kt">|glipizide</span>                    <span class="kt">|</span><span class="err">590</span><span class="kt">|TREATMENT|</span>
<span class="kt">|</span><span class="err">2</span>          <span class="kt">|dapagliflozin</span>                <span class="kt">|</span><span class="err">610</span><span class="kt">|TREATMENT|</span>
<span class="kt">|</span><span class="err">2</span>          <span class="kt">|T2DM</span>                         <span class="kt">|</span><span class="err">619</span><span class="kt">|PROBLEM</span>  <span class="kt">|</span>
<span class="kt">|</span><span class="err">2</span>          <span class="kt">|atorvastatin</span>                 <span class="kt">|</span><span class="err">636</span><span class="kt">|TREATMENT|</span>
<span class="kt">|</span><span class="err">2</span>          <span class="kt">|gemfibrozil</span>                  <span class="kt">|</span><span class="err">652</span><span class="kt">|TREATMENT|</span>
<span class="kt">+-----------+-----------------------------+---+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="bertsentencechunkembeddings">BertSentenceChunkEmbeddings</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator allows aggregating sentence embeddings with ner chunk embeddings to get specific and more accurate resolution codes. It works by averaging sentence and chunk embeddings add contextual information in the embedding value. Input to this annotator is the context (sentence) and ner chunks, while the output is embedding for each chunk that can be fed to the resolver model.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">chunkWeight</code>: Relative weight of chunk embeddings in comparison to sentence embeddings. The value should between 0 and 1. The default is 0.5, which means the chunk and sentence embeddings are given equal weight.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setMaxSentenceLength</code>: Sets max sentence length to process, by default 128.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">caseSensitive</code>: Determines whether the definitions of the white listed entities are case sensitive.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">strategy</code>: Strategy for computing embeddings. Supported strategies are: <code class="language-plaintext highlighter-rouge">sentence_average</code>, <code class="language-plaintext highlighter-rouge">scope_average</code>, <code class="language-plaintext highlighter-rouge">chunk_only</code>, <code class="language-plaintext highlighter-rouge">scope_only</code>. The default is <code class="language-plaintext highlighter-rouge">sentence_average</code>.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">scopeWindow</code>: cope window to calculate scope embeddings. The scope window is defined by two non-negative integers. The default is [0, 0], which means only the chunk embeddings are used. The first integer defines the number of tokens before the chunk and the second integer defines the number of tokens after the chunk.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputCols()</code>.</p>

    <blockquote>
      <p>For more information and examples of <code class="language-plaintext highlighter-rouge">BertSentenceChunkEmbeddings</code> annotator, you can check the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop">Spark NLP Workshop</a>, and in special, the notebook <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb">24.1.Improved_Entity_Resolution_with_SentenceChunkEmbeddings.ipynb</a>.</p>
    </blockquote>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/embeddings/bert_sentence_embeddings/index.html#sparknlp_jsl.annotator.embeddings.bert_sentence_embeddings.BertSentenceChunkEmbeddings">BertSentenceChunkEmbeddings</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/embeddings/BertSentenceChunkEmbeddings.html">BertSentenceChunkEmbeddings</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/BertSentenceChunkEmbeddings.ipynb">BertSentenceChunkEmbeddingsNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="c1"># Define the pipeline
</span>
<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_abbreviation_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">'ABBR'</span><span class="p">])</span>

<span class="n">sentence_chunk_embeddings</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">BertSentenceChunkEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setChunkWeight</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    
<span class="n">resolver_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
      <span class="n">document_assembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>
      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">sentence_chunk_embeddings</span>
<span class="p">])</span>


<span class="n">sample_text</span> <span class="o">=</span> <span class="p">[</span>
<span class="s">"""The patient admitted from the IR for aggressive irrigation of the Miami pouch. DISCHARGE DIAGNOSES: 1. A 58-year-old female with a history of stage 2 squamous cell carcinoma of the cervix status post total pelvic exenteration in 1991."""</span><span class="p">,</span>
<span class="s">"""Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA: Laboratory tests include a CBC which is normal. 
Blood Type: AB positive. Rubella: Immune. VDRL: Nonreactive. Hepatitis C surface antigen: Negative. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet."""</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">IntegerType</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sample_text</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">resolver_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(sentence_embeddings) AS s"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"s.result"</span><span class="p">,</span> <span class="s">"slice(s.embeddings, 1, 5) AS averageEmbedding"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------+--------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span><span class="n">averageEmbedding</span>                                              <span class="o">|</span>
<span class="o">+------+--------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">IR</span>    <span class="o">|</span><span class="p">[</span><span class="mf">0.11792798</span><span class="p">,</span> <span class="mf">0.36022937</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0620842</span><span class="p">,</span> <span class="mf">0.87576616</span><span class="p">,</span> <span class="mf">0.5389829</span><span class="p">]</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">CBC</span>   <span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.07262431</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.671684</span><span class="p">,</span> <span class="mf">0.009878114</span><span class="p">,</span> <span class="mf">0.76053196</span><span class="p">,</span> <span class="mf">0.4687413</span><span class="p">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">AB</span>    <span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.2781681</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.43619046</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.20924012</span><span class="p">,</span> <span class="mf">0.84943366</span><span class="p">,</span> <span class="mf">0.40831584</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">VDRL</span>  <span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.07109344</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.20644212</span><span class="p">,</span> <span class="mf">0.0367461</span><span class="p">,</span> <span class="mf">0.43459156</span><span class="p">,</span> <span class="mf">0.3684616</span><span class="p">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">HIV</span>   <span class="o">|</span><span class="p">[</span><span class="o">-</span><span class="mf">0.1740405</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4599509</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.041505605</span><span class="p">,</span> <span class="mf">0.61368394</span><span class="p">,</span> <span class="mf">0.66777927</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------+--------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_abbreviation_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="ss">'ABB</span><span class="n">R</span><span class="o">'))</span>

<span class="k">val</span> <span class="nv">sentenceChunkEmbeddings</span> <span class="k">=</span> <span class="nv">BertSentenceChunkEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbluebert_base_uncased_mli"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
      <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setChunkWeight</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>
      <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">True</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">wordEmbeddings</span><span class="o">,</span>
      <span class="n">nerModel</span><span class="o">,</span>
      <span class="n">nerConverter</span><span class="o">,</span>
      <span class="n">sentenceChunkEmbeddings</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">sampleText</span> <span class="k">=</span> <span class="s">"The patient admitted from the IR for aggressive irrigation of the Miami pouch. DISCHARGE DIAGNOSES: 1. A 58-year-old female with a history of stage 2 squamous cell carcinoma of the cervix status post total pelvic exenteration in 1991."</span> <span class="o">+</span>
<span class="s">"Gravid with estimated fetal weight of 6-6/12 pounds. LOWER EXTREMITIES: No edema. LABORATORY DATA: Laboratory tests include a CBC which is normal. 
Blood Type: AB positive. Rubella: Immune. VDRL: Nonreactive. Hepatitis C surface antigen: Negative. HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet."</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">sampleText</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"sampleText"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+------+--------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span><span class="n">averageEmbedding</span>                                              <span class="o">|</span>
<span class="o">+------+--------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">IR</span>    <span class="o">|[</span><span class="err">0</span><span class="kt">.</span><span class="err">11792798</span>, <span class="err">0</span><span class="kt">.</span><span class="err">36022937</span>, <span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">0620842</span>, <span class="err">0</span><span class="kt">.</span><span class="err">87576616</span>, <span class="err">0</span><span class="kt">.</span><span class="err">5389829</span><span class="o">]</span>   <span class="o">|</span>
<span class="o">|</span><span class="nc">CBC</span>   <span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07262431</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">671684</span>, <span class="err">0</span><span class="kt">.</span><span class="err">009878114</span>, <span class="err">0</span><span class="kt">.</span><span class="err">76053196</span>, <span class="err">0</span><span class="kt">.</span><span class="err">4687413</span><span class="o">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="nc">AB</span>    <span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2781681</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">43619046</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">20924012</span>, <span class="err">0</span><span class="kt">.</span><span class="err">84943366</span>, <span class="err">0</span><span class="kt">.</span><span class="err">40831584</span><span class="o">]|</span>
<span class="o">|</span><span class="nc">VDRL</span>  <span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07109344</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">20644212</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0367461</span>, <span class="err">0</span><span class="kt">.</span><span class="err">43459156</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3684616</span><span class="o">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="nc">HIV</span>   <span class="o">|[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1740405</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">4599509</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">041505605</span>, <span class="err">0</span><span class="kt">.</span><span class="err">61368394</span>, <span class="err">0</span><span class="kt">.</span><span class="err">66777927</span><span class="o">]|</span>
<span class="o">+------+--------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunk2token">Chunk2Token</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>A feature transformer that converts the input array of strings (annotatorType CHUNK) into an
array of chunk-based tokens (annotatorType TOKEN).</p>

    <p>When the input is empty, an empty array is returned.</p>

    <p>This Annotator is specially convenient when using NGramGenerator annotations as inputs to WordEmbeddingsModels.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunk2_token/index.html">Chunk2Token</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/Chunk2Token.html">Chunk2Token</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Chunk2Token.ipynb">Chunk2TokenNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 
<span class="c1"># Define a pipeline for generating n-grams
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">ngrammer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NGramGenerator</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableCumulative</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDelimiter</span><span class="p">(</span><span class="s">"_"</span><span class="p">)</span>

<span class="c1"># Stage to convert n-gram CHUNKS to TOKEN type
</span><span class="n">chunk2Token</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Chunk2Token</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ngrams"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngram_tokens"</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document</span><span class="p">,</span> 
    <span class="n">sentenceDetector</span><span class="p">,</span> 
    <span class="n">token</span><span class="p">,</span> 
    <span class="n">ngrammer</span><span class="p">,</span> 
    <span class="n">chunk2Token</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ngram_tokens)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+----------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                             <span class="o">|</span>
<span class="o">+----------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">A_63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>  <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old_man</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="n">man_presents</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>  <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">presents_to</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">27</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">to_the</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="p">},</span> <span class="p">[]}</span>        <span class="o">|</span>
<span class="o">+----------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># Define a pipeline for generating n-grams
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">ngrammer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NGramGenerator</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableCumulative</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> 

<span class="c1"># Stage to convert n-gram CHUNKS to TOKEN type
</span><span class="n">chunk2Token</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">Chunk2Token</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ngrams"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngram_tokens"</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document</span><span class="p">,</span> 
    <span class="n">sentenceDetector</span><span class="p">,</span> 
    <span class="n">token</span><span class="p">,</span> 
    <span class="n">ngrammer</span><span class="p">,</span> 
    <span class="n">chunk2Token</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ngram_tokens)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                 <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="n">Our</span> <span class="n">competitors</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>    <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="n">competitors</span> <span class="n">include</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="n">include</span> <span class="n">the</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="n">the</span> <span class="n">following</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span>     <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="n">following</span> <span class="n">by</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="p">},</span> <span class="p">[]}</span>      <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span> 
<span class="c1"># Define a pipeline for generating n-grams
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">ngrammer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NGramGenerator</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setN</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableCumulative</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngrams"</span><span class="p">)</span> 

<span class="c1"># Stage to convert n-gram CHUNKS to TOKEN type
</span><span class="n">chunk2Token</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">Chunk2Token</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ngrams"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ngram_tokens"</span><span class="p">)</span>

<span class="n">trainingPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document</span><span class="p">,</span> 
    <span class="n">sentenceDetector</span><span class="p">,</span> 
    <span class="n">token</span><span class="p">,</span> 
    <span class="n">ngrammer</span><span class="p">,</span> 
    <span class="n">chunk2Token</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">trainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ngram_tokens)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                    <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">This</span> <span class="ow">is</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="ow">is</span> <span class="n">an</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                  <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="n">an</span> <span class="n">Intellectual</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="n">Intellectual</span> <span class="n">Property</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">token</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">41</span><span class="p">,</span> <span class="n">Property</span> <span class="n">Agreement</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Define a pipeline for generating n-grams</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ngrammer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGramGenerator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEnableCumulative</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDelimiter</span><span class="o">(</span><span class="s">"_"</span><span class="o">)</span>

<span class="c1">// Stage to convert n-gram CHUNKS to TOKEN type</span>
<span class="k">val</span> <span class="nv">chunk2Token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Token</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngram_tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">token</span><span class="o">,</span> 
    <span class="n">ngrammer</span><span class="o">,</span> 
    <span class="n">chunk2Token</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+----------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                             <span class="o">|</span>
<span class="o">+----------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">3</span><span class="o">,</span> <span class="mi">15</span><span class="o">,</span> <span class="nc">A_63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">19</span><span class="o">,</span> <span class="mi">63</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old_man</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">17</span><span class="o">,</span> <span class="mi">28</span><span class="o">,</span> <span class="n">man_presents</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">21</span><span class="o">,</span> <span class="mi">31</span><span class="o">,</span> <span class="n">presents_to</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">},</span> <span class="o">[]}</span>   <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">35</span><span class="o">,</span> <span class="n">to_the</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">},</span> <span class="o">[]}</span>        <span class="o">|</span>
<span class="o">+----------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Define a pipeline for generating n-grams</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ngrammer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGramGenerator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEnableCumulative</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>

<span class="c1">// Stage to convert n-gram CHUNKS to TOKEN type</span>
<span class="k">val</span> <span class="nv">chunk2Token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Token</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngram_tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">token</span><span class="o">,</span> 
    <span class="n">ngrammer</span><span class="o">,</span> 
    <span class="n">chunk2Token</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                 <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">14</span><span class="o">,</span> <span class="nc">Our</span> <span class="n">competitors</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}</span>    <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="n">competitors</span> <span class="n">include</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">16</span><span class="o">,</span> <span class="mi">26</span><span class="o">,</span> <span class="n">include</span> <span class="n">the</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="o">},</span> <span class="o">[]}</span>       <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">24</span><span class="o">,</span> <span class="mi">36</span><span class="o">,</span> <span class="n">the</span> <span class="n">following</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">},</span> <span class="o">[]}</span>     <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">28</span><span class="o">,</span> <span class="mi">39</span><span class="o">,</span> <span class="n">following</span> <span class="n">by</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">},</span> <span class="o">[]}</span>      <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Define a pipeline for generating n-grams</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ngrammer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NGramGenerator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setN</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEnableCumulative</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>

<span class="c1">// Stage to convert n-gram CHUNKS to TOKEN type</span>
<span class="k">val</span> <span class="nv">chunk2Token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Token</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ngrams"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ngram_tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">trainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">token</span><span class="o">,</span> 
    <span class="n">ngrammer</span><span class="o">,</span> 
    <span class="n">chunk2Token</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">trainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                    <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">6</span><span class="o">,</span> <span class="nc">This</span> <span class="n">is</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}</span>                <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">5</span><span class="o">,</span> <span class="mi">9</span><span class="o">,</span> <span class="n">is</span> <span class="n">an</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span>                  <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="n">an</span> <span class="nc">Intellectual</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="o">},</span> <span class="o">[]}</span>       <span class="o">|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">11</span><span class="o">,</span> <span class="mi">31</span><span class="o">,</span> <span class="nc">Intellectual</span> <span class="nc">Property</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">token</span><span class="o">,</span> <span class="mi">24</span><span class="o">,</span> <span class="mi">41</span><span class="o">,</span> <span class="nc">Property</span> <span class="nc">Agreement</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">},</span> <span class="o">[]}</span>   <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunkconverter">ChunkConverter</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Convert chunks from <a href="https://nlp.johnsnowlabs.com/docs/en/annotators#regexmatcher">RegexMatcher</a> to chunks with a entity in the metadata.</p>

    <p>This annotator is important when the user wants to merge entities identified by NER models together with rules-based matching used by the RegexMathcer annotator. In the following steps of the pipeline, all the identified entities can be treated in a unified field.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</li>
      <li><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</li>
      <li><code class="language-plaintext highlighter-rouge">resetSentenceIndices</code>: Whether to reset sentence indices to treat the entire output as if it originates from a single document. Default: False.</li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunk_converter/index.html#sparknlp_jsl.annotator.chunker.chunk_converter.ChunkConverter.html">ChunkConverter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkConverter.html">ChunkConverter</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ChunkConverter.ipynb">ChunkConverterNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># Creating the pipeline
</span><span class="n">rules</span> <span class="o">=</span> <span class="s">'''
</span><span class="se">\b</span><span class="s">[A-Z]+(\s+[A-Z]+)*:</span><span class="se">\b</span><span class="s">, SECTION_HEADER
'''</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'regex_rules.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""
POSTOPERATIVE DIAGNOSIS: Cervical lymphadenopathy.
PROCEDURE:  Excisional biopsy of right cervical lymph node.
ANESTHESIA:  General endotracheal anesthesia.
Specimen:  Right cervical lymph node.
EBL: 10 cc.
COMPLICATIONS:  None.
FINDINGS: Enlarged level 2 lymph node was identified and removed and sent for pathologic examination.
FLUIDS:  Please see anesthesia report.
URINE OUTPUT:  None recorded during the case.
INDICATIONS FOR PROCEDURE:  This is a 43-year-old female with a several-year history of persistent cervical lymphadenopathy. She reports that it is painful to palpation on the right and has had multiple CT scans as well as an FNA which were all nondiagnostic. After risks and benefits of surgery were discussed with the patient, an informed consent was obtained. She was scheduled for an excisional biopsy of the right cervical lymph node.
PROCEDURE IN DETAIL:  The patient was taken to the operating room and placed in the supine position. She was anesthetized with general endotracheal anesthesia. The neck was then prepped and draped in the sterile fashion. Again, noted on palpation there was an enlarged level 2 cervical lymph node.A 3-cm horizontal incision was made over this lymph node. Dissection was carried down until the sternocleidomastoid muscle was identified. The enlarged lymph node that measured approximately 2 cm in diameter was identified and was removed and sent to Pathology for touch prep evaluation. The area was then explored for any other enlarged lymph nodes. None were identified, and hemostasis was achieved with electrocautery. A quarter-inch Penrose drain was placed in the wound.The wound was then irrigated and closed with 3-0 interrupted Vicryl sutures for a deep closure followed by a running 4-0 Prolene subcuticular suture. Mastisol and Steri-Strip were placed over the incision, and sterile bandage was applied. The patient tolerated this procedure well and was extubated without complications and transported to the recovery room in stable condition. She will return to the office tomorrow in followup to have the Penrose drain removed.
"""</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical_large"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span><span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\

<span class="n">regex_matcher</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RegexMatcher</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStrategy</span><span class="p">(</span><span class="s">"MATCH_ALL"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setExternalRules</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'/content/regex_rules.txt'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">)</span>

<span class="n">chunkConverter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_chunk"</span><span class="p">)</span>

<span class="n">merger</span><span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"regex_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"merged_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMergeOverlapping</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkPrecedence</span><span class="p">(</span><span class="s">"field"</span><span class="p">)</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">regex_matcher</span><span class="p">,</span>
    <span class="n">chunkConverter</span><span class="p">,</span>
    <span class="n">merger</span>
<span class="p">])</span>

<span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">merged_chunks</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">merged_chunks</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
                  <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"merged_entity"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="o">+----------------------------------------------+--------------+</span>
<span class="o">|</span>                                         <span class="n">chunk</span><span class="o">|</span> <span class="n">merged_entity</span><span class="o">|</span>
<span class="o">+----------------------------------------------+--------------+</span>
<span class="o">|</span>                      <span class="n">POSTOPERATIVE</span> <span class="n">DIAGNOSIS</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                      <span class="n">Cervical</span> <span class="n">lymphadenopathy</span><span class="o">|</span>       <span class="n">PROBLEM</span><span class="o">|</span>
<span class="o">|</span>                                    <span class="n">PROCEDURE</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span><span class="n">Excisional</span> <span class="n">biopsy</span> <span class="n">of</span> <span class="n">right</span> <span class="n">cervical</span> <span class="n">lymph</span> <span class="n">node</span><span class="o">|</span>          <span class="n">TEST</span><span class="o">|</span>
<span class="o">|</span>                                   <span class="n">ANESTHESIA</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>               <span class="n">General</span> <span class="n">endotracheal</span> <span class="n">anesthesia</span><span class="o">|</span>     <span class="n">TREATMENT</span><span class="o">|</span>
<span class="o">|</span>                     <span class="n">Right</span> <span class="n">cervical</span> <span class="n">lymph</span> <span class="n">node</span><span class="o">|</span>       <span class="n">PROBLEM</span><span class="o">|</span>
<span class="o">|</span>                                          <span class="n">EBL</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                                <span class="n">COMPLICATIONS</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                                     <span class="n">FINDINGS</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                   <span class="n">Enlarged</span> <span class="n">level</span> <span class="mi">2</span> <span class="n">lymph</span> <span class="n">node</span><span class="o">|</span>       <span class="n">PROBLEM</span><span class="o">|</span>
<span class="o">|</span>                        <span class="n">pathologic</span> <span class="n">examination</span><span class="o">|</span>          <span class="n">TEST</span><span class="o">|</span>
<span class="o">|</span>                                       <span class="n">FLUIDS</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                                 <span class="n">URINE</span> <span class="n">OUTPUT</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                    <span class="n">INDICATIONS</span> <span class="n">FOR</span> <span class="n">PROCEDURE</span><span class="p">:</span><span class="o">|</span><span class="n">SECTION_HEADER</span><span class="o">|</span>
<span class="o">+----------------------------------------------+--------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># Creating the pipeline
</span><span class="n">rules</span> <span class="o">=</span> <span class="s">'''
</span><span class="se">\b</span><span class="s">[A-Z]+(\s+[A-Z]+)*:</span><span class="se">\b</span><span class="s">, SECTION_HEADER
'''</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'regex_rules.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span>

<span class="n">sample_text</span><span class="o">=</span><span class="s">"""AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price. """</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
    <span class="c1"># .setWhiteList(["ORG"]) # Return only ORG entities
</span>
<span class="n">regex_matcher</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RegexMatcher</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStrategy</span><span class="p">(</span><span class="s">"MATCH_ALL"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setExternalRules</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'/content/regex_rules.txt'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">)</span>

<span class="n">chunkConverter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_chunk"</span><span class="p">)</span>

<span class="n">merger</span><span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"regex_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"merged_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMergeOverlapping</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkPrecedence</span><span class="p">(</span><span class="s">"field"</span><span class="p">)</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">regex_matcher</span><span class="p">,</span>
    <span class="n">chunkConverter</span><span class="p">,</span>
    <span class="n">merger</span>
<span class="p">])</span>

<span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">merged_chunks</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">merged_chunks</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
                  <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"merged_entity"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="o">+--------+-------------+</span>
<span class="o">|</span>   <span class="n">chunk</span><span class="o">|</span><span class="n">merged_entity</span><span class="o">|</span>
<span class="o">+--------+-------------+</span>
<span class="o">|</span><span class="n">Group</span> <span class="n">LP</span><span class="o">|</span>          <span class="n">ORG</span><span class="o">|</span>
<span class="o">+--------+-------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># Creating the pipeline
</span><span class="n">rules</span> <span class="o">=</span> <span class="s">'''
</span><span class="se">\b</span><span class="s">[A-Z]+(\s+[A-Z]+)*:</span><span class="se">\b</span><span class="s">, SECTION_HEADER
'''</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'regex_rules.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span>

<span class="n">sample_text</span><span class="o">=</span><span class="s">"""AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price. """</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_org_per_role_date"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>
    <span class="c1"># .setWhiteList(["ORG"]) # Return only ORG entities
</span>
<span class="n">regex_matcher</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RegexMatcher</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStrategy</span><span class="p">(</span><span class="s">"MATCH_ALL"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setExternalRules</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'/content/regex_rules.txt'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">','</span><span class="p">)</span>

<span class="n">chunkConverter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_chunk"</span><span class="p">)</span>

<span class="n">merger</span><span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"regex_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"merged_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMergeOverlapping</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkPrecedence</span><span class="p">(</span><span class="s">"field"</span><span class="p">)</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">regex_matcher</span><span class="p">,</span>
    <span class="n">chunkConverter</span><span class="p">,</span>
    <span class="n">merger</span>
<span class="p">])</span>

<span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">merged_chunks</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">merged_chunks</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
                  <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"merged_entity"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="o">+--------+-------------+</span>
<span class="o">|</span>   <span class="n">chunk</span><span class="o">|</span><span class="n">merged_entity</span><span class="o">|</span>
<span class="o">+--------+-------------+</span>
<span class="o">|</span><span class="n">Group</span> <span class="n">LP</span><span class="o">|</span>          <span class="n">ORG</span><span class="o">|</span>
<span class="o">+--------+-------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// val rules = """\b[A-Z]+(\s+[A-Z]+)*:\b, SECTION_HEADER""" </span>
<span class="c1">// with open("regex_rules.txt","w") as f: </span>
<span class="c1">//    f.write(rules) </span>


<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical_large"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span><span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">regex_matcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexMatcher</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setStrategy</span><span class="o">(</span><span class="s">"MATCH_ALL"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex_matches"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setExternalRules</span><span class="o">(</span><span class="n">path</span><span class="o">=</span><span class="s">"/content/regex_rules.txt"</span><span class="o">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunkConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"regex_matches"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">merger</span><span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"regex_chunk"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"merged_chunks"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMergeOverlapping</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setChunkPrecedence</span><span class="o">(</span><span class="s">"field"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">word_embeddings</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span> 
    <span class="n">ner_converter</span><span class="o">,</span> 
    <span class="n">regex_matcher</span><span class="o">,</span> 
    <span class="n">chunkConverter</span><span class="o">,</span> 
    <span class="n">merger</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"POSTOPERATIVE DIAGNOSIS: Cervical lymphadenopathy. PROCEDURE: Excisional biopsy of right cervical lymph node. ANESTHESIA: General endotracheal anesthesia. Specimen: Right cervical lymph node. EBL: 10 cc. COMPLICATIONS: None. FINDINGS: Enlarged level 2 lymph node was identified and removed and sent for pathologic examination. FLUIDS: Please see anesthesia report. URINE OUTPUT: None recorded during the case. INDICATIONS FOR PROCEDURE: This is a 43-year-old female with a several-year history of persistent cervical lymphadenopathy. She reports that it is painful to palpation on the right and has had multiple CT scans as well as an FNA which were all nondiagnostic. After risks and benefits of surgery were discussed with the patient,an informed consent was obtained. She was scheduled for an excisional biopsy of the right cervical lymph node. PROCEDURE IN DETAIL: The patient was taken to the operating room and placed in the supine position. She was anesthetized with general endotracheal anesthesia. The neck was then prepped and draped in the sterile fashion. Again,noted on palpation there was an enlarged level 2 cervical lymph node.A 3-cm horizontal incision was made over this lymph node. Dissection was carried down until the sternocleidomastoid muscle was identified. The enlarged lymph node that measured approximately 2 cm in diameter was identified and was removed and sent to Pathology for touch prep evaluation. The area was then explored for any other enlarged lymph nodes. None were identified,and hemostasis was achieved with electrocautery. A quarter-inch Penrose drain was placed in the wound.The wound was then irrigated and closed with 3-0 interrupted Vicryl sutures for a deep closure followed by a running 4-0 Prolene subcuticular suture. Mastisol and Steri-Strip were placed over the incision,and sterile bandage was applied. The patient tolerated this procedure well and was extubated without complications and transported to the recovery room in stable condition. She will return to the office tomorrow in followup to have the Penrose drain removed."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+----------------------------------------------+--------------+</span>
<span class="o">|</span>                                         <span class="n">chunk</span><span class="o">|</span> <span class="n">merged_entity</span><span class="o">|</span>
<span class="o">+----------------------------------------------+--------------+</span>
<span class="o">|</span>                      <span class="nc">POSTOPERATIVE</span> <span class="nc">DIAGNOSIS</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                      <span class="nc">Cervical</span> <span class="n">lymphadenopathy</span><span class="o">|</span>       <span class="nc">PROBLEM</span><span class="o">|</span>
<span class="o">|</span>                                    <span class="nc">PROCEDURE</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Excisional</span> <span class="n">biopsy</span> <span class="n">of</span> <span class="n">right</span> <span class="n">cervical</span> <span class="n">lymph</span> <span class="n">node</span><span class="o">|</span>          <span class="nc">TEST</span><span class="o">|</span>
<span class="o">|</span>                                   <span class="nc">ANESTHESIA</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>               <span class="nc">General</span> <span class="n">endotracheal</span> <span class="n">anesthesia</span><span class="o">|</span>     <span class="nc">TREATMENT</span><span class="o">|</span>
<span class="o">|</span>                     <span class="nc">Right</span> <span class="n">cervical</span> <span class="n">lymph</span> <span class="n">node</span><span class="o">|</span>       <span class="nc">PROBLEM</span><span class="o">|</span>
<span class="o">|</span>                                          <span class="nc">EBL</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                                <span class="nc">COMPLICATIONS</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                                     <span class="nc">FINDINGS</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                   <span class="nc">Enlarged</span> <span class="n">level</span> <span class="mi">2</span> <span class="n">lymph</span> <span class="n">node</span><span class="o">|</span>       <span class="nc">PROBLEM</span><span class="o">|</span>
<span class="o">|</span>                        <span class="n">pathologic</span> <span class="n">examination</span><span class="o">|</span>          <span class="nc">TEST</span><span class="o">|</span>
<span class="o">|</span>                                       <span class="nc">FLUIDS</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                                 <span class="nc">URINE</span> <span class="nc">OUTPUT</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">|</span>                    <span class="nc">INDICATIONS</span> <span class="nc">FOR</span> <span class="nc">PROCEDURE</span><span class="o">:|</span><span class="nc">SECTION_HEADER</span><span class="o">|</span>
<span class="o">+----------------------------------------------+--------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// val rules = """\b[A-Z]+(\s+[A-Z]+)*:\b, SECTION_HEADER""" </span>
<span class="c1">// with open("regex_rules.txt","w") as f: </span>
<span class="c1">//    f.write(rules) </span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span><span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>  
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
    <span class="c1">// .setWhiteList(Array("ORG")) </span>

<span class="c1">// Return only ORG entities </span>
<span class="k">val</span> <span class="nv">regex_matcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexMatcher</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setStrategy</span><span class="o">(</span><span class="s">"MATCH_ALL"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex_matches"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setExternalRules</span><span class="o">(</span><span class="n">path</span><span class="o">=</span><span class="s">"/content/regex_rules.txt"</span><span class="o">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunkConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"regex_matches"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex_chunk"</span><span class="o">)</span> 
 
<span class="k">val</span> <span class="nv">merger</span><span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"regex_chunk"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"merged_chunks"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMergeOverlapping</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setChunkPrecedence</span><span class="o">(</span><span class="s">"field"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">word_embeddings</span><span class="o">,</span> 
    <span class="n">ner_model</span><span class="o">,</span> 
    <span class="n">ner_converter</span><span class="o">,</span> 
    <span class="n">regex_matcher</span><span class="o">,</span> 
    <span class="n">chunkConverter</span><span class="o">,</span> 
    <span class="n">merger</span> <span class="o">))</span> 
    
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------+</span>
<span class="o">|</span>   <span class="n">chunk</span><span class="o">|</span><span class="n">merged_entity</span><span class="o">|</span>
<span class="o">+--------+-------------+</span>
<span class="o">|</span><span class="nc">Group</span> <span class="nc">LP</span><span class="o">|</span>          <span class="nc">ORG</span><span class="o">|</span>
<span class="o">+--------+-------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// val rules = """[A-Z]+[\s+[A-Z]+]*,SECTION_HEADER """ </span>
<span class="c1">// with open("regex_rules.txt","w") as f: </span>
<span class="c1">//    f.write(rules) </span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_org_per_role_date"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span><span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>  
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
    <span class="c1">// .setWhiteList(Array("ORG")) </span>

<span class="c1">// Return only ORG entities </span>
<span class="k">val</span> <span class="nv">regex_matcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexMatcher</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setStrategy</span><span class="o">(</span><span class="s">"MATCH_ALL"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex_matches"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setExternalRules</span><span class="o">(</span><span class="n">path</span><span class="o">=</span><span class="s">"/content/regex_rules.txt"</span><span class="o">,</span><span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunkConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"regex_matches"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex_chunk"</span><span class="o">)</span> 
 
<span class="k">val</span> <span class="nv">merger</span><span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"regex_chunk"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"merged_chunks"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMergeOverlapping</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setChunkPrecedence</span><span class="o">(</span><span class="s">"field"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span><span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">word_embeddings</span><span class="o">,</span> 
    <span class="n">ner_model</span><span class="o">,</span> 
    <span class="n">ner_converter</span><span class="o">,</span> 
    <span class="n">regex_matcher</span><span class="o">,</span> 
    <span class="n">chunkConverter</span><span class="o">,</span> 
    <span class="n">merger</span> <span class="o">))</span> 
    
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
                          
<span class="o">+--------+-------------+</span>
<span class="o">|</span>   <span class="n">chunk</span><span class="o">|</span><span class="n">merged_entity</span><span class="o">|</span>
<span class="o">+--------+-------------+</span>
<span class="o">|</span><span class="nc">Group</span> <span class="nc">LP</span><span class="o">|</span>          <span class="nc">ORG</span><span class="o">|</span>
<span class="o">+--------+-------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunkentityresolver">ChunkEntityResolver</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The ChunkEntityResolverModel encompasses the functionality to produce a normalized entity from a specialized ontology or curated dataset (such as ICD-10, RxNorm, SNOMED, etc.). This model includes comprehensive parameters and methods essential for its training. It operates by transforming a dataset that incorporates two Input Annotations: TOKEN and WORD_EMBEDDINGS, sourced from tools like ChunkTokenizer and ChunkEmbeddings Annotators. Ultimately, it generates the normalized entity relevant to the specified trained ontology or curated dataset, ensuring accurate entity resolution within the given context.</p>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a>.</p>

    <p><code class="language-plaintext highlighter-rouge">Importand Note</code>: This annotator has been deprecated.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/">ChunkEntityResolverModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="c1"># Using pretrained models for SNOMED
# First the prior steps of the pipeline are defined.
# Output of types TOKEN and WORD_EMBEDDINGS are needed.
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">icdo_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_bionlp"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_ner"</span><span class="p">)</span>

<span class="n">icdo_chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"icdo_ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Cancer"</span><span class="p">])</span>

<span class="n">icdo_chunk_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">ChunkEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"icdo_chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icdo_chunk_embeddings"</span><span class="p">)</span>

<span class="n">icdo_chunk_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkEntityResolverModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"chunkresolve_icdo_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span><span class="s">"icdo_chunk_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tm_icdo_code"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">ner_chunk_tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">ChunkTokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_token"</span><span class="p">)</span>
    
<span class="n">ner_chunk_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">ChunkEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_embeddings"</span><span class="p">)</span>

<span class="c1"># Definition of the SNOMED Resolution
</span><span class="n">ner_snomed_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkEntityResolverModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"chunkresolve_snomed_findings_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_token"</span><span class="p">,</span><span class="s">"ner_chunk_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_result"</span><span class="p">)</span>

<span class="n">pipelineFull</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
      <span class="n">docAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>

      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_chunk_embeddings</span><span class="p">,</span>
      <span class="n">ner_chunk_tokenizer</span><span class="p">,</span>
      <span class="n">ner_snomed_resolver</span><span class="p">,</span>

      <span class="n">icdo_ner</span><span class="p">,</span>
      <span class="n">icdo_chunk</span><span class="p">,</span>
      <span class="n">icdo_chunk_embeddings</span><span class="p">,</span>
      <span class="n">icdo_chunk_resolver</span>
<span class="p">])</span>
<span class="n">pipelineModelFull</span> <span class="o">=</span> <span class="n">pipelineFull</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipelineModelFull</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(snomed_result)"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"col.metadata.target_text"</span><span class="p">,</span>
    <span class="s">"col.metadata.resolved_text"</span><span class="p">,</span>
    <span class="s">"col.metadata.confidence"</span><span class="p">,</span>
    <span class="s">"col.metadata.all_k_results"</span><span class="p">,</span>
    <span class="s">"col.metadata.all_k_resolutions"</span><span class="p">)</span>
  <span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="err">$</span><span class="s">"confidence"</span> <span class="o">&gt;</span> <span class="mf">0.2</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="o">|</span>         <span class="n">target_text</span><span class="o">|</span>       <span class="n">resolved_text</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>       <span class="n">all_k_results</span><span class="o">|</span>   <span class="n">all_k_resolutions</span><span class="o">|</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="o">|</span><span class="n">hypercholesterolemia</span><span class="o">|</span><span class="n">Hypercholesterolemia</span><span class="o">|</span>    <span class="mf">0.2524</span><span class="o">|</span><span class="mi">13644009</span><span class="p">:::</span><span class="mf">267432.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypercholesterole</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                 <span class="n">CBC</span><span class="o">|</span>             <span class="n">Neocyte</span><span class="o">|</span>    <span class="mf">0.4980</span><span class="o">|</span><span class="mi">259680000</span><span class="p">:::</span><span class="mf">11573.</span><span class="p">..</span><span class="o">|</span><span class="n">Neocyte</span><span class="p">:::</span><span class="n">Blood</span> <span class="n">g</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                <span class="n">CD38</span><span class="o">|</span>       <span class="n">Hypoviscosity</span><span class="o">|</span>    <span class="mf">0.2560</span><span class="o">|</span><span class="mi">47872005</span><span class="p">:::</span><span class="mf">370970.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypoviscosity</span><span class="p">:::</span><span class="n">E</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>           <span class="n">platelets</span><span class="o">|</span> <span class="n">Increased</span> <span class="n">platelets</span><span class="o">|</span>    <span class="mf">0.5267</span><span class="o">|</span><span class="mi">6631009</span><span class="p">:::</span><span class="mf">2596800.</span><span class="p">..</span><span class="o">|</span><span class="n">Increased</span> <span class="n">platele</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>                <span class="n">CD38</span><span class="o">|</span>       <span class="n">Hypoviscosity</span><span class="o">|</span>    <span class="mf">0.2560</span><span class="o">|</span><span class="mi">47872005</span><span class="p">:::</span><span class="mf">370970.</span><span class="p">..</span><span class="o">|</span><span class="n">Hypoviscosity</span><span class="p">:::</span><span class="n">E</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------+--------------------+----------+--------------------+--------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="c1">// Using pretrained models for SNOMED</span>
<span class="c1">// First the prior steps of the pipeline are defined.</span>
<span class="c1">// Output of types TOKEN and WORD_EMBEDDINGS are needed.</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"A 63-year-old man presents to the hospital ..."</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">icdo_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_bionlp"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">icdo_chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"icdo_ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"Cancer"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">icdo_chunk_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEmbeddings</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"icdo_chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icdo_chunk_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">icdo_chunk_resolver</span> <span class="k">=</span> <span class="nv">ChunkEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"chunkresolve_icdo_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span><span class="s">"icdo_chunk_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tm_icdo_code"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_chunk_tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkTokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_token"</span><span class="o">)</span>
  
<span class="k">val</span> <span class="nv">ner_chunk_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEmbeddings</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_embeddings"</span><span class="o">)</span>

<span class="c1">// Definition of the SNOMED Resolution</span>
<span class="k">val</span> <span class="nv">ner_snomed_resolver</span> <span class="k">=</span> <span class="nc">ChunkEntityResolverModel</span><span class="o">\</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"chunkresolve_snomed_findings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_token"</span><span class="o">,</span><span class="s">"ner_chunk_embeddings"</span><span class="o">))\</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_result"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineFull</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">docAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">word_embeddings</span><span class="o">,</span>

    <span class="n">clinical_ner</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">ner_chunk_embeddings</span><span class="o">,</span>
    <span class="n">ner_chunk_tokenizer</span><span class="o">,</span>
    <span class="n">ner_snomed_resolver</span><span class="o">,</span>

    <span class="n">icdo_ner</span><span class="o">,</span>
    <span class="n">icdo_chunk</span><span class="o">,</span>
    <span class="n">icdo_chunk_embeddings</span><span class="o">,</span>
    <span class="n">icdo_chunk_resolver</span>
<span class="o">))</span>
<span class="k">val</span> <span class="nv">pipelineModelFull</span> <span class="k">=</span> <span class="nv">pipelineFull</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModelFull</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Show results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(snomed_result)")</span>
<span class="c1">//   .selectExpr(</span>
<span class="c1">//     "col.metadata.target_text",</span>
<span class="c1">//     "col.metadata.resolved_text",</span>
<span class="c1">//     "col.metadata.confidence",</span>
<span class="c1">//     "col.metadata.all_k_results",</span>
<span class="c1">//     "col.metadata.all_k_resolutions")</span>
<span class="c1">//   .filter($"confidence" &gt; 0.2).show(5)</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">// |         target_text|       resolved_text|confidence|       all_k_results|   all_k_resolutions|</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">// |hypercholesterolemia|Hypercholesterolemia|    0.2524|13644009:::267432...|Hypercholesterole...|</span>
<span class="c1">// |                 CBC|             Neocyte|    0.4980|259680000:::11573...|Neocyte:::Blood g...|</span>
<span class="c1">// |                CD38|       Hypoviscosity|    0.2560|47872005:::370970...|Hypoviscosity:::E...|</span>
<span class="c1">// |           platelets| Increased platelets|    0.5267|6631009:::2596800...|Increased platele...|</span>
<span class="c1">// |                CD38|       Hypoviscosity|    0.2560|47872005:::370970...|Hypoviscosity:::E...|</span>
<span class="c1">// +--------------------+--------------------+----------+--------------------+--------------------+</span>
<span class="c1">//</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Contains all the parameters and methods to train a ChunkEntityResolverModel.
It transform a dataset with two Input Annotations of types TOKEN and WORD_EMBEDDINGS, coming from e.g. ChunkTokenizer
and ChunkEmbeddings Annotators and returns the normalized entity for a particular trained ontology / curated dataset.
(e.g. ICD-10, RxNorm, SNOMED etc.)</p>

    <p>To use pretrained models please use ChunkEntityResolverModel
and see the <a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/">ChunkEntityResolverApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="c1"># Training a SNOMED model
# Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.
</span><span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">chunkEmb</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">ChunkEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk_embeddings"</span><span class="p">)</span>

<span class="n">snomedTrainingPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document</span><span class="p">,</span>
    <span class="n">chunk</span><span class="p">,</span>
    <span class="n">token</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">chunkEmb</span>
<span class="p">])</span>

<span class="n">snomedTrainingModel</span> <span class="o">=</span> <span class="n">snomedTrainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">snomedData</span> <span class="o">=</span> <span class="n">snomedTrainingModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">snomedExtractor</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkEntityResolverApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"chunk_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"recognized"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAlternatives</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableWmd</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableTfidf</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableJaccard</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEnableSorensenDice</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableJaroWinkler</span><span class="p">(</span><span class="bp">True</span><span class="p">).</span><span class="n">setEnableLevenshtein</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDistanceWeights</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setAllDistancesMetadata</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"MAX"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mf">1e32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">snomedExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snomedData</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="c1">// Training a SNOMED model</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.</span>
<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span><span class="o">\</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkEmb</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEmbeddings</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document</span><span class="o">,</span>
    <span class="n">chunk</span><span class="o">,</span>
    <span class="n">token</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">chunkEmb</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">snomedExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkEntityResolverApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"chunk_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"recognized"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setAlternatives</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEnableWmd</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableTfidf</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableJaccard</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEnableSorensenDice</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableJaroWinkler</span><span class="o">(</span><span class="kc">true</span><span class="o">).</span><span class="py">setEnableLevenshtein</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDistanceWeights</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setAllDistancesMetadata</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"MAX"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1</span><span class="n">e32</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">snomedExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunkfilterer">ChunkFilterer</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Filters entities coming from CHUNK annotations. Filters can be set via a white list of terms or a regular expression.
White list criteria is enabled by default. To use regex, <code class="language-plaintext highlighter-rouge">criteria</code> has to be set to <code class="language-plaintext highlighter-rouge">regex</code>.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">criteria</code>: Tag representing what is the criteria to filter the chunks. Possibles values are: - isIn: Filter by the chunk - regex: Filter using a regex</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">whiteList</code>: If defined, list of entities to process. The rest will be ignored.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">blackList</code>: If defined, list of entities to ignore. The rest will be processed.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">regex</code>: If defined, list of regex to process the chunks (Default: []).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">filterEntity</code>: If equal to “entity”, use the ner label to filter. If set to “result”, use the result attribute of the annotation to filter.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">entitiesConfidence</code>: Path to csv with pairs (entity,confidenceThreshold). Filter the chunks with entities which have confidence lower than the confidence threshold.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT,CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunker_filterer/index.html#sparknlp_jsl.annotator.chunker.chunker_filterer.ChunkFilterer">ChunkFilterer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkFilterer.html">ChunkFilterer</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ChunkFilterer.ipynb">ChunkFiltererNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># Filtering POS tags
# First pipeline stages to extract the POS tags are defined
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"pos"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"(&lt;NN&gt;)+"</span><span class="p">])</span>

<span class="c1"># Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.
</span><span class="n">chunkerFilter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"chunk"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"isin"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"gastroenteritis"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">docAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">posTagger</span><span class="p">,</span>
  <span class="n">chunker</span><span class="p">,</span>
  <span class="n">chunkerFilter</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Has a past history of gastroenteritis and stomach pain, however patient ..."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunk)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="n">gastroenteritis</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span>                <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">42</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="n">stomach</span> <span class="n">pain</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>                   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="n">patient</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span>                        <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">81</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="n">stomach</span> <span class="n">pain</span> <span class="n">now</span><span class="p">.</span><span class="n">We</span> <span class="n">don</span><span class="s">'t care, {sentence -&gt; 0, chunk -&gt; 4}, []}|
|{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}              |
+---------------------------------------------------------------------------------+

result.selectExpr("explode(filtered)").show(truncate=False)
+-------------------------------------------------------------------+
|col                                                                |
+-------------------------------------------------------------------+
|{chunk, 22, 36, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 1}, []}  |
|{chunk, 118, 132, gastroenteritis, {sentence -&gt; 0, chunk -&gt; 5}, []}|
+-------------------------------------------------------------------+
</span></code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># Filtering POS tags
# First pipeline stages to extract the POS tags are defined
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"pos"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"(&lt;NN&gt;)+"</span><span class="p">])</span>

<span class="c1"># Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.
</span><span class="n">chunkerFilter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"chunk"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"isin"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"rate"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">docAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">posTagger</span><span class="p">,</span>
  <span class="n">chunker</span><span class="p">,</span>
  <span class="n">chunkerFilter</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunk)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                    <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">73</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">92</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(filtered)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                    <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">92</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># Filtering POS tags
# First pipeline stages to extract the POS tags are defined
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">chunker</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"pos"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"(&lt;NN&gt;)+"</span><span class="p">])</span>

<span class="c1"># Then the chunks can be filtered via a white list. Here only terms with "gastroenteritis" remain.
</span><span class="n">chunkerFilter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkFilterer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"chunk"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCriteria</span><span class="p">(</span><span class="s">"isin"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"rate"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">docAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">posTagger</span><span class="p">,</span>
  <span class="n">chunker</span><span class="p">,</span>
  <span class="n">chunkerFilter</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(chunk)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                    <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">73</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">92</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(filtered)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                    <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">92</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Filtering POS tags</span>
<span class="c1">// First pipeline stages to extract the POS tags are defined</span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunker</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"pos"</span><span class="o">,</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"(&lt;NN&gt;) +"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">chunkerFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkFilterer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"chunk"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"isin"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"gastroenteritis"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">docAssembler</span><span class="o">,</span> 
  <span class="n">sentenceDetector</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">posTagger</span><span class="o">,</span> 
  <span class="n">chunker</span><span class="o">,</span> 
  <span class="n">chunkerFilter</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""Has a past history of gastroenteritis and stomach pain, however patient ..."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// result.selectExpr("explode(chunk)").show(truncate=false)</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">11</span><span class="o">,</span> <span class="mi">17</span><span class="o">,</span> <span class="n">history</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}</span>                        <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="mi">36</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span>                <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">42</span><span class="o">,</span> <span class="mi">53</span><span class="o">,</span> <span class="n">stomach</span> <span class="n">pain</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="o">},</span> <span class="o">[]}</span>                   <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">64</span><span class="o">,</span> <span class="mi">70</span><span class="o">,</span> <span class="n">patient</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="o">},</span> <span class="o">[]}</span>                        <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">81</span><span class="o">,</span> <span class="mi">110</span><span class="o">,</span> <span class="n">stomach</span> <span class="n">pain</span> <span class="nv">now</span><span class="o">.</span><span class="py">We</span> <span class="n">don</span><span class="ss">'t</span> <span class="n">care</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">118</span><span class="o">,</span> <span class="mi">132</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="o">},</span> <span class="o">[]}</span>              <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------+</span>

<span class="c1">// result.selectExpr("explode(filtered)").show(truncate=false)</span>
<span class="o">+-------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">22</span><span class="o">,</span> <span class="mi">36</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span>  <span class="o">|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">118</span><span class="o">,</span> <span class="mi">132</span><span class="o">,</span> <span class="n">gastroenteritis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">+-------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunker</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"pos"</span><span class="o">,</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"(&lt;NN&gt;) +"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">chunkerFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkFilterer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"chunk"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"isin"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">docAssembler</span><span class="o">,</span> 
  <span class="n">sentenceDetector</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">posTagger</span><span class="o">,</span> 
  <span class="n">chunker</span><span class="o">,</span> 
  <span class="n">chunkerFilter</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// result.selectExpr("explode(chunk)").show(truncate=false)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                    <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">73</span><span class="o">,</span> <span class="mi">77</span><span class="o">,</span> <span class="n">basis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">92</span><span class="o">,</span> <span class="mi">95</span><span class="o">,</span> <span class="n">rate</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>

<span class="c1">// result.selectExpr("explode(filtered)").show(truncate=False)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                    <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">92</span><span class="o">,</span> <span class="mi">95</span><span class="o">,</span> <span class="n">rate</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunker</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"pos"</span><span class="o">,</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"(&lt;NN&gt;) +"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">chunkerFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkFilterer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"chunk"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setCriteria</span><span class="o">(</span><span class="s">"isin"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">docAssembler</span><span class="o">,</span> 
  <span class="n">sentenceDetector</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">posTagger</span><span class="o">,</span> 
  <span class="n">chunker</span><span class="o">,</span> 
  <span class="n">chunkerFilter</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// result.selectExpr("explode(chunk)").show(truncate=false)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                    <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">73</span><span class="o">,</span> <span class="mi">77</span><span class="o">,</span> <span class="n">basis</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">},</span> <span class="o">[]}|</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">92</span><span class="o">,</span> <span class="mi">95</span><span class="o">,</span> <span class="n">rate</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>

<span class="c1">// result.selectExpr("explode(filtered)").show(truncate=False)</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                    <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
<span class="o">|{</span><span class="n">chunk</span><span class="o">,</span> <span class="mi">92</span><span class="o">,</span> <span class="mi">95</span><span class="o">,</span> <span class="n">rate</span><span class="o">,</span> <span class="o">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="o">,</span> <span class="n">chunk</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">},</span> <span class="o">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunkkeyphraseextraction">ChunkKeyPhraseExtraction</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Chunk KeyPhrase Extraction uses Bert Sentence Embeddings to determine the most relevant key phrases describing a text. 
The input to the model consists of chunk annotations and sentence or document annotation. The model compares the chunks  against the corresponding sentences/documents and selects the chunks which are most representative of the broader text context (i.e. the document or the sentence they belong to). The key phrases candidates (i.e. the input chunks) can be  generated in various ways, e.g. by NGramGenerator, TextMatcher or NerConverter. The model operates either at sentence (selecting the most descriptive chunks from the sentence they belong to) or at document level. In the latter case, the key phrases are selected to represent all the input document annotations.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setConcatenateSentences(value: Boolean)</code>: Concatenate the input sentence/documentation annotations before computing their embedding Default value is ‘true’.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setDivergence(value: Float)</code>: Set the level of divergence of the extracted key phrases.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setDocumentLevelProcessing(value: Boolean)</code>: Extract key phrases from the whole document (true) or from particular sentences which the chunks refer to (false) Default value is ‘true’.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setDropPunctuation(value: Boolean)</code>: Remove punctuation marks from input chunks.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setSelectMostDifferent(value: Boolean)</code>: Let the model return the top N key phrases which are the most different from each other.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setTopN(value: Int)</code>: Set the number of key phrases to extract.</p>
      </li>
    </ul>

    <p>This model is a subclass of [[BertSentenceEmbeddings]] and shares all parameters with it. It can load any pretrained BertSentenceEmbeddings model. Available models can be found at the <a href="https://nlp.johnsnowlabs.com/models?task=Sentence+Embeddings">Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunk_key_phrase_extraction/index.html#sparknlp_jsl.annotator.chunker.chunk_key_phrase_extraction.ChunkKeyPhraseExtraction">ChunkKeyPhraseExtraction</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkKeyPhraseExtraction.html">ChunkKeyPhraseExtraction</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ChunkKeyPhraseExtraction.ipynb">ChunkKeyPhraseExtractionNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span> \

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl_slim"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">key_phrase_extractor</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkKeyPhraseExtraction</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setTopN</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDocumentLevelProcessing</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDivergence</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documenter</span><span class="p">,</span> 
    <span class="n">sentencer</span><span class="p">,</span> 
    <span class="n">tokenizer</span><span class="p">,</span> 
    <span class="n">embeddings</span><span class="p">,</span> 
    <span class="n">ner_tagger</span><span class="p">,</span> 
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">key_phrase_extractor</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Her Diabetes has become type 2 in the last year with her Diabetes.He complains of swelling in his right forearm."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_chunk_key_phrases) AS key_phrase"</span><span class="p">)</span>\
       <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"key_phrase.result"</span><span class="p">,</span>
                   <span class="s">"key_phrase.metadata.entity"</span><span class="p">,</span>
                   <span class="s">"key_phrase.metadata.DocumentSimilarity"</span><span class="p">,</span>
                   <span class="s">"key_phrase.metadata.MMRScore"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------+-------------------------+------------------+-----------------+</span>
<span class="o">|</span><span class="n">result</span>  <span class="o">|</span><span class="n">entity</span>                   <span class="o">|</span><span class="n">DocumentSimilarity</span><span class="o">|</span><span class="n">MMRScore</span>         <span class="o">|</span>
<span class="o">+--------+-------------------------+------------------+-----------------+</span>
<span class="o">|</span><span class="n">Diabetes</span><span class="o">|</span><span class="n">Disease_Syndrome_Disorder</span><span class="o">|</span><span class="mf">0.66827321499841</span>  <span class="o">|</span><span class="mf">0.400963944931921</span><span class="o">|</span>
<span class="o">+--------+-------------------------+------------------+-----------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
        
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">key_phrase_extractor</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkKeyPhraseExtraction</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setTopN</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDocumentLevelProcessing</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDivergence</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">key_phrase_extractor</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"""In 2020, we acquired certain assets of Spell Security Private Limited (also known as "Spell Security"). More specifically, their Compliance product - Policy Compliance (PC)")."""</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_chunk_key_phrases) AS key_phrase"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"key_phrase.result"</span><span class="p">,</span>
                  <span class="s">"key_phrase.metadata.entity"</span><span class="p">,</span>
                  <span class="s">"key_phrase.metadata.DocumentSimilarity"</span><span class="p">,</span>
                  <span class="s">"key_phrase.metadata.MMRScore"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------------------------------+-------+------------------+-------------------+</span>
<span class="o">|</span><span class="n">result</span>                        <span class="o">|</span><span class="n">entity</span> <span class="o">|</span><span class="n">DocumentSimilarity</span><span class="o">|</span><span class="n">MMRScore</span>           <span class="o">|</span>
<span class="o">+------------------------------+-------+------------------+-------------------+</span>
<span class="o">|</span><span class="n">Policy</span> <span class="n">Compliance</span>             <span class="o">|</span><span class="n">PRODUCT</span><span class="o">|</span><span class="mf">0.6446724461374882</span><span class="o">|</span><span class="mf">0.38680348305268175</span><span class="o">|</span>
<span class="o">|</span><span class="n">Spell</span> <span class="n">Security</span> <span class="n">Private</span> <span class="n">Limited</span><span class="o">|</span><span class="n">ORG</span>    <span class="o">|</span><span class="mf">0.6282153013401193</span><span class="o">|</span><span class="mf">0.3769291957818915</span> <span class="o">|</span>
<span class="o">+------------------------------+-------+------------------+-------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
        
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">key_phrase_extractor</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkKeyPhraseExtraction</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setTopN</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDocumentLevelProcessing</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDivergence</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">key_phrase_extractor</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"""This INTELLECTUAL PROPERTY AGREEMENT (this "Agreement"), dated as of December 31, 2018 (the "Effective Date") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ("Seller") and AFI Licensing LLC, a Delaware limited liability company ("Licensing" and together with Seller, "Arizona") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand, a "Party" and collectively, the "Parties").
"""</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_chunk_key_phrases) AS key_phrase"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"key_phrase.result"</span><span class="p">,</span>
                  <span class="s">"key_phrase.metadata.entity"</span><span class="p">,</span>
                  <span class="s">"key_phrase.metadata.DocumentSimilarity"</span><span class="p">,</span>
                  <span class="s">"key_phrase.metadata.MMRScore"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------+------+------------------+-------------------+</span>
<span class="o">|</span><span class="n">result</span>        <span class="o">|</span><span class="n">entity</span><span class="o">|</span><span class="n">DocumentSimilarity</span><span class="o">|</span><span class="n">MMRScore</span>           <span class="o">|</span>
<span class="o">+--------------+------+------------------+-------------------+</span>
<span class="o">|</span><span class="n">Buyer</span> <span class="n">Entities</span><span class="o">|</span><span class="n">ALIAS</span> <span class="o">|</span><span class="mf">0.5680936022739617</span><span class="o">|</span><span class="mf">0.34085617490878395</span><span class="o">|</span>
<span class="o">+--------------+------+------------------+-------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_tagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl_slim"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span> 
 
<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"ner_tags"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">key_phrase_extractor</span> <span class="k">=</span> <span class="nv">ChunkKeyPhraseExtraction</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setTopN</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setDocumentLevelProcessing</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setDivergence</span><span class="o">(</span><span class="mf">0.4</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"ner_chunks"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
  <span class="n">documenter</span><span class="o">,</span> 
  <span class="n">sentencer</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">embeddings</span><span class="o">,</span> 
  <span class="n">ner_tagger</span><span class="o">,</span> 
  <span class="n">ner_converter</span><span class="o">,</span> 
  <span class="n">key_phrase_extractor</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""Her Diabetes has become type 2 in the last year with her Diabetes.He complains of swelling in his right forearm."""</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------------------+------------------+-----------------+</span>
<span class="o">|</span><span class="n">result</span>  <span class="o">|</span><span class="n">entity</span>                   <span class="o">|</span><span class="nc">DocumentSimilarity</span><span class="o">|</span><span class="nc">MMRScore</span>         <span class="o">|</span>
<span class="o">+--------+-------------------------+------------------+-----------------+</span>
<span class="o">|</span><span class="nc">Diabetes</span><span class="o">|</span><span class="nc">Disease_Syndrome_Disorder</span><span class="o">|</span><span class="mf">0.66827321499841</span>  <span class="o">|</span><span class="mf">0.400963944931921</span><span class="o">|</span>
<span class="o">+--------+-------------------------+------------------+-----------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> <span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">key_phrase_extractor</span> <span class="k">=</span> <span class="nv">ChunkKeyPhraseExtraction</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setTopN</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setDocumentLevelProcessing</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setDivergence</span><span class="o">(</span><span class="mf">0.4</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
  <span class="n">documentAssembler</span><span class="o">,</span> 
  <span class="n">sentenceDetector</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">embeddings</span><span class="o">,</span> 
  <span class="n">ner_model</span><span class="o">,</span> <span class="n">n</span>
  <span class="n">er_converter</span><span class="o">,</span> 
  <span class="n">key_phrase_extractor</span><span class="o">)</span> <span class="o">)</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""In 2020, we acquired certain assets of Spell Security Private Limited (also known as "Spell Security"). More specifically, their Compliance product - Policy Compliance (PC)."""</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+------------------------------+-------+------------------+-------------------+</span>
<span class="o">|</span><span class="n">result</span>                        <span class="o">|</span><span class="n">entity</span> <span class="o">|</span><span class="nc">DocumentSimilarity</span><span class="o">|</span><span class="nc">MMRScore</span>           <span class="o">|</span>
<span class="o">+------------------------------+-------+------------------+-------------------+</span>
<span class="o">|</span><span class="nc">Policy</span> <span class="nc">Compliance</span>             <span class="o">|</span><span class="nc">PRODUCT</span><span class="o">|</span><span class="mf">0.6446724461374882</span><span class="o">|</span><span class="mf">0.38680348305268175</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Spell</span> <span class="nc">Security</span> <span class="nc">Private</span> <span class="nc">Limited</span><span class="o">|</span><span class="nc">ORG</span>    <span class="o">|</span><span class="mf">0.6282153013401193</span><span class="o">|</span><span class="mf">0.3769291957818915</span> <span class="o">|</span>
<span class="o">+------------------------------+-------+------------------+-------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> <span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">key_phrase_extractor</span> <span class="k">=</span> <span class="nv">ChunkKeyPhraseExtraction</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setTopN</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setDocumentLevelProcessing</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setDivergence</span><span class="o">(</span><span class="mf">0.4</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_key_phrases"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
  <span class="n">documentAssembler</span><span class="o">,</span> 
  <span class="n">sentenceDetector</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">embeddings</span><span class="o">,</span> 
  <span class="n">ner_model</span><span class="o">,</span> <span class="n">n</span>
  <span class="n">er_converter</span><span class="o">,</span> 
  <span class="n">key_phrase_extractor</span><span class="o">)</span> <span class="o">)</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""This INTELLECTUAL PROPERTY AGREEMENT (this "Agreement"), dated as of December 31, 2018 (the "Effective Date") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ("Seller") and AFI Licensing LLC, a Delaware limited liability company ("Licensing" and together with Seller, "Arizona") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand, a "Party" and collectively, the "Parties")."""</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------+------+------------------+-------------------+</span>
<span class="o">|</span><span class="n">result</span>        <span class="o">|</span><span class="n">entity</span><span class="o">|</span><span class="nc">DocumentSimilarity</span><span class="o">|</span><span class="nc">MMRScore</span>           <span class="o">|</span>
<span class="o">+--------------+------+------------------+-------------------+</span>
<span class="o">|</span><span class="nc">Buyer</span> <span class="nc">Entities</span><span class="o">|</span><span class="nc">ALIAS</span> <span class="o">|</span><span class="mf">0.5680936022739617</span><span class="o">|</span><span class="mf">0.34085617490878395</span><span class="o">|</span>
<span class="o">+--------------+------+------------------+-------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunkmapper">ChunkMapper</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries.</p>

    <p>This is the AnnotatorModel of the ChunkMapper, which can be used to access pretrained models with the <code class="language-plaintext highlighter-rouge">.pretrained()</code> or <code class="language-plaintext highlighter-rouge">.load()</code> methods. To train a new model, check the documentation of the <a href="https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#chunkmapperapproach">ChunkMapperApproach</a> annotator.</p>

    <p>The annotator also allows using fuzzy matching, which can take into consideration parts of the tokens tha can map even when word order is different, char ngrams that can map even when thre are typos, and using fuzzy distance metric (Jaccard, Levenshtein, etc.).</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setRels</code> <em>(List[str])</em>: Relations that we are going to use to map the chunk</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setLowerCase</code> <em>(Boolean)</em>: Set if we want to map the chunks in lower case or not (Default: True)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setAllowMultiTokenChunk</code> <em>(Boolean)</em>: Whether to skip relations with multitokens (Default: True)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setMultivaluesRelations</code> <em>(Boolean)</em>:  Whether to decide to return all values in a relation together or separately (Default: False)</p>
      </li>
    </ul>

    <p>Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb">Healthcare Chunk Mapping</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LABEL_DEPENDENCY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunkmapper/index.html#sparknlp_jsl.annotator.chunker.chunkmapper.ChunkMapperModel">ChunkMapperModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/finance/chunk_classification/resolution/ChunkMapperModel.html">ChunkMapperModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ChunkMapperModel.ipynb">ChunkMapperModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DRUG"</span><span class="p">])</span>

<span class="n">chunkToDoc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunk2Doc</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks_doc"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span>\
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks_doc"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">rxnorm_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span>\
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sbert_embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>\

<span class="n">resolver2chunk</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Resolution2Chunk</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"rxnorm_code"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_chunk"</span><span class="p">)</span>\

<span class="n">chunkerMapper</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"rxnorm_drug_brandname_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"rxnorm_chunk"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_drug_brandname_mapper"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"rxnorm_brandname"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">documenter</span><span class="p">,</span>
        <span class="n">sentencer</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">words_embedder</span><span class="p">,</span>
        <span class="n">ner_tagger</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">chunkToDoc</span><span class="p">,</span>
        <span class="n">sbert_embedder</span><span class="p">,</span>
        <span class="n">rxnorm_resolver</span><span class="p">,</span>
        <span class="n">resolver2chunk</span><span class="p">,</span>
        <span class="n">chunkerMapper</span>
        <span class="p">])</span>


<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"The doctor prescribed Sinequan 150 MG for depression and Zonalon 50 mg for managing skin itching"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span><span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunks</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                     <span class="n">result</span><span class="p">.</span><span class="n">rxnorm_code</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
                  <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">),</span>
                          <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="o">+----------+-----------+----------------------------+</span>
<span class="o">|</span><span class="n">ner_chunks</span><span class="o">|</span><span class="n">rxnorm_code</span><span class="o">|</span><span class="n">rxnorm_drug_brandname_mapper</span><span class="o">|</span>
<span class="o">+----------+-----------+----------------------------+</span>
<span class="o">|</span>  <span class="n">Sinequan</span><span class="o">|</span>     <span class="mi">224915</span><span class="o">|</span>         <span class="n">Sinequan</span> <span class="p">(</span><span class="n">Sinequan</span><span class="p">)</span><span class="o">|</span>
<span class="o">|</span>   <span class="n">Zonalon</span><span class="o">|</span>       <span class="mi">9801</span><span class="o">|</span>           <span class="n">Zonalon</span> <span class="p">(</span><span class="n">Zonalon</span><span class="p">)</span><span class="o">|</span>
<span class="o">+----------+-----------+----------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_ticker"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">CM</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finmapper_nasdaq_ticker_stock_screener'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'finance/models'</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mappings"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span> 
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span> 
  <span class="n">ner_converter</span><span class="p">,</span> 
  <span class="n">CM</span><span class="p">])</span>
                                 
<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"""There are some serious purchases and sales of AMZN stock today."""</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="o">+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span><span class="n">result</span>                                                                                                                                                             <span class="o">|</span>
<span class="o">+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">AMZN</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">AMZN</span><span class="p">,</span> <span class="n">Amazon</span><span class="p">.</span><span class="n">com</span> <span class="n">Inc</span><span class="p">.</span> <span class="n">Common</span> <span class="n">Stock</span><span class="p">,</span> <span class="err">$</span><span class="mf">98.12</span><span class="p">,</span> <span class="mf">2.85</span><span class="p">,</span> <span class="mf">2.991</span><span class="o">%</span><span class="p">,</span> <span class="mf">9.98556270184E11</span><span class="p">,</span> <span class="n">United</span> <span class="n">States</span><span class="p">,</span> <span class="mi">1997</span><span class="p">,</span> <span class="mi">85412563</span><span class="p">,</span> <span class="n">Consumer</span> <span class="n">Discretionary</span><span class="p">,</span> <span class="n">Catalog</span><span class="o">/</span><span class="n">Specialty</span> <span class="n">Distribution</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'glove_100d'</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">'document'</span><span class="p">,</span> <span class="s">'token'</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'embeddings'</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"onto_100"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
 
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"CARDINAL"</span><span class="p">])</span>

<span class="n">CM</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkMapperModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legmapper_edgar_irs"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mappings"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span> 
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span> 
  <span class="n">ner_converter</span><span class="p">,</span> 
  <span class="n">CM</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"""873474341 is an American multinational corporation that is engaged in the design, development, manufacturing, and worldwide marketing and sales of footwear, apparel, equipment, accessories, and services"""</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span><span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="o">+-----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>     <span class="o">|</span><span class="n">result</span>                                                                                                                                                               <span class="o">|</span>
<span class="o">+-----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="mi">873474341</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">Masterworks</span> <span class="mi">096</span><span class="p">,</span> <span class="n">LLC</span><span class="p">,</span> <span class="n">RETAIL</span><span class="o">-</span><span class="n">RETAIL</span> <span class="n">STORES</span><span class="p">,</span> <span class="n">NEC</span> <span class="p">[</span><span class="mi">5990</span><span class="p">],</span> <span class="mi">5990</span><span class="p">,</span> <span class="mi">873474341</span><span class="p">,</span> <span class="mi">1231</span><span class="p">,</span> <span class="n">NY</span><span class="p">,</span> <span class="n">DE</span><span class="p">,</span> <span class="mi">225</span> <span class="n">LIBERTY</span> <span class="n">STREET</span><span class="p">,</span> <span class="n">NEW</span> <span class="n">YORK</span><span class="p">,</span> <span class="n">NY</span><span class="p">,</span> <span class="mi">10281</span><span class="p">,</span> <span class="mi">2035185172</span><span class="p">,</span> <span class="p">,</span> <span class="p">,</span> <span class="mi">2022</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1894064</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
 <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_tagger</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span>
 <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"ner_tags"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"DRUG"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunkToDoc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Doc</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks_doc"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sbert_embedder</span> <span class="k">=</span> <span class="nc">BertSentenceEmbeddings</span>
 <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunks_doc"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">rxnorm_resolver</span> <span class="k">=</span> <span class="nc">SentenceEntityResolverModel</span>
 <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"rxnorm_code"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">resolver2chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Resolution2Chunk</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"rxnorm_code"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"rxnorm_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunkerMapper</span> <span class="k">=</span> <span class="nv">ChunkMapperModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"rxnorm_drug_brandname_mapper"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"rxnorm_chunk"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"rxnorm_drug_brandname_mapper"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"rxnorm_brandname"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
 <span class="n">documenter</span><span class="o">,</span> 
 <span class="n">sentencer</span><span class="o">,</span> 
 <span class="n">tokenizer</span><span class="o">,</span> 
 <span class="n">words_embedder</span><span class="o">,</span> 
 <span class="n">ner_tagger</span><span class="o">,</span> 
 <span class="n">ner_converter</span><span class="o">,</span> 
 <span class="n">chunkToDoc</span><span class="o">,</span> 
 <span class="n">sbert_embedder</span><span class="o">,</span> 
 <span class="n">rxnorm_resolver</span><span class="o">,</span> 
 <span class="n">resolver2chunk</span><span class="o">,</span>
  <span class="n">chunkerMapper</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""The doctor prescribed Sinequan 150 MG for depression and Zonalon 50 mg for managing skin itching"""</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span><span class="k">=</span> <span class="nv">mapper_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+----------+-----------+----------------------------+</span>
<span class="o">|</span><span class="n">ner_chunks</span><span class="o">|</span><span class="n">rxnorm_code</span><span class="o">|</span><span class="n">rxnorm_drug_brandname_mapper</span><span class="o">|</span>
<span class="o">+----------+-----------+----------------------------+</span>
<span class="o">|</span>  <span class="nc">Sinequan</span><span class="o">|</span>     <span class="mi">224915</span><span class="o">|</span>         <span class="nc">Sinequan</span> <span class="o">(</span><span class="nc">Sinequan</span><span class="o">)|</span>
<span class="o">|</span>   <span class="nc">Zonalon</span><span class="o">|</span>       <span class="mi">9801</span><span class="o">|</span>           <span class="nc">Zonalon</span> <span class="o">(</span><span class="nc">Zonalon</span><span class="o">)|</span>
<span class="o">+----------+-----------+----------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_ticker"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">CM</span> <span class="k">=</span> <span class="nv">ChunkMapperModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finmapper_nasdaq_ticker_stock_screener"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mappings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
  <span class="n">document_assembler</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">embeddings</span><span class="o">,</span> 
  <span class="n">ner_model</span><span class="o">,</span> 
  <span class="n">ner_converter</span><span class="o">,</span> 
  <span class="nc">CM</span><span class="o">)</span> <span class="o">)</span> 
 
<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""There are some serious purchases and sales of AMZN stock today."""</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span><span class="o">|</span><span class="n">result</span>                                                                                                                                                             <span class="o">|</span>
<span class="o">+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">AMZN</span><span class="o">]|[</span><span class="kt">AMZN</span>, <span class="kt">Amazon.com</span> <span class="kt">Inc.</span> <span class="kt">Common</span> <span class="kt">Stock</span>, <span class="kt">$98.</span><span class="err">12</span>, <span class="err">2</span><span class="kt">.</span><span class="err">85</span>, <span class="err">2</span><span class="kt">.</span><span class="err">991</span><span class="kt">%</span>, <span class="err">9</span><span class="kt">.</span><span class="err">98556270184</span><span class="kt">E11</span>, <span class="kt">United</span> <span class="kt">States</span>, <span class="err">1997</span>, <span class="err">85412563</span>, <span class="kt">Consumer</span> <span class="kt">Discretionary</span>, <span class="kt">Catalog/Specialty</span> <span class="kt">Distribution</span><span class="o">]|</span>
<span class="o">+------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"glove_100d"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">NerDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"onto_100"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"CARDINAL"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">CM</span> <span class="k">=</span> <span class="nv">ChunkMapperModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legmapper_edgar_irs"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"legal/models"</span><span class="o">)</span> 
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mappings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
  <span class="n">document_assembler</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">embeddings</span><span class="o">,</span> 
  <span class="n">ner_model</span><span class="o">,</span> 
  <span class="n">ner_converter</span><span class="o">,</span> 
  <span class="nc">CM</span><span class="o">)</span> <span class="o">)</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""873474341 is an American multinational corporation that is engaged in the design,development,manufacturing,and worldwide marketing and sales of footwear,apparel,equipment,accessories,and services"""</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span><span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>     <span class="o">|</span><span class="n">result</span>                                                                                                                                                               <span class="o">|</span>
<span class="o">+-----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="err">873474341</span><span class="o">]|[</span><span class="kt">Masterworks</span> <span class="err">096</span>, <span class="kt">LLC</span>, <span class="kt">RETAIL-RETAIL</span> <span class="kt">STORES</span>, <span class="kt">NEC</span> <span class="o">[</span><span class="err">5990</span><span class="o">]</span>, <span class="err">5990</span>, <span class="err">873474341</span>, <span class="err">1231</span>, <span class="kt">NY</span>, <span class="kt">DE</span>, <span class="err">225</span> <span class="kt">LIBERTY</span> <span class="kt">STREET</span>, <span class="kt">NEW</span> <span class="kt">YORK</span>, <span class="kt">NY</span>, <span class="err">10281</span>, <span class="err">2035185172</span>, , , <span class="err">2022</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">10</span>, <span class="err">1894064</span><span class="o">]|</span>
<span class="o">+-----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>We can use ChunkMapper to map entities with their associated code/reference based on pre-defined dictionaries.</p>

    <p>This is the AnnotatorApproach of the ChunkMapper, which can be used to train ChunkMapper models by giving a custom mapping dictionary. To use pretriained models, check the documentation of the <a href="https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#chunkmappermodel">ChunkMapperModel</a> annotator.</p>

    <p>The annotator also allows using fuzzy matching, which can take into consideration parts of the tokens tha can map even when word order is different, char ngrams that can map even when thre are typos, and using fuzzy distance metric (Jaccard, Levenshtein, etc.).</p>

    <p>Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb">Healthcare Chunk Mapping</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LABEL_DEPENDENCY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunkmapper/index.html#sparknlp_jsl.annotator.chunker.chunkmapper.ChunkMapperApproach">ChunkMapperApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/finance/chunk_classification/resolution/ChunkMapperApproach.html">ChunkMapperApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ChunkMapperApproach.ipynb">ChunkMapperApproachModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># First, create a dictionay in JSON format following this schema:
</span><span class="kn">import</span> <span class="nn">json</span>
<span class="n">data_set</span><span class="o">=</span> <span class="p">{</span>
  <span class="s">"mappings"</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s">"key"</span><span class="p">:</span> <span class="s">"metformin"</span><span class="p">,</span>
      <span class="s">"relations"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"action"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"hypoglycemic"</span><span class="p">,</span> <span class="s">"Drugs Used In Diabetes"</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"treatment"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"diabetes"</span><span class="p">,</span> <span class="s">"t2dm"</span><span class="p">]</span>
        <span class="p">}</span>
      <span class="p">]</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'sample_drug.json'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>


<span class="c1"># Create a pipeline
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1">#NER model to detect drug in the text
</span><span class="n">clinical_ner</span> <span class="o">=</span>  <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology_small"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLabelCasing</span><span class="p">(</span><span class="s">"upper"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DRUG"</span><span class="p">])</span>

<span class="n">chunkerMapper</span> <span class="o">=</span>  <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMapperApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mappings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"/content/sample_drug.json"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"action"</span><span class="p">])</span> <span class="c1">#or treatment
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">chunkerMapper</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"The patient was given 1 unit of metformin daily."</span><span class="p">]</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">res</span><span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">stages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">write</span><span class="p">().</span><span class="n">save</span><span class="p">(</span><span class="s">"models/drug_mapper"</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># First, create a dictionay in JSON format following this schema:
</span><span class="kn">import</span> <span class="nn">json</span>

<span class="n">data_set</span><span class="o">=</span> <span class="p">{</span>
  <span class="s">"mappings"</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s">"key"</span><span class="p">:</span> <span class="s">"Rayton Solar Inc."</span><span class="p">,</span>
      <span class="s">"relations"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"name"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">'Rayton Solar Inc.'</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"sic"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">'SEMICONDUCTORS &amp; RELATED DEVICES [3674]'</span><span class="p">]</span>
        <span class="p">}]</span>
    <span class="p">}]</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'sample_finance.json'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Create a pipeline
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">finance_ner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"ORG"</span><span class="p">])</span> <span class="c1"># Return only ORG entities
</span>
<span class="n">chunkerMapper</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMapperApproach</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mappings"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"/content/sample_finance.json"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setRels</span><span class="p">(</span><span class="n">all_rels</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">sentence_detector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">word_embeddings</span><span class="p">,</span>
  <span class="n">finance_ner</span><span class="p">,</span>
  <span class="n">ner_converter</span><span class="p">,</span>
  <span class="n">chunkerMapper</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price. "</span><span class="p">]</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">res</span><span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">stages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">write</span><span class="p">().</span><span class="n">save</span><span class="p">(</span><span class="s">"models/finance_mapper"</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># First, create a dictionay in JSON format following this schema:
</span><span class="kn">import</span> <span class="nn">json</span>

<span class="n">data_set</span><span class="o">=</span> <span class="p">{</span>
  <span class="s">"mappings"</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s">"key"</span><span class="p">:</span> <span class="s">"Rayton Solar Inc."</span><span class="p">,</span>
      <span class="s">"relations"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"name"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">'Rayton Solar Inc.'</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"sic"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">'SEMICONDUCTORS &amp; RELATED DEVICES [3674]'</span><span class="p">]</span>
        <span class="p">}]</span>
    <span class="p">}]</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'sample_legal.json'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c1"># Create a pipeline
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">legal_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_org_per_role_date"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"ORG"</span><span class="p">])</span> <span class="c1"># Return only ORG entities
</span>
<span class="n">chunkerMapper</span> <span class="o">=</span>  <span class="n">legal</span><span class="p">.</span><span class="n">ChunkMapperApproach</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mappings"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"/content/sample_legal.json"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setRels</span><span class="p">(</span><span class="n">all_rels</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">sentence_detector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">word_embeddings</span><span class="p">,</span>
  <span class="n">legal_ner</span><span class="p">,</span>
  <span class="n">ner_converter</span><span class="p">,</span>
  <span class="n">chunkerMapper</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="s">"AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price. "</span><span class="p">]</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">res</span><span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">stages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">write</span><span class="p">().</span><span class="n">save</span><span class="p">(</span><span class="s">"models/legal_mapper"</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> <span class="c1">//NER model to detect drug in the text </span>

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology_small"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"DRUG"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">chunkerMapper</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMapperApproach</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mappings"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"/content/sample_drug.json"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"action"</span><span class="o">)</span> <span class="o">)</span> <span class="c1">//or treatment </span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span> 
  <span class="n">sentence_detector</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">word_embeddings</span><span class="o">,</span> 
  <span class="n">clinical_ner</span><span class="o">,</span> 
  <span class="n">ner_converter</span><span class="o">,</span> 
  <span class="n">chunkerMapper</span><span class="o">)</span> <span class="o">)</span> 
<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"The patient was given 1 unit of metformin daily."</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nf">seq</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">text</span><span class="o">))</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span> 

<span class="n">res</span><span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span> 
<span class="nv">model</span><span class="o">.</span><span class="py">stagesArray</span><span class="o">(-</span><span class="mi">1</span><span class="o">)</span> <span class="o">.</span><span class="py">write</span><span class="o">()</span> <span class="o">.</span><span class="py">save</span><span class="o">(</span><span class="s">"models/drug_mapper"</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">)</span> <span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">finance_ner</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">)</span> <span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">)</span> <span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ORG"</span><span class="o">)</span> <span class="o">)</span> <span class="c1">// Return only ORG entities </span>

<span class="k">val</span> <span class="nv">chunkerMapper</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMapperApproach</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mappings"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"/content/sample_json"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="n">all_rels</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
  <span class="n">document_assembler</span><span class="o">,</span> 
  <span class="n">sentence_detector</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">word_embeddings</span><span class="o">,</span> 
  <span class="n">finance_ner</span><span class="o">,</span> 
  <span class="n">ner_converter</span><span class="o">,</span> 
  <span class="n">chunkerMapper</span><span class="o">)</span> <span class="o">)</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price. "</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nf">seq</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">text</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span> 
<span class="n">res</span><span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span> 

<span class="nv">model</span><span class="o">.</span><span class="py">stagesArray</span><span class="o">(-</span><span class="mi">1</span><span class="o">)</span> <span class="o">.</span><span class="py">write</span><span class="o">()</span> <span class="o">.</span><span class="py">save</span><span class="o">(</span><span class="s">"models/finance_mapper"</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
 
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">legal_ner</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_org_per_role_date"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"legal/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"ORG"</span><span class="o">)</span> <span class="c1">// Return only ORG entities </span>

<span class="k">val</span> <span class="nv">chunkerMapper</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMapperApproach</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mappings"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"/content/sample_json"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="n">all_rels</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
  <span class="n">document_assembler</span><span class="o">,</span> 
  <span class="n">sentence_detector</span><span class="o">,</span> 
  <span class="n">tokenizer</span><span class="o">,</span> 
  <span class="n">word_embeddings</span><span class="o">,</span> 
  <span class="n">legal_ner</span><span class="o">,</span> 
  <span class="n">ner_converter</span><span class="o">,</span> 
  <span class="n">chunkerMapper</span><span class="o">)</span> <span class="o">)</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"AWA Group LP intends to pay dividends on the Common Units on a quarterly basis at an annual rate of 8.00% of the Offering Price. "</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nf">seq</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span> 

<span class="n">res</span><span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span> 
<span class="nv">model</span><span class="o">.</span><span class="py">stagesArray</span><span class="o">(-</span><span class="mi">1</span><span class="o">)</span> <span class="o">.</span><span class="py">write</span><span class="o">()</span> <span class="o">.</span><span class="py">save</span><span class="o">(</span><span class="s">"models/legal_mapper"</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunkmapperfilterer">ChunkMapperFilterer</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">ChunkMapperFilterer</code> is an annotator to be used after <code class="language-plaintext highlighter-rouge">ChunkMapper</code> that allows to filter chunks based on the results of the mapping, whether it was successful or failed.</p>

    <p>Parametres:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">ReturnCriteria</code> <em>(String)</em>: Has two possible values: “success” or “fail”. If “fail” (default), returns the chunks that are not in the label dependencies; if “success”, returns the labels that were successfully mapped by the <code class="language-plaintext highlighter-rouge">ChunkMapperModel</code> annotator.</li>
    </ul>

    <p>Example usage and more details can be found on Spark NLP Workshop repository accessible in GitHub, for example the notebook <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb">Healthcare Chunk Mapping</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, LABEL_DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunkmapper_filterer/index.html#sparknlp_jsl.annotator.chunker.chunkmapper_filterer.ChunkMapperFilterer">ChunkMapperFilterer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkMapperFilterer.html">ChunkMapperFilterer</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ChunkMapperFilterer.ipynb">ChunkMapperFiltererNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology_greedy"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="n">chunkerMapper</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"rxnorm_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"RxNorm_Mapper"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"rxnorm_code"</span><span class="p">])</span>

<span class="n">chunk_mapper_filterer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMapperFilterer</span><span class="p">()</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">,</span> <span class="s">"RxNorm_Mapper"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunks_fail"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setReturnCriteria</span><span class="p">(</span><span class="s">"fail"</span><span class="p">)</span>

<span class="n">mapper_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
      <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">document_assembler</span><span class="p">,</span>
          <span class="n">sentence_detector</span><span class="p">,</span>
          <span class="n">tokenizer</span><span class="p">,</span>
          <span class="n">word_embeddings</span><span class="p">,</span>
          <span class="n">ner_model</span><span class="p">,</span>
          <span class="n">ner_converter</span><span class="p">,</span>
          <span class="n">chunkerMapper</span><span class="p">,</span>
          <span class="n">chunkerMapper</span><span class="p">,</span>
          <span class="n">chunk_mapper_filterer</span>
      <span class="p">])</span>

<span class="n">samples</span> <span class="o">=</span> <span class="p">[[</span><span class="s">"The patient was given Adapin 10 MG, coumadn 5 mg"</span><span class="p">],</span>
           <span class="p">[</span><span class="s">"The patient was given Avandia 4 mg, Tegretol, zitiga"</span><span class="p">]</span> <span class="p">]</span>
           
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">samples</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">mapper_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"chunk.result as chunk"</span><span class="p">,</span> 
                  <span class="s">"RxNorm_Mapper.result as RxNorm_Mapper"</span><span class="p">,</span> 
                  <span class="s">"chunks_fail.result as chunks_fail"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------+----------------------+--------------+</span>
<span class="o">|</span><span class="n">chunk</span>                           <span class="o">|</span><span class="n">RxNorm_Mapper</span>         <span class="o">|</span><span class="n">chunks_fail</span>   <span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Adapin</span> <span class="mi">10</span> <span class="n">MG</span><span class="p">,</span> <span class="n">coumadn</span> <span class="mi">5</span> <span class="n">mg</span><span class="p">]</span>    <span class="o">|</span><span class="p">[</span><span class="mi">1000049</span><span class="p">,</span> <span class="n">NONE</span><span class="p">]</span>       <span class="o">|</span><span class="p">[</span><span class="n">coumadn</span> <span class="mi">5</span> <span class="n">mg</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">Avandia</span> <span class="mi">4</span> <span class="n">mg</span><span class="p">,</span> <span class="n">Tegretol</span><span class="p">,</span> <span class="n">zitiga</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="mi">261242</span><span class="p">,</span> <span class="mi">203029</span><span class="p">,</span> <span class="n">NONE</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">zitiga</span><span class="p">]</span>      <span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
 
<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology_greedy"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkerMapper</span> <span class="k">=</span> <span class="nv">ChunkMapperModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"rxnorm_mapper"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"RxNorm_Mapper"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"rxnorm_code"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">chunk_mapper_filterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMapperFilterer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">,</span> <span class="s">"RxNorm_Mapper"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunks_fail"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setReturnCriteria</span><span class="o">(</span><span class="s">"fail"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">mapper_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">sentence_detector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">word_embeddings</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">chunkerMapper</span><span class="o">,</span>
    <span class="n">chunk_mapper_filterer</span>
    <span class="o">))</span>


<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The patient was given Adapin 10 MG, coumadn 5 mg"</span><span class="o">,</span>
<span class="s">"The patient was given Avandia 4 mg, Tegretol, zitiga"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">mapper_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------------------------+----------------------+--------------+</span>
<span class="o">|</span><span class="n">chunk</span>                           <span class="o">|</span><span class="nc">RxNorm_Mapper</span>         <span class="o">|</span><span class="n">chunks_fail</span>   <span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+</span>
<span class="o">|[</span><span class="kt">Adapin</span> <span class="err">10</span> <span class="kt">MG</span>, <span class="kt">coumadn</span> <span class="err">5</span> <span class="kt">mg</span><span class="o">]</span>    <span class="o">|[</span><span class="err">1000049</span>, <span class="kt">NONE</span><span class="o">]</span>       <span class="o">|[</span><span class="kt">coumadn</span> <span class="err">5</span> <span class="kt">mg</span><span class="o">]|</span>
<span class="o">|[</span><span class="kt">Avandia</span> <span class="err">4</span> <span class="kt">mg</span>, <span class="kt">Tegretol</span>, <span class="kt">zitiga</span><span class="o">]|[</span><span class="err">261242</span>, <span class="err">203029</span>, <span class="kt">NONE</span><span class="o">]|[</span><span class="kt">zitiga</span><span class="o">]</span>      <span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunkmerge">ChunkMerge</h2>

  <div class="annotator_type tac mont">Approach</div>

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Merges two chunk columns coming from two annotators(NER, ContextualParser or any other annotator producing
chunks). The merger of the two chunk columns is made by selecting one chunk from one of the columns according
to certain criteria.
The decision on which chunk to select is made according to the chunk indices in the source document.
(chunks with longer lengths and highest information will be kept from each source)
Labels can be changed by setReplaceDictResource.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</li>
      <li><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</li>
      <li><code class="language-plaintext highlighter-rouge">mergeOverlapping</code>: (Boolean) Sets whether to merge overlapping matched chunks. Default <code class="language-plaintext highlighter-rouge">True</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">falsePositivesResource</code>: Sets file with false positive pairs</li>
      <li><code class="language-plaintext highlighter-rouge">replaceDictResource</code>: Sets replace dictionary pairs for NER labels</li>
      <li><code class="language-plaintext highlighter-rouge">blackList</code>: (String List) If defined, list of entities to ignore. The rest will be processed.</li>
      <li><code class="language-plaintext highlighter-rouge">whiteList</code>: (String List) If defined, list of entities to accept.</li>
      <li><code class="language-plaintext highlighter-rouge">selectionStrategy</code>: (String) Sets Whether to select annotations sequentially based on annotation order <code class="language-plaintext highlighter-rouge">Sequential</code> or using any other available strategy; currently only <code class="language-plaintext highlighter-rouge">Sequential</code> and <code class="language-plaintext highlighter-rouge">DiverseLonger</code> are available. Default <code class="language-plaintext highlighter-rouge">Sequential</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">orderingFeatures</code>: (String List) The ordering features to use for overlapping entities. Possible values are <code class="language-plaintext highlighter-rouge">ChunkBegin, ChunkLength, ChunkPrecedence, ChunkConfidence.</code></li>
      <li><code class="language-plaintext highlighter-rouge">defaultConfidence</code>: (Float) Sets when ChunkConfidence ordering feature is included and a given annotation does not have any confidence. The value of this param will be used as a confidence score for annotations without a confidence score.</li>
      <li><code class="language-plaintext highlighter-rouge">chunkPrecedence</code>: (String List) Sets what is the precedence order when a chunk labeled by two models.</li>
      <li><code class="language-plaintext highlighter-rouge">chunkPrecedenceValuePrioritization</code>: (String List) Sets when ChunkPrecedence ordering feature is used. This param contains an Array of comma-separated values representing the desired order of prioritization for the values in the metadata fields included from chunkPrecedence.</li>
      <li><code class="language-plaintext highlighter-rouge">resetSentenceIndices</code>: Whether to reset sentence indices to treat the entire output as if it originates from a single document. Default: False.</li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/merge/chunk_merge/index.html#sparknlp_jsl.annotator.merge.chunk_merge.ChunkMergeApproach">ChunkMergeApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/merge/ChunkMergeApproach.html">ChunkMergeApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># Annotator that transforms a text column from dataframe into an Annotation ready for NLP
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="c1"># Sentence Detector annotator, processes various sentences per line
</span><span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Clinical word embeddings trained on PubMED dataset
</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># 1- ner_clinical model
</span><span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"clinical_ner"</span><span class="p">)</span>

<span class="n">clinical_ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"clinical_ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"clinical_ner_chunk"</span><span class="p">)</span>

<span class="c1"># 2- posology ner model
</span><span class="n">posology_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"posology_ner"</span><span class="p">)</span>

<span class="n">posology_ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"posology_ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"posology_ner_chunk"</span><span class="p">)</span>

<span class="c1"># 3- generate a text matcher annotator that extracts female related entities
</span><span class="n">entities</span> <span class="o">=</span> <span class="p">[</span><span class="s">'she'</span><span class="p">,</span> <span class="s">'her'</span><span class="p">,</span> <span class="s">'girl'</span><span class="p">,</span> <span class="s">'woman'</span><span class="p">,</span> <span class="s">'women'</span><span class="p">,</span> <span class="s">'womanish'</span><span class="p">,</span> <span class="s">'womanlike'</span><span class="p">,</span> <span class="s">'womanly'</span><span class="p">,</span> <span class="s">'madam'</span><span class="p">,</span> <span class="s">'madame'</span><span class="p">,</span> <span class="s">'senora'</span><span class="p">,</span> <span class="s">'lady'</span><span class="p">,</span> <span class="s">'miss'</span><span class="p">,</span> <span class="s">'girlfriend'</span><span class="p">,</span> <span class="s">'wife'</span><span class="p">,</span> <span class="s">'bride'</span><span class="p">,</span> <span class="s">'misses'</span><span class="p">,</span> <span class="s">'mrs.'</span><span class="p">,</span> <span class="s">'female'</span><span class="p">]</span>
<span class="k">with</span> <span class="nb">open</span> <span class="p">(</span><span class="s">'female_entities.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">entities</span><span class="p">:</span>
        <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

<span class="c1"># Find female entities using TextMatcher
</span><span class="n">female_entity_extractor</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">TextMatcher</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">'token'</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"female_entities"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEntities</span><span class="p">(</span><span class="s">"female_entities.txt"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEntityValue</span><span class="p">(</span><span class="s">'female_entity'</span><span class="p">)</span>

<span class="c1"># Chunk Merge annotator is used to merge columns
</span><span class="n">chunk_merger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"posology_ner_chunk"</span><span class="p">,</span> <span class="s">'clinical_ner_chunk'</span><span class="p">,</span> <span class="s">"female_entities"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'merged_ner_chunk'</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">clinical_ner_converter</span><span class="p">,</span>
    <span class="n">posology_ner</span><span class="p">,</span>
    <span class="n">posology_ner_converter</span><span class="p">,</span>
    <span class="n">female_entity_extractor</span><span class="p">,</span>
    <span class="n">chunk_merger</span><span class="p">])</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""The lady was treated with a five-day course of amoxicillin for a respiratory tract infection .
She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG ."""</span>


<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">model</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(merged_ner_chunk) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span><span class="s">"a.end"</span><span class="p">,</span><span class="s">"a.result as chunk"</span><span class="p">,</span><span class="s">"a.metadata.entity as entity"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
<span class="o">+-----+---+-----------------------------+-------------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>                        <span class="o">|</span><span class="n">entity</span>       <span class="o">|</span>
<span class="o">+-----+---+-----------------------------+-------------+</span>
<span class="o">|</span><span class="mi">4</span>    <span class="o">|</span><span class="mi">7</span>  <span class="o">|</span><span class="n">lady</span>                         <span class="o">|</span><span class="n">female_entity</span><span class="o">|</span>
<span class="o">|</span><span class="mi">47</span>   <span class="o">|</span><span class="mi">57</span> <span class="o">|</span><span class="n">amoxicillin</span>                  <span class="o">|</span><span class="n">DRUG</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">63</span>   <span class="o">|</span><span class="mi">91</span> <span class="o">|</span><span class="n">a</span> <span class="n">respiratory</span> <span class="n">tract</span> <span class="n">infection</span><span class="o">|</span><span class="n">PROBLEM</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">95</span>   <span class="o">|</span><span class="mi">97</span> <span class="o">|</span><span class="n">She</span>                          <span class="o">|</span><span class="n">female_entity</span><span class="o">|</span>
<span class="o">|</span><span class="mi">106</span>  <span class="o">|</span><span class="mi">114</span><span class="o">|</span><span class="n">metformin</span>                    <span class="o">|</span><span class="n">DRUG</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">118</span>  <span class="o">|</span><span class="mi">126</span><span class="o">|</span><span class="n">glipizide</span>                    <span class="o">|</span><span class="n">TREATMENT</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">134</span>  <span class="o">|</span><span class="mi">146</span><span class="o">|</span><span class="n">dapagliflozin</span>                <span class="o">|</span><span class="n">TREATMENT</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">152</span>  <span class="o">|</span><span class="mi">155</span><span class="o">|</span><span class="n">T2DM</span>                         <span class="o">|</span><span class="n">PROBLEM</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">161</span>  <span class="o">|</span><span class="mi">172</span><span class="o">|</span><span class="n">atorvastatin</span>                 <span class="o">|</span><span class="n">DRUG</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">178</span>  <span class="o">|</span><span class="mi">188</span><span class="o">|</span><span class="n">gemfibrozil</span>                  <span class="o">|</span><span class="n">TREATMENT</span>    <span class="o">|</span>
<span class="o">+-----+---+-----------------------------+-------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">bert_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">fin_ner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finner_deid'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ORG"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span> <span class="c1"># Replace "ORG" entity as "PARTY"
</span>
<span class="n">ner_finner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_org_per_role_date"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_finner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter_finner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_finner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_finner_chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">'ROLE'</span><span class="p">])</span> <span class="c1"># Just use "ROLE" entity from this NER
</span>
<span class="n">chunk_merge</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_finner_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">bert_embeddings</span><span class="p">,</span>
      <span class="n">fin_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_finner</span><span class="p">,</span>
      <span class="n">ner_converter_finner</span><span class="p">,</span>
      <span class="n">chunk_merge</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">deid_merged_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">deid_merged_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+---------------------+---------+</span>
<span class="o">|</span><span class="n">Jeffrey</span> <span class="n">Preston</span> <span class="n">Bezos</span><span class="o">|</span><span class="n">PERSON</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">founder</span>              <span class="o">|</span><span class="n">ROLE</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">CEO</span>                  <span class="o">|</span><span class="n">ROLE</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">Amazon</span>               <span class="o">|</span><span class="n">PARTY</span>    <span class="o">|</span>
<span class="o">+---------------------+---------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">legal_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ALIAS"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span>

<span class="n">ner_signers</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_signers"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_signers"</span><span class="p">)</span> 
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter_signers</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_signers"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_signer_chunk"</span><span class="p">)</span>

<span class="n">chunk_merge</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_signer_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">legal_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_signers</span><span class="p">,</span>
      <span class="n">ner_converter_signers</span><span class="p">,</span>
      <span class="n">chunk_merge</span><span class="p">])</span>


<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"ENTIRE AGREEMENT.  This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter.

2THEMART.COM, INC.:  I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99    Date: 6/11/99 "</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">deid_merged_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">deid_merged_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-----------------------+--------------+</span>
<span class="o">|</span><span class="n">chunk</span>                  <span class="o">|</span><span class="n">ner_label</span>     <span class="o">|</span>
<span class="o">+-----------------------+--------------+</span>
<span class="o">|</span><span class="n">ENTIRE</span> <span class="n">AGREEMENT</span>       <span class="o">|</span><span class="n">DOC</span>           <span class="o">|</span>
<span class="o">|</span><span class="n">INC</span>                    <span class="o">|</span><span class="n">PARTY</span>         <span class="o">|</span>
<span class="o">|</span><span class="n">J</span><span class="p">.</span> <span class="n">Magliarditi</span>         <span class="o">|</span><span class="n">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">Bajaj</span>                  <span class="o">|</span><span class="n">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">Dominic</span> <span class="n">J</span><span class="p">.</span> <span class="n">Magliarditi</span> <span class="o">|</span><span class="n">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">Sanjay</span> <span class="n">Bajaj</span>           <span class="o">|</span><span class="n">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">President</span>              <span class="o">|</span><span class="n">SIGNING_TITLE</span> <span class="o">|</span>
<span class="o">|</span><span class="n">VP</span> <span class="n">Business</span> <span class="n">Development</span><span class="o">|</span><span class="n">SIGNING_TITLE</span> <span class="o">|</span>
<span class="o">+-----------------------+--------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Annotator that transforms a text column from dataframe into an Annotation ready for NLP </span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
 
<span class="c1">// Sentence Detector annotator,processes various sentences per line </span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
 
<span class="c1">// Tokenizer splits words in a relevant format for NLP </span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 
 
<span class="c1">// Clinical word embeddings trained on PubMED dataset </span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 
 
<span class="c1">// 1- ner_clinical model </span>
<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"clinical_ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">clinical_ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"clinical_ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"clinical_ner_chunk"</span><span class="o">)</span> 
 
<span class="c1">// 2- posology ner model </span>
<span class="k">val</span> <span class="nv">posology_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"posology_ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">posology_ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"posology_ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"posology_ner_chunk"</span><span class="o">)</span> 
 
<span class="c1">// 3- generate a text matcher annotator that extracts female related entities </span>
<span class="k">val</span> <span class="nv">entities</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"she"</span><span class="o">,</span><span class="s">"her"</span><span class="o">,</span><span class="s">"girl"</span><span class="o">,</span><span class="s">"woman"</span><span class="o">,</span><span class="s">"women"</span><span class="o">,</span><span class="s">"womanish"</span><span class="o">,</span><span class="s">"womanlike"</span><span class="o">,</span><span class="s">"womanly"</span><span class="o">,</span><span class="s">"madam"</span><span class="o">,</span><span class="s">"madame"</span><span class="o">,</span><span class="s">"senora"</span><span class="o">,</span><span class="s">"lady"</span><span class="o">,</span><span class="s">"miss"</span><span class="o">,</span><span class="s">"girlfriend"</span><span class="o">,</span><span class="s">"wife"</span><span class="o">,</span><span class="s">"bride"</span><span class="o">,</span><span class="s">"misses"</span><span class="o">,</span><span class="s">"mrs."</span><span class="o">,</span><span class="s">"female"</span><span class="o">)</span>

<span class="k">with</span> <span class="nf">open</span> <span class="o">(</span><span class="ss">'female_entities</span><span class="o">.</span><span class="py">txt</span><span class="o">',</span> <span class="sc">'w'</span><span class="o">)</span> <span class="n">as</span> <span class="n">f</span><span class="k">:</span>
    <span class="kt">for</span> <span class="kt">i</span> <span class="kt">in</span> <span class="kt">entities:</span>
        <span class="kt">f.write</span><span class="o">(</span><span class="kt">i+'\n'</span><span class="o">)</span>
 
<span class="c1">// Find female entities using TextMatcher </span>
<span class="k">val</span> <span class="nv">female_entity_extractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextMatcher</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"female_entities"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setEntities</span><span class="o">(</span><span class="s">"female_entities.txt"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setEntityValue</span><span class="o">(</span><span class="s">"female_entity"</span><span class="o">)</span> 
 
<span class="c1">// Chunk Merge annotator is used to merge columns </span>
<span class="k">val</span> <span class="nv">chunk_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"posology_ner_chunk"</span><span class="o">,</span><span class="s">"clinical_ner_chunk"</span><span class="o">,</span><span class="s">"female_entities"</span><span class="o">))</span>
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"merged_ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">word_embeddings</span><span class="o">,</span> 
    <span class="n">clinical_ner</span><span class="o">,</span> 
    <span class="n">clinical_ner_converter</span><span class="o">,</span> 
    <span class="n">posology_ner</span><span class="o">,</span> 
    <span class="n">posology_ner_converter</span><span class="o">,</span> 
    <span class="n">female_entity_extractor</span><span class="o">,</span> 
    <span class="n">chunk_merger</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="o">=</span><span class="s">"""The lady was treated with a five-day course of amoxicillin for a respiratory tract infection .
She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG ."""</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----+---+-----------------------------+-------------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">chunk</span>                        <span class="o">|</span><span class="n">entity</span>       <span class="o">|</span>
<span class="o">+-----+---+-----------------------------+-------------+</span>
<span class="o">|</span><span class="mi">4</span>    <span class="o">|</span><span class="mi">7</span>  <span class="o">|</span><span class="n">lady</span>                         <span class="o">|</span><span class="n">female_entity</span><span class="o">|</span>
<span class="o">|</span><span class="mi">47</span>   <span class="o">|</span><span class="mi">57</span> <span class="o">|</span><span class="n">amoxicillin</span>                  <span class="o">|</span><span class="nc">DRUG</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">63</span>   <span class="o">|</span><span class="mi">91</span> <span class="o">|</span><span class="n">a</span> <span class="n">respiratory</span> <span class="n">tract</span> <span class="n">infection</span><span class="o">|</span><span class="nc">PROBLEM</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">95</span>   <span class="o">|</span><span class="mi">97</span> <span class="o">|</span><span class="nc">She</span>                          <span class="o">|</span><span class="n">female_entity</span><span class="o">|</span>
<span class="o">|</span><span class="mi">106</span>  <span class="o">|</span><span class="mi">114</span><span class="o">|</span><span class="n">metformin</span>                    <span class="o">|</span><span class="nc">DRUG</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">118</span>  <span class="o">|</span><span class="mi">126</span><span class="o">|</span><span class="n">glipizide</span>                    <span class="o">|</span><span class="nc">TREATMENT</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">134</span>  <span class="o">|</span><span class="mi">146</span><span class="o">|</span><span class="n">dapagliflozin</span>                <span class="o">|</span><span class="nc">TREATMENT</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">152</span>  <span class="o">|</span><span class="mi">155</span><span class="o">|</span><span class="n">T2DM</span>                         <span class="o">|</span><span class="nc">PROBLEM</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">161</span>  <span class="o">|</span><span class="mi">172</span><span class="o">|</span><span class="n">atorvastatin</span>                 <span class="o">|</span><span class="nc">DRUG</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">178</span>  <span class="o">|</span><span class="mi">188</span><span class="o">|</span><span class="n">gemfibrozil</span>                  <span class="o">|</span><span class="nc">TREATMENT</span>    <span class="o">|</span>
<span class="o">+-----+---+-----------------------------+-------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">bert_embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">fin_ner</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'finner_dei</span><span class="n">d</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">({</span><span class="s">"ORG"</span><span class="k">:</span> <span class="err">"</span><span class="kt">PARTY</span><span class="err">"</span><span class="o">})</span> <span class="k">#</span> <span class="nc">Replace</span> <span class="s">"ORG"</span> <span class="n">entity</span> <span class="n">as</span> <span class="s">"PARTY"</span>

<span class="k">val</span> <span class="nv">ner_finner</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_org_per_role_date"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"bert_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_finner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_finner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_finner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_finner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">([</span><span class="kt">'ROLE'</span><span class="o">])</span> <span class="k">#</span> <span class="nc">Just</span> <span class="n">use</span> <span class="s">"ROLE"</span> <span class="n">entity</span> <span class="n">from</span> <span class="k">this</span> <span class="nc">NER</span>

<span class="k">val</span> <span class="nv">chunk_merge</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_finner_chunk"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_merged_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span> 
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">bert_embeddings</span><span class="o">,</span>
      <span class="n">fin_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">ner_finner</span><span class="o">,</span>
      <span class="n">ner_converter_finner</span><span class="o">,</span>
      <span class="n">chunk_merge</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">#</span> <span class="nc">Show</span> <span class="n">results</span>
<span class="n">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+---------------------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+---------------------+---------+</span>
<span class="o">|</span><span class="nc">Jeffrey</span> <span class="nc">Preston</span> <span class="nc">Bezos</span><span class="o">|</span><span class="nc">PERSON</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">founder</span>              <span class="o">|</span><span class="nc">ROLE</span>     <span class="o">|</span>
<span class="o">|</span><span class="nc">CEO</span>                  <span class="o">|</span><span class="nc">ROLE</span>     <span class="o">|</span>
<span class="o">|</span><span class="nc">Amazon</span>               <span class="o">|</span><span class="nc">PARTY</span>    <span class="o">|</span>
<span class="o">+---------------------+---------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">legal_ner</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">({</span><span class="s">"ALIAS"</span><span class="k">:</span> <span class="err">"</span><span class="kt">PARTY</span><span class="err">"</span><span class="o">})</span>

<span class="k">val</span> <span class="nv">ner_signers</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_signers"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_signers"</span><span class="o">)</span> 
    <span class="o">#.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_signers</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_signers"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_signer_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk_merge</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_signer_chunk"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_merged_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span> 
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">legal_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">ner_signers</span><span class="o">,</span>
      <span class="n">ner_converter_signers</span><span class="o">,</span>
      <span class="n">chunk_merge</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"ENTIRE AGREEMENT.  This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter.
2THEMART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/99 Date: 6/11/99 "</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">#</span> <span class="nc">Show</span> <span class="n">results</span>
<span class="n">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------+--------------+</span>
<span class="o">|</span><span class="n">chunk</span>                  <span class="o">|</span><span class="n">ner_label</span>     <span class="o">|</span>
<span class="o">+-----------------------+--------------+</span>
<span class="o">|</span><span class="nc">ENTIRE</span> <span class="nc">AGREEMENT</span>       <span class="o">|</span><span class="nc">DOC</span>           <span class="o">|</span>
<span class="o">|</span><span class="nc">INC</span>                    <span class="o">|</span><span class="nc">PARTY</span>         <span class="o">|</span>
<span class="o">|</span><span class="n">J</span><span class="o">.</span> <span class="nc">Magliarditi</span>         <span class="o">|</span><span class="nc">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Bajaj</span>                  <span class="o">|</span><span class="nc">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Dominic</span> <span class="n">J</span><span class="o">.</span> <span class="nc">Magliarditi</span> <span class="o">|</span><span class="nc">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Sanjay</span> <span class="nc">Bajaj</span>           <span class="o">|</span><span class="nc">SIGNING_PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="nc">President</span>              <span class="o">|</span><span class="nc">SIGNING_TITLE</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">VP</span> <span class="nc">Business</span> <span class="nc">Development</span><span class="o">|</span><span class="nc">SIGNING_TITLE</span> <span class="o">|</span>
<span class="o">+-----------------------+--------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="chunksentencesplitter">ChunkSentenceSplitter</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">ChunkSentenceSplitter</code> annotator can split the documents into chunks according to separators given as <code class="language-plaintext highlighter-rouge">CHUNK</code> columns. It is useful when you need to perform different models or analysis in different sections of your document (for example, for different headers, clauses, items, etc.). The given separator chunk can be the output from, for example, <a href="https://nlp.johnsnowlabs.com/docs/en/annotators#regexmatcher">RegexMatcher</a> or <a href="https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#nermodel">NerModel</a>.</p>

    <p>Parametres;</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">GroupBySentences</code>: (boolean) Sets the groupBySentences that allow split the paragraphs grouping the chunks by sentences.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">InsertChunk</code>: (boolean) Whether to insert the chunk in the paragraph or not.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">DefaultEntity</code>: (str) Sets the key in the metadata dictionary that you want to filter (by default ‘entity’)</p>
      </li>
    </ul>

    <p>For detailed usage of this annotator, visit <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/18.Chunk_Sentence_Splitter.ipynb">this notebook</a> from our <code class="language-plaintext highlighter-rouge">Spark NLP Workshop</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunk_sentence_splitter/index.html#sparknlp_jsl.annotator.chunker.chunk_sentence_splitter.ChunkSentenceSplitter">ChunkSentenceSplitter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkSentenceSplitter.html">ChunkSentenceSplitter</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ChunkSentenceSplitter.ipynb">ChunkSentenceSplitterNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># Defining the pipeline
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl_slim"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Header"</span><span class="p">])</span>

<span class="c1">#applying ChunkSentenceSplitter
</span><span class="n">chunkSentenceSplitter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkSentenceSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"paragraphs"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGroupBySentences</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline_model</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
  <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">chunkSentenceSplitter</span>
  <span class="p">])</span>


<span class="n">sentences</span> <span class="o">=</span> <span class="p">[[</span><span class="s">"""Sample Name: Mesothelioma - Pleural Biopsy
Description: Right pleural effusion and suspected malignant mesothelioma. (Medical Transcription Sample Report)
PREOPERATIVE DIAGNOSIS:  Right pleural effusion and suspected malignant mesothelioma.
POSTOPERATIVE DIAGNOSIS: Right pleural effusion, suspected malignant mesothelioma.
ANESTHESIA: General double-lumen endotracheal.
DESCRIPTION OF FINDINGS:  Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.
SPECIMEN:  Pleural biopsies for pathology and microbiology.
INDICATIONS:  Briefly, this is a 66-year-old gentleman who has been transferred from an outside hospital after a pleural effusion had been drained and biopsies taken from the right chest that were thought to be consistent with mesothelioma. Upon transfer, he had a right pleural effusion demonstrated on x-ray as well as some shortness of breath and dyspnea on exertion. The risks, benefits, and alternatives to right VATS pleurodesis and pleural biopsy were discussed with the patient and his family and they wished to proceed.
Dr. X was present for the entire procedure which was right VATS pleurodesis and pleural biopsies.The counts were correct x2 at the end of the case."""</span><span class="p">]]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sentences</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">paragraphs</span> <span class="o">=</span> <span class="n">pipeline_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">paragraphs</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(paragraphs) as result"</span><span class="p">)</span>\
          <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"result.result"</span><span class="p">,</span><span class="s">"result.metadata.entity"</span><span class="p">,</span> <span class="s">"result.metadata.splitter_chunk"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------+------------+------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>      <span class="n">entity</span><span class="o">|</span>          <span class="n">splitter_chunk</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------+------------------------+</span>
<span class="o">|</span>                                     <span class="n">Sample</span> <span class="n">Name</span><span class="p">:</span> <span class="n">Mesothelioma</span> <span class="o">-</span> <span class="n">Pleural</span> <span class="n">Biopsy</span> <span class="o">|</span><span class="n">introduction</span><span class="o">|</span>                     <span class="n">UNK</span><span class="o">|</span>
<span class="o">|</span><span class="n">Description</span><span class="p">:</span> <span class="n">Right</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="ow">and</span> <span class="n">suspected</span> <span class="n">malignant</span> <span class="n">mesothelioma</span><span class="p">.</span> <span class="p">(</span><span class="n">Me</span><span class="p">...</span><span class="o">|</span>      <span class="n">Header</span><span class="o">|</span>            <span class="n">Description</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span><span class="n">PREOPERATIVE</span> <span class="n">DIAGNOSIS</span><span class="p">:</span>  <span class="n">Right</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="ow">and</span> <span class="n">suspected</span> <span class="n">malignant</span> <span class="n">mesot</span><span class="p">...</span><span class="o">|</span>      <span class="n">Header</span><span class="o">|</span> <span class="n">PREOPERATIVE</span> <span class="n">DIAGNOSIS</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span><span class="n">POSTOPERATIVE</span> <span class="n">DIAGNOSIS</span><span class="p">:</span> <span class="n">Right</span> <span class="n">pleural</span> <span class="n">effusion</span><span class="p">,</span> <span class="n">suspected</span> <span class="n">malignant</span> <span class="n">mesothel</span><span class="p">...</span><span class="o">|</span>      <span class="n">Header</span><span class="o">|</span><span class="n">POSTOPERATIVE</span> <span class="n">DIAGNOSIS</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span>                                 <span class="n">ANESTHESIA</span><span class="p">:</span> <span class="n">General</span> <span class="n">double</span><span class="o">-</span><span class="n">lumen</span> <span class="n">endotracheal</span><span class="p">.</span> <span class="o">|</span>      <span class="n">Header</span><span class="o">|</span>             <span class="n">ANESTHESIA</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span><span class="n">DESCRIPTION</span> <span class="n">OF</span> <span class="n">FINDINGS</span><span class="p">:</span>  <span class="n">Right</span> <span class="n">pleural</span> <span class="n">effusion</span><span class="p">,</span> <span class="n">firm</span> <span class="n">nodules</span><span class="p">,</span> <span class="n">diffuse</span> <span class="n">scatt</span><span class="p">...</span><span class="o">|</span>      <span class="n">Header</span><span class="o">|</span><span class="n">DESCRIPTION</span> <span class="n">OF</span> <span class="n">FINDINGS</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span>                    <span class="n">SPECIMEN</span><span class="p">:</span>  <span class="n">Pleural</span> <span class="n">biopsies</span> <span class="k">for</span> <span class="n">pathology</span> <span class="ow">and</span> <span class="n">microbiology</span><span class="p">.</span> <span class="o">|</span>      <span class="n">Header</span><span class="o">|</span>               <span class="n">SPECIMEN</span><span class="p">:</span><span class="o">|</span>
<span class="o">|</span><span class="n">INDICATIONS</span><span class="p">:</span>  <span class="n">Briefly</span><span class="p">,</span> <span class="n">this</span> <span class="ow">is</span> <span class="n">a</span> <span class="mi">66</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span> <span class="n">gentleman</span> <span class="n">who</span> <span class="n">has</span> <span class="n">been</span> <span class="n">transferr</span><span class="p">...</span><span class="o">|</span>      <span class="n">Header</span><span class="o">|</span>            <span class="n">INDICATIONS</span><span class="p">:</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------+------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_headers"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">chunkSentenceSplitter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkSentenceSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"paragraphs"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGroupBySentences</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
    
<span class="n">nlp_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">chunkSentenceSplitter</span><span class="p">])</span>


<span class="n">text</span> <span class="o">=</span> <span class="s">"""2. DEFINITION. 

For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1 and 2 Appointment as Reseller.

2.1 Appointment. 

The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6

2.2 Customer Agreements."""</span>

<span class="n">sdf</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">paragraphs</span> <span class="o">=</span> <span class="n">nlp_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sdf</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">sdf</span><span class="p">)</span>

<span class="n">paragraphs</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(paragraphs) as result"</span><span class="p">)</span>\
          <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"result.result"</span><span class="p">,</span><span class="s">"result.metadata.entity"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="o">+--------------------------------------------------+---------+</span>
<span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>   <span class="n">entity</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------+</span>
<span class="o">|</span>                                               <span class="mf">2.</span> <span class="o">|</span>   <span class="n">HEADER</span><span class="o">|</span>
<span class="o">|</span><span class="n">DEFINITION</span><span class="p">.</span>   <span class="n">For</span> <span class="n">purposes</span> <span class="n">of</span> <span class="n">this</span> <span class="n">Agreement</span><span class="p">,</span> <span class="n">t</span><span class="p">...</span><span class="o">|</span><span class="n">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                               <span class="mf">2.1</span> <span class="n">Appointment</span><span class="p">.</span>   <span class="o">|</span><span class="n">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">Company</span> <span class="n">hereby</span> <span class="p">[</span><span class="o">***</span><span class="p">].</span> <span class="n">Allscripts</span> <span class="n">may</span> <span class="n">also</span> <span class="n">d</span><span class="p">...</span><span class="o">|</span><span class="n">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                        <span class="mi">6</span>  <span class="mf">2.2</span> <span class="n">Customer</span> <span class="n">Agreements</span><span class="o">|</span>   <span class="n">HEADER</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
        
<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_headers"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">chunkSentenceSplitter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ChunkSentenceSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"paragraphs"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGroupBySentences</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
    
<span class="n">nlp_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">chunkSentenceSplitter</span><span class="p">])</span>


<span class="n">text</span> <span class="o">=</span> <span class="s">"""AGREEMENT

NOW, THEREFORE, for good and valuable consideration, and in consideration of the mutual covenants and conditions herein contained, the Parties agree as follows:

2. Definitions. For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1. 2. Appointment as Reseller.

2.1 Appointment. The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6

2.2 Customer Agreements.

a) Subscriptions. Allscripts and its Affiliates may sell Subscriptions for terms no less than one year and no greater than four (4) years on a subscription basis to Persons who subsequently execute a Customer Agreement, provided that Allscripts may enter into Customer Agreements with terms longer than four (4) years with large organizations, provided that Phreesia consents in each instance in writing in advance, which consent will not be unreasonably withheld."""</span>

<span class="n">sdf</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">paragraphs</span> <span class="o">=</span> <span class="n">nlp_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sdf</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">sdf</span><span class="p">)</span>

<span class="n">paragraphs</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(paragraphs) as result"</span><span class="p">)</span>\
          <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"result.result"</span><span class="p">,</span><span class="s">"result.metadata.entity"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="o">+--------------------------------------------------+---------+</span>
<span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>   <span class="n">entity</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------+</span>
<span class="o">|</span><span class="n">AGREEMENT</span> <span class="n">NOW</span><span class="p">,</span> <span class="n">THEREFORE</span><span class="p">,</span> <span class="k">for</span> <span class="n">good</span> <span class="ow">and</span> <span class="n">valuabl</span><span class="p">...</span> <span class="o">|</span><span class="n">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                        <span class="n">Appointment</span> <span class="k">as</span> <span class="n">Reseller</span><span class="p">.</span>  <span class="o">|</span><span class="n">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                                 <span class="mf">2.1</span> <span class="n">Appointment</span><span class="p">.</span> <span class="o">|</span><span class="n">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">Company</span> <span class="n">hereby</span> <span class="p">[</span><span class="o">***</span><span class="p">].</span> <span class="n">Allscripts</span> <span class="n">may</span> <span class="n">also</span> <span class="n">d</span><span class="p">...</span><span class="o">|</span><span class="n">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                     <span class="mi">6</span> <span class="mf">2.2</span> <span class="n">Customer</span> <span class="n">Agreements</span><span class="p">.</span>   <span class="o">|</span>   <span class="n">HEADER</span><span class="o">|</span>
<span class="o">|</span><span class="n">a</span><span class="p">)</span> <span class="n">Subscriptions</span><span class="p">.</span> <span class="n">Allscripts</span> <span class="ow">and</span> <span class="n">its</span> <span class="n">Affiliates</span><span class="p">...</span><span class="o">|</span><span class="n">SUBHEADER</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl_slim"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"Header"</span><span class="o">)</span>

<span class="k">#</span><span class="n">applying</span> <span class="nc">ChunkSentenceSplitter</span>
<span class="k">val</span> <span class="nv">chunkSentenceSplitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkSentenceSplitter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"paragraphs"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setGroupBySentences</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline_model</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">word_embeddings</span><span class="o">,</span>
    <span class="n">clinical_ner</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">chunkSentenceSplitter</span>
<span class="o">))</span>


<span class="k">val</span> <span class="nv">sentences</span> <span class="k">=</span> <span class="o">(</span><span class="s">"""Sample Name: Mesothelioma - Pleural Biopsy
Description: Right pleural effusion and suspected malignant mesothelioma. (Medical Transcription Sample Report)
PREOPERATIVE DIAGNOSIS:  Right pleural effusion and suspected malignant mesothelioma.
POSTOPERATIVE DIAGNOSIS: Right pleural effusion, suspected malignant mesothelioma.
ANESTHESIA: General double-lumen endotracheal.
DESCRIPTION OF FINDINGS:  Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.
SPECIMEN:  Pleural biopsies for pathology and microbiology.
INDICATIONS:  Briefly, this is a 66-year-old gentleman who has been transferred from an outside hospital after a pleural effusion had been drained and biopsies taken from the right chest that were thought to be consistent with mesothelioma. Upon transfer, he had a right pleural effusion demonstrated on x-ray as well as some shortness of breath and dyspnea on exertion. The risks, benefits, and alternatives to right VATS pleurodesis and pleural biopsy were discussed with the patient and his family and they wished to proceed.
Dr. X was present for the entire procedure which was right VATS pleurodesis and pleural biopsies.The counts were correct x2 at the end of the case."""</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">sentences</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">paragraphs</span> <span class="k">=</span> <span class="nv">pipeline_model</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>


<span class="o">+--------------------------------------------------------------------------------+------------+------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">result</span><span class="o">|</span>      <span class="n">entity</span><span class="o">|</span>          <span class="n">splitter_chunk</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------+------------------------+</span>
<span class="o">|</span>                                     <span class="nc">Sample</span> <span class="nc">Name</span><span class="k">:</span> <span class="kt">Mesothelioma</span> <span class="kt">-</span> <span class="kt">Pleural</span> <span class="kt">Biopsy</span> <span class="kt">|introduction|</span>                     <span class="kt">UNK|</span>
<span class="kt">|Description:</span> <span class="kt">Right</span> <span class="kt">pleural</span> <span class="kt">effusion</span> <span class="kt">and</span> <span class="kt">suspected</span> <span class="kt">malignant</span> <span class="kt">mesothelioma.</span> <span class="o">(</span><span class="kt">Me...|</span>      <span class="kt">Header|</span>            <span class="kt">Description:|</span>
<span class="kt">|PREOPERATIVE</span> <span class="kt">DIAGNOSIS:</span>  <span class="kt">Right</span> <span class="kt">pleural</span> <span class="kt">effusion</span> <span class="kt">and</span> <span class="kt">suspected</span> <span class="kt">malignant</span> <span class="kt">mesot...|</span>      <span class="kt">Header|</span> <span class="kt">PREOPERATIVE</span> <span class="kt">DIAGNOSIS:|</span>
<span class="kt">|POSTOPERATIVE</span> <span class="kt">DIAGNOSIS:</span> <span class="kt">Right</span> <span class="kt">pleural</span> <span class="kt">effusion</span><span class="o">,</span> <span class="kt">suspected</span> <span class="kt">malignant</span> <span class="kt">mesothel...|</span>      <span class="kt">Header|POSTOPERATIVE</span> <span class="kt">DIAGNOSIS:|</span>
<span class="kt">|</span>                                 <span class="kt">ANESTHESIA:</span> <span class="kt">General</span> <span class="kt">double-lumen</span> <span class="kt">endotracheal.</span> <span class="kt">|</span>      <span class="kt">Header|</span>             <span class="kt">ANESTHESIA:|</span>
<span class="kt">|DESCRIPTION</span> <span class="kt">OF</span> <span class="kt">FINDINGS:</span>  <span class="kt">Right</span> <span class="kt">pleural</span> <span class="kt">effusion</span><span class="o">,</span> <span class="n">firm</span> <span class="n">nodules</span><span class="o">,</span> <span class="n">diffuse</span> <span class="n">scatt</span><span class="o">...|</span>      <span class="nc">Header</span><span class="o">|</span><span class="nc">DESCRIPTION</span> <span class="nc">OF</span> <span class="nc">FINDINGS</span><span class="o">:|</span>
<span class="o">|</span>                    <span class="nc">SPECIMEN</span><span class="k">:</span>  <span class="kt">Pleural</span> <span class="kt">biopsies</span> <span class="kt">for</span> <span class="kt">pathology</span> <span class="kt">and</span> <span class="kt">microbiology.</span> <span class="kt">|</span>      <span class="kt">Header|</span>               <span class="kt">SPECIMEN:|</span>
<span class="kt">|INDICATIONS:</span>  <span class="kt">Briefly</span><span class="o">,</span> <span class="k">this</span> <span class="n">is</span> <span class="n">a</span> <span class="mi">66</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span> <span class="n">gentleman</span> <span class="n">who</span> <span class="n">has</span> <span class="n">been</span> <span class="n">transferr</span><span class="o">...|</span>      <span class="nc">Header</span><span class="o">|</span>            <span class="nc">INDICATIONS</span><span class="o">:|</span>
<span class="o">+--------------------------------------------------------------------------------+------------+------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
        
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_headers"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkSentenceSplitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkSentenceSplitter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"paragraphs"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setGroupBySentences</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlp_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">chunkSentenceSplitter</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""2. DEFINITION. 

For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1 and 2 Appointment as Reseller.

2.1 Appointment. 

The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6

2.2 Customer Agreements."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">paragraphs</span> <span class="k">=</span> <span class="nv">nlp_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>


<span class="o">+--------------------------------------------------+---------+</span>
<span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>   <span class="n">entity</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------+</span>
<span class="o">|</span>                                               <span class="mf">2.</span> <span class="o">|</span>   <span class="nc">HEADER</span><span class="o">|</span>
<span class="o">|</span><span class="nc">DEFINITION</span><span class="o">.</span>   <span class="nc">For</span> <span class="n">purposes</span> <span class="n">of</span> <span class="k">this</span> <span class="nc">Agreement</span><span class="o">,</span> <span class="n">t</span><span class="o">...|</span><span class="nc">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                               <span class="mf">2.1</span> <span class="nc">Appointment</span><span class="o">.</span>   <span class="o">|</span><span class="nc">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span><span class="nc">The</span> <span class="nc">Company</span> <span class="n">hereby</span> <span class="o">[</span><span class="kt">***</span><span class="o">].</span> <span class="nc">Allscripts</span> <span class="n">may</span> <span class="n">also</span> <span class="n">d</span><span class="o">...|</span><span class="nc">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                        <span class="mi">6</span>  <span class="mf">2.2</span> <span class="nc">Customer</span> <span class="nc">Agreements</span><span class="o">|</span>   <span class="nc">HEADER</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
        
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_headers"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkSentenceSplitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkSentenceSplitter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"paragraphs"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setGroupBySentences</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    
<span class="k">val</span> <span class="nv">nlp_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">chunkSentenceSplitter</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""AGREEMENT

NOW, THEREFORE, for good and valuable consideration, and in consideration of the mutual covenants and conditions herein contained, the Parties agree as follows:

2. Definitions. For purposes of this Agreement, the following terms have the meanings ascribed thereto in this Section 1. 2. Appointment as Reseller.

2.1 Appointment. The Company hereby [***]. Allscripts may also disclose Company's pricing information relating to its Merchant Processing Services and facilitate procurement of Merchant Processing Services on behalf of Sublicensed Customers, including, without limitation by references to such pricing information and Merchant Processing Services in Customer Agreements. 6

2.2 Customer Agreements.

a) Subscriptions. Allscripts and its Affiliates may sell Subscriptions for terms no less than one year and no greater than four (4) years on a subscription basis to Persons who subsequently execute a Customer Agreement, provided that Allscripts may enter into Customer Agreements with terms longer than four (4) years with large organizations, provided that Phreesia consents in each instance in writing in advance, which consent will not be unreasonably withheld."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">paragraphs</span> <span class="k">=</span> <span class="nv">nlp_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------------------------------------------+---------+</span>
<span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>   <span class="n">entity</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------+</span>
<span class="o">|</span><span class="nc">AGREEMENT</span> <span class="nc">NOW</span><span class="o">,</span> <span class="nc">THEREFORE</span><span class="o">,</span> <span class="k">for</span> <span class="n">good</span> <span class="n">and</span> <span class="n">valuabl</span><span class="o">...</span> <span class="o">|</span><span class="nc">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                        <span class="nc">Appointment</span> <span class="n">as</span> <span class="nc">Reseller</span><span class="o">.</span>  <span class="o">|</span><span class="nc">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                                 <span class="mf">2.1</span> <span class="nc">Appointment</span><span class="o">.</span> <span class="o">|</span><span class="nc">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span><span class="nc">The</span> <span class="nc">Company</span> <span class="n">hereby</span> <span class="o">[</span><span class="kt">***</span><span class="o">].</span> <span class="nc">Allscripts</span> <span class="n">may</span> <span class="n">also</span> <span class="n">d</span><span class="o">...|</span><span class="nc">SUBHEADER</span><span class="o">|</span>
<span class="o">|</span>                     <span class="mi">6</span> <span class="mf">2.2</span> <span class="nc">Customer</span> <span class="nc">Agreements</span><span class="o">.</span>   <span class="o">|</span>   <span class="nc">HEADER</span><span class="o">|</span>
<span class="o">|</span><span class="n">a</span><span class="o">)</span> <span class="nc">Subscriptions</span><span class="o">.</span> <span class="nc">Allscripts</span> <span class="n">and</span> <span class="n">its</span> <span class="nc">Affiliates</span><span class="o">...|</span><span class="nc">SUBHEADER</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="contextsplitassembler">ContextSplitAssembler</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Converts and assembles <code class="language-plaintext highlighter-rouge">VECTOR_SIMILARITY_RANKINGS</code> type annotations into <code class="language-plaintext highlighter-rouge">DOCUMENT</code> type.
The input annotations are expected to be of type <code class="language-plaintext highlighter-rouge">VECTOR_SIMILARITY_RANKINGS</code> and the output annotation type is <code class="language-plaintext highlighter-rouge">DOCUMENT</code>.
It concatenates the results of the input annotations into a single result, separated by a join string.
When <code class="language-plaintext highlighter-rouge">explodeSplits</code> is set to True, the splits are exploded into separate annotations.
The <code class="language-plaintext highlighter-rouge">joinString</code> parameter is used to add the delimiter between the results of annotations when combining them into a single result.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">joinString</code> <em>(str)</em>:  This parameter specifies the string that will be inserted between results of annotations when combining them into a single result. It acts as a delimiter, ensuring that the elements are properly separated and organized in the final result of annotation.  Default: <code class="language-plaintext highlighter-rouge">" "</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">explodeSplits</code> <em>(Bool)</em>: Whether to explode the splits into separate annotations or not. Default: <code class="language-plaintext highlighter-rouge">False</code>.</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">VECTOR_SIMILARITY_RANKINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/rag/context_split_assembler/index.html">ContextSplitAssembler</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/rag/ContextSplitAssembler.html">ContextSplitAssembler</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">context_split_assembler</span> <span class="o">=</span> <span class="p">(</span> <span class="n">medical</span><span class="p">.</span><span class="n">ContextSplitAssembler</span><span class="p">()</span>
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"vector_db"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">setJoinString</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
  <span class="p">.</span><span class="n">setExplodeSplits</span><span class="p">(</span><span class="bp">False</span><span class="p">))</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="contextualassertion">ContextualAssertion</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>An annotator model for contextual assertion analysis. This model identifies  contextual cues within text data, such as negation, uncertainty etc. It is used
clinical assertion detection. It annotates text chunks with assertions based on configurable rules, prefix and suffix patterns, and exception patterns.</p>

    <p>Parametres:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">inputCols</code>: Input annotations.</li>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code>: Whether to use case sensitive when matching values, by default <code class="language-plaintext highlighter-rouge">False</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">prefixAndSuffixMatch</code>: Whether to match both prefix and suffix to annotate the hit, by default <code class="language-plaintext highlighter-rouge">False</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">prefixKeywords</code>: Prefix keywords to match.</li>
      <li><code class="language-plaintext highlighter-rouge">suffixKeywords</code>: Suffix keywords to match</li>
      <li><code class="language-plaintext highlighter-rouge">exceptionKeywords</code>: Exception keywords not to match.</li>
      <li><code class="language-plaintext highlighter-rouge">prefixRegexPatterns</code>: Prefix regex patterns to match</li>
      <li><code class="language-plaintext highlighter-rouge">suffixRegexPatterns</code>: Suffix regex pattern to match</li>
      <li><code class="language-plaintext highlighter-rouge">exceptionRegexPatterns</code>: Exception regex pattern not to match</li>
      <li><code class="language-plaintext highlighter-rouge">scopeWindow</code>: The scope window of the assertion expression</li>
      <li><code class="language-plaintext highlighter-rouge">assertion</code>: Assertion to match</li>
      <li><code class="language-plaintext highlighter-rouge">scopeWindowDelimiter</code>: Delimiters used to limit the scope window.</li>
      <li><code class="language-plaintext highlighter-rouge">includeChunkToScope</code>: Whether to include chunk to scope when matching values</li>
      <li><code class="language-plaintext highlighter-rouge">ConfidenceCalculationDirection</code>: Indicates the direction for calculating assertion confidence (left, right, or both; default is left).</li>
    </ul>

    <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.3.Contextual_Assertion.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/contextual_assertion/index.html#sparknlp_jsl.annotator.assertion.contextual_assertion">ContextualAssertion</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/context/ContextualAssertion.html">ContextualAssertion</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">MedicalNerModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">contextual_assertion</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ContextualAssertion</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPrefixKeywords</span><span class="p">([</span><span class="s">"no"</span><span class="p">,</span> <span class="s">"not"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setSuffixKeywords</span><span class="p">([</span><span class="s">"unlikely"</span><span class="p">,</span><span class="s">"negative"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setPrefixRegexPatterns</span><span class="p">([</span><span class="s">"</span><span class="se">\\</span><span class="s">b(no|without|denies|never|none|free of|not include)</span><span class="se">\\</span><span class="s">b"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setSuffixRegexPatterns</span><span class="p">([</span><span class="s">"</span><span class="se">\\</span><span class="s">b(free of|negative for|absence of|not|rule out)</span><span class="se">\\</span><span class="s">b"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setExceptionKeywords</span><span class="p">([</span><span class="s">"without"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setExceptionRegexPatterns</span><span class="p">([</span><span class="s">"</span><span class="se">\\</span><span class="s">b(not clearly)</span><span class="se">\\</span><span class="s">b"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">addPrefixKeywords</span><span class="p">([</span><span class="s">"negative for"</span><span class="p">,</span><span class="s">"negative"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">addSuffixKeywords</span><span class="p">([</span><span class="s">"absent"</span><span class="p">,</span><span class="s">"neither"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPrefixAndSuffixMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setAssertion</span><span class="p">(</span><span class="s">"absent"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setScopeWindow</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setIncludeChunkToScope</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setScopeWindowDelimiters</span><span class="p">([</span><span class="s">","</span><span class="p">])</span>

<span class="n">flattener</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Flattener</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setExplodeSelectedFields</span><span class="p">({</span><span class="s">"assertion"</span><span class="p">:[</span><span class="s">"metadata.ner_chunk as ner_chunk"</span><span class="p">,</span>
                                            <span class="s">"begin as begin"</span><span class="p">,</span>
                                            <span class="s">"end as end"</span><span class="p">,</span>
                                            <span class="s">"metadata.ner_label as ner_label"</span><span class="p">,</span>
                                            <span class="s">"result as result"</span><span class="p">]})</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">contextual_assertion</span><span class="p">,</span>
    <span class="n">flattener</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""Patient resting in bed. Patient given azithromycin without any difficulty. Patient has audible wheezing, states chest tightness.
No evidence of hypertension. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating
associated with pneumonia. Patient refused pain but tylenol still given. Neither substance abuse nor alcohol use however cocaine
once used in the last year. Alcoholism unlikely. Patient has headache and fever. Patient is not diabetic. Not clearly of diarrhea.
Lab reports confirm lymphocytopenia. Cardaic rhythm is Sinus bradycardia. Patient also has a history of cardiac injury.
No kidney injury reported. No abnormal rashes or ulcers. Patient might not have liver disease. Confirmed absence of hemoptysis.
Although patient has severe pneumonia and fever, test reports are negative for COVID-19 infection. COVID-19 viral infection absent.
"""</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># result
</span><span class="o">+------------------+-----+---+---------+------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>         <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------------------+-----+---+---------+------+</span>
<span class="o">|</span><span class="n">nausea</span>            <span class="o">|</span><span class="mi">173</span>  <span class="o">|</span><span class="mi">178</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">Alcoholism</span>        <span class="o">|</span><span class="mi">413</span>  <span class="o">|</span><span class="mi">422</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">diabetic</span>          <span class="o">|</span><span class="mi">481</span>  <span class="o">|</span><span class="mi">488</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">kidney</span> <span class="n">injury</span>     <span class="o">|</span><span class="mi">639</span>  <span class="o">|</span><span class="mi">651</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">abnormal</span> <span class="n">rashes</span>   <span class="o">|</span><span class="mi">666</span>  <span class="o">|</span><span class="mi">680</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">liver</span> <span class="n">disease</span>     <span class="o">|</span><span class="mi">716</span>  <span class="o">|</span><span class="mi">728</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">COVID</span><span class="o">-</span><span class="mi">19</span> <span class="n">infection</span><span class="o">|</span><span class="mi">843</span>  <span class="o">|</span><span class="mi">860</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">viral</span> <span class="n">infection</span>   <span class="o">|</span><span class="mi">872</span>  <span class="o">|</span><span class="mi">886</span><span class="o">|</span><span class="n">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">+------------------+-----+---+---------+------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span> <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"nerTags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"nerTags"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"nerChunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">contextualAssertion</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextualAssertion</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span><span class="s">"nerChunks"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setScopeWindow</span><span class="o">(</span><span class="mi">2</span><span class="o">,</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPrefixRegexPatterns</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"\\b(no|without|denies|never|none|free of|negative for|not include)\\b"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setSuffixRegexPatterns</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"\\b(free of|negative for|absence of|absence|not|neither|rule out)\\b"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setPrefixKeywords</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"not"</span><span class="o">,</span><span class="s">"never"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setSuffixKeywords</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"no"</span><span class="o">,</span><span class="s">"never"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setIncludeChunkToScope</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">addPrefixKeywords</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"negative for"</span><span class="o">,</span><span class="s">"no evidence of"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">addSuffixKeywords</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"declined"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setAssertion</span><span class="o">(</span><span class="s">"absent"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setScopeWindowDelimiter</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">","</span><span class="o">))</span>



<span class="k">val</span> <span class="nv">flattener</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Flattener</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"assertion"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setExplodeSelectedFields</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"assertion"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span> <span class="s">"metadata.ner_chunk as ner_chunk "</span><span class="o">,</span><span class="s">"begin as begin"</span><span class="o">,</span><span class="s">"end as end"</span><span class="o">,</span><span class="s">" "</span><span class="nv">metadata</span><span class="o">.</span><span class="py">ner_label</span> <span class="n">as</span> <span class="n">ner_label</span><span class="s">","</span><span class="n">result</span> <span class="n">as</span> <span class="n">result</span><span class="s">",
) ) )

val pipeline = new Pipeline()
  .setStages(Array(documentAssembler,
                  sentenceDetector,
                  tokenizer,
                  embedder,
                  nerTagger,
                  nerConverter,
                  contextualAssertion,
                  flattener
                  ))

val text = "</span><span class="nc">Patient</span> <span class="n">resting</span> <span class="n">in</span> <span class="n">bed</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">given</span> <span class="n">azithromycin</span> <span class="n">without</span> <span class="n">any</span> <span class="n">difficulty</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">has</span> <span class="n">audible</span> <span class="n">wheezing</span><span class="o">,</span> <span class="n">states</span> <span class="n">chest</span> <span class="n">tightness</span><span class="o">.</span><span class="s">" +
"</span> <span class="nc">No</span> <span class="n">evidence</span> <span class="n">of</span> <span class="n">hypertension</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">denies</span> <span class="n">nausea</span> <span class="n">at</span> <span class="k">this</span> <span class="n">time</span><span class="o">.</span> <span class="n">zofran</span> <span class="n">declined</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">is</span> <span class="n">also</span> <span class="n">having</span> <span class="n">intermittent</span> <span class="n">sweating</span> <span class="s">" +
"</span><span class="n">associated</span> <span class="k">with</span> <span class="n">pneumonia</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">refused</span> <span class="n">pain</span> <span class="n">but</span> <span class="n">tylenol</span> <span class="n">still</span> <span class="n">given</span><span class="o">.</span> <span class="nc">Neither</span> <span class="n">substance</span> <span class="n">abuse</span> <span class="n">nor</span> <span class="n">alcohol</span> <span class="n">use</span> <span class="n">however</span> <span class="n">cocaine</span> <span class="s">" +
"</span><span class="n">once</span> <span class="n">used</span> <span class="n">in</span> <span class="n">the</span> <span class="n">last</span> <span class="n">year</span><span class="o">.</span> <span class="nc">Alcoholism</span> <span class="n">unlikely</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">has</span> <span class="n">headache</span> <span class="n">and</span> <span class="n">fever</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">is</span> <span class="n">not</span> <span class="n">diabetic</span><span class="o">.</span> <span class="nc">Not</span> <span class="n">clearly</span> <span class="n">of</span> <span class="n">diarrhea</span><span class="o">.</span> <span class="s">" +
"</span><span class="nc">Lab</span> <span class="n">reports</span> <span class="n">confirm</span> <span class="n">lymphocytopenia</span><span class="o">.</span> <span class="nc">Cardaic</span> <span class="n">rhythm</span> <span class="n">is</span> <span class="nc">Sinus</span> <span class="n">bradycardia</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">also</span> <span class="n">has</span> <span class="n">a</span> <span class="n">history</span> <span class="n">of</span> <span class="n">cardiac</span> <span class="n">injury</span><span class="o">.</span><span class="s">" +
"</span> <span class="nc">No</span> <span class="n">kidney</span> <span class="n">injury</span> <span class="n">reported</span><span class="o">.</span> <span class="nc">No</span> <span class="n">abnormal</span> <span class="n">rashes</span> <span class="n">or</span> <span class="n">ulcers</span><span class="o">.</span> <span class="nc">Patient</span> <span class="n">might</span> <span class="n">not</span> <span class="n">have</span> <span class="n">liver</span> <span class="n">disease</span><span class="o">.</span> <span class="nc">Confirmed</span> <span class="n">absence</span> <span class="n">of</span> <span class="n">hemoptysis</span><span class="o">.</span><span class="s">" +
"</span> <span class="nc">Although</span> <span class="n">patient</span> <span class="n">has</span> <span class="n">severe</span> <span class="n">pneumonia</span> <span class="n">and</span> <span class="n">fever</span><span class="o">,</span> <span class="n">test</span> <span class="n">reports</span> <span class="n">are</span> <span class="n">negative</span> <span class="k">for</span> <span class="nc">COVID</span><span class="o">-</span><span class="mi">19</span> <span class="n">infection</span><span class="o">.</span> <span class="nc">COVID</span><span class="o">-</span><span class="mi">19</span> <span class="n">viral</span> <span class="n">infection</span> <span class="n">absent</span><span class="o">.</span><span class="s">"

val dataSet = Seq(text).toDS.toDF("</span><span class="n">text</span><span class="err">"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dataSet</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">dataSet</span><span class="o">)</span>

<span class="k">#</span> <span class="n">result</span>
<span class="o">+------------------+-----+---+---------+------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>         <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------------------+-----+---+---------+------+</span>
<span class="o">|</span><span class="n">nausea</span>            <span class="o">|</span><span class="mi">173</span>  <span class="o">|</span><span class="mi">178</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Alcoholism</span>        <span class="o">|</span><span class="mi">413</span>  <span class="o">|</span><span class="mi">422</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">diabetic</span>          <span class="o">|</span><span class="mi">481</span>  <span class="o">|</span><span class="mi">488</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">kidney</span> <span class="n">injury</span>     <span class="o">|</span><span class="mi">639</span>  <span class="o">|</span><span class="mi">651</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">abnormal</span> <span class="n">rashes</span>   <span class="o">|</span><span class="mi">666</span>  <span class="o">|</span><span class="mi">680</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">liver</span> <span class="n">disease</span>     <span class="o">|</span><span class="mi">716</span>  <span class="o">|</span><span class="mi">728</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="nc">COVID</span><span class="o">-</span><span class="mi">19</span> <span class="n">infection</span><span class="o">|</span><span class="mi">843</span>  <span class="o">|</span><span class="mi">860</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">|</span><span class="n">viral</span> <span class="n">infection</span>   <span class="o">|</span><span class="mi">872</span>  <span class="o">|</span><span class="mi">886</span><span class="o">|</span><span class="nc">PROBLEM</span>  <span class="o">|</span><span class="n">absent</span><span class="o">|</span>
<span class="o">+------------------+-----+---+---------+------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="contextualentityfilterer">ContextualEntityFilterer</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>ContextualEntityFilterer can filter chunks coming from CHUNK annotations based on entity(identifier,field) info in metadata and contextual cues.
Filters can be done via white list entities, black list entities, black list word and white list words.
The filter can be applied to the scope of the sentence or the document.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">ruleScope</code>: The rule scope to apply the filter. Options: sentence, document.</li>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code>:  Whether to use case-sensitive when matching words. Default is <code class="language-plaintext highlighter-rouge">False</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">rules</code>: The filtering rules. Each rule is a dictionary with the following keys:
        <ul>
          <li><code class="language-plaintext highlighter-rouge">entity</code>: The target entity field for filtering.</li>
          <li><code class="language-plaintext highlighter-rouge">scopeWindow</code>: A list of two integers [before, after], specifying how many tokens/chunks before and after the target to consider.</li>
          <li><code class="language-plaintext highlighter-rouge">whiteListEntities</code>: The white list of entities. If one of the entity from this list appears within the scope window, the chunk will be kept. Only one element is enough to keep the chunk.</li>
          <li><code class="language-plaintext highlighter-rouge">blackListEntities</code>: The black list of entities. If an entity from this list appears within the scope window, the chunk will be filtered out. All elements must be absent to keep the chunk.</li>
          <li><code class="language-plaintext highlighter-rouge">scopeWindowLevel</code>: Determines whether the <code class="language-plaintext highlighter-rouge">scopeWindow</code> is applied at the token or chunk level. Options: <code class="language-plaintext highlighter-rouge">token</code>, <code class="language-plaintext highlighter-rouge">chunk</code>.</li>
          <li><code class="language-plaintext highlighter-rouge">blackListWords</code>: The black list of words. If a word from this list appears within the scope window, the chunk will be filtered out.</li>
          <li><code class="language-plaintext highlighter-rouge">whiteListWords</code>: The white list of words. If a word from this list appears within the scope window, the chunk will be kept.</li>
          <li><code class="language-plaintext highlighter-rouge">confidenceThreshold</code>: The confidence threshold to filter the chunks. Filtering is only applied if the confidence of the chunk is below the threshold.</li>
          <li><code class="language-plaintext highlighter-rouge">possibleRegexContext</code> : The possible regex context to filter the chunks. If the regex is found in the context(chunk), the chunk is kept.</li>
          <li><code class="language-plaintext highlighter-rouge">impossibleRegexContext</code> : The impossible regex context to filter the chunks. If the regex is found in the context(chunk), the chunk is removed.</li>
        </ul>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/context/contextual_entity_filterer/index.html">ContextualEntityFilterer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/context/ContextualEntityFilterer.html">ContextualEntityFilterer</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ContextualEntityFilterer.ipynb">ContextualEntityFilterer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_deid</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_subentity_docwise"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>  \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_deid_subentity_docwise"</span><span class="p">)</span>

<span class="n">ner_deid_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_deid_subentity_docwise"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_subentity_docwise"</span><span class="p">)</span>

<span class="n">rules</span> <span class="o">=</span><span class="p">[{</span>   <span class="s">"entity"</span><span class="p">:</span> <span class="s">"STATE"</span><span class="p">,</span>
            <span class="s">"scopeWindow"</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
            <span class="s">"whiteListEntities"</span><span class="p">:</span> <span class="p">[</span><span class="s">"CITY"</span><span class="p">],</span>
            <span class="s">"blackListEntities"</span><span class="p">:</span> <span class="p">[</span><span class="s">"NAME"</span><span class="p">],</span>
            <span class="s">"scopeWindowLevel"</span><span class="p">:</span> <span class="s">"token"</span>
        <span class="p">}]</span>

<span class="n">contextual_entity_filterer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ContextualEntityFilterer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk_subentity_docwise"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filtered_ner_chunks"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRules</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRuleScope</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> 

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
  <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>
      <span class="n">ner_deid</span><span class="p">,</span>
      <span class="n">ner_deid_converter</span><span class="p">,</span>
      <span class="n">contextual_entity_filterer</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"NY, a 34-year-old woman, Dr. Michael Johnson cares wit her, at CarePlus Clinic, located at 456 Elm Street, NewYork, NY has recommended starting insulin therapy."</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>


<span class="c1"># result
</span>
<span class="o">+---------------+-----+---+---------+----------+</span>
<span class="o">|</span><span class="n">chunk</span>          <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+---------------+-----+---+---------+----------+</span>
<span class="o">|</span><span class="n">NY</span>             <span class="o">|</span><span class="mi">0</span>    <span class="o">|</span><span class="mi">1</span>  <span class="o">|</span><span class="n">STATE</span>    <span class="o">|</span><span class="mf">0.9299</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">34</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span>    <span class="o">|</span><span class="mi">6</span>    <span class="o">|</span><span class="mi">16</span> <span class="o">|</span><span class="n">AGE</span>      <span class="o">|</span><span class="mf">0.7687</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">Michael</span> <span class="n">Johnson</span><span class="o">|</span><span class="mi">29</span>   <span class="o">|</span><span class="mi">43</span> <span class="o">|</span><span class="n">DOCTOR</span>   <span class="o">|</span><span class="mf">0.89965</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">CarePlus</span> <span class="n">Clinic</span><span class="o">|</span><span class="mi">63</span>   <span class="o">|</span><span class="mi">77</span> <span class="o">|</span><span class="n">HOSPITAL</span> <span class="o">|</span><span class="mf">0.9661</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">456</span> <span class="n">Elm</span> <span class="n">Street</span> <span class="o">|</span><span class="mi">91</span>   <span class="o">|</span><span class="mi">104</span><span class="o">|</span><span class="n">STREET</span>   <span class="o">|</span><span class="mf">0.7733667</span> <span class="o">|</span>
<span class="o">|</span><span class="n">NewYork</span>        <span class="o">|</span><span class="mi">107</span>  <span class="o">|</span><span class="mi">113</span><span class="o">|</span><span class="n">CITY</span>     <span class="o">|</span><span class="mf">0.9302</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">NY</span>             <span class="o">|</span><span class="mi">116</span>  <span class="o">|</span><span class="mi">117</span><span class="o">|</span><span class="n">STATE</span>    <span class="o">|</span><span class="mf">0.9991</span>    <span class="o">|</span>
<span class="o">+---------------+-----+---+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_deid</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_subentity_docwise"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_deid_subentity_docwise"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_deid_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_deid_subentity_docwise"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_subentity_docwise"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">rules</span> <span class="k">=</span>
  <span class="s">"""
    |[{
    |"entity": "STATE",
    |  "scopeWindow": [2, 2],
    |  "whiteListEntities": ["CITY"],
    |  "blackListEntities": ["NAME"],
    |  "scopeWindowLevel": "token"
    |
    | }
    | ]
    |
    |"""</span><span class="o">.</span><span class="py">stripMargin</span>

<span class="k">val</span> <span class="nv">contextual_entity_filterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextualEntityFilterer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk_subentity_docwise"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filtered_ner_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRulesAsStr</span><span class="o">(</span><span class="n">rules</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRuleScope</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span>
  <span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">word_embeddings</span><span class="o">,</span>
    <span class="n">ner_deid</span><span class="o">,</span>
    <span class="n">ner_deid_converter</span><span class="o">,</span>
    <span class="n">contextual_entity_filterer</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"NY, a 34-year-old woman, Dr. Michael Johnson cares wit her, at CarePlus Clinic, located at 456 Elm Street, NewYork, NY has recommended starting insulin therapy."</span>
<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>


<span class="k">#</span> <span class="n">result</span>
<span class="o">+---------------+-----+---+---------+----------+</span>
<span class="o">|</span><span class="n">chunk</span>          <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+---------------+-----+---+---------+----------+</span>
<span class="o">|</span><span class="nc">NY</span>             <span class="o">|</span><span class="mi">0</span>    <span class="o">|</span><span class="mi">1</span>  <span class="o">|</span><span class="nc">STATE</span>    <span class="o">|</span><span class="mf">0.9299</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">34</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span>    <span class="o">|</span><span class="mi">6</span>    <span class="o">|</span><span class="mi">16</span> <span class="o">|</span><span class="nc">AGE</span>      <span class="o">|</span><span class="mf">0.7687</span>    <span class="o">|</span>
<span class="o">|</span><span class="nc">Michael</span> <span class="nc">Johnson</span><span class="o">|</span><span class="mi">29</span>   <span class="o">|</span><span class="mi">43</span> <span class="o">|</span><span class="nc">DOCTOR</span>   <span class="o">|</span><span class="mf">0.89965</span>   <span class="o">|</span>
<span class="o">|</span><span class="nc">CarePlus</span> <span class="nc">Clinic</span><span class="o">|</span><span class="mi">63</span>   <span class="o">|</span><span class="mi">77</span> <span class="o">|</span><span class="nc">HOSPITAL</span> <span class="o">|</span><span class="mf">0.9661</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">456</span> <span class="nc">Elm</span> <span class="nc">Street</span> <span class="o">|</span><span class="mi">91</span>   <span class="o">|</span><span class="mi">104</span><span class="o">|</span><span class="nc">STREET</span>   <span class="o">|</span><span class="mf">0.7733667</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">NewYork</span>        <span class="o">|</span><span class="mi">107</span>  <span class="o">|</span><span class="mi">113</span><span class="o">|</span><span class="nc">CITY</span>     <span class="o">|</span><span class="mf">0.9302</span>    <span class="o">|</span>
<span class="o">|</span><span class="nc">NY</span>             <span class="o">|</span><span class="mi">116</span>  <span class="o">|</span><span class="mi">117</span><span class="o">|</span><span class="nc">STATE</span>    <span class="o">|</span><span class="mf">0.9991</span>    <span class="o">|</span>
<span class="o">+---------------+-----+---+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="contextualentityruler">ContextualEntityRuler</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>ContextualEntityRuler is an annotator that updates chunks based on contextual rules.
These rules are defined in the form of dictionaries and can include prefixes, suffixes, and the context within a specified scope window around the chunks.
This annotator modifies detected chunks by replacing their entity labels or content based on the patterns and rules if they match.
It is particularly useful for refining entity recognition results according to specific needs.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code>: Whether to perform case-sensitive matching. Default is False.</li>
      <li><code class="language-plaintext highlighter-rouge">allowPunctuationInBetween</code>: Whether to allow punctuation between prefix/suffix patterns and the entity. Default is True.</li>
      <li><code class="language-plaintext highlighter-rouge">allowTokensInBetween</code>: Whether to allow tokens between prefix/suffix patterns and the entity. Default is False.</li>
      <li><code class="language-plaintext highlighter-rouge">dropEmptyChunks</code>: If True, removes chunks with empty content after applying rules. Default is False.</li>
      <li><code class="language-plaintext highlighter-rouge">mergeOverlapping</code>: If False, it returns both modified entities and the original entities at the same time. Default is True.</li>
      <li><code class="language-plaintext highlighter-rouge">rules</code>: The updating rules. Each rule is a dictionary with the following keys:
        <ul>
          <li><code class="language-plaintext highlighter-rouge">entity</code>: The target entity label to modify.<br />
    Example: <code class="language-plaintext highlighter-rouge">"AGE"</code>.</li>
          <li><code class="language-plaintext highlighter-rouge">prefixPatterns</code>: Array of patterns (words/phrases) to match <strong>before the entity</strong>.<br />
    Example: <code class="language-plaintext highlighter-rouge">["years", "old"]</code> matches entities preceded by “years” or “old.”</li>
          <li><code class="language-plaintext highlighter-rouge">suffixPatterns</code>: Array of patterns (words/phrases) to match <strong>after the entity</strong>.<br />
    Example: <code class="language-plaintext highlighter-rouge">["years", "old"]</code> matches entities followed by “years” or “old.”</li>
          <li><code class="language-plaintext highlighter-rouge">scopeWindowLevel</code>: Specifies the level of the scope window to consider.<br />
    Valid values: <code class="language-plaintext highlighter-rouge">"token"</code> or <code class="language-plaintext highlighter-rouge">"char"</code>. Default: <code class="language-plaintext highlighter-rouge">"token"</code>.</li>
          <li><code class="language-plaintext highlighter-rouge">scopeWindow</code>: A tuple defining the range of tokens or characters (based on <code class="language-plaintext highlighter-rouge">scopeWindowLevel</code>) to include in the scope.<br />
    Default for “token” level: <code class="language-plaintext highlighter-rouge">(2, 2)</code>.
    Default for “char” level: <code class="language-plaintext highlighter-rouge">(10,10)</code>
    Example: <code class="language-plaintext highlighter-rouge">(2, 3)</code> means 2 tokens/characters before and 3 after the entity are considered.</li>
          <li><code class="language-plaintext highlighter-rouge">prefixRegexes</code>: Array of regular expressions to match <strong>before the entity</strong>.<br />
    Example: <code class="language-plaintext highlighter-rouge">["\\b(years|months)\\b"]</code> matches words like “years” or “months” as prefixes.</li>
          <li><code class="language-plaintext highlighter-rouge">suffixRegexes</code>: Array of regular expressions to match <strong>after the entity</strong>.<br />
    Example: <code class="language-plaintext highlighter-rouge">["\\b(old|young)\\b"]</code> matches words like “old” or “young” as suffixes.</li>
          <li><code class="language-plaintext highlighter-rouge">prefixEntites</code>: Array of entity labels to match <strong>before the entity</strong>.<br />
    Example: <code class="language-plaintext highlighter-rouge">["DATE"]</code> matches entities of type “DATE” as prefixes.</li>
          <li><code class="language-plaintext highlighter-rouge">suffixEntities</code>: Array of entity labels to match <strong>after the entity</strong>.<br />
    Example: <code class="language-plaintext highlighter-rouge">["DATE"]</code> matches entities of type “DATE” as suffixes.</li>
          <li><code class="language-plaintext highlighter-rouge">regexInBetween</code>: Regular expression to match text between the entity and prefix/suffix. If matched, the prefix/suffix entities will be included with the target entity.</li>
          <li><code class="language-plaintext highlighter-rouge">replaceEntity</code>: Optional string specifying the new entity label to replace with the target entity label.<br />
    Example: <code class="language-plaintext highlighter-rouge">"MODIFIED_AGE"</code> replaces <code class="language-plaintext highlighter-rouge">"AGE"</code> with <code class="language-plaintext highlighter-rouge">"MODIFIED_AGE"</code> in matching cases.</li>
          <li><code class="language-plaintext highlighter-rouge">mode</code>: Specifies the operational mode for the rules. Options: <code class="language-plaintext highlighter-rouge">include</code>, <code class="language-plaintext highlighter-rouge">exclude</code>, or <code class="language-plaintext highlighter-rouge">replace_label_only</code>. Default is <code class="language-plaintext highlighter-rouge">include</code>.</li>
        </ul>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/context/contextual_entity_ruler/index.html">ContextualEntityRuler</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/context/ContextualEntityRuler.html">ContextualEntityRuler</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ContextualEntityRuler.ipynb">ContextualEntityRuler</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">jsl_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner"</span><span class="p">)</span> 

<span class="n">jsl_ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"jsl_ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">rules</span> <span class="o">=</span> <span class="p">[</span>   <span class="p">{</span>
                <span class="s">"entity"</span> <span class="p">:</span> <span class="s">"Age"</span><span class="p">,</span>
                <span class="s">"scopeWindow"</span> <span class="p">:</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">],</span>
                <span class="s">"scopeWindowLevel"</span>  <span class="p">:</span> <span class="s">"char"</span><span class="p">,</span>
                <span class="s">"suffixPatterns"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"years old"</span><span class="p">,</span> <span class="s">"year old"</span><span class="p">,</span> <span class="s">"months"</span><span class="p">,],</span>
                <span class="s">"replaceEntity"</span> <span class="p">:</span> <span class="s">"Modified_Age"</span><span class="p">,</span>
                <span class="s">"mode"</span> <span class="p">:</span> <span class="s">"exclude"</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s">"entity"</span> <span class="p">:</span> <span class="s">"Diabetes"</span><span class="p">,</span>
                <span class="s">"scopeWindow"</span> <span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
                <span class="s">"scopeWindowLevel"</span>  <span class="p">:</span> <span class="s">"token"</span><span class="p">,</span>
                <span class="s">"suffixPatterns"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"with complications"</span><span class="p">],</span>
                <span class="s">"replaceEntity"</span> <span class="p">:</span> <span class="s">"Modified_Diabetes"</span><span class="p">,</span>
                <span class="s">"mode"</span> <span class="p">:</span> <span class="s">"include"</span>
            <span class="p">},</span>
            <span class="p">{</span>
                <span class="s">"entity"</span> <span class="p">:</span> <span class="s">"Date"</span><span class="p">,</span>
                <span class="s">"suffixRegexes"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"</span><span class="se">\\</span><span class="s">d{4}"</span><span class="p">],</span>
                <span class="s">"replaceEntity"</span> <span class="p">:</span> <span class="s">"Modified_Date"</span><span class="p">,</span>
                <span class="s">"mode"</span> <span class="p">:</span> <span class="s">"include"</span>
            <span class="p">}</span>
        <span class="p">]</span>

<span class="n">contextual_entity_ruler</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ContextualEntityRuler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ruled_ner_chunks"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRules</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDropEmptyChunks</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setAllowPunctuationInBetween</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ruler_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documentAssembler</span><span class="p">,</span>
        <span class="n">sentenceDetector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">jsl_ner</span><span class="p">,</span>
        <span class="n">jsl_ner_converter</span><span class="p">,</span>
        <span class="n">contextual_entity_ruler</span><span class="p">,</span>
        <span class="n">flattener</span>
    <span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">ruler_model</span> <span class="o">=</span> <span class="n">ruler_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span><span class="s">"""The Doctor assessed the 36 years old who has a history of the diabetes mellitus with complications in May, 2006"""</span>
<span class="n">ruler_result</span> <span class="o">=</span> <span class="n">ruler_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">ruler_result</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>


<span class="c1"># result
</span>
<span class="o">+-----------------+-----+---+------------------------------------+</span>
<span class="o">|</span><span class="n">entity</span>           <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ruled_ner_chunks_result</span>             <span class="o">|</span>
<span class="o">+-----------------+-----+---+------------------------------------+</span>
<span class="o">|</span><span class="n">Modified_Age</span>     <span class="o">|</span><span class="mi">28</span>   <span class="o">|</span><span class="mi">29</span> <span class="o">|</span><span class="mi">36</span>                                  <span class="o">|</span>
<span class="o">|</span><span class="n">Modified_Diabetes</span><span class="o">|</span><span class="mi">66</span>   <span class="o">|</span><span class="mi">101</span><span class="o">|</span><span class="n">diabetes</span> <span class="n">mellitus</span> <span class="k">with</span> <span class="n">complications</span><span class="o">|</span>
<span class="o">|</span><span class="n">Modified_Date</span>    <span class="o">|</span><span class="mi">106</span>  <span class="o">|</span><span class="mi">114</span><span class="o">|</span><span class="n">May</span><span class="p">,</span> <span class="mi">2006</span>                           <span class="o">|</span>
<span class="o">+-----------------+-----+---+------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">rules</span> <span class="k">=</span>
    <span class="s">"""
    |[
    |  {
    |    "entity": "Age",
    |    "scopeWindow": [15, 15],
    |    "scopeWindowLevel": "char",
    |    "suffixPatterns": ["years old", "year old", "months"],
    |    "replaceEntity": "Modified_Age",
    |    "mode": "exclude"
    |  },
    |  {
    |    "entity": "Diabetes",
    |    "scopeWindow": [3, 3],
    |    "scopeWindowLevel": "token",
    |    "suffixPatterns": ["with complications"],
    |    "replaceEntity": "Modified_Diabetes",
    |    "mode": "include"
    |  },
    |  {
    |    "entity": "Date",
    |    "suffixRegexes": ["\\d{4}"],
    |    "replaceEntity": "Modified_Date",
    |    "mode": "include"
    |  }
    |]
    """</span><span class="o">.</span><span class="py">stripMargin</span>


<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">jslNer</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">jslNerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"jsl_ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="k">val</span>  <span class="nv">contextualEntityRuler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextualEntityRuler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ruled_ner_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRulesAsStr</span><span class="o">(</span><span class="n">rules</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDropEmptyChunks</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setAllowPunctuationInBetween</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ruler_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span>
  <span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">wordEmbeddings</span><span class="o">,</span>
    <span class="n">jslNer</span><span class="o">,</span>
    <span class="n">jslNerConverter</span><span class="o">,</span>
    <span class="n">contextualEntityRuler</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"The Doctor assessed the 36 years old who has a history of the diabetes mellitus with complications in May, 2006"</span>
<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>


<span class="k">#</span> <span class="n">result</span>
<span class="o">+-----------------+-----+---+------------------------------------+</span>
<span class="o">|</span><span class="n">entity</span>           <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ruled_ner_chunks_result</span>             <span class="o">|</span>
<span class="o">+-----------------+-----+---+------------------------------------+</span>
<span class="o">|</span><span class="nc">Modified_Age</span>     <span class="o">|</span><span class="mi">28</span>   <span class="o">|</span><span class="mi">30</span> <span class="o">|</span><span class="mi">36</span>                                  <span class="o">|</span>
<span class="o">|</span><span class="nc">Modified_Diabetes</span><span class="o">|</span><span class="mi">66</span>   <span class="o">|</span><span class="mi">101</span><span class="o">|</span><span class="n">diabetes</span> <span class="n">mellitus</span> <span class="k">with</span> <span class="n">complications</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Modified_Date</span>    <span class="o">|</span><span class="mi">106</span>  <span class="o">|</span><span class="mi">114</span><span class="o">|</span><span class="nc">May</span><span class="o">,</span> <span class="mi">2006</span>                           <span class="o">|</span>
<span class="o">+-----------------+-----+---+------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="contextualparser">ContextualParser</h2>

  <div class="annotator_type tac mont">Approach</div>

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Creates a model, that extracts entity from a document based on user defined rules.
Rule matching is based on a RegexMatcher defined in a JSON file. It is set through the parameter setJsonPath()
In this JSON file, regex is defined that you want to match along with the information that will output on metadata
field. Additionally, a dictionary can be provided with <code class="language-plaintext highlighter-rouge">setDictionary</code> to map extracted entities
to a unified representation. The first column of the dictionary file should be the representation with following
columns the possible matches.</p>

    <p>Parametres;</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</li>
      <li><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</li>
      <li><code class="language-plaintext highlighter-rouge">jsonPath</code>: Path to json file containing regex patterns and rules to match the entities.</li>
      <li><code class="language-plaintext highlighter-rouge">dictionary</code>: Path to dictionary file in tsv or csv format.</li>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code>: Whether to use case sensitive when matching values.</li>
      <li><code class="language-plaintext highlighter-rouge">prefixAndSuffixMatch</code>: Whether to match both prefix and suffix to annotate the match.</li>
      <li><code class="language-plaintext highlighter-rouge">optionalContextRules</code>: When set to true, it will output regex match regardless of context matches.</li>
      <li><code class="language-plaintext highlighter-rouge">shortestContextMatch</code>: When set to true, it will stop finding for matches when prefix/suffix data is found in the text.</li>
      <li><code class="language-plaintext highlighter-rouge">completeContextMatch</code>: Whether to do an exact match of prefix and suffix.</li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/context/contextual_parser/index.html#sparknlp_jsl.annotator.context.contextual_parser.ContextualParserApproach">ContextualParserApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/context/ContextualParserApproach.html">ContextualParserApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ContextualParserApproach.ipynb">ContextualParserApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># An example JSON file `regex_token.json` can look like this:
#
# {
#    "entity": "Stage",
#    "ruleScope": "sentence",
#    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",
#    "matchScope": "token"
#  }
#
# Which means to extract the stage code on a sentence level.
# An example pipeline could then be defined like this
# Pipeline could then be defined like this
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">contextualParser</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ContextualParserApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"/path/to/regex_token.json"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setContextMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">contextualParser</span>
  <span class="p">])</span>

<span class="c1"># Define the parser (json file needs to be provided)
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... "</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entity)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">col</span>                                                                                                                      <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="n">pT1bN0M0</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">T5</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}</span>         <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">148</span><span class="p">,</span> <span class="mi">156</span><span class="p">,</span> <span class="n">cT4bcN2M1</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}</span><span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">189</span><span class="p">,</span> <span class="mi">194</span><span class="p">,</span> <span class="n">T</span><span class="err">?</span><span class="n">N3M1</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">{</span><span class="n">chunk</span><span class="p">,</span> <span class="mi">316</span><span class="p">,</span> <span class="mi">323</span><span class="p">,</span> <span class="n">pT1bN0M0</span><span class="p">,</span> <span class="p">{</span><span class="n">field</span> <span class="o">-&gt;</span> <span class="n">Stage</span><span class="p">,</span> <span class="n">normalized</span> <span class="o">-&gt;</span> <span class="p">,</span> <span class="n">confidenceValue</span> <span class="o">-&gt;</span> <span class="mf">0.13</span><span class="p">,</span> <span class="n">hits</span> <span class="o">-&gt;</span> <span class="n">regex</span><span class="p">,</span> <span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}</span> <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># An example JSON file `regex_token.json` can look like this:
#
# {
#    "entity": "Stage",
#    "ruleScope": "sentence",
#    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",
#    "matchScope": "token"
#  }
#
# Which means to extract the stage code on a sentence level.
# An example pipeline could then be defined like this
# Pipeline could then be defined like this
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Define the parser (json file needs to be provided)
</span>
<span class="n">contextualParser</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ContextualParserApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"/path/to/regex_token.json"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setContextMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">contextualParser</span>
  <span class="p">])</span>

<span class="c1"># Define the parser (json file needs to be provided)
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Peter Parker is a nice guy and lives in New York . Bruce Wayne is also a nice guy and lives in San Antonio and Gotham City ."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entity)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                         <span class="o">|</span>
<span class="o">+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Peter</span> <span class="n">Parker</span><span class="p">,</span> <span class="n">New</span> <span class="n">York</span><span class="p">,</span> <span class="n">Bruce</span> <span class="n">Wayne</span><span class="p">,</span> <span class="n">San</span> <span class="n">Antonio</span><span class="p">,</span> <span class="n">Gotham</span> <span class="n">City</span><span class="p">]</span><span class="o">|</span>
<span class="o">+---------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># An example JSON file `regex_token.json` can look like this:
#
# {
#    "entity": "Stage",
#    "ruleScope": "sentence",
#    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",
#    "matchScope": "token"
#  }
#
# Which means to extract the stage code on a sentence level.
# An example pipeline could then be defined like this
# Pipeline could then be defined like this
</span>
<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">contextualParser</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ContextualParserApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setJsonPath</span><span class="p">(</span><span class="s">"/path/to/regex_token.json"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setContextMatch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">contextualParser</span>
  <span class="p">])</span>

<span class="c1"># Define the parser (json file needs to be provided)
</span><span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Peter Parker is a nice guy and lives in New York . Bruce Wayne is also a nice guy and lives in San Antonio and Gotham City ."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(entity)"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                         <span class="o">|</span>
<span class="o">+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Peter</span> <span class="n">Parker</span><span class="p">,</span> <span class="n">New</span> <span class="n">York</span><span class="p">,</span> <span class="n">Bruce</span> <span class="n">Wayne</span><span class="p">,</span> <span class="n">San</span> <span class="n">Antonio</span><span class="p">,</span> <span class="n">Gotham</span> <span class="n">City</span><span class="p">]</span><span class="o">|</span>
<span class="o">+---------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// An example JSON file `regex_token.json` can look like this:</span>
<span class="c1">//</span>
<span class="c1">// {</span>
<span class="c1">//    "entity": "Stage",</span>
<span class="c1">//    "ruleScope": "sentence",</span>
<span class="c1">//    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",</span>
<span class="c1">//    "matchScope": "token"</span>
<span class="c1">//  }</span>
<span class="c1">//</span>
<span class="c1">// Which means to extract the stage code on a sentence level.</span>
<span class="c1">// An example pipeline could then be defined like this</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">contextualParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextualParserApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setJsonPath</span><span class="o">(</span><span class="s">"/path/to/regex_token.json"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setContextMatch</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">contextualParser</span>
  <span class="o">))</span>

<span class="c1">// Define the parser (json file needs to be provided)</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"A patient has liver metastases pT1bN0M0 and the T5 primary site may be colon or... "</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show Results</span>
<span class="c1">//</span>
<span class="c1">// result.selectExpr("explode(entity)").show(5, truncate=false)</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |col                                                                                                                      |</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">// |{chunk, 32, 39, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []}   |</span>
<span class="c1">// |{chunk, 49, 50, T5, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 0}, []}         |</span>
<span class="c1">// |{chunk, 148, 156, cT4bcN2M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 1}, []}|</span>
<span class="c1">// |{chunk, 189, 194, T?N3M1, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 2}, []}   |</span>
<span class="c1">// |{chunk, 316, 323, pT1bN0M0, {field -&gt; Stage, normalized -&gt; , confidenceValue -&gt; 0.13, hits -&gt; regex, sentence -&gt; 3}, []} |</span>
<span class="c1">// +-------------------------------------------------------------------------------------------------------------------------+</span>
<span class="c1">//</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// An example JSON file `regex_token.json` can look like this:</span>
<span class="c1">//</span>
<span class="c1">// {</span>
<span class="c1">//    "entity": "Stage",</span>
<span class="c1">//    "ruleScope": "sentence",</span>
<span class="c1">//    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",</span>
<span class="c1">//    "matchScope": "token"</span>
<span class="c1">//  }</span>
<span class="c1">//</span>
<span class="c1">// Which means to extract the stage code on a sentence level.</span>
<span class="c1">// An example pipeline could then be defined like this</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">contextualParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextualParserApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setJsonPath</span><span class="o">(</span><span class="s">"/path/to/regex_token.json"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setContextMatch</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">contextualParser</span>
  <span class="o">))</span>

<span class="c1">// Define the parser (json file needs to be provided)</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Peter Parker is a nice guy and lives in New York . Bruce Wayne is also a nice guy and lives in San Antonio and Gotham City ."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show Results</span>

<span class="o">+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                         <span class="o">|</span>
<span class="o">+---------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Peter</span> <span class="kt">Parker</span>, <span class="kt">New</span> <span class="kt">York</span>, <span class="kt">Bruce</span> <span class="kt">Wayne</span>, <span class="kt">San</span> <span class="kt">Antonio</span>, <span class="kt">Gotham</span> <span class="kt">City</span><span class="o">]|</span>
<span class="o">+---------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// An example JSON file `regex_token.json` can look like this:</span>
<span class="c1">//</span>
<span class="c1">// {</span>
<span class="c1">//    "entity": "Stage",</span>
<span class="c1">//    "ruleScope": "sentence",</span>
<span class="c1">//    "regex": "[cpyrau]?[T][0-9X?][a-z^cpyrau]",</span>
<span class="c1">//    "matchScope": "token"</span>
<span class="c1">//  }</span>
<span class="c1">//</span>
<span class="c1">// Which means to extract the stage code on a sentence level.</span>
<span class="c1">// An example pipeline could then be defined like this</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">contextualParser</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ContextualParserApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setJsonPath</span><span class="o">(</span><span class="s">"/path/to/regex_token.json"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setContextMatch</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">contextualParser</span>
  <span class="o">))</span>

<span class="c1">// Define the parser (json file needs to be provided)</span>
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Peter Parker is a nice guy and lives in New York . Bruce Wayne is also a nice guy and lives in San Antonio and Gotham City ."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show Results</span>
<span class="o">+---------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                         <span class="o">|</span>
<span class="o">+---------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Peter</span> <span class="kt">Parker</span>, <span class="kt">New</span> <span class="kt">York</span>, <span class="kt">Bruce</span> <span class="kt">Wayne</span>, <span class="kt">San</span> <span class="kt">Antonio</span>, <span class="kt">Gotham</span> <span class="kt">City</span><span class="o">]|</span>
<span class="o">+---------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="datenormalizer">DateNormalizer</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator transforms date mentions to a common standard format: YYYY/MM/DD. It is useful when using data from different sources, some times from different countries that has different formats to represent dates.</p>

    <p>For the relative dates (next year, past month, etc.), you can define an achor date to create the normalized date by setting the parameters <code class="language-plaintext highlighter-rouge">anchorDateYear</code>, <code class="language-plaintext highlighter-rouge">anchorDateMonth</code>, and <code class="language-plaintext highlighter-rouge">anchorDateDay</code>.</p>

    <p>The resultant chunk date will contain a metada indicating whether the normalization was successful or not (True / False).</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">anchorDateYear</code>: (Int) Sets an anchor year for the relative dates such as a day after tomorrow. If not set it will use the current year.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">anchorDateMonth</code>: (Int) Sets an anchor month for the relative dates such as a day after tomorrow. If not set it will use the current month.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">anchorDateDay</code>: (Int) Sets an anchor day of the day for the relative dates such as a day after tomorrow. If not set it will use the current day.</p>
      </li>
      <li><code class="language-plaintext highlighter-rouge">outputDateformat</code>: (string) Select what output format to use. If not set, the dates will be formatted as  <code class="language-plaintext highlighter-rouge">YYYY/MM/DD</code>. Options are:
        <ul>
          <li><code class="language-plaintext highlighter-rouge">eu</code>: Format the dates as <code class="language-plaintext highlighter-rouge">DD/MM/YYYY</code></li>
          <li><code class="language-plaintext highlighter-rouge">us</code>: Format the dates as <code class="language-plaintext highlighter-rouge">MM/DD/YYYY</code></li>
        </ul>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">defaultReplacementDay</code>: (Int) Defines which value to use for creating the Day Value when original Date-Entity has no Day Information. Defaults to 15.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">defaultReplacementMonth</code>: (Int) Defines which value to use for creating the Month Value when original Date-Entity has no Month Information. Defaults to 06.</p>
      </li>
      <li><code class="language-plaintext highlighter-rouge">defaultReplacementYear</code>: (Int) Defines which value to use for creating the Year Value when original Date-Entity has no Year Information. Defaults to 2020.</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/normalizer/date_normalizer/index.html#sparknlp_jsl.annotator.normalizer.date_normalizer.DateNormalizer">DateNormalizer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/normalizer/DateNormalizer.html">DateNormalizer</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DateNormalizer.ipynb">DateNormalizerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"original_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">doc2chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date_chunk"</span><span class="p">)</span>

<span class="n">date_normalizer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DateNormalizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"date_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setAnchorDateYear</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">doc2chunk</span><span class="p">,</span> <span class="n">date_normalizer</span><span class="p">])</span>

<span class="n">dates</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"08/02/2018"</span><span class="p">,</span>
    <span class="s">"11/2018"</span><span class="p">,</span>
    <span class="s">"11/01/2018"</span><span class="p">,</span>
    <span class="s">"12Mar2021"</span><span class="p">,</span>
    <span class="s">"Jan 30, 2018"</span><span class="p">,</span>
    <span class="s">"13.04.1999"</span><span class="p">,</span>
    <span class="s">"3April 2020"</span><span class="p">,</span>
    <span class="s">"next monday"</span><span class="p">,</span>
    <span class="s">"today"</span><span class="p">,</span>
    <span class="s">"next week"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dates</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"original_date"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"date.result as normalized_date"</span><span class="p">,</span>
    <span class="s">"original_date"</span><span class="p">,</span>
    <span class="s">"date.metadata[0].normalized as metadata"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span><span class="n">normalized_date</span><span class="o">|</span><span class="n">original_date</span><span class="o">|</span><span class="n">metadata</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="p">]</span><span class="o">|</span>   <span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="mi">15</span><span class="p">]</span><span class="o">|</span>      <span class="mi">11</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="p">]</span><span class="o">|</span>   <span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2021</span><span class="o">/</span><span class="mi">03</span><span class="o">/</span><span class="mi">12</span><span class="p">]</span><span class="o">|</span>    <span class="mi">12</span><span class="n">Mar2021</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">30</span><span class="p">]</span><span class="o">|</span> <span class="n">Jan</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">1999</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">13</span><span class="p">]</span><span class="o">|</span>   <span class="mf">13.04</span><span class="p">.</span><span class="mi">1999</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2020</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">03</span><span class="p">]</span><span class="o">|</span>  <span class="mi">3</span><span class="n">April</span> <span class="mi">2020</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">11</span><span class="p">]</span><span class="o">|</span>  <span class="nb">next</span> <span class="n">monday</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">06</span><span class="p">]</span><span class="o">|</span>        <span class="n">today</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">13</span><span class="p">]</span><span class="o">|</span>    <span class="nb">next</span> <span class="n">week</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"original_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">doc2chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date_chunk"</span><span class="p">)</span>

<span class="n">date_normalizer</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DateNormalizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"date_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setAnchorDateYear</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">doc2chunk</span><span class="p">,</span> <span class="n">date_normalizer</span><span class="p">])</span>

<span class="n">dates</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"08/02/2018"</span><span class="p">,</span>
    <span class="s">"11/2018"</span><span class="p">,</span>
    <span class="s">"11/01/2018"</span><span class="p">,</span>
    <span class="s">"12Mar2021"</span><span class="p">,</span>
    <span class="s">"Jan 30, 2018"</span><span class="p">,</span>
    <span class="s">"13.04.1999"</span><span class="p">,</span>
    <span class="s">"3April 2020"</span><span class="p">,</span>
    <span class="s">"next monday"</span><span class="p">,</span>
    <span class="s">"today"</span><span class="p">,</span>
    <span class="s">"next week"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dates</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"original_date"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"date.result as normalized_date"</span><span class="p">,</span>
    <span class="s">"original_date"</span><span class="p">,</span>
    <span class="s">"date.metadata[0].normalized as metadata"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">()</span>

<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span><span class="n">normalized_date</span><span class="o">|</span><span class="n">original_date</span><span class="o">|</span><span class="n">metadata</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="p">]</span><span class="o">|</span>   <span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="mi">15</span><span class="p">]</span><span class="o">|</span>      <span class="mi">11</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="p">]</span><span class="o">|</span>   <span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2021</span><span class="o">/</span><span class="mi">03</span><span class="o">/</span><span class="mi">12</span><span class="p">]</span><span class="o">|</span>    <span class="mi">12</span><span class="n">Mar2021</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">30</span><span class="p">]</span><span class="o">|</span> <span class="n">Jan</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">1999</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">13</span><span class="p">]</span><span class="o">|</span>   <span class="mf">13.04</span><span class="p">.</span><span class="mi">1999</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2020</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">03</span><span class="p">]</span><span class="o">|</span>  <span class="mi">3</span><span class="n">April</span> <span class="mi">2020</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">11</span><span class="p">]</span><span class="o">|</span>  <span class="nb">next</span> <span class="n">monday</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">06</span><span class="p">]</span><span class="o">|</span>        <span class="n">today</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">13</span><span class="p">]</span><span class="o">|</span>    <span class="nb">next</span> <span class="n">week</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"original_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">doc2chunk</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Doc2Chunk</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date_chunk"</span><span class="p">)</span>

<span class="n">date_normalizer</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DateNormalizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"date_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setAnchorDateYear</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">doc2chunk</span><span class="p">,</span> <span class="n">date_normalizer</span><span class="p">])</span>

<span class="n">dates</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"08/02/2018"</span><span class="p">,</span>
    <span class="s">"11/2018"</span><span class="p">,</span>
    <span class="s">"11/01/2018"</span><span class="p">,</span>
    <span class="s">"12Mar2021"</span><span class="p">,</span>
    <span class="s">"Jan 30, 2018"</span><span class="p">,</span>
    <span class="s">"13.04.1999"</span><span class="p">,</span>
    <span class="s">"3April 2020"</span><span class="p">,</span>
    <span class="s">"next monday"</span><span class="p">,</span>
    <span class="s">"today"</span><span class="p">,</span>
    <span class="s">"next week"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">dates</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"original_date"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>


<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span><span class="n">normalized_date</span><span class="o">|</span><span class="n">original_date</span><span class="o">|</span><span class="n">metadata</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="p">]</span><span class="o">|</span>   <span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="mi">15</span><span class="p">]</span><span class="o">|</span>      <span class="mi">11</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="p">]</span><span class="o">|</span>   <span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2021</span><span class="o">/</span><span class="mi">03</span><span class="o">/</span><span class="mi">12</span><span class="p">]</span><span class="o">|</span>    <span class="mi">12</span><span class="n">Mar2021</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2018</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">30</span><span class="p">]</span><span class="o">|</span> <span class="n">Jan</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">2018</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">1999</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">13</span><span class="p">]</span><span class="o">|</span>   <span class="mf">13.04</span><span class="p">.</span><span class="mi">1999</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2020</span><span class="o">/</span><span class="mi">04</span><span class="o">/</span><span class="mi">03</span><span class="p">]</span><span class="o">|</span>  <span class="mi">3</span><span class="n">April</span> <span class="mi">2020</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">11</span><span class="p">]</span><span class="o">|</span>  <span class="nb">next</span> <span class="n">monday</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">06</span><span class="p">]</span><span class="o">|</span>        <span class="n">today</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="p">[</span><span class="mi">2000</span><span class="o">/</span><span class="mi">12</span><span class="o">/</span><span class="mi">13</span><span class="p">]</span><span class="o">|</span>    <span class="nb">next</span> <span class="n">week</span><span class="o">|</span>    <span class="n">true</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"original_date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">doc2chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">date_normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DateNormalizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"date_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setAnchorDateYear</span><span class="o">(</span><span class="mi">2000</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">doc2chunk</span><span class="o">,</span> 
    <span class="n">date_normalizer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"08/02/2018"</span><span class="o">),(</span><span class="s">"11/2018"</span><span class="o">),(</span><span class="s">"11/01/2018"</span><span class="o">),(</span><span class="s">"next monday"</span><span class="o">),(</span><span class="s">"today"</span><span class="o">),(</span><span class="s">"next week"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"original_date"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span><span class="n">normalized_date</span><span class="o">|</span><span class="n">original_date</span><span class="o">|</span><span class="n">metadata</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">08</span><span class="kt">/</span><span class="err">02</span><span class="o">]|</span>   <span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">11</span><span class="kt">/</span><span class="err">15</span><span class="o">]|</span>      <span class="mi">11</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">11</span><span class="kt">/</span><span class="err">01</span><span class="o">]|</span>   <span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2021</span><span class="kt">/</span><span class="err">03</span><span class="kt">/</span><span class="err">12</span><span class="o">]|</span>    <span class="mi">12</span><span class="nc">Mar2021</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">30</span><span class="o">]|</span> <span class="nc">Jan</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">1999</span><span class="kt">/</span><span class="err">04</span><span class="kt">/</span><span class="err">13</span><span class="o">]|</span>   <span class="mf">13.04</span><span class="o">.</span><span class="mi">1999</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2020</span><span class="kt">/</span><span class="err">04</span><span class="kt">/</span><span class="err">03</span><span class="o">]|</span>  <span class="mi">3</span><span class="nc">April</span> <span class="mi">2020</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">11</span><span class="o">]|</span>  <span class="n">next</span> <span class="n">monday</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">06</span><span class="o">]|</span>        <span class="n">today</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">13</span><span class="o">]|</span>    <span class="n">next</span> <span class="n">week</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"original_date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">doc2chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">date_normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DateNormalizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"date_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setAnchorDateYear</span><span class="o">(</span><span class="mi">2000</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">doc2chunk</span><span class="o">,</span> 
    <span class="n">date_normalizer</span>
<span class="o">))</span>
 
<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"08/02/2018"</span><span class="o">),(</span><span class="s">"11/2018"</span><span class="o">),(</span><span class="s">"11/01/2018"</span><span class="o">),(</span><span class="s">"next monday"</span><span class="o">),(</span><span class="s">"today"</span><span class="o">),(</span><span class="s">"next week"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"original_date"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>


<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span><span class="n">normalized_date</span><span class="o">|</span><span class="n">original_date</span><span class="o">|</span><span class="n">metadata</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">08</span><span class="kt">/</span><span class="err">02</span><span class="o">]|</span>   <span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">11</span><span class="kt">/</span><span class="err">15</span><span class="o">]|</span>      <span class="mi">11</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">11</span><span class="kt">/</span><span class="err">01</span><span class="o">]|</span>   <span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2021</span><span class="kt">/</span><span class="err">03</span><span class="kt">/</span><span class="err">12</span><span class="o">]|</span>    <span class="mi">12</span><span class="nc">Mar2021</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">30</span><span class="o">]|</span> <span class="nc">Jan</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">1999</span><span class="kt">/</span><span class="err">04</span><span class="kt">/</span><span class="err">13</span><span class="o">]|</span>   <span class="mf">13.04</span><span class="o">.</span><span class="mi">1999</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2020</span><span class="kt">/</span><span class="err">04</span><span class="kt">/</span><span class="err">03</span><span class="o">]|</span>  <span class="mi">3</span><span class="nc">April</span> <span class="mi">2020</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">11</span><span class="o">]|</span>  <span class="n">next</span> <span class="n">monday</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">06</span><span class="o">]|</span>        <span class="n">today</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">13</span><span class="o">]|</span>    <span class="n">next</span> <span class="n">week</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"original_date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">doc2chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">date_normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DateNormalizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"date_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"date"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setAnchorDateYear</span><span class="o">(</span><span class="mi">2000</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">doc2chunk</span><span class="o">,</span> 
    <span class="n">date_normalizer</span>
<span class="o">))</span>
 
<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"08/02/2018"</span><span class="o">),(</span><span class="s">"11/2018"</span><span class="o">),(</span><span class="s">"11/01/2018"</span><span class="o">),(</span><span class="s">"next monday"</span><span class="o">),(</span><span class="s">"today"</span><span class="o">),(</span><span class="s">"next week"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"original_date"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>


<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span><span class="n">normalized_date</span><span class="o">|</span><span class="n">original_date</span><span class="o">|</span><span class="n">metadata</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">08</span><span class="kt">/</span><span class="err">02</span><span class="o">]|</span>   <span class="mi">08</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">11</span><span class="kt">/</span><span class="err">15</span><span class="o">]|</span>      <span class="mi">11</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">11</span><span class="kt">/</span><span class="err">01</span><span class="o">]|</span>   <span class="mi">11</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2021</span><span class="kt">/</span><span class="err">03</span><span class="kt">/</span><span class="err">12</span><span class="o">]|</span>    <span class="mi">12</span><span class="nc">Mar2021</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2018</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">30</span><span class="o">]|</span> <span class="nc">Jan</span> <span class="mi">30</span><span class="o">,</span> <span class="mi">2018</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">1999</span><span class="kt">/</span><span class="err">04</span><span class="kt">/</span><span class="err">13</span><span class="o">]|</span>   <span class="mf">13.04</span><span class="o">.</span><span class="mi">1999</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2020</span><span class="kt">/</span><span class="err">04</span><span class="kt">/</span><span class="err">03</span><span class="o">]|</span>  <span class="mi">3</span><span class="nc">April</span> <span class="mi">2020</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">11</span><span class="o">]|</span>  <span class="n">next</span> <span class="n">monday</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">06</span><span class="o">]|</span>        <span class="n">today</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">|</span>   <span class="o">[</span><span class="err">2000</span><span class="kt">/</span><span class="err">12</span><span class="kt">/</span><span class="err">13</span><span class="o">]|</span>    <span class="n">next</span> <span class="n">week</span><span class="o">|</span>    <span class="kc">true</span><span class="o">|</span>
<span class="o">+---------------+-------------+--------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="deidentification">DeIdentification</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Deidentification is a critical and important technology to facilitate the use of structured or unstructured clinical text while protecting patient privacy and confidentiality. John Snow Labs teams has invested great efforts in developing methods and corpora for deidentification of clinical text, PDF, image, DICOM, containing Protected Health Information (PHI):</p>

    <ul>
      <li>individual’s past, present, or future physical or mental health or condition.</li>
      <li>provision of health care to the individual.</li>
      <li>past, present, or future payment for the health care.</li>
    </ul>

    <p>Protected health information includes many common identifiers (e.g., name, address, birth date, Social Security Number) when they can be associated with the health information.</p>

    <p>Spark NLP for Healthcare proposes several techniques and strategies for deidentification, the principal ones are:</p>

    <p>Mask:</p>
    <ul>
      <li>entity_labels: Mask with the entity type of that chunk. (default)</li>
      <li>same_length_chars: Mask the deid entities with same length of asterix ( * ) with brackets ( [ , ] ) on both end.</li>
      <li>fixed_length_chars: Mask the deid entities with a fixed length of asterix ( * ). The length is setting up using the setFixedMaskLength() method.</li>
    </ul>

    <p>Obfuscation: replace sensetive entities with random values of the same type.</p>

    <p>Faker:  allows the user to use a set of fake entities that are in the memory of spark-nlp-internal</p>

    <p>Also there is an advanced option allowing to deidentify with multiple modes at the same time. (Multi-Mode Deididentification).
Deidentifies Input Annotations of types DOCUMENT, TOKEN and CHUNK, by either masking or obfuscating the given CHUNKS.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ageRanges</code>: (IntArrayParam) List of integers specifying limits of the age groups to preserve during obfuscation</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">blackList</code>: (StringArrayParam) List of entities that will be ignored to in the regex file.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">consistentObfuscation</code>: (BooleanParam) Whether to replace very similar entities in a document with the same randomized term (default: true) The similarity is based on the Levenshtein Distance between the words.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dateFormats</code>: (StringArrayParam) Format of dates to displace</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dateTag</code>: (Param[String]) Tag representing what are the NER entity (default: DATE)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dateToYear</code>: (BooleanParam) true if dates must be converted to years, false otherwise</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">days</code>: (IntParam) Number of days to obfuscate the dates by displacement.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">fixedMaskLength</code>: (IntParam) Select the fixed mask length: this is the length of the masking sequence that will be used when the ‘fixed_length_chars’ masking policy is selected.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ignoreRegex</code>: (BooleanParam) Select if you want to use regex file loaded in the model.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">isRandomDateDisplacement</code>: (BooleanParam) Use a random displacement days in dates entities,that random number is based on the DeIdentificationParams.seed If true use random displacement days in dates entities,if false use the DeIdentificationParams.days The default value is false.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">language</code>: (Param[String]) The language used to select the regex file and some faker entities.’en’(english),’de’(German), ‘es’(Spanish), ‘fr’(French) or ‘ro’(Romanian)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">mappingsColumn</code>: (Param[String]) This is the mapping column that will return the Annotations chunks with the fake entities</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maskingPolicy</code>: (Param[String])
Select the masking policy:
same_length_chars: Replace the obfuscated entity with a masking sequence composed of asterisks and surrounding squared brackets, being the total length of the masking sequence of the same length as the original sequence. Example, Smith -&gt; [***]. If the entity is less than 3 chars (like Jo, or 5), asterisks without brackets will be returned. entity_labels: Replace the values with the corresponding entity labels. fixed_length_chars: Replace the obfuscated entity with a masking sequence composed of a fixed number of asterisks.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">minYear</code>: (IntParam) Minimum year to use when converting date to year</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">mode</code>: (Param[String]) Mode for Anonymizer [‘mask’, ‘obfuscate’] Given the following text</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">obfuscateDate</code>: (BooleanParam) When mode==”obfuscate” whether to obfuscate dates or not.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">obfuscateRefFile</code>: (Param[String]) File with the terms to be used for Obfuscation</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">obfuscateRefSource</code>: (Param[String]) The source of obfuscation of to obfuscate the entities.For dates entities doesnt apply tha method.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputAsDocument</code>: (BooleanParam) Whether to return all sentences joined into a single document</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">refFileFormat</code>: (Param[String]) Format of the reference file for Obfuscation the default value for that is “csv”</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">refSep</code>: (Param[String]) Separator character for the csv reference file for Obfuscation de default value is “#”</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">regexOverride</code>: (BooleanParam) If is true prioritize the regex entities, if is false prioritize the ner.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">regexPatternsDictionary</code>: (ExternalResourceParam) dictionary with regular expression patterns that match some protected entity if the dictionary in not setting up we will use the default regex file.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">region</code>: (Param[String]) Usa or eu</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">returnEntityMappings</code>: (BooleanParam) With this property you select if you want to return mapping column</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">sameEntityThreshold</code>: (DoubleParam) Similarity threshold [0.0-1.0] to consider two appearances of an entity as the same (default: 0.9) For date entities this method doesn’t apply.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">sameLengthFormattedEntities</code>: (StringArrayParam) List of formatted entities to generate the same length outputs as original ones during obfuscation.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">seed</code>: (IntParam) It is the seed to select the entities on obfuscate mode.With the seed you can reply a execution several times with the same ouptut.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">selectiveObfuscationModesPath</code>: (Param[String]) Dictionary path where is the json that contains the selective obfuscation modes</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">unnormalizedDateMode</code>: (Param[String]) The mode to use if the date is not formatted.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">zipCodeTag</code>: (Param[String]) Tag representing zip codes in the obfuscate reference file (default: ZIP).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">MetadataMaskingPolicy(str)</code>: (Param[String]) Options : ‘entity_labels’, ‘same_length_chars’, ‘fixed_length_chars’ 
If set, metadata includes the masked form of the document.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">obfuscateByAgeGroups</code>: (BooleanParam) Whether to obfuscate ages based on age groups.
When True, the age groups specified in the <code class="language-plaintext highlighter-rouge">ageGroups</code> parameter will be used to obfuscate ages.
When False, the age ranges specified in the <code class="language-plaintext highlighter-rouge">ageRanges</code> parameter will be used to obfuscate ages.
Default: False</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ageGroups</code>:  A dictionary of age groups to obfuscate ages.
For this parameter to be active, the <code class="language-plaintext highlighter-rouge">obfuscateByAgeGroups</code> parameter must be true.
If the given <code class="language-plaintext highlighter-rouge">ageGroups</code> do not fully contain the ages, the ages continue to be obfuscated according to the <code class="language-plaintext highlighter-rouge">ageRanges</code> parameter.
The dictionary should contain the age group name as the key and an list of two integers as the value.
The first integer is the lower bound of the age group, and the second integer is the upper bound of the age group.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">keepYear</code>: (BooleanParam) Whether to keep the year intact when obfuscating date entities.
If True, the year will remain unchanged during the obfuscation process.
If False, the year will be modified along with the month and day.
Default: False.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">keepMonth</code> : Whether to keep the month intact when obfuscating date entities.
If True, the month will remain unchanged during the obfuscation process.
If False, the month will be modified along with the year and day.
Default: False.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">keepTextSizeForObfuscation</code> : Whether to keep the text length same obfuscating entities. If <code class="language-plaintext highlighter-rouge">True</code>, the output text will remain the same if a same length fake is available, otherwise length might vary.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">fakerLengthOffset</code> : It specifies how much length deviation is accepted in obfuscation, with <code class="language-plaintext highlighter-rouge">keepTextSizeForObfuscation</code> enabled. It must be greater than 0.</p>
      </li>
    </ul>

    <p>To create a configured DeIdentificationModel, please see the example of DeIdentification.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/deIdentification/index.html#sparknlp_jsl.annotator.deid.deIdentification.DeIdentificationModel">DeIdentificationModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DeIdentificationModel.html">DeIdentificationModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DeIdentificationModel.ipynb">DeIdentificationModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_sensitive_entities</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_enriched"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">deIdentification</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DeIdentificationModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"deidentify_large"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormats</span><span class="p">([</span><span class="s">"MM/dd/yy"</span><span class="p">,</span><span class="s">"yyyy-MM-dd"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDays</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"both"</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09."</span><span class="p">]</span>
    <span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">clinical_sensitive_entities</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">deIdentification</span>
<span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"sentence.result as Input"</span><span class="p">)</span> <span class="p">,</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"dei.result as deidentified"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="o">+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                                <span class="n">Input</span><span class="o">|</span>                                                                            <span class="n">deidentified</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="c1"># 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09.]|[# 1610960 Date : 01/18/93 PCP : Vida Rigger , 27 years-old , Record date : 2079-11-14.]|
</span><span class="o">+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span><span class="p">,</span> <span class="n">finance</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">bert_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">fin_ner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finner_deid'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span>  <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ORG"</span><span class="p">:</span> <span class="s">"COMPANY"</span><span class="p">})</span> <span class="c1"># Replace "ORG" entity as "COMPANY"
</span>
<span class="n">ner_finner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_org_per_role_date"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"bert_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_finner"</span><span class="p">)</span>
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter_finner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_finner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_finner_chunk"</span><span class="p">)</span> 
    <span class="c1"># .setWhiteList(['ROLE']) # Just use "ROLE" entity from this NER
</span>
<span class="n">chunk_merge</span> <span class="o">=</span>  <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_finner_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span>

<span class="n">deidentification</span> <span class="o">=</span>  <span class="n">finance</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"deid_merged_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"mask"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">bert_embeddings</span><span class="p">,</span>
      <span class="n">fin_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_finner</span><span class="p">,</span>
      <span class="n">ner_converter_finner</span><span class="p">,</span>
      <span class="n">chunk_merge</span><span class="p">,</span>
      <span class="n">deidentification</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"Jeffrey Preston Bezos, DoB 12/01/1964, is an American entrepreneur, founder and CEO of Amazon"</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"sentence.result"</span><span class="p">,</span> <span class="s">"deidentified.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                         <span class="o">|</span><span class="n">result</span>                                                                     <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Jeffrey</span> <span class="n">Preston</span> <span class="n">Bezos</span><span class="p">,</span> <span class="n">DoB</span> <span class="mi">12</span><span class="o">/</span><span class="mi">01</span><span class="o">/</span><span class="mi">1964</span><span class="p">,</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">American</span> <span class="n">entrepreneur</span><span class="p">,</span> <span class="n">founder</span> <span class="ow">and</span> <span class="n">CEO</span> <span class="n">of</span> <span class="n">Amazon</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="o">&lt;</span><span class="n">PERSON</span><span class="o">&gt;</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">DATE</span><span class="o">&gt;</span><span class="p">,</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">American</span> <span class="n">entrepreneur</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">ROLE</span><span class="o">&gt;</span> <span class="ow">and</span> <span class="o">&lt;</span><span class="n">ROLE</span><span class="o">&gt;</span> <span class="n">of</span> <span class="o">&lt;</span><span class="n">ORG</span><span class="o">&gt;</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">legal_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ALIAS"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span>

<span class="n">ner_signers</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_signers"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_signers"</span><span class="p">)</span>
    <span class="c1">#.setLabelCasing("upper")
</span>
<span class="n">ner_converter_signers</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_signers"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_signer_chunk"</span><span class="p">)</span>

<span class="n">chunk_merge</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_signer_chunk"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_merged_chunk"</span><span class="p">)</span>

<span class="n">deidentification</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"deid_merged_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"mask"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIgnoreRegex</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">legal_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">ner_signers</span><span class="p">,</span>
      <span class="n">ner_converter_signers</span><span class="p">,</span>
      <span class="n">chunk_merge</span><span class="p">,</span>
      <span class="n">deidentification</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"ENTIRE AGREEMENT.  This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby,</span><span class="se">\
</span><span class="s"> supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. THE MART.COM, INC.:                         I-ESCROW, INC.: By:Dominic J. Magliarditi               </span><span class="se">\
</span><span class="s">  By:Sanjay Bajaj Name: Dominic J. Magliarditi                Name: Sanjay Bajaj Title: President                            Title: VP Business Development Date: 6/21/2023 "</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"sentence.result"</span><span class="p">,</span> <span class="s">"deidentified.result"</span><span class="p">).</span><span class="n">toPandas</span><span class="p">()</span>

<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">sentence</span>                                                                                                                                                                                                                                <span class="o">|</span><span class="n">deidentified</span>                                                                                                                                                                                                                            <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">ENTIRE</span> <span class="n">AGREEMENT</span><span class="p">.</span>                                                                                                                                                                                                                       <span class="o">|&lt;</span><span class="n">DOC</span><span class="o">&gt;</span><span class="p">.</span>                                                                                                                                                                                                                                  <span class="o">|</span>
<span class="o">|</span><span class="n">This</span> <span class="n">Agreement</span> <span class="n">contains</span> <span class="n">the</span> <span class="n">entire</span> <span class="n">understanding</span> <span class="n">of</span> <span class="n">the</span> <span class="n">parties</span> <span class="n">hereto</span> <span class="k">with</span> <span class="n">respect</span> <span class="n">to</span> <span class="n">the</span> <span class="n">transactions</span> <span class="ow">and</span> <span class="n">matters</span> <span class="n">contemplated</span> <span class="n">hereby</span><span class="p">,</span> <span class="n">supersedes</span> <span class="nb">all</span> <span class="n">previous</span> <span class="n">Agreements</span> <span class="n">between</span> <span class="n">i</span><span class="o">-</span><span class="n">Escrow</span> <span class="ow">and</span> <span class="mi">2</span><span class="n">TheMart</span> <span class="n">concerning</span> <span class="n">the</span> <span class="n">subject</span> <span class="n">matter</span><span class="p">.</span><span class="o">|</span><span class="n">This</span> <span class="n">Agreement</span> <span class="n">contains</span> <span class="n">the</span> <span class="n">entire</span> <span class="n">understanding</span> <span class="n">of</span> <span class="n">the</span> <span class="n">parties</span> <span class="n">hereto</span> <span class="k">with</span> <span class="n">respect</span> <span class="n">to</span> <span class="n">the</span> <span class="n">transactions</span> <span class="ow">and</span> <span class="n">matters</span> <span class="n">contemplated</span> <span class="n">hereby</span><span class="p">,</span> <span class="n">supersedes</span> <span class="nb">all</span> <span class="n">previous</span> <span class="n">Agreements</span> <span class="n">between</span> <span class="n">i</span><span class="o">-</span><span class="n">Escrow</span> <span class="ow">and</span> <span class="mi">2</span><span class="n">TheMart</span> <span class="n">concerning</span> <span class="n">the</span> <span class="n">subject</span> <span class="n">matter</span><span class="p">.</span><span class="o">|</span>
<span class="o">|</span><span class="n">THE</span> <span class="n">MART</span><span class="p">.</span><span class="n">COM</span><span class="p">,</span> <span class="n">INC</span><span class="p">.:</span> <span class="n">I</span><span class="o">-</span><span class="n">ESCROW</span><span class="p">,</span> <span class="n">INC</span><span class="p">.:</span> <span class="n">By</span><span class="p">:</span><span class="n">Dominic</span> <span class="n">J</span><span class="p">.</span> <span class="n">Magliarditi</span>                 <span class="n">By</span><span class="p">:</span><span class="n">Sanjay</span> <span class="n">Bajaj</span> <span class="n">Name</span><span class="p">:</span> <span class="n">Dominic</span> <span class="n">J</span><span class="p">.</span> <span class="n">Magliarditi</span> <span class="n">Name</span><span class="p">:</span> <span class="n">Sanjay</span> <span class="n">Bajaj</span> <span class="n">Title</span><span class="p">:</span> <span class="n">President</span> <span class="n">Title</span><span class="p">:</span> <span class="n">VP</span> <span class="n">Business</span> <span class="n">Development</span> <span class="n">Date</span><span class="p">:</span> <span class="mi">6</span><span class="o">/</span><span class="mi">21</span><span class="o">/</span><span class="mi">2023</span>                           <span class="o">|&lt;</span><span class="n">PARTY</span><span class="o">&gt;</span><span class="p">.:</span> <span class="o">&lt;</span><span class="n">PARTY</span><span class="o">&gt;</span><span class="p">.:</span> <span class="n">By</span><span class="p">:</span><span class="n">Dominic</span> <span class="o">&lt;</span><span class="n">SIGNING_PERSON</span><span class="o">&gt;</span>                 <span class="n">By</span><span class="p">:</span><span class="n">Sanjay</span> <span class="o">&lt;</span><span class="n">SIGNING_PERSON</span><span class="o">&gt;</span> <span class="n">Name</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">SIGNING_PERSON</span><span class="o">&gt;</span> <span class="n">Name</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">SIGNING_PERSON</span><span class="o">&gt;</span> <span class="n">Title</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">SIGNING_TITLE</span><span class="o">&gt;</span> <span class="n">Title</span><span class="p">:</span> <span class="o">&lt;</span><span class="n">SIGNING_TITLE</span><span class="o">&gt;</span> <span class="n">Date</span><span class="p">:</span> <span class="mi">6</span><span class="o">/</span><span class="mi">21</span><span class="o">/</span><span class="mi">2023</span>                                  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinicalSensitiveEntities</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_enriched"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="nv">DeIdentificationModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"deidentify_large"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDateFormats</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"MM/dd/yy"</span><span class="o">,</span> <span class="s">"yyyy-MM-dd"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDays</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"both"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"# 7194334 Date : 01/13/93 PCP : Oliveira , 25 years-old , Record date : 2079-11-09."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">clinicalSensitiveEntities</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">deIdentification</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                                <span class="nc">Input</span><span class="o">|</span>                                                                            <span class="n">deidentified</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="k">#</span> <span class="err">7194334</span> <span class="kt">Date</span> <span class="kt">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">13</span><span class="kt">/</span><span class="err">93</span> <span class="kt">PCP</span> <span class="kt">:</span> <span class="kt">Oliveira</span> , <span class="err">25</span> <span class="kt">years-old</span> , <span class="kt">Record</span> <span class="kt">date</span> <span class="kt">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">09</span><span class="kt">.</span><span class="o">]|[</span><span class="k">#</span> <span class="err">1610960</span> <span class="kt">Date</span> <span class="kt">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">18</span><span class="kt">/</span><span class="err">93</span> <span class="kt">PCP</span> <span class="kt">:</span> <span class="kt">Vida</span> <span class="kt">Rigger</span> , <span class="err">27</span> <span class="kt">years-old</span> , <span class="kt">Record</span> <span class="kt">date</span> <span class="kt">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">14</span><span class="kt">.</span><span class="o">]|</span>
<span class="o">+-------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">bertEmbeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">finNer</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_deid"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"ORG"</span> <span class="o">-&gt;</span> <span class="s">"COMPANY"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">nerFinner</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_org_per_role_date"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"bert_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_finner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverterFinner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_finner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_finner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkMerge</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_finner_chunk"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_merged_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">deidentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"deid_merged_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deidentified"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"mask"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">bertEmbeddings</span><span class="o">,</span>
  <span class="n">finNer</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">nerFinner</span><span class="o">,</span>
  <span class="n">nerConverterFinner</span><span class="o">,</span>
  <span class="n">chunkMerge</span><span class="o">,</span>
  <span class="n">deidentification</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Jeffrey Preston Bezos, DoB 12/01/1964, is an American entrepreneur, founder and CEO of Amazon"</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                         <span class="o">|</span><span class="n">result</span>                                                                     <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Jeffrey</span> <span class="kt">Preston</span> <span class="kt">Bezos</span>, <span class="kt">DoB</span> <span class="err">12</span><span class="kt">/</span><span class="err">01</span><span class="kt">/</span><span class="err">1964</span>, <span class="kt">is</span> <span class="kt">an</span> <span class="kt">American</span> <span class="kt">entrepreneur</span>, <span class="kt">founder</span> <span class="kt">and</span> <span class="kt">CEO</span> <span class="kt">of</span> <span class="kt">Amazon</span><span class="o">]|[</span><span class="kt">&lt;PERSON&gt;</span>, <span class="kt">&lt;DATE&gt;</span>, <span class="kt">is</span> <span class="kt">an</span> <span class="kt">American</span> <span class="kt">entrepreneur</span>, <span class="kt">&lt;ROLE&gt;</span> <span class="kt">and</span> <span class="kt">&lt;ROLE&gt;</span> <span class="kt">of</span> <span class="kt">&lt;ORG&gt;</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------------------------------------------+---------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">legalNer</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"ALIAS"</span> <span class="o">-&gt;</span> <span class="s">"PARTY"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">nerSigners</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_signers"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_signers"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverterSigners</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_signers"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_signer_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkMerge</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_signer_chunk"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_merged_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">deidentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"deid_merged_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deidentified"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"mask"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setIgnoreRegex</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">legalNer</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">nerSigners</span><span class="o">,</span>
  <span class="n">nerConverterSigners</span><span class="o">,</span>
  <span class="n">chunkMerge</span><span class="o">,</span>
  <span class="n">deidentification</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"ENTIRE AGREEMENT. This Agreement contains the entire understanding of the parties hereto with respect to the transactions and matters contemplated hereby, supersedes all previous Agreements between i-Escrow and 2TheMart concerning the subject matter. THE MART.COM, INC.: I-ESCROW, INC.: By:Dominic J. Magliarditi By:Sanjay Bajaj Name: Dominic J. Magliarditi Name: Sanjay Bajaj Title: President Title: VP Business Development Date: 6/21/2023"</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">sentence</span>                                                                                                                                                                                                                                <span class="o">|</span><span class="n">deidentified</span>                                                                                                                                                                                                                            <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">ENTIRE</span> <span class="nc">AGREEMENT</span><span class="o">.</span>                                                                                                                                                                                                                       <span class="o">|&lt;</span><span class="nc">DOC</span><span class="o">&gt;.</span>                                                                                                                                                                                                                                  <span class="o">|</span>
<span class="o">|</span><span class="nc">This</span> <span class="nc">Agreement</span> <span class="n">contains</span> <span class="n">the</span> <span class="n">entire</span> <span class="n">understanding</span> <span class="n">of</span> <span class="n">the</span> <span class="n">parties</span> <span class="n">hereto</span> <span class="k">with</span> <span class="n">respect</span> <span class="n">to</span> <span class="n">the</span> <span class="n">transactions</span> <span class="n">and</span> <span class="n">matters</span> <span class="n">contemplated</span> <span class="n">hereby</span><span class="o">,</span> <span class="n">supersedes</span> <span class="n">all</span> <span class="n">previous</span> <span class="nc">Agreements</span> <span class="n">between</span> <span class="n">i</span><span class="o">-</span><span class="nc">Escrow</span> <span class="n">and</span> <span class="mi">2</span><span class="nc">TheMart</span> <span class="n">concerning</span> <span class="n">the</span> <span class="n">subject</span> <span class="n">matter</span><span class="o">.|</span><span class="nc">This</span> <span class="nc">Agreement</span> <span class="n">contains</span> <span class="n">the</span> <span class="n">entire</span> <span class="n">understanding</span> <span class="n">of</span> <span class="n">the</span> <span class="n">parties</span> <span class="n">hereto</span> <span class="k">with</span> <span class="n">respect</span> <span class="n">to</span> <span class="n">the</span> <span class="n">transactions</span> <span class="n">and</span> <span class="n">matters</span> <span class="n">contemplated</span> <span class="n">hereby</span><span class="o">,</span> <span class="n">supersedes</span> <span class="n">all</span> <span class="n">previous</span> <span class="nc">Agreements</span> <span class="n">between</span> <span class="n">i</span><span class="o">-</span><span class="nc">Escrow</span> <span class="n">and</span> <span class="mi">2</span><span class="nc">TheMart</span> <span class="n">concerning</span> <span class="n">the</span> <span class="n">subject</span> <span class="n">matter</span><span class="o">.|</span>
<span class="o">|</span><span class="nc">THE</span> <span class="nv">MART</span><span class="o">.</span><span class="py">COM</span><span class="o">,</span> <span class="nc">INC</span><span class="o">.</span><span class="k">:</span> <span class="kt">I-ESCROW</span><span class="o">,</span> <span class="nc">INC</span><span class="o">.</span><span class="k">:</span> <span class="kt">By:Dominic</span> <span class="kt">J.</span> <span class="kt">Magliarditi</span>                 <span class="kt">By:Sanjay</span> <span class="kt">Bajaj</span> <span class="kt">Name:</span> <span class="kt">Dominic</span> <span class="kt">J.</span> <span class="kt">Magliarditi</span> <span class="kt">Name:</span> <span class="kt">Sanjay</span> <span class="kt">Bajaj</span> <span class="kt">Title:</span> <span class="kt">President</span> <span class="kt">Title:</span> <span class="kt">VP</span> <span class="kt">Business</span> <span class="kt">Development</span> <span class="kt">Date:</span> <span class="err">6</span><span class="kt">/</span><span class="err">21</span><span class="kt">/</span><span class="err">2023</span>                           <span class="kt">|&lt;PARTY&gt;.:</span> <span class="kt">&lt;PARTY&gt;.:</span> <span class="kt">By:Dominic</span> <span class="kt">&lt;SIGNING_PERSON&gt;</span>                 <span class="kt">By:Sanjay</span> <span class="kt">&lt;SIGNING_PERSON&gt;</span> <span class="kt">Name:</span> <span class="kt">&lt;SIGNING_PERSON&gt;</span> <span class="kt">Name:</span> <span class="kt">&lt;SIGNING_PERSON&gt;</span> <span class="kt">Title:</span> <span class="kt">&lt;SIGNING_TITLE&gt;</span> <span class="kt">Title:</span> <span class="kt">&lt;SIGNING_TITLE&gt;</span> <span class="kt">Date:</span> <span class="err">6</span><span class="kt">/</span><span class="err">21</span><span class="kt">/</span><span class="err">2023</span>                                  <span class="kt">|</span>
<span class="kt">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Contains all the methods for training a DeIdentificationModel model.
This module can obfuscate or mask the entities that contains personal information. These can be set with a file of
regex patterns with setRegexPatternsDictionary, where each line is a mapping of
entity to regex.</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DATE \d{4}
AID \d{6,7}
</code></pre></div>    </div>

    <p>Additionally, obfuscation strings can be defined with setObfuscateRefFile, where each line
is a mapping of string to entity. The format and seperator can be speficied with
setRefFileFormat and setRefSep.</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Dr. Gregory House#DOCTOR
01010101#MEDICALRECORD
</code></pre></div>    </div>

    <p>Ideally this annotator works in conjunction with Demographic Named EntityRecognizers that can be trained either using
<a href="/docs/en/annotators#textmatcher">TextMatchers</a>,
<a href="/docs/en/annotators#regexmatcher">RegexMatchers</a>,
<a href="/docs/en/annotators#datematcher">DateMatchers</a>,
<a href="/docs/en/annotators#nercrf">NerCRFs</a> or
<a href="/docs/en/annotators#nerdl">NerDLs</a></p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/deIdentification/index.html#sparknlp_jsl.annotator.deid.deIdentification.DeIdentification">DeIdentification</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DeIdentification.html">DeIdentification</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="c1"># Sentence Detector annotator, processes various sentences per line
</span><span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Clinical word embeddings trained on PubMED dataset
</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)
</span><span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1">#deid model with "entity_labels"
</span><span class="n">deid_entity_labels</span><span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_entity_label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"mask"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReturnEntityMappings</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaskingPolicy</span><span class="p">(</span><span class="s">"entity_labels"</span><span class="p">)</span>

<span class="n">obs_lines</span> <span class="o">=</span> <span class="s">"""Marvin MARSHALL#PATIENT
Hubert GROGAN#PATIENT
ALTHEA COLBURN#PATIENT
Kalil AMIN#PATIENT
Inci FOUNTAIN#PATIENT
Ekaterina Rosa#DOCTOR
Rudiger Chao#DOCTOR
COLLETTE KOHLER#NAME
Mufi HIGGS#NAME"""</span>

<span class="k">with</span> <span class="nb">open</span> <span class="p">(</span><span class="s">'obfuscation.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">obs_lines</span><span class="p">)</span>

<span class="n">obfuscation</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">'obfuscation.txt'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"both"</span><span class="p">)</span>\  <span class="c1">#file or faker
</span>    <span class="p">.</span><span class="n">setGenderAwareness</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLanguage</span><span class="p">(</span><span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setUnnormalizedDateMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span>  <span class="c1">#mask or skip
</span>
<span class="n">deidPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>
      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">deid_entity_labels</span><span class="p">,</span>
      <span class="n">obfuscation</span>
      <span class="p">])</span>


<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">deidPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="c1">#sample data
</span><span class="n">text</span> <span class="o">=</span><span class="s">'''
Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson Ora , MR # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555 .
'''</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">sentence</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                     <span class="n">result</span><span class="p">.</span><span class="n">deid_entity_label</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                     <span class="n">result</span><span class="p">.</span><span class="n">deidentified</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                     <span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"deid_entity_label"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">),</span>
              <span class="p">).</span><span class="n">toPandas</span><span class="p">()</span>

<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span>                                                               <span class="n">sentence</span><span class="o">|</span>                                      <span class="n">deid_entity_label</span><span class="o">|</span>                                                     <span class="n">deidentified</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span>                          <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">13</span> <span class="p">,</span> <span class="n">David</span> <span class="n">Hale</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span><span class="o">|</span>                  <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="o">&lt;</span><span class="n">DATE</span><span class="o">&gt;</span> <span class="p">,</span> <span class="o">&lt;</span><span class="n">NAME</span><span class="o">&gt;</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span><span class="o">|</span>                  <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">25</span> <span class="p">,</span> <span class="n">Daryl</span> <span class="n">Dieter</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span><span class="o">|</span>
<span class="o">|</span>              <span class="p">,</span> <span class="n">Name</span> <span class="p">:</span> <span class="n">Hendrickson</span> <span class="n">Ora</span> <span class="p">,</span> <span class="n">MR</span> <span class="c1"># 7194334 Date : 01/13/93 .|            , Name : &lt;NAME&gt; , MR # &lt;ID&gt; Date : &lt;DATE&gt; .|         , Name : Langston Papas , MR # 4784828 Date : 01/25/93 .|
</span><span class="o">|</span>             <span class="n">PCP</span> <span class="p">:</span> <span class="n">Oliveira</span> <span class="p">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2079</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">09</span> <span class="p">.</span><span class="o">|</span><span class="n">PCP</span> <span class="p">:</span> <span class="o">&lt;</span><span class="n">NAME</span><span class="o">&gt;</span> <span class="p">,</span> <span class="o">&lt;</span><span class="n">AGE</span><span class="o">&gt;</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="o">&lt;</span><span class="n">DATE</span><span class="o">&gt;</span> <span class="p">.</span><span class="o">|</span><span class="n">PCP</span> <span class="p">:</span> <span class="n">Roseann</span> <span class="n">Lederer</span> <span class="p">,</span> <span class="mi">23</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2079</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">21</span> <span class="p">.</span><span class="o">|</span>
<span class="o">|</span><span class="n">Cocke</span> <span class="n">County</span> <span class="n">Baptist</span> <span class="n">Hospital</span> <span class="p">,</span> <span class="mi">0295</span> <span class="n">Keats</span> <span class="n">Street</span> <span class="p">,</span> <span class="n">Phone</span> <span class="mi">55</span><span class="o">-</span><span class="mi">555</span><span class="o">-</span><span class="mi">5555</span> <span class="p">.</span><span class="o">|</span>            <span class="o">&lt;</span><span class="n">LOCATION</span><span class="o">&gt;</span> <span class="p">,</span> <span class="o">&lt;</span><span class="n">LOCATION</span><span class="o">&gt;</span> <span class="p">,</span> <span class="n">Phone</span> <span class="o">&lt;</span><span class="n">CONTACT</span><span class="o">&gt;</span> <span class="p">.</span><span class="o">|</span>    <span class="mi">31</span> <span class="n">North</span> <span class="n">St</span> <span class="n">Joseph</span> <span class="n">Ave</span> <span class="p">,</span> <span class="mi">400</span> <span class="n">Tickle</span> <span class="n">St</span> <span class="p">,</span> <span class="n">Phone</span> <span class="p">(</span><span class="mi">59</span><span class="p">)</span> <span class="mi">106</span><span class="o">-</span><span class="mi">048</span> <span class="p">.</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

 <span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Ner entities
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_con"</span><span class="p">)</span>

<span class="c1"># Deidentification
</span><span class="n">deIdentification</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
    <span class="c1"># file with custom regex pattern for custom entities
</span>    <span class="p">.</span><span class="n">setRegexPatternsDictionary</span><span class="p">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="p">)</span> \
    <span class="c1"># file with custom obfuscator names for the entities
</span>    <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefFileFormat</span><span class="p">(</span><span class="s">"csv"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefSep</span><span class="p">(</span><span class="s">"#"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormats</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s">"MM/dd/yy"</span><span class="p">,</span><span class="s">"yyyy-MM-dd"</span><span class="p">))</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDays</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"file"</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">deIdentification</span>
<span class="p">])</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

 <span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Ner entities
</span><span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_con"</span><span class="p">)</span>

<span class="c1"># Deidentification
</span><span class="n">deIdentification</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dei"</span><span class="p">)</span> \
    <span class="c1"># file with custom regex pattern for custom entities
</span>    <span class="p">.</span><span class="n">setRegexPatternsDictionary</span><span class="p">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="p">)</span> \
    <span class="c1"># file with custom obfuscator names for the entities
</span>    <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefFileFormat</span><span class="p">(</span><span class="s">"csv"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRefSep</span><span class="p">(</span><span class="s">"#"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateFormats</span><span class="p">(</span><span class="n">Array</span><span class="p">(</span><span class="s">"MM/dd/yy"</span><span class="p">,</span><span class="s">"yyyy-MM-dd"</span><span class="p">))</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDays</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"file"</span><span class="p">)</span>

<span class="c1"># Pipeline
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">deIdentification</span>
<span class="p">])</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="c1">// Sentence Detector annotator, processes various sentences per line</span>
<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="c1">// Tokenizer splits words in a relevant format for NLP</span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="c1">// Clinical word embeddings trained on PubMED dataset</span>
<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)</span>
<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="c1">//deid model with "entity_labels"</span>
<span class="k">val</span> <span class="nv">deid_entity_labels</span><span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_entity_label"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"mask"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setReturnEntityMappings</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaskingPolicy</span><span class="o">(</span><span class="s">"entity_labels"</span><span class="o">)</span>
    
<span class="c1">//</span>
<span class="k">val</span> <span class="nv">obs_lines</span> <span class="k">=</span> <span class="s">"""Marvin MARSHALL#PATIENT
Hubert GROGAN#PATIENT
ALTHEA COLBURN#PATIENT
Kalil AMIN#PATIENT
Inci FOUNTAIN#PATIENT
Ekaterina Rosa#DOCTOR
Rudiger Chao#DOCTOR
COLLETTE KOHLER#NAME
Mufi HIGGS#NAME"""</span>
<span class="c1">//</span>

<span class="k">val</span> <span class="nv">obfuscation</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deidentified"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"obfuscation.txt"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"both"</span><span class="o">)</span>       <span class="c1">//file or faker  </span>
    <span class="o">.</span><span class="py">setGenderAwareness</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLanguage</span><span class="o">(</span><span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setUnnormalizedDateMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span> <span class="c1">//mask or skip</span>


<span class="k">val</span> <span class="nv">deidPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                                  <span class="n">documentAssembler</span><span class="o">,</span>
                                                  <span class="n">sentenceDetector</span><span class="o">,</span>
                                                  <span class="n">tokenizer</span><span class="o">,</span>
                                                  <span class="n">word_embeddings</span><span class="o">,</span>
                                                  <span class="n">clinical_ner</span><span class="o">,</span>
                                                  <span class="n">ner_converter</span><span class="o">,</span>
                                                  <span class="n">deid_entity_labels</span><span class="o">,</span>
                                                  <span class="n">obfuscation</span>
                                                <span class="o">))</span>

<span class="c1">//sample data</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span>
          <span class="sc">'''</span>
          <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">13</span> <span class="o">,</span> <span class="nc">David</span> <span class="nc">Hale</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span> <span class="o">,</span> <span class="nc">Name</span> <span class="k">:</span> <span class="kt">Hendrickson</span> <span class="kt">Ora</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">7194334</span> <span class="nc">Date</span> <span class="k">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">13</span><span class="kt">/</span><span class="err">93</span> <span class="kt">.</span> <span class="kt">PCP</span> <span class="kt">:</span> <span class="kt">Oliveira</span> <span class="o">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span>
          <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">09</span> <span class="kt">.</span> <span class="kt">Cocke</span> <span class="kt">County</span> <span class="kt">Baptist</span> <span class="kt">Hospital</span> <span class="o">,</span> <span class="mi">0295</span> <span class="nc">Keats</span> <span class="nc">Street</span> <span class="o">,</span> <span class="nc">Phone</span> <span class="mi">55</span><span class="o">-</span><span class="mi">555</span><span class="o">-</span><span class="mi">5555</span> <span class="o">.</span>
          <span class="sc">'''</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="k">new</span> <span class="nv">deidPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span>                                                               <span class="n">sentence</span><span class="o">|</span>                                      <span class="n">deid_entity_label</span><span class="o">|</span>                                                     <span class="n">deidentified</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------------------+</span>
<span class="o">|</span>                          <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">13</span> <span class="o">,</span> <span class="nc">David</span> <span class="nc">Hale</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.|</span>                  <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="kt">&lt;DATE&gt;</span> <span class="o">,</span> <span class="o">&lt;</span><span class="nc">NAME</span><span class="o">&gt;</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.|</span>                  <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">25</span> <span class="o">,</span> <span class="nc">Daryl</span> <span class="nc">Dieter</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.|</span>
<span class="o">|</span>              <span class="o">,</span> <span class="nc">Name</span> <span class="k">:</span> <span class="kt">Hendrickson</span> <span class="kt">Ora</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">7194334</span> <span class="nc">Date</span> <span class="k">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">13</span><span class="kt">/</span><span class="err">93</span> <span class="kt">.|</span>            <span class="o">,</span> <span class="nc">Name</span> <span class="k">:</span> <span class="kt">&lt;NAME&gt;</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="o">&lt;</span><span class="nc">ID</span><span class="o">&gt;</span> <span class="nc">Date</span> <span class="k">:</span> <span class="kt">&lt;DATE&gt;</span> <span class="kt">.|</span>         <span class="o">,</span> <span class="nc">Name</span> <span class="k">:</span> <span class="kt">Langston</span> <span class="kt">Papas</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">4784828</span> <span class="nc">Date</span> <span class="k">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">25</span><span class="kt">/</span><span class="err">93</span> <span class="kt">.|</span>
<span class="kt">|</span>             <span class="kt">PCP</span> <span class="kt">:</span> <span class="kt">Oliveira</span> <span class="o">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">09</span> <span class="kt">.|PCP</span> <span class="kt">:</span> <span class="kt">&lt;NAME&gt;</span> <span class="o">,</span> <span class="o">&lt;</span><span class="nc">AGE</span><span class="o">&gt;</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="kt">&lt;DATE&gt;</span> <span class="kt">.|PCP</span> <span class="kt">:</span> <span class="kt">Roseann</span> <span class="kt">Lederer</span> <span class="o">,</span> <span class="mi">23</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">21</span> <span class="kt">.|</span>
<span class="kt">|Cocke</span> <span class="kt">County</span> <span class="kt">Baptist</span> <span class="kt">Hospital</span> <span class="o">,</span> <span class="mi">0295</span> <span class="nc">Keats</span> <span class="nc">Street</span> <span class="o">,</span> <span class="nc">Phone</span> <span class="mi">55</span><span class="o">-</span><span class="mi">555</span><span class="o">-</span><span class="mi">5555</span> <span class="o">.|</span>            <span class="o">&lt;</span><span class="nc">LOCATION</span><span class="o">&gt;</span> <span class="o">,</span> <span class="o">&lt;</span><span class="nc">LOCATION</span><span class="o">&gt;</span> <span class="o">,</span> <span class="nc">Phone</span> <span class="o">&lt;</span><span class="nc">CONTACT</span><span class="o">&gt;</span> <span class="o">.|</span>    <span class="mi">31</span> <span class="nc">North</span> <span class="nc">St</span> <span class="nc">Joseph</span> <span class="nc">Ave</span> <span class="o">,</span> <span class="mi">400</span> <span class="nc">Tickle</span> <span class="nc">St</span> <span class="o">,</span> <span class="nc">Phone</span> <span class="o">(</span><span class="mi">59</span><span class="o">)</span> <span class="mi">106</span><span class="o">-</span><span class="mi">048</span> <span class="o">.|</span>
<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+-----------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="n">document</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
     <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Ner entities</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_con"</span><span class="o">)</span>

<span class="c1">// Deidentification</span>
<span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
     <span class="c1">// file with custom regex patterns for custom entities</span>
     <span class="o">.</span><span class="py">setRegexPatternsDictionary</span><span class="o">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="o">)</span>
     <span class="c1">// file with custom obfuscator names for the entities</span>
     <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefFileFormat</span><span class="o">(</span><span class="s">"csv"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefSep</span><span class="o">(</span><span class="s">"#"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateFormats</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"MM/dd/yy"</span><span class="o">,</span><span class="s">"yyyy-MM-dd"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDays</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"file"</span><span class="o">)</span>

<span class="c1">// Pipeline</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">deIdentification</span>
<span class="o">))</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
     <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Ner entities</span>
<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_con"</span><span class="o">)</span>

<span class="c1">// Deidentification</span>
<span class="k">val</span> <span class="nv">deIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
     <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dei"</span><span class="o">)</span>
     <span class="c1">// file with custom regex patterns for custom entities</span>
     <span class="o">.</span><span class="py">setRegexPatternsDictionary</span><span class="o">(</span><span class="s">"path/to/dic_regex_patterns_main_categories.txt"</span><span class="o">)</span>
     <span class="c1">// file with custom obfuscator names for the entities</span>
     <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"path/to/obfuscate_fixed_entities.txt"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefFileFormat</span><span class="o">(</span><span class="s">"csv"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setRefSep</span><span class="o">(</span><span class="s">"#"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateFormats</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"MM/dd/yy"</span><span class="o">,</span><span class="s">"yyyy-MM-dd"</span><span class="o">))</span>
     <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setDays</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
     <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"file"</span><span class="o">)</span>

<span class="c1">// Pipeline</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner_model</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">deIdentification</span>
<span class="o">))</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="distilbertforsequenceclassification">DistilBertForSequenceClassification</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">DistilBertForSequenceClassification</code>  can load DistilBERT Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">batchSize</code>’,  ‘Size of every batch’: default: 8,</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">coalesceSentences</code>’: “Instead of 1 class per sentence (if inputCols is ‘'’sentence’’’ output 1 class per document by averaging probabilities in all sentences.” default: False,</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxSentenceLength</code>’, ‘Max sentence length to process’, default: 128</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">caseSensitive</code>’, ‘whether to ignore case in tokens for embeddings matching’,default: True,</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/medical_distilbert_for_sequence_classification/index.html">DistilBertForSequenceClassification</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/MedicalDistilBertForSequenceClassification.html">DistilBertForSequenceClassification</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
 
<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DistilBertForSequenceClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"distilbert_sequence_classifier_ade"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"classes"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"I have an allergic reaction to vancomycin so I have itchy skin, sore throat/burning/itching, numbness of tongue and gums.I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication."</span><span class="p">],</span>
                              <span class="p">[</span><span class="s">"Religare Capital Ranbaxy has been accepting approval for Diovan since 2012"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"classes.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="o">|</span> <span class="n">text</span>                                                                                           <span class="o">|</span> <span class="n">result</span> <span class="o">|</span>
<span class="o">|------------------------------------------------------------------------------------------------|-------|</span>
<span class="o">|</span> <span class="n">I</span> <span class="n">have</span> <span class="n">an</span> <span class="n">allergic</span> <span class="n">reaction</span> <span class="n">to</span> <span class="n">vancomycin</span> <span class="n">so</span> <span class="n">I</span> <span class="n">have</span> <span class="n">itchy</span> <span class="n">skin</span><span class="p">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="o">/</span><span class="n">burning</span><span class="o">/</span><span class="n">itching</span><span class="p">,</span> <span class="n">numb</span><span class="p">...</span> <span class="o">|</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">Religare</span> <span class="n">Capital</span> <span class="n">Ranbaxy</span> <span class="n">has</span> <span class="n">been</span> <span class="n">accepting</span> <span class="n">approval</span> <span class="k">for</span> <span class="n">Diovan</span> <span class="n">since</span> <span class="mi">2012</span> <span class="o">|</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span> <span class="o">|</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">MedicalDistilBertForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"distilbert_sequence_classifier_ade"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"classes"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">sequenceClassifier</span><span class="o">))</span>

<span class="k">var</span> <span class="n">text</span> <span class="k">=</span><span class="nc">List</span><span class="o">(</span>
    <span class="nc">List</span><span class="o">(</span><span class="s">"I have an allergic reaction to vancomycin so I have itchy skin, sore throat/burning/itching, numbness of tongue and gums.I would not recommend this drug to anyone, especially since I have never had such an adverse reaction to any other medication."</span><span class="o">),</span>
    <span class="nc">List</span><span class="o">(</span><span class="s">"Religare Capital Ranbaxy has been accepting approval for Diovan since 2012"</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">|</span> <span class="n">text</span>                                                                                           <span class="o">|</span> <span class="n">result</span> <span class="o">|</span>
<span class="o">|------------------------------------------------------------------------------------------------|-------|</span>
<span class="o">|</span> <span class="n">I</span> <span class="n">have</span> <span class="n">an</span> <span class="n">allergic</span> <span class="n">reaction</span> <span class="n">to</span> <span class="n">vancomycin</span> <span class="n">so</span> <span class="n">I</span> <span class="n">have</span> <span class="n">itchy</span> <span class="n">skin</span><span class="o">,</span> <span class="n">sore</span> <span class="n">throat</span><span class="o">/</span><span class="n">burning</span><span class="o">/</span><span class="n">itching</span><span class="o">,</span> <span class="n">numb</span><span class="o">...</span> <span class="o">|</span> <span class="o">[</span><span class="kt">True</span><span class="o">]</span> <span class="o">|</span>
<span class="o">|</span> <span class="nc">Religare</span> <span class="nc">Capital</span> <span class="nc">Ranbaxy</span> <span class="n">has</span> <span class="n">been</span> <span class="n">accepting</span> <span class="n">approval</span> <span class="k">for</span> <span class="nc">Diovan</span> <span class="n">since</span> <span class="mi">2012</span> <span class="o">|</span> <span class="o">[</span><span class="kt">False</span><span class="o">]</span> <span class="o">|</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="doc2chunkinternal">Doc2ChunkInternal</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Converts <code class="language-plaintext highlighter-rouge">DOCUMENT</code>, <code class="language-plaintext highlighter-rouge">TOKEN</code> typed annotations into <code class="language-plaintext highlighter-rouge">CHUNK</code> type with the contents of a <code class="language-plaintext highlighter-rouge">chunkCol</code>. Chunk text must be contained within input <code class="language-plaintext highlighter-rouge">DOCUMENT</code>. May be either <code class="language-plaintext highlighter-rouge">StringType</code> or <code class="language-plaintext highlighter-rouge">ArrayType[StringType]</code> (using <code class="language-plaintext highlighter-rouge">setIsArray</code>). Useful for annotators that require a CHUNK type input.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p>For more extended examples on document pre-processing see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/doc2_chunk_internal/index.html#sparknlp_jsl.annotator.doc2_chunk_internal.Doc2ChunkInternal">Doc2ChunkInternal</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/annotator/Doc2ChunkInternal.html">Doc2ChunkInternal</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Doc2ChunkInternal.ipynb">Doc2ChunkInternalNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Doc2ChunkInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIsArray</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
                                    <span class="n">documentAssembler</span><span class="p">,</span>
                                    <span class="n">tokenizer</span><span class="p">,</span> 
                                    <span class="n">chunkAssembler</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="p">,</span>
            <span class="p">[</span><span class="s">"Spark NLP"</span><span class="p">,</span> <span class="s">"text processing library"</span><span class="p">,</span> <span class="s">"natural language processing"</span><span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">)</span>


<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"chunk.result"</span><span class="p">,</span> <span class="s">"chunk.annotatorType"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Spark</span> <span class="n">NLP</span><span class="p">,</span> <span class="n">text</span> <span class="n">processing</span> <span class="n">library</span><span class="p">,</span> <span class="n">natural</span> <span class="n">language</span> <span class="n">processing</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">Doc2ChunkInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIsArray</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">chunkAssembler</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="p">,</span>
            <span class="p">[</span><span class="s">"Spark NLP"</span><span class="p">,</span> <span class="s">"text processing library"</span><span class="p">,</span> <span class="s">"natural language processing"</span><span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">)</span>


<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"chunk.result"</span><span class="p">,</span> <span class="s">"chunk.annotatorType"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Spark</span> <span class="n">NLP</span><span class="p">,</span> <span class="n">text</span> <span class="n">processing</span> <span class="n">library</span><span class="p">,</span> <span class="n">natural</span> <span class="n">language</span> <span class="n">processing</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">chunkAssembler</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">Doc2ChunkInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkCol</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIsArray</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">documentAssembler</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">chunkAssembler</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="p">,</span>
            <span class="p">[</span><span class="s">"Spark NLP"</span><span class="p">,</span> <span class="s">"text processing library"</span><span class="p">,</span> <span class="s">"natural language processing"</span><span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"target"</span><span class="p">)</span>


<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"chunk.result"</span><span class="p">,</span> <span class="s">"chunk.annotatorType"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Spark</span> <span class="n">NLP</span><span class="p">,</span> <span class="n">text</span> <span class="n">processing</span> <span class="n">library</span><span class="p">,</span> <span class="n">natural</span> <span class="n">language</span> <span class="n">processing</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2ChunkInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setIsArray</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">chunkAssembler</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="o">,</span>
               <span class="s">"Spark NLP"</span><span class="o">,</span> <span class="s">"text processing library"</span><span class="o">,</span> <span class="s">"natural language processing"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"target"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|[</span><span class="kt">Spark</span> <span class="kt">NLP</span>, <span class="kt">text</span> <span class="kt">processing</span> <span class="kt">library</span>, <span class="kt">natural</span> <span class="kt">language</span> <span class="kt">processing</span><span class="o">]|[</span><span class="kt">chunk</span>, <span class="kt">chunk</span>, <span class="kt">chunk</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2ChunkInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setIsArray</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">chunkAssembler</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="o">,</span>
               <span class="s">"Spark NLP"</span><span class="o">,</span> <span class="s">"text processing library"</span><span class="o">,</span> <span class="s">"natural language processing"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"target"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|[</span><span class="kt">Spark</span> <span class="kt">NLP</span>, <span class="kt">text</span> <span class="kt">processing</span> <span class="kt">library</span>, <span class="kt">natural</span> <span class="kt">language</span> <span class="kt">processing</span><span class="o">]|[</span><span class="kt">chunk</span>, <span class="kt">chunk</span>, <span class="kt">chunk</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2ChunkInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setChunkCol</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setIsArray</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">chunkAssembler</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"Spark NLP is an open-source text processing library for advanced natural language processing."</span><span class="o">,</span>
               <span class="s">"Spark NLP"</span><span class="o">,</span> <span class="s">"text processing library"</span><span class="o">,</span> <span class="s">"natural language processing"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"target"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                           <span class="o">|</span><span class="n">annotatorType</span>        <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
<span class="o">|[</span><span class="kt">Spark</span> <span class="kt">NLP</span>, <span class="kt">text</span> <span class="kt">processing</span> <span class="kt">library</span>, <span class="kt">natural</span> <span class="kt">language</span> <span class="kt">processing</span><span class="o">]|[</span><span class="kt">chunk</span>, <span class="kt">chunk</span>, <span class="kt">chunk</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------------+---------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="docmapper">DocMapper</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">DocMapper</code> uses the text representation of document annotations to map clinical codes to other codes or relevant information.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setRels</code> <em>(List[str])</em>: Relations that we are going to use to map the document</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setLowerCase</code> <em>(Boolean)</em>: Set if we want to map the documents in lower case or not (Default: True)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setAllowMultiTokenChunk</code> <em>(Boolean)</em>: Whether to skip relations with multitokens (Default: True)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setMultivaluesRelations</code> <em>(Boolean)</em>:  Whether to decide to return all values in a relation together or separately (Default: False)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setDoExceptionHandling</code>: If it is set as True, the annotator tries to process as usual and ff exception-causing data (e.g. corrupted record/ document) is passed to the annotator, an exception warning is emitted which has the exception message.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LABEL_DEPENDENCY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/docmapper/index.html#sparknlp_jsl.annotator.chunker.docmapper.DocMapperModel">DocMapperModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/DocMapperModel.html">DocMapperModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DocMapperModel.ipynb">DocMapperModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1">#ChunkMapper Pipeline
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="c1">#drug_action_treatment_mapper 
</span><span class="n">docMapper</span><span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocMapperModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"drug_action_treatment_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mappings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"action"</span><span class="p">,</span> <span class="s">"treatment"</span><span class="p">])</span>

<span class="n">mapperPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">docMapper</span><span class="p">])</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Dermovate"</span><span class="p">],</span> <span class="p">[</span><span class="s">"Aspagin"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">mapperPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test_data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">res</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">mappings</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                  <span class="n">res</span><span class="p">.</span><span class="n">mappings</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"col"</span><span class="p">))</span>\
    <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">),</span>
            <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"mapping_result"</span><span class="p">),</span>
            <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['1']['relation']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
            <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['1']['all_relations']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"all_mappings"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------+----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">ner_chunk</span><span class="o">|</span><span class="n">mapping_result</span>        <span class="o">|</span><span class="n">relation</span> <span class="o">|</span><span class="n">all_mappings</span>                                                                                                                                                                                                           <span class="o">|</span>
<span class="o">+---------+----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">Dermovate</span><span class="o">|</span><span class="n">anti</span><span class="o">-</span><span class="n">inflammatory</span>     <span class="o">|</span><span class="n">action</span>   <span class="o">|</span><span class="n">corticosteroids</span><span class="p">:::</span> <span class="n">dermatological</span> <span class="n">preparations</span><span class="p">:::</span><span class="n">very</span> <span class="n">strong</span>                                                                                                                                                           <span class="o">|</span>
<span class="o">|</span><span class="n">Dermovate</span><span class="o">|</span><span class="n">lupus</span>                 <span class="o">|</span><span class="n">treatment</span><span class="o">|</span><span class="n">discoid</span> <span class="n">lupus</span> <span class="n">erythematosus</span><span class="p">:::</span><span class="n">empeines</span><span class="p">:::</span><span class="n">psoriasis</span><span class="p">:::</span><span class="n">eczema</span>                                                                                                                                                            <span class="o">|</span>
<span class="o">|</span><span class="n">Aspagin</span>  <span class="o">|</span><span class="n">analgesic</span>             <span class="o">|</span><span class="n">action</span>   <span class="o">|</span><span class="n">anti</span><span class="o">-</span><span class="n">inflammatory</span><span class="p">:::</span><span class="n">antipyretic</span>                                                                                                                                                                                        <span class="o">|</span>
<span class="o">|</span><span class="n">Aspagin</span>  <span class="o">|</span><span class="n">ankylosing</span> <span class="n">spondylitis</span><span class="o">|</span><span class="n">treatment</span><span class="o">|</span><span class="n">arthralgia</span><span class="p">:::</span><span class="n">pain</span><span class="p">:::</span><span class="n">bursitis</span><span class="p">:::</span><span class="n">headache</span><span class="p">:::</span><span class="n">migraine</span><span class="p">:::</span><span class="n">myositis</span><span class="p">:::</span><span class="n">neuralgia</span><span class="p">:::</span><span class="n">osteoarthritis</span><span class="p">:::</span><span class="n">gout</span><span class="p">:::</span><span class="n">rheumatoid</span> <span class="n">arthritis</span><span class="p">:::</span><span class="n">spondylitis</span><span class="p">:::</span><span class="n">spondyloarthritis</span><span class="p">:::</span><span class="n">tendinitis</span><span class="p">:::</span><span class="n">tenosynovitis</span><span class="p">:::</span><span class="n">crush</span> <span class="n">injury</span><span class="p">:::</span><span class="n">golfer</span><span class="s">'s elbow|
+---------+----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</span></code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// ChunkMapper Pipeline</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="c1">// drug_action_treatment_mapper </span>
<span class="k">val</span> <span class="nv">docMapper</span><span class="k">=</span> <span class="nc">DocMapperModel</span><span class="o">().</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"drug_action_treatment_mapper"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mappings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"action"</span><span class="o">,</span> <span class="s">"treatment"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">mapperPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">docMapper</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"Dermovate"</span><span class="o">,</span> <span class="s">"Aspagin"</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">mapperPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span>

<span class="c1">// Show results</span>

<span class="o">+---------+----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">ner_chunk</span><span class="o">|</span><span class="n">mapping_result</span>        <span class="o">|</span><span class="n">relation</span> <span class="o">|</span><span class="n">all_mappings</span>                                                                                                                                                                                                           <span class="o">|</span>
<span class="o">+---------+----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">Dermovate</span><span class="o">|</span><span class="n">anti</span><span class="o">-</span><span class="n">inflammatory</span>     <span class="o">|</span><span class="n">action</span>   <span class="o">|</span><span class="n">corticosteroids</span><span class="o">:::</span> <span class="n">dermatological</span> <span class="n">preparations</span><span class="o">:::</span><span class="n">very</span> <span class="n">strong</span>                                                                                                                                                           <span class="o">|</span>
<span class="o">|</span><span class="nc">Dermovate</span><span class="o">|</span><span class="n">lupus</span>                 <span class="o">|</span><span class="n">treatment</span><span class="o">|</span><span class="n">discoid</span> <span class="n">lupus</span> <span class="n">erythematosus</span><span class="o">:::</span><span class="n">empeines</span><span class="o">:::</span><span class="n">psoriasis</span><span class="o">:::</span><span class="n">eczema</span>                                                                                                                                                            <span class="o">|</span>
<span class="o">|</span><span class="nc">Aspagin</span>  <span class="o">|</span><span class="n">analgesic</span>             <span class="o">|</span><span class="n">action</span>   <span class="o">|</span><span class="n">anti</span><span class="o">-</span><span class="n">inflammatory</span><span class="o">:::</span><span class="n">antipyretic</span>                                                                                                                                                                                        <span class="o">|</span>
<span class="o">|</span><span class="nc">Aspagin</span>  <span class="o">|</span><span class="n">ankylosing</span> <span class="n">spondylitis</span><span class="o">|</span><span class="n">treatment</span><span class="o">|</span><span class="n">arthralgia</span><span class="o">:::</span><span class="n">pain</span><span class="o">:::</span><span class="n">bursitis</span><span class="o">:::</span><span class="n">headache</span><span class="o">:::</span><span class="n">migraine</span><span class="o">:::</span><span class="n">myositis</span><span class="o">:::</span><span class="n">neuralgia</span><span class="o">:::</span><span class="n">osteoarthritis</span><span class="o">:::</span><span class="n">gout</span><span class="o">:::</span><span class="n">rheumatoid</span> <span class="n">arthritis</span><span class="o">:::</span><span class="n">spondylitis</span><span class="o">:::</span><span class="n">spondyloarthritis</span><span class="o">:::</span><span class="n">tendinitis</span><span class="o">:::</span><span class="n">tenosynovitis</span><span class="o">:::</span><span class="n">crush</span> <span class="n">injury</span><span class="o">:::</span><span class="n">golfer</span><span class="ss">'s</span> <span class="n">elbow</span><span class="o">|</span>
<span class="o">+---------+----------------------+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">DocMapper</code> that can be used to map short strings via DocumentAssembler without using any other annotator between to convert strings to Chunk type that ChunkMapperModel expects.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setDictionary</code> <em>(Str)</em>: Dictionary path where is the JsonDictionary that contains the mappings columns</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setRels</code> <em>(Boolean)</em>: Relations that we are going to use to map the document</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setLowerCase</code> <em>(Boolean)</em>: Set if we want to map the documents in lower case or not (Default: True)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setAllowMultiTokenChunk</code> <em>(Boolean)</em>: Whether to skip relations with multitokens (Default: True)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setMultivaluesRelations</code> <em>(Boolean)</em>:  Whether to decide to return all values in a relation together or separately (Default: False)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setDoExceptionHandling</code>: If it is set as True, the annotator tries to process as usual and ff exception-causing data (e.g. corrupted record/ document) is passed to the annotator, an exception warning is emitted which has the exception message.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">LABEL_DEPENDENCY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/docmapper/index.html#sparknlp_jsl.annotator.chunker.docmapper.DocMapperApproach.name">DocMapperApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/DocMapperApproach.html">DocMapperApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DocMapperApproach.ipynb">DocMapperApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span>  <span class="n">medical</span>

<span class="n">data_set</span><span class="o">=</span> <span class="p">{</span>
  <span class="s">"mappings"</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s">"key"</span><span class="p">:</span> <span class="s">"metformin"</span><span class="p">,</span>
      <span class="s">"relations"</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"action"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"hypoglycemic"</span><span class="p">,</span> <span class="s">"Drugs Used In Diabetes"</span><span class="p">]</span>
        <span class="p">},</span>
        <span class="p">{</span>
          <span class="s">"key"</span><span class="p">:</span> <span class="s">"treatment"</span><span class="p">,</span>
          <span class="s">"values"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"diabetes"</span><span class="p">,</span> <span class="s">"t2dm"</span><span class="p">]</span>
        <span class="p">}</span>
      <span class="p">]</span>
    <span class="p">}</span>
  <span class="p">]</span>
<span class="p">}</span>

<span class="kn">import</span> <span class="nn">json</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'sample_drug.json'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">chunkerMapper</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocMapperApproach</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"mappings"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDictionary</span><span class="p">(</span><span class="s">"./sample_drug.json"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"action"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">document_assembler</span><span class="p">,</span>
                                     <span class="n">chunkerMapper</span><span class="p">])</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"metformin"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test_data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>


<span class="c1">## Results
</span><span class="n">res</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">mappings</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                  <span class="n">res</span><span class="p">.</span><span class="n">mappings</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"col"</span><span class="p">))</span>\
    <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"document"</span><span class="p">),</span>
            <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"mapping_result"</span><span class="p">),</span>
            <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['1']['relation']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
            <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['1']['all_relations']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"all_mappings"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------+--------------+--------+----------------------+</span>
<span class="o">|</span><span class="n">document</span> <span class="o">|</span><span class="n">mapping_result</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">all_mappings</span>          <span class="o">|</span>
<span class="o">+---------+--------------+--------+----------------------+</span>
<span class="o">|</span><span class="n">metformin</span><span class="o">|</span><span class="n">hypoglycemic</span>  <span class="o">|</span><span class="n">action</span>  <span class="o">|</span><span class="n">Drugs</span> <span class="n">Used</span> <span class="n">In</span> <span class="n">Diabetes</span><span class="o">|</span>
<span class="o">+---------+--------------+--------+----------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="cm">/* sample_drug.json file
{
  "mappings": [
    {
      "key": "metformin",
      "relations": [
        {
          "key": "action",
          "values" : ["hypoglycemic", "Drugs Used In Diabetes"]
        },
        {
          "key": "treatment",
          "values" : ["diabetes", "t2dm"]
        }
      ]
    }
  ]
}
*/</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">chunkerMapper</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocMapperApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"mappings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDictionary</span><span class="o">(</span><span class="s">"./sample_drug.json"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="s">"action"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">document_assembler</span><span class="o">,</span> <span class="n">chunkerMapper</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"metformin"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span>


<span class="c1">// Results </span>

<span class="o">+---------+--------------+--------+----------------------+</span>
<span class="o">|</span><span class="n">document</span> <span class="o">|</span><span class="n">mapping_result</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">all_mappings</span>          <span class="o">|</span>
<span class="o">+---------+--------------+--------+----------------------+</span>
<span class="o">|</span><span class="n">metformin</span><span class="o">|</span><span class="n">hypoglycemic</span>  <span class="o">|</span><span class="n">action</span>  <span class="o">|</span><span class="nc">Drugs</span> <span class="nc">Used</span> <span class="nc">In</span> <span class="nc">Diabetes</span><span class="o">|</span>
<span class="o">+---------+--------------+--------+----------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="documentfiltererbyclassifier">DocumentFiltererByClassifier</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The DocumentFiltererByClassifier function is designed to filter documents based on the outcomes generated by classifier annotators. It operates using a white list and a black list. The white list comprises classifier results that meet the criteria to pass through the filter, while the black list includes results that are prohibited from passing through. This filtering process is sensitive to cases by default. However, by setting caseSensitive to False, the filter becomes case-insensitive, allowing for a broader range of matches based on the specified criteria. This function serves as an effective tool for systematically sorting and managing documents based on specific classifier outcomes, facilitating streamlined document handling and organization.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">whiteList</code>: (list) If defined, list of entities to process. The rest will be ignored.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">CaseSensitive</code>: (bool) Determines whether the definitions of the white listed entities are case sensitive.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CATEGORY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DocumentFiltererByClassifier.ipynb">DocumentFiltererByClassifierNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">example</span> <span class="o">=</span> <span class="s">"""Medical Specialty:
Cardiovascular / Pulmonary

Sample Name: Aortic Valve Replacement

Description: Aortic valve replacement using a mechanical valve and two-vessel coronary artery bypass grafting procedure using saphenous vein graft to the first obtuse marginal artery and left radial artery graft to the left anterior descending artery.
(Medical Transcription Sample Report)

DIAGNOSIS: Aortic valve stenosis with coronary artery disease associated with congestive heart failure. The patient has diabetes and is morbidly obese.

PROCEDURES: Aortic valve replacement using a mechanical valve and two-vessel coronary artery bypass grafting procedure using saphenous vein graft to the first obtuse marginal artery and left radial artery graft to the left anterior descending artery.

ANESTHESIA: General endotracheal

INCISION: Median sternotomy

INDICATIONS: The patient presented with severe congestive heart failure associated with the patient's severe diabetes. The patient was found to have moderately stenotic aortic valve. In addition, The patient had significant coronary artery disease consisting of a chronically occluded right coronary artery but a very important large obtuse marginal artery coming off as the main circumflex system. The patient also has a left anterior descending artery which has moderate disease and this supplies quite a bit of collateral to the patient's right system. It was decided to perform a valve replacement as well as coronary artery bypass grafting procedure.

FINDINGS: The left ventricle is certainly hypertrophied· The aortic valve leaflet is calcified and a severe restrictive leaflet motion. It is a tricuspid type of valve. The coronary artery consists of a large left anterior descending artery which is associated with 60% stenosis but a large obtuse marginal artery which has a tight proximal stenosis.

The radial artery was used for the left anterior descending artery. Flow was excellent. Looking at the targets in the posterior descending artery territory, there did not appear to be any large branches. On the angiogram these vessels appeared to be quite small. Because this is a chronically occluded vessel and the patient has limited conduit due to the patient's massive obesity, attempt to bypass to this area was not undertaken. The patient was brought to the operating room

PROCEDURE: The patient was brought to the operating room and placed in supine position. A median sternotomy incision was carried out and conduits were taken from the left arm as well as the right thigh. The patient weighs nearly three hundred pounds. There was concern as to taking down the left internal mammary artery. Because the radial artery appeared to be a good conduit The patient would have arterial graft to the left anterior descending artery territory. The patient was cannulated after the aorta and atrium were exposed and full heparinization.

The patient went on cardiopulmonary bypass and the aortic cross-clamp was applied Cardioplegia was delivered through the coronary sinuses in a retrograde manner. The patient was cooled to 32 degrees. Iced slush was applied to the heart. The aortic valve was then exposed through the aortic root by transverse incision. The valve leaflets were removed and the #23 St. Jude mechanical valve was secured into position by circumferential pledgeted sutures. At this point, aortotomy was closed.

The first obtuse marginal artery was a very large target and the vein graft to this target indeed produced an excellent amount of flow. Proximal anastomosis was then carried out to the foot of the aorta. The left anterior descending artery does not have severe disease but is also a very good target and the radial artery was anastomosed to this target in an end-to-side manner. The two proximal anastomoses were then carried out to the root of the aorta.

The patient came off cardiopulmonary bypass after aortic cross-clamp was released. The patient was adequately warmed. Protamine was given without adverse effect. Sternal closure was then done using wires. The subcutaneous layers were closed using Vicryl suture. The skin was approximated using staples.
"""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">example</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\

<span class="n">document_splitter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">InternalDocumentSplitter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"splits"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setSplitMode</span><span class="p">(</span><span class="s">"recursive"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkOverlap</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setExplodeSplits</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPatternsAreRegex</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setSplitPatterns</span><span class="p">([</span><span class="s">"</span><span class="se">\n\n</span><span class="s">"</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setKeepSeparators</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTrimWhitespace</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="c1">#.setEnableSentenceIncrement(False)
</span>
<span class="n">sequenceClassifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">BertForSequenceClassification</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'bert_sequence_classifier_clinical_sections'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"splits"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">document_filterer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocumentFiltererByClassifier</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"splits"</span><span class="p">,</span> <span class="s">"prediction"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filteredDocuments"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Diagnostic and Laboratory Data"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">document_splitter</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span><span class="p">,</span>
    <span class="c1">#document_filterer
</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># before filterer result
</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"splits.result[0] as splits"</span><span class="p">,</span>
                  <span class="s">"prediction.result[0] as classes"</span>
                  <span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">splits</span><span class="o">|</span>                       <span class="n">classes</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
<span class="o">|</span><span class="n">Medical</span> <span class="n">Specialty</span><span class="p">:</span>\<span class="n">nCardiovascular</span> <span class="o">/</span> <span class="n">Pulmonary</span>\<span class="n">n</span>\<span class="n">nSample</span> <span class="n">Name</span><span class="p">:</span> <span class="n">Aortic</span> <span class="n">Valve</span> <span class="n">R</span><span class="p">...</span><span class="o">|</span>                       <span class="n">History</span><span class="o">|</span>
<span class="o">|</span><span class="n">Description</span><span class="p">:</span> <span class="n">Aortic</span> <span class="n">valve</span> <span class="n">replacement</span> <span class="n">using</span> <span class="n">a</span> <span class="n">mechanical</span> <span class="n">valve</span> <span class="ow">and</span> <span class="n">two</span><span class="o">-</span><span class="n">vessel</span><span class="p">...</span><span class="o">|</span><span class="n">Complications</span> <span class="ow">and</span> <span class="n">Risk</span> <span class="n">Factors</span><span class="o">|</span>
<span class="o">|</span>                                           <span class="p">(</span><span class="n">Medical</span> <span class="n">Transcription</span> <span class="n">Sample</span> <span class="n">Report</span><span class="p">)</span><span class="o">|</span><span class="n">Complications</span> <span class="ow">and</span> <span class="n">Risk</span> <span class="n">Factors</span><span class="o">|</span>
<span class="o">|</span><span class="n">DIAGNOSIS</span><span class="p">:</span> <span class="n">Aortic</span> <span class="n">valve</span> <span class="n">stenosis</span> <span class="k">with</span> <span class="n">coronary</span> <span class="n">artery</span> <span class="n">disease</span> <span class="n">associated</span> <span class="k">with</span><span class="p">...</span><span class="o">|</span><span class="n">Diagnostic</span> <span class="ow">and</span> <span class="n">Laboratory</span> <span class="n">Data</span><span class="o">|</span>
<span class="o">|</span><span class="n">PROCEDURES</span><span class="p">:</span> <span class="n">Aortic</span> <span class="n">valve</span> <span class="n">replacement</span> <span class="n">using</span> <span class="n">a</span> <span class="n">mechanical</span> <span class="n">valve</span> <span class="ow">and</span> <span class="n">two</span><span class="o">-</span><span class="n">vessel</span> <span class="p">...</span><span class="o">|</span>                    <span class="n">Procedures</span><span class="o">|</span>
<span class="o">|</span>                 <span class="n">ANESTHESIA</span><span class="p">:</span> <span class="n">General</span> <span class="n">endotracheal</span>\<span class="n">n</span>\<span class="n">nINCISION</span><span class="p">:</span> <span class="n">Median</span> <span class="n">sternotomy</span><span class="o">|</span>                    <span class="n">Procedures</span><span class="o">|</span>
<span class="o">|</span><span class="n">INDICATIONS</span><span class="p">:</span> <span class="n">The</span> <span class="n">patient</span> <span class="n">presented</span> <span class="k">with</span> <span class="n">severe</span> <span class="n">congestive</span> <span class="n">heart</span> <span class="n">failure</span> <span class="n">assoc</span><span class="p">...</span><span class="o">|</span>     <span class="n">Consultation</span> <span class="ow">and</span> <span class="n">Referral</span><span class="o">|</span>
<span class="o">|</span><span class="n">FINDINGS</span><span class="p">:</span> <span class="n">The</span> <span class="n">left</span> <span class="n">ventricle</span> <span class="ow">is</span> <span class="n">certainly</span> <span class="n">hypertrophied</span><span class="err">·</span> <span class="n">The</span> <span class="n">aortic</span> <span class="n">valve</span> <span class="n">lea</span><span class="p">...</span><span class="o">|</span><span class="n">Diagnostic</span> <span class="ow">and</span> <span class="n">Laboratory</span> <span class="n">Data</span><span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">radial</span> <span class="n">artery</span> <span class="n">was</span> <span class="n">used</span> <span class="k">for</span> <span class="n">the</span> <span class="n">left</span> <span class="n">anterior</span> <span class="n">descending</span> <span class="n">artery</span><span class="p">.</span> <span class="n">Flow</span> <span class="n">was</span> <span class="p">...</span><span class="o">|</span><span class="n">Diagnostic</span> <span class="ow">and</span> <span class="n">Laboratory</span> <span class="n">Data</span><span class="o">|</span>
<span class="o">|</span><span class="n">PROCEDURE</span><span class="p">:</span> <span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">brought</span> <span class="n">to</span> <span class="n">the</span> <span class="n">operating</span> <span class="n">room</span> <span class="ow">and</span> <span class="n">placed</span> <span class="ow">in</span> <span class="n">supine</span><span class="p">...</span><span class="o">|</span>                    <span class="n">Procedures</span><span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">went</span> <span class="n">on</span> <span class="n">cardiopulmonary</span> <span class="n">bypass</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">aortic</span> <span class="n">cross</span><span class="o">-</span><span class="n">clamp</span> <span class="n">was</span> <span class="n">app</span><span class="p">...</span><span class="o">|</span>                    <span class="n">Procedures</span><span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">first</span> <span class="n">obtuse</span> <span class="n">marginal</span> <span class="n">artery</span> <span class="n">was</span> <span class="n">a</span> <span class="n">very</span> <span class="n">large</span> <span class="n">target</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">vein</span> <span class="n">graft</span> <span class="n">t</span><span class="p">...</span><span class="o">|</span><span class="n">Diagnostic</span> <span class="ow">and</span> <span class="n">Laboratory</span> <span class="n">Data</span><span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">came</span> <span class="n">off</span> <span class="n">cardiopulmonary</span> <span class="n">bypass</span> <span class="n">after</span> <span class="n">aortic</span> <span class="n">cross</span><span class="o">-</span><span class="n">clamp</span> <span class="n">was</span> <span class="n">rele</span><span class="p">...</span><span class="o">|</span>                    <span class="n">Procedures</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>


<span class="c1"># after filterer result
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">document_splitter</span><span class="p">,</span>
    <span class="n">sequenceClassifier</span><span class="p">,</span>
    <span class="n">document_filterer</span>
<span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"filteredDocuments.result[0] as splits"</span><span class="p">,</span>
                  <span class="s">"filteredDocuments.metadata[0].class_label as classes"</span><span class="p">)</span>\
                  <span class="p">.</span><span class="nb">filter</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">"classes"</span><span class="p">).</span><span class="n">isNotNull</span><span class="p">()).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">splits</span><span class="o">|</span>                       <span class="n">classes</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
<span class="o">|</span><span class="n">DIAGNOSIS</span><span class="p">:</span> <span class="n">Aortic</span> <span class="n">valve</span> <span class="n">stenosis</span> <span class="k">with</span> <span class="n">coronary</span> <span class="n">artery</span> <span class="n">disease</span> <span class="n">associated</span> <span class="k">with</span><span class="p">...</span><span class="o">|</span><span class="n">Diagnostic</span> <span class="ow">and</span> <span class="n">Laboratory</span> <span class="n">Data</span><span class="o">|</span>
<span class="o">|</span><span class="n">FINDINGS</span><span class="p">:</span> <span class="n">The</span> <span class="n">left</span> <span class="n">ventricle</span> <span class="ow">is</span> <span class="n">certainly</span> <span class="n">hypertrophied</span><span class="err">·</span> <span class="n">The</span> <span class="n">aortic</span> <span class="n">valve</span> <span class="n">lea</span><span class="p">...</span><span class="o">|</span><span class="n">Diagnostic</span> <span class="ow">and</span> <span class="n">Laboratory</span> <span class="n">Data</span><span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">radial</span> <span class="n">artery</span> <span class="n">was</span> <span class="n">used</span> <span class="k">for</span> <span class="n">the</span> <span class="n">left</span> <span class="n">anterior</span> <span class="n">descending</span> <span class="n">artery</span><span class="p">.</span> <span class="n">Flow</span> <span class="n">was</span> <span class="p">...</span><span class="o">|</span><span class="n">Diagnostic</span> <span class="ow">and</span> <span class="n">Laboratory</span> <span class="n">Data</span><span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">first</span> <span class="n">obtuse</span> <span class="n">marginal</span> <span class="n">artery</span> <span class="n">was</span> <span class="n">a</span> <span class="n">very</span> <span class="n">large</span> <span class="n">target</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">vein</span> <span class="n">graft</span> <span class="n">t</span><span class="p">...</span><span class="o">|</span><span class="n">Diagnostic</span> <span class="ow">and</span> <span class="n">Laboratory</span> <span class="n">Data</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
 
<span class="k">val</span> <span class="nv">example</span> <span class="k">=</span> <span class="s">"Medical Specialty:
Cardiovascular / Pulmonary
Sample Name: Aortic Valve Replacement
Description: Aortic valve replacement using a mechanical valve and two-vessel coronary artery bypass grafting procedure using saphenous vein graft to the first obtuse marginal artery and left radial artery graft to the left anterior descending artery.
(Medical Transcription Sample Report)
DIAGNOSIS: Aortic valve stenosis with coronary artery disease associated with congestive heart failure. The patient has diabetes and is morbidly obese.
PROCEDURES: Aortic valve replacement using a mechanical valve and two-vessel coronary artery bypass grafting procedure using saphenous vein graft to the first obtuse marginal artery and left radial artery graft to the left anterior descending artery.
ANESTHESIA: General endotracheal
INCISION: Median sternotomy
INDICATIONS: The patient presented with severe congestive heart failure associated with the patient's severe diabetes. The patient was found to have moderately stenotic aortic valve. In addition, The patient had significant coronary artery disease consisting of a chronically occluded right coronary artery but a very important large obtuse marginal artery coming off as the main circumflex system. The patient also has a left anterior descending artery which has moderate disease and this supplies quite a bit of collateral to the patient's right system. It was decided to perform a valve replacement as well as coronary artery bypass grafting procedure.
FINDINGS: The left ventricle is certainly hypertrophied· The aortic valve leaflet is calcified and a severe restrictive leaflet motion. It is a tricuspid type of valve. The coronary artery consists of a large left anterior descending artery which is associated with 60% stenosis but a large obtuse marginal artery which has a tight proximal stenosis.
The radial artery was used for the left anterior descending artery. Flow was excellent. Looking at the targets in the posterior descending artery territory, there did not appear to be any large branches. On the angiogram these vessels appeared to be quite small. Because this is a chronically occluded vessel and the patient has limited conduit due to the patient's massive obesity, attempt to bypass to this area was not undertaken. The patient was brought to the operating room
PROCEDURE: The patient was brought to the operating room and placed in supine position. A median sternotomy incision was carried out and conduits were taken from the left arm as well as the right thigh. The patient weighs nearly three hundred pounds. There was concern as to taking down the left internal mammary artery. Because the radial artery appeared to be a good conduit The patient would have arterial graft to the left anterior descending artery territory. The patient was cannulated after the aorta and atrium were exposed and full heparinization.
The patient went on cardiopulmonary bypass and the aortic cross-clamp was applied Cardioplegia was delivered through the coronary sinuses in a retrograde manner. The patient was cooled to 32 degrees. Iced slush was applied to the heart. The aortic valve was then exposed through the aortic root by transverse incision. The valve leaflets were removed and the #23 St. Jude mechanical valve was secured into position by circumferential pledgeted sutures. At this point, aortotomy was closed.
The first obtuse marginal artery was a very large target and the vein graft to this target indeed produced an excellent amount of flow. Proximal anastomosis was then carried out to the foot of the aorta. The left anterior descending artery does not have severe disease but is also a very good target and the radial artery was anastomosed to this target in an end-to-side manner. The two proximal anastomoses were then carried out to the root of the aorta.
The patient came off cardiopulmonary bypass after aortic cross-clamp was released. The patient was adequately warmed. Protamine was given without adverse effect. Sternal closure was then done using wires. The subcutaneous layers were closed using Vicryl suture. The skin was approximated using staples.
"</span>

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">example</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">document_splitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">InternalDocumentSplitter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"splits"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setSplitMode</span><span class="o">(</span><span class="s">"recursive"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setChunkSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setChunkOverlap</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setExplodeSplits</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setPatternsAreRegex</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setSplitPatterns</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">" "</span><span class="o">,</span><span class="s">" "</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setKeepSeparators</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setTrimWhitespace</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
  <span class="c1">//.setEnableSentenceIncrement(false) </span>

<span class="k">val</span> <span class="nv">sequenceClassifier</span> <span class="k">=</span> <span class="nv">MedicalBertForSequenceClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_sequence_classifier_clinical_sections"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"splits"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">document_filterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentFiltererByClassifier</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"splits"</span><span class="o">,</span><span class="s">"prediction"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filteredDocuments"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"Diagnostic and Laboratory Data"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
                                              <span class="n">document_assembler</span><span class="o">,</span> 
                                              <span class="n">tokenizer</span><span class="o">,</span> 
                                              <span class="n">document_splitter</span><span class="o">,</span> 
                                              <span class="n">sequenceClassifier</span><span class="o">,</span> 
                                              <span class="c1">//document_filterer )) </span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// before filterer result </span>

<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">splits</span><span class="o">|</span>                       <span class="n">classes</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
<span class="o">|</span><span class="nc">Medical</span> <span class="nc">Specialty</span><span class="o">:\</span><span class="n">nCardiovascular</span> <span class="o">/</span> <span class="nc">Pulmonary</span><span class="o">\</span><span class="n">n</span><span class="o">\</span><span class="n">nSample</span> <span class="nc">Name</span><span class="k">:</span> <span class="kt">Aortic</span> <span class="kt">Valve</span> <span class="kt">R...|</span>                       <span class="kt">History|</span>
<span class="kt">|Description:</span> <span class="kt">Aortic</span> <span class="kt">valve</span> <span class="kt">replacement</span> <span class="kt">using</span> <span class="kt">a</span> <span class="kt">mechanical</span> <span class="kt">valve</span> <span class="kt">and</span> <span class="kt">two-vessel...|Complications</span> <span class="kt">and</span> <span class="kt">Risk</span> <span class="kt">Factors|</span>
<span class="kt">|</span>                                           <span class="o">(</span><span class="kt">Medical</span> <span class="kt">Transcription</span> <span class="kt">Sample</span> <span class="kt">Report</span><span class="o">)</span><span class="kt">|Complications</span> <span class="kt">and</span> <span class="kt">Risk</span> <span class="kt">Factors|</span>
<span class="kt">|DIAGNOSIS:</span> <span class="kt">Aortic</span> <span class="kt">valve</span> <span class="kt">stenosis</span> <span class="kt">with</span> <span class="kt">coronary</span> <span class="kt">artery</span> <span class="kt">disease</span> <span class="kt">associated</span> <span class="kt">with...|Diagnostic</span> <span class="kt">and</span> <span class="kt">Laboratory</span> <span class="kt">Data|</span>
<span class="kt">|PROCEDURES:</span> <span class="kt">Aortic</span> <span class="kt">valve</span> <span class="kt">replacement</span> <span class="kt">using</span> <span class="kt">a</span> <span class="kt">mechanical</span> <span class="kt">valve</span> <span class="kt">and</span> <span class="kt">two-vessel</span> <span class="kt">...|</span>                    <span class="kt">Procedures|</span>
<span class="kt">|</span>                 <span class="kt">ANESTHESIA:</span> <span class="kt">General</span> <span class="kt">endotracheal\n\nINCISION:</span> <span class="kt">Median</span> <span class="kt">sternotomy|</span>                    <span class="kt">Procedures|</span>
<span class="kt">|INDICATIONS:</span> <span class="kt">The</span> <span class="kt">patient</span> <span class="kt">presented</span> <span class="kt">with</span> <span class="kt">severe</span> <span class="kt">congestive</span> <span class="kt">heart</span> <span class="kt">failure</span> <span class="kt">assoc...|</span>     <span class="kt">Consultation</span> <span class="kt">and</span> <span class="kt">Referral|</span>
<span class="kt">|FINDINGS:</span> <span class="kt">The</span> <span class="kt">left</span> <span class="kt">ventricle</span> <span class="kt">is</span> <span class="kt">certainly</span> <span class="kt">hypertrophied</span><span class="err">·</span> <span class="kt">The</span> <span class="kt">aortic</span> <span class="kt">valve</span> <span class="kt">lea...|Diagnostic</span> <span class="kt">and</span> <span class="kt">Laboratory</span> <span class="kt">Data|</span>
<span class="kt">|The</span> <span class="kt">radial</span> <span class="kt">artery</span> <span class="kt">was</span> <span class="kt">used</span> <span class="kt">for</span> <span class="kt">the</span> <span class="kt">left</span> <span class="kt">anterior</span> <span class="kt">descending</span> <span class="kt">artery.</span> <span class="kt">Flow</span> <span class="kt">was</span> <span class="kt">...|Diagnostic</span> <span class="kt">and</span> <span class="kt">Laboratory</span> <span class="kt">Data|</span>
<span class="kt">|PROCEDURE:</span> <span class="kt">The</span> <span class="kt">patient</span> <span class="kt">was</span> <span class="kt">brought</span> <span class="kt">to</span> <span class="kt">the</span> <span class="kt">operating</span> <span class="kt">room</span> <span class="kt">and</span> <span class="kt">placed</span> <span class="kt">in</span> <span class="kt">supine...|</span>                    <span class="kt">Procedures|</span>
<span class="kt">|The</span> <span class="kt">patient</span> <span class="kt">went</span> <span class="kt">on</span> <span class="kt">cardiopulmonary</span> <span class="kt">bypass</span> <span class="kt">and</span> <span class="kt">the</span> <span class="kt">aortic</span> <span class="kt">cross-clamp</span> <span class="kt">was</span> <span class="kt">app...|</span>                    <span class="kt">Procedures|</span>
<span class="kt">|The</span> <span class="kt">first</span> <span class="kt">obtuse</span> <span class="kt">marginal</span> <span class="kt">artery</span> <span class="kt">was</span> <span class="kt">a</span> <span class="kt">very</span> <span class="kt">large</span> <span class="kt">target</span> <span class="kt">and</span> <span class="kt">the</span> <span class="kt">vein</span> <span class="kt">graft</span> <span class="kt">t...|Diagnostic</span> <span class="kt">and</span> <span class="kt">Laboratory</span> <span class="kt">Data|</span>
<span class="kt">|The</span> <span class="kt">patient</span> <span class="kt">came</span> <span class="kt">off</span> <span class="kt">cardiopulmonary</span> <span class="kt">bypass</span> <span class="kt">after</span> <span class="kt">aortic</span> <span class="kt">cross-clamp</span> <span class="kt">was</span> <span class="kt">rele...|</span>                    <span class="kt">Procedures|</span>
<span class="kt">+--------------------------------------------------------------------------------+------------------------------+</span>


<span class="c1">// after filterer result</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
                                              <span class="n">document_assembler</span><span class="o">,</span> 
                                              <span class="n">tokenizer</span><span class="o">,</span> 
                                              <span class="n">document_splitter</span><span class="o">,</span> 
                                              <span class="n">sequenceClassifier</span><span class="o">,</span> 
                                              <span class="n">document_filterer</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
<span class="o">|</span>                                                                          <span class="n">splits</span><span class="o">|</span>                       <span class="n">classes</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+------------------------------+</span>
<span class="o">|</span><span class="nc">DIAGNOSIS</span><span class="k">:</span> <span class="kt">Aortic</span> <span class="kt">valve</span> <span class="kt">stenosis</span> <span class="kt">with</span> <span class="kt">coronary</span> <span class="kt">artery</span> <span class="kt">disease</span> <span class="kt">associated</span> <span class="kt">with...|Diagnostic</span> <span class="kt">and</span> <span class="kt">Laboratory</span> <span class="kt">Data|</span>
<span class="kt">|FINDINGS:</span> <span class="kt">The</span> <span class="kt">left</span> <span class="kt">ventricle</span> <span class="kt">is</span> <span class="kt">certainly</span> <span class="kt">hypertrophied</span><span class="err">·</span> <span class="kt">The</span> <span class="kt">aortic</span> <span class="kt">valve</span> <span class="kt">lea...|Diagnostic</span> <span class="kt">and</span> <span class="kt">Laboratory</span> <span class="kt">Data|</span>
<span class="kt">|The</span> <span class="kt">radial</span> <span class="kt">artery</span> <span class="kt">was</span> <span class="kt">used</span> <span class="kt">for</span> <span class="kt">the</span> <span class="kt">left</span> <span class="kt">anterior</span> <span class="kt">descending</span> <span class="kt">artery.</span> <span class="kt">Flow</span> <span class="kt">was</span> <span class="kt">...|Diagnostic</span> <span class="kt">and</span> <span class="kt">Laboratory</span> <span class="kt">Data|</span>
<span class="kt">|The</span> <span class="kt">first</span> <span class="kt">obtuse</span> <span class="kt">marginal</span> <span class="kt">artery</span> <span class="kt">was</span> <span class="kt">a</span> <span class="kt">very</span> <span class="kt">large</span> <span class="kt">target</span> <span class="kt">and</span> <span class="kt">the</span> <span class="kt">vein</span> <span class="kt">graft</span> <span class="kt">t...|Diagnostic</span> <span class="kt">and</span> <span class="kt">Laboratory</span> <span class="kt">Data|</span>
<span class="kt">+--------------------------------------------------------------------------------+------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="documentfiltererbyner">DocumentFiltererByNER</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The <code class="language-plaintext highlighter-rouge">DocumentFiltererByNER</code> annotator returns sentences containing the entity chunks you have filtered, allowing you to see only the sentences with the entities you want.It is particularly useful for extracting and organizing the results obtained from Spark NLP Pipelines.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">blackList</code>: If defined, list of entities to ignore. The rest will be processed.</li>
      <li><code class="language-plaintext highlighter-rouge">whiteList</code>: If defined, list of entities to process. The rest will be ignored.</li>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code>: Determines whether the definitions of the white listed and black listed entities are case sensitive or not.</li>
      <li><code class="language-plaintext highlighter-rouge">outputAsDocument</code>: Whether to return all sentences joined into a single document.(default : <code class="language-plaintext highlighter-rouge">False</code>).</li>
      <li><code class="language-plaintext highlighter-rouge">joinString</code>: This parameter specifies the string that will be inserted between results of documents when combining them into a single result if outputAsDocument is set to <code class="language-plaintext highlighter-rouge">True</code> (default is : “ “).</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/document_filterer_by_ner/index.html#">DocumentFiltererByNER</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/DocumentFiltererByNER.html">DocumentFiltererByNER</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DocumentFiltererByNER.ipynb">DocumentFiltererByNER</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_jsl</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">filterer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocumentFiltererByNER</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"filterer"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Disease_Syndrome_Disorder"</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">ner_jsl</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">filterer</span><span class="p">])</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"Coronavirus disease (COVID-19) is an infectious disease caused by the SARS-CoV-2 virus."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Most people infected with the virus will experience mild to moderate respiratory illness and recover without requiring special treatment."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"However, some will become seriously ill and require medical attention. "</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Older people and those with underlying medical conditions like cardiovascular disease, diabetes, chronic respiratory disease, or cancer are more likely to develop serious illness."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Anyone can get sick with COVID-19 and become seriously ill or die at any age."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"The best way to prevent and slow down transmission is to be well informed about the disease and how the virus spreads."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Protect yourself and others from infection by staying at least 1 metre apart from others, wearing a properly fitted mask, and washing your hands or using an alcohol-based rub frequently."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Get vaccinated when it’s your turn and follow local guidance."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"Stay home if you feel unwell."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"If you have a fever, cough and difficulty breathing, seek medical attention."</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"The virus can spread from an infected person’s mouth or nose in small liquid particles when they cough, sneeze, speak, sing or breathe. "</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"These particles range from larger respiratory droplets to smaller aerosols. It is important to practice respiratory etiquette, for example by coughing into a flexed elbow, and to stay home and self-isolate until you recover if you feel unwell."</span><span class="p">]</span>
    <span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.window</span> <span class="kn">import</span> <span class="n">Window</span> <span class="k">as</span> <span class="n">W</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>
<span class="n">spark_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">coalesce</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">withColumn</span><span class="p">(</span><span class="s">"idx"</span><span class="p">,</span> <span class="n">F</span><span class="p">.</span><span class="n">monotonically_increasing_id</span><span class="p">())</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">spark_df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">spark_df</span><span class="p">)</span>

<span class="c1"># Result
</span>
<span class="n">res</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"idx as doc_id"</span><span class="p">,</span><span class="s">"explode(filterer) as filter"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>

<span class="o">+------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">doc_id</span><span class="o">|</span>                                                                          <span class="nb">filter</span><span class="o">|</span>
<span class="o">+------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>     <span class="mi">0</span><span class="o">|</span><span class="p">{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">86</span><span class="p">,</span> <span class="n">Coronavirus</span> <span class="n">disease</span> <span class="p">(</span><span class="n">COVID</span><span class="o">-</span><span class="mi">19</span><span class="p">)</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">infectious</span> <span class="n">DISAESE</span> <span class="n">cau</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>     <span class="mi">1</span><span class="o">|</span><span class="p">{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">136</span><span class="p">,</span> <span class="n">Most</span> <span class="n">people</span> <span class="n">infected</span> <span class="k">with</span> <span class="n">the</span> <span class="n">virus</span> <span class="n">will</span> <span class="n">experience</span> <span class="n">mild</span> <span class="n">t</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>     <span class="mi">3</span><span class="o">|</span><span class="p">{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">178</span><span class="p">,</span> <span class="n">Older</span> <span class="n">people</span> <span class="ow">and</span> <span class="n">those</span> <span class="k">with</span> <span class="n">underlying</span> <span class="n">medical</span> <span class="n">conditions</span> <span class="p">...</span><span class="o">|</span>
<span class="o">|</span>     <span class="mi">6</span><span class="o">|</span><span class="p">{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">185</span><span class="p">,</span> <span class="n">Protect</span> <span class="n">yourself</span> <span class="ow">and</span> <span class="n">others</span> <span class="k">from</span> <span class="n">infection</span> <span class="n">by</span> <span class="n">staying</span> <span class="n">at</span> <span class="n">l</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">10</span><span class="o">|</span><span class="p">{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span> <span class="n">The</span> <span class="n">virus</span> <span class="n">can</span> <span class="n">spread</span> <span class="k">from</span> <span class="n">an</span> <span class="n">infected</span> <span class="n">person</span><span class="err">’</span><span class="n">s</span> <span class="n">mouth</span> <span class="ow">or</span> <span class="n">no</span><span class="p">...</span><span class="o">|</span>
<span class="o">+------+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
 
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nc">SentenceDetectorDLModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_jsl</span> <span class="k">=</span> <span class="nc">NerModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">filterer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentFiltererByNER</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"filterer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"Disease_Syndrome_Disorder"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">wordEmbeddings</span><span class="o">,</span>
  <span class="n">ner_jsl</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">filterer</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Coronavirus disease (COVID-19) is an infectious disease caused by the SARS-CoV-2 virus."</span><span class="o">,</span>
  <span class="s">"Most people infected with the virus will experience mild to moderate respiratory illness and recover without requiring special treatment."</span><span class="o">,</span>
  <span class="s">"However, some will become seriously ill and require medical attention."</span><span class="o">,</span>
  <span class="s">"Older people and those with underlying medical conditions like cardiovascular disease, diabetes, chronic respiratory disease, or cancer are more likely to develop serious illness."</span><span class="o">,</span>
  <span class="s">"Anyone can get sick with COVID-19 and become seriously ill or die at any age."</span><span class="o">,</span>
  <span class="s">"The best way to prevent and slow down transmission is to be well informed about the disease and how the virus spreads."</span><span class="o">,</span>
  <span class="s">"Protect yourself and others from infection by staying at least 1 metre apart from others, wearing a properly fitted mask, and washing your hands or using an alcohol-based rub frequently."</span><span class="o">,</span>
  <span class="s">"Get vaccinated when it’s your turn and follow local guidance."</span><span class="o">,</span>
  <span class="s">"Stay home if you feel unwell."</span><span class="o">,</span>
  <span class="s">"If you have a fever, cough and difficulty breathing, seek medical attention."</span><span class="o">,</span>
  <span class="s">"The virus can spread from an infected person’s mouth or nose in small liquid particles when they cough, sneeze, speak, sing or breathe."</span><span class="o">,</span>
  <span class="s">"These particles range from larger respiratory droplets to smaller aerosols. It is important to practice respiratory etiquette, for example by coughing into a flexed elbow, and to stay home and self-isolate until you recover if you feel unwell."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dfWithIdx</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">coalesce</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="py">withColumn</span><span class="o">(</span><span class="s">"idx"</span><span class="o">,</span> <span class="nf">monotonically_increasing_id</span><span class="o">())</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">dfWithIdx</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">dfWithIdx</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span> 

<span class="c1">// result </span>

<span class="o">+------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">doc_id</span><span class="o">|</span>                                                                          <span class="n">filter</span><span class="o">|</span>
<span class="o">+------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>     <span class="mi">0</span><span class="o">|{</span><span class="n">document</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">86</span><span class="o">,</span> <span class="nc">Coronavirus</span> <span class="nf">disease</span> <span class="o">(</span><span class="nc">COVID</span><span class="o">-</span><span class="mi">19</span><span class="o">)</span> <span class="n">is</span> <span class="n">an</span> <span class="n">infectious</span> <span class="nc">DISAESE</span> <span class="n">cau</span><span class="o">...|</span>
<span class="o">|</span>     <span class="mi">1</span><span class="o">|{</span><span class="n">document</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">136</span><span class="o">,</span> <span class="nc">Most</span> <span class="n">people</span> <span class="n">infected</span> <span class="k">with</span> <span class="n">the</span> <span class="n">virus</span> <span class="n">will</span> <span class="n">experience</span> <span class="n">mild</span> <span class="n">t</span><span class="o">...|</span>
<span class="o">|</span>     <span class="mi">3</span><span class="o">|{</span><span class="n">document</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">178</span><span class="o">,</span> <span class="nc">Older</span> <span class="n">people</span> <span class="n">and</span> <span class="n">those</span> <span class="k">with</span> <span class="n">underlying</span> <span class="n">medical</span> <span class="n">conditions</span> <span class="o">...|</span>
<span class="o">|</span>     <span class="mi">6</span><span class="o">|{</span><span class="n">document</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">185</span><span class="o">,</span> <span class="nc">Protect</span> <span class="n">yourself</span> <span class="n">and</span> <span class="n">others</span> <span class="n">from</span> <span class="n">infection</span> <span class="n">by</span> <span class="n">staying</span> <span class="n">at</span> <span class="n">l</span><span class="o">...|</span>
<span class="o">|</span>    <span class="mi">10</span><span class="o">|{</span><span class="n">document</span><span class="o">,</span> <span class="mi">0</span><span class="o">,</span> <span class="mi">134</span><span class="o">,</span> <span class="nc">The</span> <span class="n">virus</span> <span class="n">can</span> <span class="n">spread</span> <span class="n">from</span> <span class="n">an</span> <span class="n">infected</span> <span class="n">person</span><span class="err">’</span><span class="n">s</span> <span class="n">mouth</span> <span class="n">or</span> <span class="n">no</span><span class="o">...|</span>
<span class="o">+------+--------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="documenthashcoder">DocumentHashCoder</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator can replace dates in a column of <code class="language-plaintext highlighter-rouge">DOCUMENT</code> type according with the hash code of any other column. It uses the hash of the specified column and creates a new document column containing the day shift information. In sequence, the <code class="language-plaintext highlighter-rouge">DeIdentification</code> annotator deidentifies the document with the shifted date information.</p>

    <p>If the specified column contains strings that can be parsed to integers, use those numbers to make the shift in the data accordingly.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">PatientIdColumn</code> <em>(String)</em>: Name of the column containing patient ID.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setDateShiftColumn</code> <em>(String)</em>: Sets column to be used for hash or predefined shift.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setNewDateShift</code> <em>(String)</em>: Sets column that has a reference of where chunk begins.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setRangeDays</code> <em>(int)</em>: Sets the range of dates to be sampled from.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setSeed</code> <em>(int)</em>: Sets the seed for random number generator.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/doccument_hashcoder/index.html#sparknlp_jsl.annotator.deid.doccument_hashcoder.DocumentHashCoder">DocumentHashCoder</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DocumentHashCoder.html">DocumentHashCoder</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DocumentHashCoder.ipynb">DocumentHashCoderNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s">'patientID'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'A001'</span><span class="p">,</span> <span class="s">'A001'</span><span class="p">,</span> 
                    <span class="s">'A003'</span><span class="p">,</span> <span class="s">'A003'</span><span class="p">],</span>
     <span class="s">'text'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'Chris Brown was discharged on 10/02/2022'</span><span class="p">,</span> 
               <span class="s">'Mark White was discharged on 10/04/2022'</span><span class="p">,</span> 
               <span class="s">'John was discharged on 15/03/2022'</span><span class="p">,</span>
               <span class="s">'John Moore was discharged on 15/12/2022'</span>
              <span class="p">],</span>
     <span class="s">'dateshift'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'10'</span><span class="p">,</span> <span class="s">'10'</span><span class="p">,</span> 
                    <span class="s">'30'</span><span class="p">,</span> <span class="s">'30'</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">my_input_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">documentHasher</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocumentHashCoder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document2"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPatientIdColumn</span><span class="p">(</span><span class="s">"patientID"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setNewDateShift</span><span class="p">(</span><span class="s">"shift_days"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">de_identification</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"document2"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLanguage</span><span class="p">(</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">'faker'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseShifDays</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRegion</span><span class="p">(</span><span class="s">'us'</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">documentHasher</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">de_identification</span>

<span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">,</span> <span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"patientID"</span><span class="p">)</span>
<span class="n">pipeline_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">pipeline_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">my_input_df</span><span class="p">)</span>
<span class="n">output</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'patientID'</span><span class="p">,</span><span class="s">'text'</span><span class="p">,</span> <span class="s">'deid_text.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+---------+----------------------------------------+---------------------------------------------+</span>
<span class="o">|</span><span class="n">patientID</span><span class="o">|</span><span class="n">text</span>                                    <span class="o">|</span><span class="n">result</span>                                       <span class="o">|</span>
<span class="o">+---------+----------------------------------------+---------------------------------------------+</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="n">Chris</span> <span class="n">Brown</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2022</span><span class="o">|</span><span class="p">[</span><span class="n">Aldona</span> <span class="n">Bar</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">05</span><span class="o">/</span><span class="mi">18</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="n">Mark</span> <span class="n">White</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">02</span><span class="o">/</span><span class="mi">28</span><span class="o">/</span><span class="mi">2020</span> <span class="o">|</span><span class="p">[</span><span class="n">Leta</span> <span class="n">Speller</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">14</span><span class="o">/</span><span class="mi">2019</span><span class="p">]</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="n">John</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">03</span><span class="o">/</span><span class="mi">15</span><span class="o">/</span><span class="mi">2022</span>       <span class="o">|</span><span class="p">[</span><span class="n">Lonia</span> <span class="n">Blood</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">01</span><span class="o">/</span><span class="mi">19</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="n">John</span> <span class="n">Moore</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">12</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2022</span> <span class="o">|</span><span class="p">[</span><span class="n">Murriel</span> <span class="n">Hopper</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">11</span><span class="o">/</span><span class="mi">06</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span><span class="o">|</span>
<span class="o">+---------+----------------------------------------+---------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s">'patientID'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'A001'</span><span class="p">,</span> <span class="s">'A001'</span><span class="p">,</span> 
                    <span class="s">'A003'</span><span class="p">,</span> <span class="s">'A003'</span><span class="p">],</span>
     <span class="s">'text'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'Chris Brown was discharged on 10/02/2022'</span><span class="p">,</span> 
               <span class="s">'Mark White was discharged on 10/04/2022'</span><span class="p">,</span> 
               <span class="s">'John was discharged on 15/03/2022'</span><span class="p">,</span>
               <span class="s">'John Moore was discharged on 15/12/2022'</span>
              <span class="p">],</span>
     <span class="s">'dateshift'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'10'</span><span class="p">,</span> <span class="s">'10'</span><span class="p">,</span> 
                    <span class="s">'30'</span><span class="p">,</span> <span class="s">'30'</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">my_input_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">documentHasher</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DocumentHashCoder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document2"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPatientIdColumn</span><span class="p">(</span><span class="s">"patientID"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setNewDateShift</span><span class="p">(</span><span class="s">"shift_days"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">de_identification</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"document2"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLanguage</span><span class="p">(</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">'faker'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseShifDays</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRegion</span><span class="p">(</span><span class="s">'us'</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">documentHasher</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">de_identification</span>

<span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">,</span> <span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"patientID"</span><span class="p">)</span>
<span class="n">pipeline_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">pipeline_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">my_input_df</span><span class="p">)</span>
<span class="n">output</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'patientID'</span><span class="p">,</span><span class="s">'text'</span><span class="p">,</span> <span class="s">'deid_text.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">patientID</span><span class="o">|</span><span class="n">text</span>                                    <span class="o">|</span><span class="n">result</span>                                        <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="n">Chris</span> <span class="n">Brown</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2022</span><span class="o">|</span><span class="p">[</span><span class="n">Andreas</span> <span class="n">Newport</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">04</span><span class="o">/</span><span class="mi">09</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="n">Mark</span> <span class="n">White</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">02</span><span class="o">/</span><span class="mi">28</span><span class="o">/</span><span class="mi">2020</span> <span class="o">|</span><span class="p">[</span><span class="n">Kara</span> <span class="n">Dies</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">09</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2019</span><span class="p">]</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="n">John</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">03</span><span class="o">/</span><span class="mi">15</span><span class="o">/</span><span class="mi">2022</span>       <span class="o">|</span><span class="p">[</span><span class="n">Lane</span> <span class="n">Hacker</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">02</span><span class="o">/</span><span class="mi">17</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="n">John</span> <span class="n">Moore</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">12</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2022</span> <span class="o">|</span><span class="p">[</span><span class="n">Orlena</span> <span class="n">Sheldon</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">12</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s">'patientID'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'A001'</span><span class="p">,</span> <span class="s">'A001'</span><span class="p">,</span> 
                    <span class="s">'A003'</span><span class="p">,</span> <span class="s">'A003'</span><span class="p">],</span>
     <span class="s">'text'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'Chris Brown was discharged on 10/02/2022'</span><span class="p">,</span> 
               <span class="s">'Mark White was discharged on 10/04/2022'</span><span class="p">,</span> 
               <span class="s">'John was discharged on 15/03/2022'</span><span class="p">,</span>
               <span class="s">'John Moore was discharged on 15/12/2022'</span>
              <span class="p">],</span>
     <span class="s">'dateshift'</span> <span class="p">:</span> <span class="p">[</span><span class="s">'10'</span><span class="p">,</span> <span class="s">'10'</span><span class="p">,</span> 
                    <span class="s">'30'</span><span class="p">,</span> <span class="s">'30'</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">my_input_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">documentHasher</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DocumentHashCoder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document2"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPatientIdColumn</span><span class="p">(</span><span class="s">"patientID"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setNewDateShift</span><span class="p">(</span><span class="s">"shift_days"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document2"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">de_identification</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"document2"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deid_text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateTag</span><span class="p">(</span><span class="s">"DATE"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLanguage</span><span class="p">(</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">'faker'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setUseShifDays</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRegion</span><span class="p">(</span><span class="s">'us'</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">documentHasher</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">de_identification</span>

<span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">,</span> <span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"patientID"</span><span class="p">)</span>
<span class="n">pipeline_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">pipeline_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">my_input_df</span><span class="p">)</span>
<span class="n">output</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'patientID'</span><span class="p">,</span><span class="s">'text'</span><span class="p">,</span> <span class="s">'deid_text.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">patientID</span><span class="o">|</span><span class="n">text</span>                                    <span class="o">|</span><span class="n">result</span>                                        <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="n">Chris</span> <span class="n">Brown</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2022</span><span class="o">|</span><span class="p">[</span><span class="n">Andreas</span> <span class="n">Newport</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">04</span><span class="o">/</span><span class="mi">09</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="n">Mark</span> <span class="n">White</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">02</span><span class="o">/</span><span class="mi">28</span><span class="o">/</span><span class="mi">2020</span> <span class="o">|</span><span class="p">[</span><span class="n">Kara</span> <span class="n">Dies</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">09</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2019</span><span class="p">]</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="n">John</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">03</span><span class="o">/</span><span class="mi">15</span><span class="o">/</span><span class="mi">2022</span>       <span class="o">|</span><span class="p">[</span><span class="n">Lane</span> <span class="n">Hacker</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">02</span><span class="o">/</span><span class="mi">17</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="n">John</span> <span class="n">Moore</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">12</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2022</span> <span class="o">|</span><span class="p">[</span><span class="n">Orlena</span> <span class="n">Sheldon</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">12</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2022</span><span class="p">]</span> <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
  
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"A001"</span><span class="o">,</span> <span class="s">"Chris Brown was discharged on 10/02/2022"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A001"</span><span class="o">,</span> <span class="s">"Mark White was discharged on 02/28/2020"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A002"</span><span class="o">,</span> <span class="s">"John was discharged on 03/15/2022"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A002"</span><span class="o">,</span> <span class="s">"John Moore was discharged on 12/31/2022"</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">columns</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"patientID"</span><span class="o">,</span> <span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">myInputDF</span><span class="k">:</span> <span class="kt">DataFrame</span> <span class="o">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="n">columns</span><span class="k">:</span> <span class="k">_</span><span class="kt">*</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">my_input_df</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">documentHasher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentHashCoder</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document2"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setPatientIdColumn</span><span class="o">(</span><span class="s">"patientID"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setNewDateShift</span><span class="o">(</span><span class="s">"shift_days"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document2"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"word_embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">de_identification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"document2"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setLanguage</span><span class="o">(</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"faker"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setUseShifDays</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setRegion</span><span class="o">(</span><span class="s">"us"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">documentHasher</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">clinicalNer</span><span class="o">,</span>
      <span class="n">nerConverter</span><span class="o">,</span>
      <span class="n">deIdentification</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">emptyData</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">""</span><span class="o">,</span> <span class="s">""</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"patientID"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyData</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">myInputDF</span><span class="o">)</span>

<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">patientID</span><span class="o">|</span><span class="n">text</span>                                    <span class="o">|</span><span class="n">result</span>                                        <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="nc">Chris</span> <span class="nc">Brown</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2022</span><span class="o">|[</span><span class="kt">Andreas</span> <span class="kt">Newport</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">04</span><span class="kt">/</span><span class="err">09</span><span class="kt">/</span><span class="err">2022</span><span class="o">]|</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="nc">Mark</span> <span class="nc">White</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">02</span><span class="o">/</span><span class="mi">28</span><span class="o">/</span><span class="mi">2020</span> <span class="o">|[</span><span class="kt">Kara</span> <span class="kt">Dies</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">09</span><span class="kt">/</span><span class="err">05</span><span class="kt">/</span><span class="err">2019</span><span class="o">]</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="nc">John</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">03</span><span class="o">/</span><span class="mi">15</span><span class="o">/</span><span class="mi">2022</span>       <span class="o">|[</span><span class="kt">Lane</span> <span class="kt">Hacker</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">02</span><span class="kt">/</span><span class="err">17</span><span class="kt">/</span><span class="err">2022</span><span class="o">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="nc">John</span> <span class="nc">Moore</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">12</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2022</span> <span class="o">|[</span><span class="kt">Orlena</span> <span class="kt">Sheldon</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">12</span><span class="kt">/</span><span class="err">05</span><span class="kt">/</span><span class="err">2022</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
  
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"A001"</span><span class="o">,</span> <span class="s">"Chris Brown was discharged on 10/02/2022"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A001"</span><span class="o">,</span> <span class="s">"Mark White was discharged on 02/28/2020"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A002"</span><span class="o">,</span> <span class="s">"John was discharged on 03/15/2022"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A002"</span><span class="o">,</span> <span class="s">"John Moore was discharged on 12/31/2022"</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">columns</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"patientID"</span><span class="o">,</span> <span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">myInputDF</span><span class="k">:</span> <span class="kt">DataFrame</span> <span class="o">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="n">columns</span><span class="k">:</span> <span class="k">_</span><span class="kt">*</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">my_input_df</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">documentHasher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentHashCoder</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document2"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setPatientIdColumn</span><span class="o">(</span><span class="s">"patientID"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setNewDateShift</span><span class="o">(</span><span class="s">"shift_days"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document2"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"word_embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">de_identification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"document2"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setLanguage</span><span class="o">(</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"faker"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setUseShifDays</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setRegion</span><span class="o">(</span><span class="s">"us"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">documentHasher</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">clinicalNer</span><span class="o">,</span>
      <span class="n">nerConverter</span><span class="o">,</span>
      <span class="n">deIdentification</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">emptyData</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">""</span><span class="o">,</span> <span class="s">""</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"patientID"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyData</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">myInputDF</span><span class="o">)</span>

<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">patientID</span><span class="o">|</span><span class="n">text</span>                                    <span class="o">|</span><span class="n">result</span>                                        <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="nc">Chris</span> <span class="nc">Brown</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2022</span><span class="o">|[</span><span class="kt">Andreas</span> <span class="kt">Newport</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">04</span><span class="kt">/</span><span class="err">09</span><span class="kt">/</span><span class="err">2022</span><span class="o">]|</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="nc">Mark</span> <span class="nc">White</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">02</span><span class="o">/</span><span class="mi">28</span><span class="o">/</span><span class="mi">2020</span> <span class="o">|[</span><span class="kt">Kara</span> <span class="kt">Dies</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">09</span><span class="kt">/</span><span class="err">05</span><span class="kt">/</span><span class="err">2019</span><span class="o">]</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="nc">John</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">03</span><span class="o">/</span><span class="mi">15</span><span class="o">/</span><span class="mi">2022</span>       <span class="o">|[</span><span class="kt">Lane</span> <span class="kt">Hacker</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">02</span><span class="kt">/</span><span class="err">17</span><span class="kt">/</span><span class="err">2022</span><span class="o">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="nc">John</span> <span class="nc">Moore</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">12</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2022</span> <span class="o">|[</span><span class="kt">Orlena</span> <span class="kt">Sheldon</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">12</span><span class="kt">/</span><span class="err">05</span><span class="kt">/</span><span class="err">2022</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
  
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"A001"</span><span class="o">,</span> <span class="s">"Chris Brown was discharged on 10/02/2022"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A001"</span><span class="o">,</span> <span class="s">"Mark White was discharged on 02/28/2020"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A002"</span><span class="o">,</span> <span class="s">"John was discharged on 03/15/2022"</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"A002"</span><span class="o">,</span> <span class="s">"John Moore was discharged on 12/31/2022"</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">columns</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"patientID"</span><span class="o">,</span> <span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">myInputDF</span><span class="k">:</span> <span class="kt">DataFrame</span> <span class="o">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="n">columns</span><span class="k">:</span> <span class="k">_</span><span class="kt">*</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">my_input_df</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">documentHasher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentHashCoder</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document2"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setPatientIdColumn</span><span class="o">(</span><span class="s">"patientID"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setNewDateShift</span><span class="o">(</span><span class="s">"shift_days"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document2"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"word_embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document2"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">de_identification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"document2"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deid_text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setDateTag</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setLanguage</span><span class="o">(</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"faker"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setUseShifDays</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setRegion</span><span class="o">(</span><span class="s">"us"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">documentHasher</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">embeddings</span><span class="o">,</span>
      <span class="n">clinicalNer</span><span class="o">,</span>
      <span class="n">nerConverter</span><span class="o">,</span>
      <span class="n">deIdentification</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">emptyData</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">""</span><span class="o">,</span> <span class="s">""</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"patientID"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyData</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">myInputDF</span><span class="o">)</span>

<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">patientID</span><span class="o">|</span><span class="n">text</span>                                    <span class="o">|</span><span class="n">result</span>                                        <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="nc">Chris</span> <span class="nc">Brown</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">10</span><span class="o">/</span><span class="mi">02</span><span class="o">/</span><span class="mi">2022</span><span class="o">|[</span><span class="kt">Andreas</span> <span class="kt">Newport</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">04</span><span class="kt">/</span><span class="err">09</span><span class="kt">/</span><span class="err">2022</span><span class="o">]|</span>
<span class="o">|</span><span class="n">A001</span>     <span class="o">|</span><span class="nc">Mark</span> <span class="nc">White</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">02</span><span class="o">/</span><span class="mi">28</span><span class="o">/</span><span class="mi">2020</span> <span class="o">|[</span><span class="kt">Kara</span> <span class="kt">Dies</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">09</span><span class="kt">/</span><span class="err">05</span><span class="kt">/</span><span class="err">2019</span><span class="o">]</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="nc">John</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">03</span><span class="o">/</span><span class="mi">15</span><span class="o">/</span><span class="mi">2022</span>       <span class="o">|[</span><span class="kt">Lane</span> <span class="kt">Hacker</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">02</span><span class="kt">/</span><span class="err">17</span><span class="kt">/</span><span class="err">2022</span><span class="o">]</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">A002</span>     <span class="o">|</span><span class="nc">John</span> <span class="nc">Moore</span> <span class="n">was</span> <span class="n">discharged</span> <span class="n">on</span> <span class="mi">12</span><span class="o">/</span><span class="mi">31</span><span class="o">/</span><span class="mi">2022</span> <span class="o">|[</span><span class="kt">Orlena</span> <span class="kt">Sheldon</span> <span class="kt">was</span> <span class="kt">discharged</span> <span class="kt">on</span> <span class="err">12</span><span class="kt">/</span><span class="err">05</span><span class="kt">/</span><span class="err">2022</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+---------+----------------------------------------+----------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="documentlogregclassifier">DocumentLogRegClassifier</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Classifies documents with a Logarithmic Regression algorithm.
Currently there are no pretrained models available.
Please see DocumentLogRegClassifierApproach to train your own model.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setMergeChunks</code>: Sets whether to merge all chunks in a document or not (Default: false).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setLabels</code>: Sets array to output the label in the original form.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setVectorizationModel</code>: Sets a path to the classification model if it has been already trained.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setClassificationModel</code>: Sets a path to the the classification model if it has been already trained.</p>
      </li>
    </ul>

    <p>Please check out the <a href="https://nlp.johnsnowlabs.com/models">Models Hub</a> for available models in the future.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/document_log_classifier/index.html#sparknlp_jsl.annotator.classification.document_log_classifier.DocumentLogRegClassifierModel">DocumentLogRegClassifierModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/DocumentLogRegClassifierModel.html">DocumentLogRegClassifierModel</a></td>
        </tr>
      </tbody>
    </table>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Trains a model to classify documents with a Logarithmic Regression algorithm. Training data requires columns for
text and their label. The result is a trained DocumentLogRegClassifierModel.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxIter</code>: Maximum number of iterations.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">tol</code>: Convergence tolerance after each iteration.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setLabels</code>: Sets array to output the label in the original form.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setVectorizationModel</code>: Sets a path to the classification model if it has been already trained.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setClassificationModel</code>: Sets a path to the the classification model if it has been already trained.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/document_log_classifier/index.html#sparknlp_jsl.annotator.classification.document_log_classifier.DocumentLogRegClassifierApproach">DocumentLogRegClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/DocumentLogRegClassifierApproach.html">DocumentLogRegClassifierApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="c1"># Define pipeline stages to prepare the data
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Normalizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>

<span class="n">stopwords_cleaner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StopWordsCleaner</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"normalized"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Stemmer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"cleanTokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>

<span class="c1"># Define the document classifier and fit training data to it
</span><span class="n">logreg</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocumentLogRegClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"stem"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">normalizer</span><span class="p">,</span>
  <span class="n">stopwords_cleaner</span><span class="p">,</span>
  <span class="n">stemmer</span><span class="p">,</span>
  <span class="n">logreg</span>
<span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>
<span class="c1"># Define pipeline stages to prepare the data
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Normalizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>

<span class="n">stopwords_cleaner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StopWordsCleaner</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"normalized"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Stemmer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"cleanTokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>

<span class="c1"># Define the document classifier and fit training data to it
</span><span class="n">logreg</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DocumentLogRegClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"stem"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">normalizer</span><span class="p">,</span>
  <span class="n">stopwords_cleaner</span><span class="p">,</span>
  <span class="n">stemmer</span><span class="p">,</span>
  <span class="n">logreg</span>
<span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>
<span class="c1"># Define pipeline stages to prepare the data
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">normalizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Normalizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>

<span class="n">stopwords_cleaner</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StopWordsCleaner</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"normalized"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cleanTokens"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Stemmer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"cleanTokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"stem"</span><span class="p">)</span>

<span class="c1"># Define the document classifier and fit training data to it
</span><span class="n">logreg</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DocumentLogRegClassifierApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"stem"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">document_assembler</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">normalizer</span><span class="p">,</span>
  <span class="n">stopwords_cleaner</span><span class="p">,</span>
  <span class="n">stemmer</span><span class="p">,</span>
  <span class="n">logreg</span>
<span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span> 
<span class="c1">// Define pipeline stages to prepare the data</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwords_cleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Stemmer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>

<span class="c1">// Define the document classifier and fit training data to it</span>
<span class="k">val</span> <span class="nv">logreg</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentLogRegClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwords_cleaner</span><span class="o">,</span>
  <span class="n">stemmer</span><span class="o">,</span>
  <span class="n">logreg</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span> 

<span class="c1">// Define pipeline stages to prepare the data</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwords_cleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Stemmer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>

<span class="c1">// Define the document classifier and fit training data to it</span>
<span class="k">val</span> <span class="nv">logreg</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentLogRegClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwords_cleaner</span><span class="o">,</span>
  <span class="n">stemmer</span><span class="o">,</span>
  <span class="n">logreg</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Define pipeline stages to prepare the data</span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Normalizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stopwords_cleaner</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StopWordsCleaner</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">stemmer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Stemmer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"cleanTokens"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>

<span class="c1">// Define the document classifier and fit training data to it</span>
<span class="k">val</span> <span class="nv">logreg</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentLogRegClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"stem"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">normalizer</span><span class="o">,</span>
  <span class="n">stopwords_cleaner</span><span class="o">,</span>
  <span class="n">stemmer</span><span class="o">,</span>
  <span class="n">logreg</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="documentmlclassifier">DocumentMLClassifier</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">DocumentMLClassifier</code> classifies documents with a Logarithmic Regression algorithm.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/document_ml_classifier/index.html#sparknlp_jsl.annotator.classification.document_ml_classifier.DocumentMLClassifierModel">DocumentMLClassifierModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/DocumentMLClassifierModel.html">DocumentMLClassifierModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DocumentMLClassifierModel.ipynb">DocumentMLClassifierModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">classifier_ml</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocumentMLClassifierModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"classifierml_ade"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">clf_Pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">classifier_ml</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"""I feel great after taking tylenol."""</span><span class="p">],</span> <span class="p">[</span><span class="s">"""Detection of activated eosinophils in nasal polyps of an aspirin-induced asthma patient."""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">clf_Pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span><span class="s">'prediction.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+----------------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span><span class="n">text</span>                                                                                    <span class="o">|</span><span class="n">result</span> <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span><span class="n">Detection</span> <span class="n">of</span> <span class="n">activated</span> <span class="n">eosinophils</span> <span class="ow">in</span> <span class="n">nasal</span> <span class="n">polyps</span> <span class="n">of</span> <span class="n">an</span> <span class="n">aspirin</span><span class="o">-</span><span class="n">induced</span> <span class="n">asthma</span> <span class="n">patient</span><span class="p">.</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">I</span> <span class="n">feel</span> <span class="n">great</span> <span class="n">after</span> <span class="n">taking</span> <span class="n">tylenol</span><span class="p">.</span>                                                      <span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------+-------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">classifier_ml</span> <span class="k">=</span> <span class="nv">DocumentMLClassifierModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"classifierml_ade"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clf_Pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">classifier_ml</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"I feel great after taking tylenol."</span><span class="o">,</span>
  <span class="s">"Detection of activated eosinophils in nasal polyps of an aspirin-induced asthma patient."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">clf_Pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>

<span class="o">+----------------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span><span class="n">text</span>                                                                                    <span class="o">|</span><span class="n">result</span> <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span><span class="nc">Detection</span> <span class="n">of</span> <span class="n">activated</span> <span class="n">eosinophils</span> <span class="n">in</span> <span class="n">nasal</span> <span class="n">polyps</span> <span class="n">of</span> <span class="n">an</span> <span class="n">aspirin</span><span class="o">-</span><span class="n">induced</span> <span class="n">asthma</span> <span class="n">patient</span><span class="o">.|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span><span class="n">I</span> <span class="n">feel</span> <span class="n">great</span> <span class="n">after</span> <span class="n">taking</span> <span class="n">tylenol</span><span class="o">.</span>                                                      <span class="o">|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">+----------------------------------------------------------------------------------------+-------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Trains a model to classify documents with a Logarithmic Regression algorithm. Training data requires columns for text and their label. The result is a trained DocumentMLClassifierModel.</p>

    <p>Parametres:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">labelCol</code>: (str) Sets column with the value result we are trying to predict.</li>
      <li><code class="language-plaintext highlighter-rouge">maxIter</code>: (Int) Sets maximum number of iterations.</li>
      <li><code class="language-plaintext highlighter-rouge">tol</code>: (float) Sets convergence tolerance after each iteration.</li>
      <li><code class="language-plaintext highlighter-rouge">fitIntercept</code>: (str) Sets whether to fit an intercept term, default is true.</li>
      <li><code class="language-plaintext highlighter-rouge">vectorizationModelPath</code>: (str) Sets a path to the classification model if it has been already trained.</li>
      <li><code class="language-plaintext highlighter-rouge">classificationModelPath</code>: (str) Sets a path to the classification model if it has been already trained.</li>
      <li><code class="language-plaintext highlighter-rouge">classificationModelClass</code>: (str) Sets a the classification model class from SparkML to use; possible values are: logreg, svm.</li>
      <li><code class="language-plaintext highlighter-rouge">minTokenNgram</code>: (int) Sets minimum number of tokens for Ngrams.</li>
      <li><code class="language-plaintext highlighter-rouge">maxTokenNgram</code>: (int) Sets maximum number of tokens for Ngrams.</li>
      <li><code class="language-plaintext highlighter-rouge">mergeChunks</code>: (boolean) whether to merge all chunks in a document or not (Default: false)</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/document_ml_classifier/index.html#sparknlp_jsl.annotator.classification.document_ml_classifier.DocumentMLClassifierApproach">DocumentMLClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/DocumentMLClassifierApproach.html">DocumentMLClassifierApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DocumentMLClassifierApproach.ipynb">DocumentMLClassifierApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 

<span class="n">document</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">token</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">classifier_logreg</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DocumentMLClassifierApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setClassificationModelClass</span><span class="p">(</span><span class="s">"logreg"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setFitIntercept</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document</span><span class="p">,</span> 
    <span class="n">token</span><span class="p">,</span> 
    <span class="n">classifier_logreg</span><span class="p">])</span>

<span class="n">result_logreg</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">test_data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">token</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">classifier_logreg</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentMLClassifierApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setClassificationModelClass</span><span class="o">(</span><span class="s">"logreg"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setFitIntercept</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document</span><span class="o">,</span>
    <span class="n">token</span><span class="o">,</span>
    <span class="n">classifier_logreg</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">result_logreg</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">train_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="drugnormalizer">DrugNormalizer</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Annotator which normalizes raw text from clinical documents, e.g. scraped web pages or xml documents, from document type columns into Sentence.
Removes all dirty characters from text following one or more input regex patterns.
Can apply non wanted character removal which a specific policy.
Can apply lower case normalization.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">lowercase</code>: (boolean) whether to convert strings to lowercase. Default is False.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">policy</code>: (str) rule to remove patterns from text.  Valid policy values are:</p>
        <ul>
          <li><strong>“all”</strong>,</li>
          <li><strong>“abbreviations”</strong>,</li>
          <li><strong>“dosages”</strong></li>
        </ul>
      </li>
    </ul>

    <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/23.Drug_Normalizer.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/normalizer/drug_normalizer/index.html#sparknlp_jsl.annotator.normalizer.drug_normalizer.DrugNormalizer">DrugNormalizer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/DrugNormalizer.html">DrugNormalizer</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/DrugNormalizer.ipynb">DrugNormalizerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># Sample data
</span><span class="n">data_to_normalize</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
            <span class="p">(</span><span class="s">"A"</span><span class="p">,</span> <span class="s">"Sodium Chloride/Potassium Chloride 13bag"</span><span class="p">,</span> <span class="s">"Sodium Chloride / Potassium Chloride 13 bag"</span><span class="p">),</span>
            <span class="p">(</span><span class="s">"B"</span><span class="p">,</span> <span class="s">"interferon alfa-2b 10 million unit ( 1 ml ) injec"</span><span class="p">,</span> <span class="s">"interferon alfa - 2b 10000000 unt ( 1 ml ) injection"</span><span class="p">),</span>
            <span class="p">(</span><span class="s">"C"</span><span class="p">,</span> <span class="s">"aspirin 10 meq/ 5 ml oral sol"</span><span class="p">,</span> <span class="s">"aspirin 2 meq/ml oral solution"</span><span class="p">)</span>
        <span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"cuid"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">,</span> <span class="s">"target_normalized_text"</span><span class="p">)</span>

<span class="c1"># Annotator that transforms a text column from dataframe into normalized text (with all policy)
</span>
<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">drug_normalizer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DrugNormalizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document_normalized"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPolicy</span><span class="p">(</span><span class="s">"all"</span><span class="p">)</span>

<span class="n">drug_normalizer_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">drug_normalizer</span>
    <span class="p">])</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">drug_normalizer_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_to_normalize</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data_to_normalize</span><span class="p">)</span>

<span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"target_normalized_text"</span><span class="p">,</span> <span class="s">"explode(document_normalized.result) as all_normalized_text"</span><span class="p">)</span>
<span class="n">ds</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-------------------------------------------------------------------------------------------+----------------------------------------------------+----------------------------------------------------+</span>
<span class="o">|</span><span class="n">document</span>                                                                                   <span class="o">|</span><span class="n">target_normalized_text</span>                              <span class="o">|</span><span class="n">all_normalized_text</span>                                 <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------+----------------------------------------------------+----------------------------------------------------+</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="n">Sodium</span> <span class="n">Chloride</span><span class="o">/</span><span class="n">Potassium</span> <span class="n">Chloride</span> <span class="mi">13</span><span class="n">bag</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span>         <span class="o">|</span><span class="n">Sodium</span> <span class="n">Chloride</span> <span class="o">/</span> <span class="n">Potassium</span> <span class="n">Chloride</span> <span class="mi">13</span> <span class="n">bag</span>         <span class="o">|</span><span class="n">Sodium</span> <span class="n">Chloride</span> <span class="o">/</span> <span class="n">Potassium</span> <span class="n">Chloride</span> <span class="mi">13</span> <span class="n">bag</span>         <span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="n">interferon</span> <span class="n">alfa</span><span class="o">-</span><span class="mi">2</span><span class="n">b</span> <span class="mi">10</span> <span class="n">million</span> <span class="n">unit</span> <span class="p">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="p">)</span> <span class="n">injec</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span><span class="o">|</span><span class="n">interferon</span> <span class="n">alfa</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b</span> <span class="mi">10000000</span> <span class="n">unt</span> <span class="p">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="p">)</span> <span class="n">injection</span><span class="o">|</span><span class="n">interferon</span> <span class="n">alfa</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b</span> <span class="mi">10000000</span> <span class="n">unt</span> <span class="p">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="p">)</span> <span class="n">injection</span><span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="n">aspirin</span> <span class="mi">10</span> <span class="n">meq</span><span class="o">/</span> <span class="mi">5</span> <span class="n">ml</span> <span class="n">oral</span> <span class="n">sol</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span>                    <span class="o">|</span><span class="n">aspirin</span> <span class="mi">2</span> <span class="n">meq</span><span class="o">/</span><span class="n">ml</span> <span class="n">oral</span> <span class="n">solution</span>                      <span class="o">|</span><span class="n">aspirin</span> <span class="mi">2</span> <span class="n">meq</span><span class="o">/</span><span class="n">ml</span> <span class="n">oral</span> <span class="n">solution</span>                      <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------+----------------------------------------------------+----------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Sample data </span>
<span class="k">val</span> <span class="nv">data_to_normalize</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> <span class="o">(</span><span class="s">"A"</span><span class="o">,</span><span class="s">"Sodium Chloride/Potassium Chloride 13bag"</span><span class="o">,</span><span class="s">"Sodium Chloride / Potassium Chloride 13 bag"</span><span class="o">)</span> <span class="o">,</span> <span class="o">(</span><span class="s">"B"</span><span class="o">,</span><span class="s">"interferon alfa-2b 10 million unit ( 1 ml ) injec"</span><span class="o">,</span><span class="s">"interferon alfa - 2b 10000000 unt ( 1 ml ) injection"</span><span class="o">)</span> <span class="o">,</span> <span class="o">(</span><span class="s">"C"</span><span class="o">,</span><span class="s">"aspirin 10 meq/ 5 ml oral sol"</span><span class="o">,</span><span class="s">"aspirin 2 meq/ml oral solution"</span><span class="o">)</span> <span class="o">))</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"cuid"</span><span class="o">,</span><span class="s">"text"</span><span class="o">,</span><span class="s">"target_normalized_text"</span><span class="o">)</span> 

<span class="c1">// Annotator that transforms a text column from dataframe into normalized text (with all policy) </span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">drug_normalizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DrugNormalizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document_normalized"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setPolicy</span><span class="o">(</span><span class="s">"all"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">drug_normalizer_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">document_assembler</span><span class="o">,</span> 
  <span class="n">drug_normalizer</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">ds</span> <span class="k">=</span> <span class="nv">drug_normalizer_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data_to_normalize</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data_to_normalize</span><span class="o">)</span> 

<span class="o">+-------------------------------------------------------------------------------------------+----------------------------------------------------+----------------------------------------------------+</span>
<span class="o">|</span><span class="n">document</span>                                                                                   <span class="o">|</span><span class="n">target_normalized_text</span>                              <span class="o">|</span><span class="n">all_normalized_text</span>                                 <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------+----------------------------------------------------+----------------------------------------------------+</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">39</span>, <span class="kt">Sodium</span> <span class="kt">Chloride/Potassium</span> <span class="kt">Chloride</span> <span class="err">13</span><span class="kt">bag</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]</span>         <span class="o">|</span><span class="nc">Sodium</span> <span class="nc">Chloride</span> <span class="o">/</span> <span class="nc">Potassium</span> <span class="nc">Chloride</span> <span class="mi">13</span> <span class="n">bag</span>         <span class="o">|</span><span class="nc">Sodium</span> <span class="nc">Chloride</span> <span class="o">/</span> <span class="nc">Potassium</span> <span class="nc">Chloride</span> <span class="mi">13</span> <span class="n">bag</span>         <span class="o">|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">48</span>, <span class="kt">interferon</span> <span class="kt">alfa-</span><span class="err">2</span><span class="kt">b</span> <span class="err">10</span> <span class="kt">million</span> <span class="kt">unit</span> <span class="o">(</span> <span class="err">1</span> <span class="kt">ml</span> <span class="o">)</span> <span class="kt">injec</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]|</span><span class="n">interferon</span> <span class="n">alfa</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b</span> <span class="mi">10000000</span> <span class="nf">unt</span> <span class="o">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="o">)</span> <span class="n">injection</span><span class="o">|</span><span class="n">interferon</span> <span class="n">alfa</span> <span class="o">-</span> <span class="mi">2</span><span class="n">b</span> <span class="mi">10000000</span> <span class="nf">unt</span> <span class="o">(</span> <span class="mi">1</span> <span class="n">ml</span> <span class="o">)</span> <span class="n">injection</span><span class="o">|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">28</span>, <span class="kt">aspirin</span> <span class="err">10</span> <span class="kt">meq/</span> <span class="err">5</span> <span class="kt">ml</span> <span class="kt">oral</span> <span class="kt">sol</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]</span>                    <span class="o">|</span><span class="n">aspirin</span> <span class="mi">2</span> <span class="n">meq</span><span class="o">/</span><span class="n">ml</span> <span class="n">oral</span> <span class="n">solution</span>                      <span class="o">|</span><span class="n">aspirin</span> <span class="mi">2</span> <span class="n">meq</span><span class="o">/</span><span class="n">ml</span> <span class="n">oral</span> <span class="n">solution</span>                      <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------+----------------------------------------------------+----------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="entitychunkembeddings">EntityChunkEmbeddings</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Weighted average embeddings of multiple named entities chunk annotations.</p>

    <p>Entity Chunk Embeddings uses BERT Sentence embeddings to compute a weighted average vector represention of related entity chunks.  The input the model consists of chunks of recognized named entities. One or more entities are selected as target entities and for each of them a list of related entities is specified (if empty, all other entities are assumed to be related).</p>

    <p>The model looks for chunks of the target entities and then tries to pair each target entity (e.g. DRUG)  with other related entities (e.g. DOSAGE, STRENGTH, FORM, etc). The criterion for pairing a target entity with another related entity is that they appear in the same sentence and the maximal syntactic distance is below a predefined threshold.</p>

    <p>The relationship between target and related entities is one-to-many, meaning that if there multiple instances of the same target entity (e.g.) within a sentence, the model will map a related entity (e.g. DOSAGE) to at most one of the instances of the target entity. For example, if there is a sentence “The patient was given 125 mg of paracetamol and metformin”, the model will pair “125 mg” to “paracetamol”, but not to “metformin”.</p>

    <p>The output of the model is an average embeddings of the chunks of each of the target entities and their related entities. It is possible to specify a particular weight for each entity type.</p>

    <p>An entity can be defined both as target a entity and as a related entity for some other target entity. For example, we may want to compute the embeddings of SYMPTOMs and their related entities, as well as the embeddings of DRUGs and their related entities, one of each is also SYMPTOM. In such cases, it is possible to use the TARGET_ENTITY:RELATED_ENTITY notation to specify the weight of an related entity (e.g. “DRUG:SYMPTOM” to set the weight of SYMPTOM when it appears as an related entity to target entity DRUG). The relative weights of entities for particular entity chunk embeddings are available in the annotations metadata.</p>

    <p>This model is a subclass of <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> and shares all parameters
with it. It can load any pretrained <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> model.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">targetEntities</code>: (dict) The target entities mapped to lists of their related entities. A target entity with an empty list of related entities means all other entities are assumed to be related to it. Entity names are case insensitive. <em>Mandatory to set at least one entity</em></p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">entityWeights</code>: (dict) The relative weights of drug related entities. If not set, all entities have equal weights. If the list is non-empty and some entity is not in it, then its weight is set to 0. The notation TARGET_ENTITY:RELATED_ENTITY can be used to specify the weight of a entity which is related to specific target entity (e.g. “DRUG:SYMPTOM” -&gt; 0.3f). Entity names are case insensitive.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxSyntacticDistance</code>: (Int) Maximal syntactic distance between the drug entity and the other drug related entities. Default value is 2.</p>
      </li>
    </ul>

    <p>The default model is <code class="language-plaintext highlighter-rouge">"sbiobert_base_cased_mli"</code> from <code class="language-plaintext highlighter-rouge">clinical/models</code>.
Other available models can be found at <a href="https://nlp.johnsnowlabs.com/models?task=Embeddings">Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DEPENDENCY, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/embeddings/entity_chunk_embeddings/index.html#sparknlp_jsl.annotator.embeddings.entity_chunk_embeddings.EntityChunkEmbeddings">EntityChunkEmbeddingsModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/embeddings/EntityChunkEmbeddings.html">EntityChunkEmbeddingsModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/EntityChunkEmbeddings.ipynb">EntityChunkEmbeddingsModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">posology_ner_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology_large"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">pos_tager</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tag"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos_tag"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">entity_chunk_embeddings</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">EntityChunkEmbeddings</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"drug_chunk_embeddings"</span><span class="p">)</span>

<span class="n">entity_chunk_embeddings</span><span class="p">.</span><span class="n">setTargetEntities</span><span class="p">({</span><span class="s">"DRUG"</span><span class="p">:</span> <span class="p">[</span><span class="s">"STRENGTH"</span><span class="p">,</span> <span class="s">"ROUTE"</span><span class="p">,</span> <span class="s">"FORM"</span><span class="p">]})</span>

<span class="n">rxnorm_re</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_rxnorm_augmented_re"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"drug_chunk_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">rxnorm_pipeline_re</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">documenter</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">posology_ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">pos_tager</span><span class="p">,</span>
        <span class="n">dependency_parser</span><span class="p">,</span>
        <span class="n">entity_chunk_embeddings</span><span class="p">,</span>
        <span class="n">rxnorm_re</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">rxnorm_model</span> <span class="o">=</span> <span class="n">rxnorm_pipeline_re</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">data_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"The patient was given metformin 500 mg tablet, 2.5 mg of coumadin and then ibuprofen."</span>
        <span class="p">],</span>
        <span class="p">[</span>
            <span class="s">"The patient was given metformin 400 mg, coumadin 5 mg, coumadin, amlodipine 10 MG tablet"</span>
        <span class="p">],</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">rxnorm_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data_df</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"drug_chunk_embeddings.result"</span><span class="p">,</span> <span class="s">"drug_chunk_embeddings.embeddings"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                              <span class="n">result</span><span class="o">|</span>                                                                                                                                                                                              <span class="n">embeddings</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>               <span class="p">[</span><span class="n">metformin</span> <span class="mi">500</span> <span class="n">mg</span> <span class="n">tablet</span><span class="p">,</span> <span class="mf">2.5</span> <span class="n">mg</span> <span class="n">coumadin</span><span class="p">,</span> <span class="n">ibuprofen</span><span class="p">]</span><span class="o">|</span><span class="p">[[</span><span class="mf">0.13060866</span><span class="p">,</span> <span class="mf">0.26946265</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.50702775</span><span class="p">,</span> <span class="mf">0.7724293</span><span class="p">,</span> <span class="mf">0.7356907</span><span class="p">,</span> <span class="mf">0.0962475</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5546377</span><span class="p">,</span> <span class="mf">0.0534295</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.55345106</span><span class="p">,</span> <span class="mf">0.48484787</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.35735086</span><span class="p">,</span> <span class="mf">0.49109104</span><span class="p">,</span> <span class="mf">0.84404886</span><span class="p">,</span> <span class="mf">0.30384326</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9923568</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.24454081</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">metformin</span> <span class="mi">400</span> <span class="n">mg</span><span class="p">,</span> <span class="n">coumadin</span> <span class="mi">5</span> <span class="n">mg</span><span class="p">,</span> <span class="n">coumadin</span><span class="p">,</span> <span class="n">amlodipine</span> <span class="mi">10</span> <span class="n">MG</span> <span class="n">tablet</span><span class="p">]</span><span class="o">|</span><span class="p">[[</span><span class="o">-</span><span class="mf">0.177948</span><span class="p">,</span> <span class="mf">0.25489503</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5724586</span><span class="p">,</span> <span class="mf">0.8031439</span><span class="p">,</span> <span class="mf">0.9211674</span><span class="p">,</span> <span class="mf">0.3558219</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.37258363</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.194855</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7407244</span><span class="p">,</span> <span class="mf">0.48175216</span><span class="p">,</span> <span class="mf">0.040639203</span><span class="p">,</span> <span class="mf">0.6822441</span><span class="p">,</span> <span class="mf">0.5768623</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.19830275</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1513872</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.32279214</span><span class="p">,</span> <span class="mf">0.6181</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">posology_ner_model</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology_large"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pos_tager</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tag"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"pos_tag"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">entity_chunk_embeddings</span> <span class="k">=</span> <span class="nv">EntityChunkEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"dependencies"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"drug_chunk_embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">entity_chunk_embeddings</span><span class="o">.</span><span class="py">setTargetEntities</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"DRUG"</span> <span class="o">-&gt;</span> <span class="s">"Array("</span><span class="nc">STRENGTH</span><span class="s">","</span><span class="nc">ROUTE</span><span class="s">","</span><span class="nc">FORM</span><span class="s">")"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">rxnorm_re</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_rxnorm_augmented_re"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"drug_chunk_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"rxnorm_code"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">rxnorm_pipeline_re</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
    <span class="n">documenter</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">embeddings</span><span class="o">,</span> 
    <span class="n">posology_ner_model</span><span class="o">,</span> 
    <span class="n">ner_converter</span><span class="o">,</span> 
    <span class="n">pos_tager</span><span class="o">,</span> 
    <span class="n">dependency_parser</span><span class="o">,</span> 
    <span class="n">entity_chunk_embeddings</span><span class="o">,</span>
    <span class="n">rxnorm_re</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">rxnorm_model</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span> <span class="s">"The patient was given metformin 500 mg tablet,2.5 mg of coumadin and then ibuprofen."</span> <span class="o">),</span> <span class="o">(</span> <span class="s">"The patient was given metformin 400 mg,coumadin 5 mg,coumadin,amlodipine 10 MG tablet"</span> <span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">results</span> <span class="k">=</span> <span class="nv">rxnorm_model</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">rxnorm_model</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">rxnorm_model</span><span class="o">)</span> 


<span class="o">+--------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                              <span class="n">result</span><span class="o">|</span>                                                                                                                                                                                              <span class="n">embeddings</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>               <span class="o">[</span><span class="kt">metformin</span> <span class="err">500</span> <span class="kt">mg</span> <span class="kt">tablet</span>, <span class="err">2</span><span class="kt">.</span><span class="err">5</span> <span class="kt">mg</span> <span class="kt">coumadin</span>, <span class="kt">ibuprofen</span><span class="o">]|[[</span><span class="err">0</span><span class="kt">.</span><span class="err">13060866</span>, <span class="err">0</span><span class="kt">.</span><span class="err">26946265</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">50702775</span>, <span class="err">0</span><span class="kt">.</span><span class="err">7724293</span>, <span class="err">0</span><span class="kt">.</span><span class="err">7356907</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0962475</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">5546377</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0534295</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">55345106</span>, <span class="err">0</span><span class="kt">.</span><span class="err">48484787</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">35735086</span>, <span class="err">0</span><span class="kt">.</span><span class="err">49109104</span>, <span class="err">0</span><span class="kt">.</span><span class="err">84404886</span>, <span class="err">0</span><span class="kt">.</span><span class="err">30384326</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">9923568</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">24454081</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3</span><span class="kt">...|</span>
<span class="kt">|</span><span class="o">[</span><span class="kt">metformin</span> <span class="err">400</span> <span class="kt">mg</span>, <span class="kt">coumadin</span> <span class="err">5</span> <span class="kt">mg</span>, <span class="kt">coumadin</span>, <span class="kt">amlodipine</span> <span class="err">10</span> <span class="kt">MG</span> <span class="kt">tablet</span><span class="o">]</span><span class="kt">|</span><span class="o">[[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">177948</span>, <span class="err">0</span><span class="kt">.</span><span class="err">25489503</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">5724586</span>, <span class="err">0</span><span class="kt">.</span><span class="err">8031439</span>, <span class="err">0</span><span class="kt">.</span><span class="err">9211674</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3558219</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">37258363</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">194855</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">7407244</span>, <span class="err">0</span><span class="kt">.</span><span class="err">48175216</span>, <span class="err">0</span><span class="kt">.</span><span class="err">040639203</span>, <span class="err">0</span><span class="kt">.</span><span class="err">6822441</span>, <span class="err">0</span><span class="kt">.</span><span class="err">5768623</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">19830275</span>, <span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">1513872</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">32279214</span>, <span class="err">0</span><span class="kt">.</span><span class="err">6181</span><span class="kt">...|</span>
<span class="kt">+--------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="entityrulerinternal">EntityRulerInternal</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator match exact strings or regex patterns provided in a file against a Document and assigns them an named entity. The definitions can contain any number of named entities.</p>

    <p>Parametres:</p>
    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setPatternsResource</code> <em>(str)</em>: Sets Resource in JSON or CSV format to map entities to patterns.
      path : str
          Path to the resource
      read_as : str, optional
          How to interpret the resource, by default ReadAs.TEXT
      options : dict, optional
          Options for parsing the resource, by default {“format”: “JSON”}</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setSentenceMatch</code> <em>(Boolean)</em>: Whether to find match at sentence level. True: sentence level. False: token level.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setAlphabetResource</code> <em>(str)</em>: Alphabet Resource (a simple plain text with all language characters)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setUseStorage</code> <em>(Boolean)</em>: Sets whether to use RocksDB storage to serialize patterns.</p>
      </li>
    </ul>

    <p>See <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/40.Rule_Based_Entity_Matchers.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/er/entity_ruler_internal/index.html#module-sparknlp_jsl.annotator.er.entity_ruler_internal">EntityRulerInternal</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerInternalModel.html">EntityRulerInternal</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">entityRuler</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">EntityRulerInternalApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entities"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPatternsResource</span><span class="p">(</span><span class="s">"entities.json"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">entityRuler</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">'''John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01.'''</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Result
</span><span class="o">+---------------+-----+---+-------+</span>
<span class="o">|</span>          <span class="n">chunk</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span>  <span class="n">label</span><span class="o">|</span>
<span class="o">+---------------+-----+---+-------+</span>
<span class="o">|</span>        <span class="n">aspirin</span><span class="o">|</span>   <span class="mi">25</span><span class="o">|</span> <span class="mi">31</span><span class="o">|</span>   <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span><span class="n">heart</span> <span class="n">condition</span><span class="o">|</span>   <span class="mi">41</span><span class="o">|</span> <span class="mi">55</span><span class="o">|</span><span class="n">Disease</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">paracetamol</span><span class="o">|</span>   <span class="mi">69</span><span class="o">|</span> <span class="mi">79</span><span class="o">|</span>   <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span>          <span class="n">fever</span><span class="o">|</span>   <span class="mi">89</span><span class="o">|</span> <span class="mi">93</span><span class="o">|</span><span class="n">Symptom</span><span class="o">|</span>
<span class="o">|</span>       <span class="n">headache</span><span class="o">|</span>   <span class="mi">99</span><span class="o">|</span><span class="mi">106</span><span class="o">|</span><span class="n">Symptom</span><span class="o">|</span>
<span class="o">|</span>     <span class="n">tonsilitis</span><span class="o">|</span>  <span class="mi">129</span><span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="n">Disease</span><span class="o">|</span>
<span class="o">|</span>      <span class="n">ibuprofen</span><span class="o">|</span>  <span class="mi">141</span><span class="o">|</span><span class="mi">149</span><span class="o">|</span>   <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">lansoprazol</span><span class="o">|</span>  <span class="mi">177</span><span class="o">|</span><span class="mi">187</span><span class="o">|</span>   <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span>           <span class="n">GORD</span><span class="o">|</span>  <span class="mi">198</span><span class="o">|</span><span class="mi">201</span><span class="o">|</span><span class="n">Disease</span><span class="o">|</span>
<span class="o">+---------------+-----+---+-------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">entityRuler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EntityRulerInternalApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entities"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPatternsResource</span><span class="o">(</span><span class="s">"entities.json"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">entityRuler</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"""John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsillitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01."""</span><span class="o">)</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">#</span> <span class="nc">Result</span>
<span class="o">+---------------+-----+---+-------+</span>
<span class="o">|</span>          <span class="n">chunk</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span>  <span class="n">label</span><span class="o">|</span>
<span class="o">+---------------+-----+---+-------+</span>
<span class="o">|</span>        <span class="n">aspirin</span><span class="o">|</span>   <span class="mi">25</span><span class="o">|</span> <span class="mi">31</span><span class="o">|</span>   <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span><span class="n">heart</span> <span class="n">condition</span><span class="o">|</span>   <span class="mi">41</span><span class="o">|</span> <span class="mi">55</span><span class="o">|</span><span class="nc">Disease</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">paracetamol</span><span class="o">|</span>   <span class="mi">69</span><span class="o">|</span> <span class="mi">79</span><span class="o">|</span>   <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span>          <span class="n">fever</span><span class="o">|</span>   <span class="mi">89</span><span class="o">|</span> <span class="mi">93</span><span class="o">|</span><span class="nc">Symptom</span><span class="o">|</span>
<span class="o">|</span>       <span class="n">headache</span><span class="o">|</span>   <span class="mi">99</span><span class="o">|</span><span class="mi">106</span><span class="o">|</span><span class="nc">Symptom</span><span class="o">|</span>
<span class="o">|</span>     <span class="n">tonsilitis</span><span class="o">|</span>  <span class="mi">129</span><span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="nc">Disease</span><span class="o">|</span>
<span class="o">|</span>      <span class="n">ibuprofen</span><span class="o">|</span>  <span class="mi">141</span><span class="o">|</span><span class="mi">149</span><span class="o">|</span>   <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">lansoprazol</span><span class="o">|</span>  <span class="mi">177</span><span class="o">|</span><span class="mi">187</span><span class="o">|</span>   <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span>           <span class="nc">GORD</span><span class="o">|</span>  <span class="mi">198</span><span class="o">|</span><span class="mi">201</span><span class="o">|</span><span class="nc">Disease</span><span class="o">|</span>
<span class="o">+---------------+-----+---+-------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>EntityRulerInternal will handle the chunks output based on the patterns defined, as shown in the example below. We can define an id field to identify entities.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setPatternsResource</code> <em>(str)</em>: Sets Resource in JSON or CSV format to map entities to patterns.
      path : str
          Path to the resource
      read_as : str, optional
          How to interpret the resource, by default ReadAs.TEXT
      options : dict, optional
          Options for parsing the resource, by default {“format”: “JSON”}</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setSentenceMatch</code> <em>(Boolean)</em>: Whether to find match at sentence level. True: sentence level. False: token level.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setAlphabetResource</code> <em>(str)</em>: Alphabet Resource (a simple plain text with all language characters)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setUseStorage</code> <em>(Boolean)</em>: Sets whether to use RocksDB storage to serialize patterns.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/er/entity_ruler_internal/index.html#module-sparknlp_jsl.annotator.er.entity_ruler_internal">FewShotClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerInternalApproach.html">EntityRulerInternal</a></td>
        </tr>
      </tbody>
    </table>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="featuresassembler">FeaturesAssembler</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The FeaturesAssembler is used to collect features from different columns. It can collect features from single value
columns (anything which can be cast to a float, if casts fails then the value is set to 0), array columns or
SparkNLP annotations (if the annotation is an embedding, it takes the embedding, otherwise tries to cast the
<code class="language-plaintext highlighter-rouge">result</code> field). The output of the transformer is a <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code> annotation (the numeric vector is in the
<code class="language-plaintext highlighter-rouge">embeddings</code> field).</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column name or an Array of strings (column names).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in the camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/feature_assembler/index.html#sparknlp_jsl.annotator.feature_assembler.FeaturesAssembler.name">FeaturesAssembler</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/FeaturesAssembler.html">FeaturesAssembler</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/FeaturesAssembler.ipynb">FeatureAssemblerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">medical</span><span class="p">,</span> <span class="n">nlp</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">features_asm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">embeddings_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">sentence_embeddings</span><span class="p">,</span>
        <span class="n">features_asm</span>
    <span class="p">])</span>

<span class="n">data_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"PROCEDURES PERFORMED: Colonoscopy. INDICATIONS: Renewed symptoms likely consistent with active flare of Inflammatory Bowel Disease, not responsive to conventional therapy including sulfasalazine, cortisone, local therapy. PROCEDURE: Informed consent was obtained prior to the procedure with special attention to benefits, risks, alternatives. Risks explained as bleeding, infection, bowel perforation, aspiration pneumonia, or reaction to the medications. Vital signs were monitored by blood pressure, heart rate, and oxygen saturation. Supplemental O2 given. Specifics discussed. Preprocedure physical exam performed. Stable vital signs. Lungs clear. Cardiac exam showed regular rhythm. Abdomen soft. Her past history, her past workup, her past visitation with me for Inflammatory Bowel Disease, well responsive to sulfasalazine reviewed. She currently has a flare and is not responding, therefore, likely may require steroid taper. At the same token, her symptoms are mild. She has rectal bleeding, essentially only some rusty stools. There is not significant diarrhea, just some lower stools. No significant pain. Therefore, it is possible that we are just dealing with a hemorrhoidal bleed, therefore, colonoscopy now needed. Past history reviewed. Specifics of workup, need for followup, and similar discussed. All questions answered. A normal digital rectal examination was performed. The PCF-160 AL was inserted into the anus and advanced to the cecum without difficulty, as identified by the ileocecal valve, cecal stump, and appendical orifice. All mucosal aspects thoroughly inspected, including a retroflexed examination. Withdrawal time was greater than six minutes. Unfortunately, the terminal ileum could not be intubated despite multiple attempts. Findings were those of a normal cecum, right colon, transverse colon, descending colon. A small cecal polyp was noted, this was biopsy-removed, placed in bottle #1. Random biopsies from the cecum obtained, bottle #2; random biopsies from the transverse colon obtained, as well as descending colon obtained, bottle #3. There was an area of inflammation in the proximal sigmoid colon, which was biopsied, placed in bottle #4. There was an area of relative sparing, with normal sigmoid lining, placed in bottle #5, randomly biopsied, and then inflammation again in the distal sigmoid colon and rectum biopsied, bottle #6, suggesting that we may be dealing with Crohn disease, given the relative sparing of the sigmoid colon and junk lesion. Retroflexed showed hemorrhoidal disease. Scope was then withdrawn, patient left in good condition. IMPRESSION: Active flare of Inflammatory Bowel Disease, question of Crohn disease. PLAN: I will have the patient follow up with me, will follow up on histology, follow up on the polyps. She will be put on a steroid taper and make an appointment and hopefully steroids alone will do the job. If not, she may be started on immune suppressive medication, such as azathioprine, or similar. All of this has been reviewed with the patient. All questions answered."</span>
        <span class="p">],</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">embeddings_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data_df</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"features"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">features</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[{</span><span class="n">feature_vector</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.00896873</span><span class="p">,</span> <span class="mf">0.011731416</span><span class="p">,</span> <span class="mf">0.12154201</span><span class="p">,</span> <span class="mf">0.1149235</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14689414</span><span class="p">,</span> <span class="mf">0.0103584975</span><span class="p">,</span> <span class="mf">0.053073216</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.056412186</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05143186</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0118978135</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.12175384</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.035894137</span><span class="p">,</span> <span class="mf">0.11812756</span><span class="p">,</span> <span class="mf">0.094671555</span><span class="p">,</span> <span class="mf">0.15838866</span><span class="p">,</span> <span class="mf">0.15260744</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.004094441</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.13675772</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07472433</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.035856977</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.026730005</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.21840473</span><span class="p">,</span> <span class="mf">0.029632289</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.011515695</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.20407394</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07848257</span><span class="p">,</span> <span class="mf">0.040990185</span><span class="p">,</span> <span class="mf">0.23028605</span><span class="p">,</span> <span class="mf">0.077140555</span><span class="p">,</span> <span class="mf">0.066990435</span><span class="p">,</span> <span class="mf">0.015219222</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10295644</span><span class="p">,</span> <span class="mf">0.038072545</span><span class="p">,</span> <span class="mf">0.10786369</span><span class="p">,</span> <span class="mf">0.121525764</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09569349</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.06309264</span><span class="p">,</span> <span class="mf">0.2778952</span><span class="p">,</span> <span class="mf">0.06462455</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10851931</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14370486</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1466352</span><span class="p">,</span> <span class="mf">0.08354363</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.078758985</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.08377953</span><span class="p">,</span> <span class="mf">0.12384644</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.23281692</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25607574</span><span class="p">,</span> <span class="mf">0.16399069</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07780675</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18302177</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18325584</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.12128636</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0010129504</span><span class="p">,</span> <span class="mf">0.0070792097</span><span class="p">,</span> <span class="mf">0.20506753</span><span class="p">,</span> <span class="mf">0.034964647</span><span class="p">,</span> <span class="mf">0.058425985</span><span class="p">,</span> <span class="mf">0.19572404</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.103953235</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.20159312</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.099047214</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07337802</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.03713124</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.055443633</span><span class="p">,</span> <span class="mf">0.11107734</span><span class="p">,</span> <span class="mf">0.048563413</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.038048305</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.020617828</span><span class="p">,</span> <span class="mf">0.17082842</span><span class="p">,</span> <span class="mf">0.069010496</span><span class="p">,</span> <span class="mf">0.08457101</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.038229663</span><span class="p">,</span> <span class="mf">0.073144384</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.092326105</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10054428</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.3286112E-4</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.046703782</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.080231875</span><span class="p">,</span> <span class="mf">0.02524295</span><span class="p">,</span> <span class="mf">0.01368699</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.19783853</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.03501917</span><span class="p">,</span> <span class="mf">0.13324805</span><span class="p">,</span> <span class="mf">0.09053264</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0958231</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0032442473</span><span class="p">,</span> <span class="mf">0.19218525</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.027179888</span><span class="p">,</span> <span class="mf">0.030672349</span><span class="p">,</span> <span class="mf">0.12848215</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.014700146</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.089054875</span><span class="p">,</span> <span class="mf">0.13839856</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.15778734</span><span class="p">,</span> <span class="mf">0.07103226</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.060303356</span><span class="p">,</span> <span class="mf">0.20854644</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.008389737</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1473986</span><span class="p">]}]</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">features_asm</span> <span class="o">=</span><span class="n">finance</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">embeddings_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">sentence_embeddings</span><span class="p">,</span>
        <span class="n">features_asm</span>
    <span class="p">])</span>

<span class="n">data_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span>
        <span class="p">],</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">embeddings_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data_df</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"features"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">features</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[{</span><span class="n">feature_vector</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.05989722</span><span class="p">,</span> <span class="mf">0.10907035</span><span class="p">,</span> <span class="mf">0.25595385</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.21656203</span><span class="p">,</span> <span class="mf">0.20777024</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.17276664</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.045803867</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14506632</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16928527</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.10008922</span><span class="p">,</span> <span class="mf">0.18800992</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.36529806</span><span class="p">,</span> <span class="mf">0.22592439</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.118487455</span><span class="p">,</span> <span class="mf">0.006129823</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2674002</span><span class="p">,</span> <span class="mf">0.37149927</span><span class="p">,</span> <span class="mf">0.12375746</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.30488327</span><span class="p">,</span> <span class="mf">0.2507765</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.060471725</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.22705032</span><span class="p">,</span> <span class="mf">0.39436466</span><span class="p">,</span> <span class="mf">0.40368417</span><span class="p">,</span> <span class="mf">0.15569581</span><span class="p">,</span> <span class="mf">0.083455965</span><span class="p">,</span> <span class="mf">0.11193783</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2783573</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.23566169</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.12444999</span><span class="p">,</span> <span class="mf">0.22503565</span><span class="p">,</span> <span class="mf">0.43343276</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3165808</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.057086047</span><span class="p">,</span> <span class="mf">0.050554093</span><span class="p">,</span> <span class="mf">0.3512633</span><span class="p">,</span> <span class="mf">0.17572127</span><span class="p">,</span> <span class="mf">0.19258633</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09170296</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25344467</span><span class="p">,</span> <span class="mf">0.018219033</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.117947415</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.03234701</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1549039</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0147800855</span><span class="p">,</span> <span class="mf">0.076972865</span><span class="p">,</span> <span class="mf">0.08612865</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14120182</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18348631</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4500436</span><span class="p">,</span> <span class="mf">0.038739346</span><span class="p">,</span> <span class="mf">0.12991442</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.032128494</span><span class="p">,</span> <span class="mf">0.7483725</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09843177</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6700389</span><span class="p">,</span> <span class="mf">0.0060545397</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1044135</span><span class="p">,</span> <span class="mf">1.2469376</span><span class="p">,</span> <span class="mf">0.32064447</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.17263599</span><span class="p">,</span> <span class="mf">0.31999183</span><span class="p">,</span> <span class="mf">0.0077194544</span><span class="p">,</span> <span class="mf">0.15370668</span><span class="p">,</span> <span class="mf">0.59472036</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16953614</span><span class="p">,</span> <span class="mf">0.3042488</span><span class="p">,</span> <span class="mf">0.25355336</span><span class="p">,</span> <span class="mf">0.60402286</span><span class="p">,</span> <span class="mf">0.07441569</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.12468894</span><span class="p">,</span> <span class="mf">0.03140718</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2630037</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.37703836</span><span class="p">,</span> <span class="mf">0.034783553</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.058904923</span><span class="p">,</span> <span class="mf">0.022686867</span><span class="p">,</span> <span class="mf">0.07962498</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7945683</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.21051218</span><span class="p">,</span> <span class="mf">0.6615892</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18747853</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25412843</span><span class="p">,</span> <span class="mf">0.26003888</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0803214</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.026889319</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.11805089</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14200646</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.019682527</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2372327</span><span class="p">,</span> <span class="mf">0.0090960255</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.071929</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.115089305</span><span class="p">,</span> <span class="mf">0.21781716</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3569975</span><span class="p">,</span> <span class="mf">0.07799677</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.096894525</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.34368798</span><span class="p">,</span> <span class="mf">0.66465</span><span class="p">,</span> <span class="mf">0.14913023</span><span class="p">]}]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">features_asm</span> <span class="o">=</span><span class="n">legal</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">embeddings_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">sentence_embeddings</span><span class="p">,</span>
        <span class="n">features_asm</span>
    <span class="p">])</span>

<span class="n">data_df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span>
            <span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span>
        <span class="p">],</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">embeddings_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data_df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data_df</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"features"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">features</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[{</span><span class="n">feature_vector</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[</span><span class="mf">0.02474357</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.08310143</span><span class="p">,</span> <span class="mf">0.4801927</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.070223466</span><span class="p">,</span> <span class="mf">0.33147717</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18737249</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.048361354</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.052325998</span><span class="p">,</span> <span class="mf">0.053252153</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0067390013</span><span class="p">,</span> <span class="mf">0.2836935</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25569317</span><span class="p">,</span> <span class="mf">0.3415577</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.19251995</span><span class="p">,</span> <span class="mf">0.051623292</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25131556</span><span class="p">,</span> <span class="mf">0.3472208</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.036604006</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.35653928</span><span class="p">,</span> <span class="mf">0.13225944</span><span class="p">,</span> <span class="mf">0.18795085</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09561886</span><span class="p">,</span> <span class="mf">0.4695179</span><span class="p">,</span> <span class="mf">0.22093144</span><span class="p">,</span> <span class="mf">0.32058474</span><span class="p">,</span> <span class="mf">0.057281215</span><span class="p">,</span> <span class="mf">0.082858086</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3714214</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.19219379</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.26751986</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.148075</span><span class="p">,</span> <span class="mf">0.6410107</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07821157</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.06398429</span><span class="p">,</span> <span class="mf">6.32831E-5</span><span class="p">,</span> <span class="mf">0.21222909</span><span class="p">,</span> <span class="mf">0.33145514</span><span class="p">,</span> <span class="mf">0.2575328</span><span class="p">,</span> <span class="mf">0.009346781</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.21482512</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.22197871</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14005142</span><span class="p">,</span> <span class="mf">0.04592571</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2919176</span><span class="p">,</span> <span class="mf">0.011854073</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.14047821</span><span class="p">,</span> <span class="mf">0.22201888</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.13500921</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.101019345</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.31175214</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0031539474</span><span class="p">,</span> <span class="mf">0.07841865</span><span class="p">,</span> <span class="mf">0.23760447</span><span class="p">,</span> <span class="mf">0.8622971</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.21095662</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9944092</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.090888076</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.45743433</span><span class="p">,</span> <span class="mf">1.5815442</span><span class="p">,</span> <span class="mf">0.4848822</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.12528154</span><span class="p">,</span> <span class="mf">0.33802572</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.16203907</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.09874586</span><span class="p">,</span> <span class="mf">0.63106954</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.21860953</span><span class="p">,</span> <span class="mf">0.39005432</span><span class="p">,</span> <span class="mf">0.25023165</span><span class="p">,</span> <span class="mf">0.66769457</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.13867687</span><span class="p">,</span> <span class="mf">0.02832079</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.17432508</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05764636</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.44529453</span><span class="p">,</span> <span class="mf">0.032839067</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2266792</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.002856281</span><span class="p">,</span> <span class="mf">0.007823931</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0165309</span><span class="p">,</span> <span class="mf">0.08553613</span><span class="p">,</span> <span class="mf">0.38090998</span><span class="p">,</span> <span class="mf">0.011592574</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.18031952</span><span class="p">,</span> <span class="mf">0.37968582</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.77948713</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.068393</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.029594865</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2165647</span><span class="p">,</span> <span class="mf">0.1665183</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.23963346</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.017649503</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.24768801</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2725593</span><span class="p">,</span> <span class="mf">0.14533372</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.36786577</span><span class="p">,</span> <span class="mf">0.23388086</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.20129707</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.33582142</span><span class="p">,</span> <span class="mf">0.5970527</span><span class="p">,</span> <span class="mf">0.12596472</span><span class="p">]}]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEmbeddings</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"AVERAGE"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
        <span class="n">document_assembler</span><span class="o">,</span>
        <span class="n">tokenizer</span><span class="o">,</span>
        <span class="n">word_embeddings</span><span class="o">,</span>
        <span class="n">sentence_embeddings</span><span class="o">,</span>
        <span class="n">features_asm</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"PROCEDURES PERFORMED: Colonoscopy. INDICATIONS: Renewed symptoms likely consistent with active flare of Inflammatory Bowel Disease, not responsive to conventional therapy including sulfasalazine, cortisone, local therapy. PROCEDURE: Informed consent was obtained prior to the procedure with special attention to benefits, risks, alternatives. Risks explained as bleeding, infection, bowel perforation, aspiration pneumonia, or reaction to the medications. Vital signs were monitored by blood pressure, heart rate, and oxygen saturation. Supplemental O2 given. Specifics discussed. Preprocedure physical exam performed. Stable vital signs. Lungs clear. Cardiac exam showed regular rhythm. Abdomen soft. Her past history, her past workup, her past visitation with me for Inflammatory Bowel Disease, well responsive to sulfasalazine reviewed. She currently has a flare and is not responding, therefore, likely may require steroid taper. At the same token, her symptoms are mild. She has rectal bleeding, essentially only some rusty stools. There is not significant diarrhea, just some lower stools. No significant pain. Therefore, it is possible that we are just dealing with a hemorrhoidal bleed, therefore, colonoscopy now needed. Past history reviewed. Specifics of workup, need for followup, and similar discussed. All questions answered. A normal digital rectal examination was performed. The PCF-160 AL was inserted into the anus and advanced to the cecum without difficulty, as identified by the ileocecal valve, cecal stump, and appendical orifice. All mucosal aspects thoroughly inspected, including a retroflexed examination. Withdrawal time was greater than six minutes. Unfortunately, the terminal ileum could not be intubated despite multiple attempts. Findings were those of a normal cecum, right colon, transverse colon, descending colon. A small cecal polyp was noted, this was biopsy-removed, placed in bottle #1. Random biopsies from the cecum obtained, bottle #2; random biopsies from the transverse colon obtained, as well as descending colon obtained, bottle #3. There was an area of inflammation in the proximal sigmoid colon, which was biopsied, placed in bottle #4. There was an area of relative sparing, with normal sigmoid lining, placed in bottle #5, randomly biopsied, and then inflammation again in the distal sigmoid colon and rectum biopsied, bottle #6, suggesting that we may be dealing with Crohn disease, given the relative sparing of the sigmoid colon and junk lesion. Retroflexed showed hemorrhoidal disease. Scope was then withdrawn, patient left in good condition. IMPRESSION: Active flare of Inflammatory Bowel Disease, question of Crohn disease. PLAN: I will have the patient follow up with me, will follow up on histology, follow up on the polyps. She will be put on a steroid taper and make an appointment and hopefully steroids alone will do the job. If not, she may be started on immune suppressive medication, such as azathioprine, or similar. All of this has been reviewed with the patient. All questions answered."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data_df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data_df</span><span class="o">)</span>

<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">features</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[{</span><span class="kt">feature_vector</span>, <span class="err">0</span>, <span class="err">0</span>, , <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">00896873</span>, <span class="err">0</span><span class="kt">.</span><span class="err">011731416</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12154201</span>, <span class="err">0</span><span class="kt">.</span><span class="err">1149235</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14689414</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0103584975</span>, <span class="err">0</span><span class="kt">.</span><span class="err">053073216</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">056412186</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">05143186</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0118978135</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">12175384</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">035894137</span>, <span class="err">0</span><span class="kt">.</span><span class="err">11812756</span>, <span class="err">0</span><span class="kt">.</span><span class="err">094671555</span>, <span class="err">0</span><span class="kt">.</span><span class="err">15838866</span>, <span class="err">0</span><span class="kt">.</span><span class="err">15260744</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">004094441</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">13675772</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07472433</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">035856977</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">026730005</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">21840473</span>, <span class="err">0</span><span class="kt">.</span><span class="err">029632289</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">011515695</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">20407394</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07848257</span>, <span class="err">0</span><span class="kt">.</span><span class="err">040990185</span>, <span class="err">0</span><span class="kt">.</span><span class="err">23028605</span>, <span class="err">0</span><span class="kt">.</span><span class="err">077140555</span>, <span class="err">0</span><span class="kt">.</span><span class="err">066990435</span>, <span class="err">0</span><span class="kt">.</span><span class="err">015219222</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">10295644</span>, <span class="err">0</span><span class="kt">.</span><span class="err">038072545</span>, <span class="err">0</span><span class="kt">.</span><span class="err">10786369</span>, <span class="err">0</span><span class="kt">.</span><span class="err">121525764</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">09569349</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">06309264</span>, <span class="err">0</span><span class="kt">.</span><span class="err">2778952</span>, <span class="err">0</span><span class="kt">.</span><span class="err">06462455</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">10851931</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14370486</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1466352</span>, <span class="err">0</span><span class="kt">.</span><span class="err">08354363</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">078758985</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">08377953</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12384644</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">23281692</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">25607574</span>, <span class="err">0</span><span class="kt">.</span><span class="err">16399069</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07780675</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">18302177</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">18325584</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">12128636</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0010129504</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0070792097</span>, <span class="err">0</span><span class="kt">.</span><span class="err">20506753</span>, <span class="err">0</span><span class="kt">.</span><span class="err">034964647</span>, <span class="err">0</span><span class="kt">.</span><span class="err">058425985</span>, <span class="err">0</span><span class="kt">.</span><span class="err">19572404</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">103953235</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">20159312</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">099047214</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07337802</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03713124</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">055443633</span>, <span class="err">0</span><span class="kt">.</span><span class="err">11107734</span>, <span class="err">0</span><span class="kt">.</span><span class="err">048563413</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">038048305</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">020617828</span>, <span class="err">0</span><span class="kt">.</span><span class="err">17082842</span>, <span class="err">0</span><span class="kt">.</span><span class="err">069010496</span>, <span class="err">0</span><span class="kt">.</span><span class="err">08457101</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">038229663</span>, <span class="err">0</span><span class="kt">.</span><span class="err">073144384</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">092326105</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">10054428</span>, <span class="kt">-</span><span class="err">4</span><span class="kt">.</span><span class="err">3286112</span><span class="kt">E-</span><span class="err">4</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">046703782</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">080231875</span>, <span class="err">0</span><span class="kt">.</span><span class="err">02524295</span>, <span class="err">0</span><span class="kt">.</span><span class="err">01368699</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">19783853</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03501917</span>, <span class="err">0</span><span class="kt">.</span><span class="err">13324805</span>, <span class="err">0</span><span class="kt">.</span><span class="err">09053264</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0958231</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0032442473</span>, <span class="err">0</span><span class="kt">.</span><span class="err">19218525</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">027179888</span>, <span class="err">0</span><span class="kt">.</span><span class="err">030672349</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12848215</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">014700146</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">089054875</span>, <span class="err">0</span><span class="kt">.</span><span class="err">13839856</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">15778734</span>, <span class="err">0</span><span class="kt">.</span><span class="err">07103226</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">060303356</span>, <span class="err">0</span><span class="kt">.</span><span class="err">20854644</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">008389737</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1473986</span><span class="o">]}]|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEmbeddings</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"AVERAGE"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
        <span class="n">document_assembler</span><span class="o">,</span>
        <span class="n">tokenizer</span><span class="o">,</span>
        <span class="n">word_embeddings</span><span class="o">,</span>
        <span class="n">sentence_embeddings</span><span class="o">,</span>
        <span class="n">features_asm</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Our competitors include the following by general category: legacy antivirus product providers, such as McAfee LLC and Broadcom Inc."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data_df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data_df</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">features</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[{</span><span class="kt">feature_vector</span>, <span class="err">0</span>, <span class="err">0</span>, , <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[</span><span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">05989722</span>, <span class="err">0</span><span class="kt">.</span><span class="err">10907035</span>, <span class="err">0</span><span class="kt">.</span><span class="err">25595385</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">21656203</span>, <span class="err">0</span><span class="kt">.</span><span class="err">20777024</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">17276664</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">045803867</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14506632</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">16928527</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">10008922</span>, <span class="err">0</span><span class="kt">.</span><span class="err">18800992</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">36529806</span>, <span class="err">0</span><span class="kt">.</span><span class="err">22592439</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">118487455</span>, <span class="err">0</span><span class="kt">.</span><span class="err">006129823</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2674002</span>, <span class="err">0</span><span class="kt">.</span><span class="err">37149927</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12375746</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">30488327</span>, <span class="err">0</span><span class="kt">.</span><span class="err">2507765</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">060471725</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">22705032</span>, <span class="err">0</span><span class="kt">.</span><span class="err">39436466</span>, <span class="err">0</span><span class="kt">.</span><span class="err">40368417</span>, <span class="err">0</span><span class="kt">.</span><span class="err">15569581</span>, <span class="err">0</span><span class="kt">.</span><span class="err">083455965</span>, <span class="err">0</span><span class="kt">.</span><span class="err">11193783</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2783573</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">23566169</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">12444999</span>, <span class="err">0</span><span class="kt">.</span><span class="err">22503565</span>, <span class="err">0</span><span class="kt">.</span><span class="err">43343276</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">3165808</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">057086047</span>, <span class="err">0</span><span class="kt">.</span><span class="err">050554093</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3512633</span>, <span class="err">0</span><span class="kt">.</span><span class="err">17572127</span>, <span class="err">0</span><span class="kt">.</span><span class="err">19258633</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">09170296</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">25344467</span>, <span class="err">0</span><span class="kt">.</span><span class="err">018219033</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">117947415</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">03234701</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1549039</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0147800855</span>, <span class="err">0</span><span class="kt">.</span><span class="err">076972865</span>, <span class="err">0</span><span class="kt">.</span><span class="err">08612865</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14120182</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">18348631</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">4500436</span>, <span class="err">0</span><span class="kt">.</span><span class="err">038739346</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12991442</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">032128494</span>, <span class="err">0</span><span class="kt">.</span><span class="err">7483725</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">09843177</span>, <span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">6700389</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0060545397</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">1044135</span>, <span class="err">1</span><span class="kt">.</span><span class="err">2469376</span>, <span class="err">0</span><span class="kt">.</span><span class="err">32064447</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">17263599</span>, <span class="err">0</span><span class="kt">.</span><span class="err">31999183</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0077194544</span>, <span class="err">0</span><span class="kt">.</span><span class="err">15370668</span>, <span class="err">0</span><span class="kt">.</span><span class="err">59472036</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">16953614</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3042488</span>, <span class="err">0</span><span class="kt">.</span><span class="err">25355336</span>, <span class="err">0</span><span class="kt">.</span><span class="err">60402286</span>, <span class="err">0</span><span class="kt">.</span><span class="err">07441569</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">12468894</span>, <span class="err">0</span><span class="kt">.</span><span class="err">03140718</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2630037</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">37703836</span>, <span class="err">0</span><span class="kt">.</span><span class="err">034783553</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">058904923</span>, <span class="err">0</span><span class="kt">.</span><span class="err">022686867</span>, <span class="err">0</span><span class="kt">.</span><span class="err">07962498</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">7945683</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">21051218</span>, <span class="err">0</span><span class="kt">.</span><span class="err">6615892</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">18747853</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">25412843</span>, <span class="err">0</span><span class="kt">.</span><span class="err">26003888</span>, <span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">0803214</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">026889319</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">11805089</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14200646</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">019682527</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2372327</span>, <span class="err">0</span><span class="kt">.</span><span class="err">0090960255</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">071929</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">115089305</span>, <span class="err">0</span><span class="kt">.</span><span class="err">21781716</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">3569975</span>, <span class="err">0</span><span class="kt">.</span><span class="err">07799677</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">096894525</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">34368798</span>, <span class="err">0</span><span class="kt">.</span><span class="err">66465</span>, <span class="err">0</span><span class="kt">.</span><span class="err">14913023</span><span class="o">]}]|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEmbeddings</span><span class="o">()</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"AVERAGE"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
        <span class="n">document_assembler</span><span class="o">,</span>
        <span class="n">tokenizer</span><span class="o">,</span>
        <span class="n">word_embeddings</span><span class="o">,</span>
        <span class="n">sentence_embeddings</span><span class="o">,</span>
        <span class="n">features_asm</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"This is an Intellectual Property Agreement between Amazon Inc. and Atlantic Inc."</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data_df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data_df</span><span class="o">)</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">features</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[{</span><span class="kt">feature_vector</span>, <span class="err">0</span>, <span class="err">0</span>, , <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[</span><span class="err">0</span><span class="kt">.</span><span class="err">02474357</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">08310143</span>, <span class="err">0</span><span class="kt">.</span><span class="err">4801927</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">070223466</span>, <span class="err">0</span><span class="kt">.</span><span class="err">33147717</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">18737249</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">048361354</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">052325998</span>, <span class="err">0</span><span class="kt">.</span><span class="err">053252153</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0067390013</span>, <span class="err">0</span><span class="kt">.</span><span class="err">2836935</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">25569317</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3415577</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">19251995</span>, <span class="err">0</span><span class="kt">.</span><span class="err">051623292</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">25131556</span>, <span class="err">0</span><span class="kt">.</span><span class="err">3472208</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">036604006</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">35653928</span>, <span class="err">0</span><span class="kt">.</span><span class="err">13225944</span>, <span class="err">0</span><span class="kt">.</span><span class="err">18795085</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">09561886</span>, <span class="err">0</span><span class="kt">.</span><span class="err">4695179</span>, <span class="err">0</span><span class="kt">.</span><span class="err">22093144</span>, <span class="err">0</span><span class="kt">.</span><span class="err">32058474</span>, <span class="err">0</span><span class="kt">.</span><span class="err">057281215</span>, <span class="err">0</span><span class="kt">.</span><span class="err">082858086</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">3714214</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">19219379</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">26751986</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">148075</span>, <span class="err">0</span><span class="kt">.</span><span class="err">6410107</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">07821157</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">06398429</span>, <span class="err">6</span><span class="kt">.</span><span class="err">32831</span><span class="kt">E-</span><span class="err">5</span>, <span class="err">0</span><span class="kt">.</span><span class="err">21222909</span>, <span class="err">0</span><span class="kt">.</span><span class="err">33145514</span>, <span class="err">0</span><span class="kt">.</span><span class="err">2575328</span>, <span class="err">0</span><span class="kt">.</span><span class="err">009346781</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">21482512</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">22197871</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14005142</span>, <span class="err">0</span><span class="kt">.</span><span class="err">04592571</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2919176</span>, <span class="err">0</span><span class="kt">.</span><span class="err">011854073</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">14047821</span>, <span class="err">0</span><span class="kt">.</span><span class="err">22201888</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">13500921</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">101019345</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">31175214</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">0031539474</span>, <span class="err">0</span><span class="kt">.</span><span class="err">07841865</span>, <span class="err">0</span><span class="kt">.</span><span class="err">23760447</span>, <span class="err">0</span><span class="kt">.</span><span class="err">8622971</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">21095662</span>, <span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">9944092</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">090888076</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">45743433</span>, <span class="err">1</span><span class="kt">.</span><span class="err">5815442</span>, <span class="err">0</span><span class="kt">.</span><span class="err">4848822</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">12528154</span>, <span class="err">0</span><span class="kt">.</span><span class="err">33802572</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">16203907</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">09874586</span>, <span class="err">0</span><span class="kt">.</span><span class="err">63106954</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">21860953</span>, <span class="err">0</span><span class="kt">.</span><span class="err">39005432</span>, <span class="err">0</span><span class="kt">.</span><span class="err">25023165</span>, <span class="err">0</span><span class="kt">.</span><span class="err">66769457</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">13867687</span>, <span class="err">0</span><span class="kt">.</span><span class="err">02832079</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">17432508</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">05764636</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">44529453</span>, <span class="err">0</span><span class="kt">.</span><span class="err">032839067</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2266792</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">002856281</span>, <span class="err">0</span><span class="kt">.</span><span class="err">007823931</span>, <span class="kt">-</span><span class="err">1</span><span class="kt">.</span><span class="err">0165309</span>, <span class="err">0</span><span class="kt">.</span><span class="err">08553613</span>, <span class="err">0</span><span class="kt">.</span><span class="err">38090998</span>, <span class="err">0</span><span class="kt">.</span><span class="err">011592574</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">18031952</span>, <span class="err">0</span><span class="kt">.</span><span class="err">37968582</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">77948713</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">068393</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">029594865</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2165647</span>, <span class="err">0</span><span class="kt">.</span><span class="err">1665183</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">23963346</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">017649503</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">24768801</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">2725593</span>, <span class="err">0</span><span class="kt">.</span><span class="err">14533372</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">36786577</span>, <span class="err">0</span><span class="kt">.</span><span class="err">23388086</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">20129707</span>, <span class="kt">-</span><span class="err">0</span><span class="kt">.</span><span class="err">33582142</span>, <span class="err">0</span><span class="kt">.</span><span class="err">5970527</span>, <span class="err">0</span><span class="kt">.</span><span class="err">12596472</span><span class="o">]}]|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="fewshotassertionclassifiermodel">FewShotAssertionClassifierModel</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>FewShotAssertionClassifierModel does assertion classification using can run large (LLMS based)
few shot classifiers based on the SetFit approach.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">batchSize</code> <em>(Int)</em>: Batch size</li>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code> <em>(Bool)</em>: Whether the classifier is sensitive to text casing</li>
      <li><code class="language-plaintext highlighter-rouge">maxSentenceLength</code> <em>(Int)</em>: The maximum length of the input text</li>
      <li><code class="language-plaintext highlighter-rouge">blackList</code> <em>(list[str])</em>: If defined, list of entities to ignore. The rest will be processed.</li>
      <li><code class="language-plaintext highlighter-rouge">whiteList</code> <em>(list[str])</em>:  If defined, list of entities to process. The rest will be ignored. Do not include IOB prefix on labels.</li>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code> <em>(Bool)</em>: Determines whether the definitions of the white listed and black listed entities are case sensitive. Default: True.</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/few_shot_assertion_classifier/index.html">FewShotAssertionClassifierModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/FewShotAssertionClassifierModel.html">FewShotAssertionClassifierModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/FewShotClassifierModel.ipynb">FewShotAssertionClassifierModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setSplitChars</span><span class="p">([</span><span class="s">"-"</span><span class="p">,</span> <span class="s">"\/"</span><span class="p">])</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># ner_oncology
</span><span class="n">ner_oncology</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_oncology"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_oncology"</span><span class="p">)</span>

<span class="n">ner_oncology_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_oncology"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">few_shot_assertion_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FewShotAssertionSentenceConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_sentence"</span><span class="p">)</span>

<span class="n">e5_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">E5Embeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"e5_base_v2_embeddings_medical_assertion_oncology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"assertion_sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_embedding"</span><span class="p">)</span>

<span class="n">few_shot_assertion_classifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FewShotAssertionClassifierModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"fewhot_assertion_oncology_e5_base_v2_oncology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"assertion_embedding"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_fewshot"</span><span class="p">)</span>

<span class="n">assertion_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">ner_oncology</span><span class="p">,</span>
        <span class="n">ner_oncology_converter</span><span class="p">,</span>
        <span class="n">few_shot_assertion_converter</span><span class="p">,</span>
        <span class="n">e5_embeddings</span><span class="p">,</span>
        <span class="n">few_shot_assertion_classifier</span>
    <span class="p">])</span>

<span class="n">sample_text</span><span class="o">=</span> <span class="p">[</span>
    <span class="s">"""The patient is suspected to have colorectal cancer. Her family history is positive for other cancers. The result of the biopsy was positive. A CT scan was ordered to rule out metastases."""</span>
    <span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">sample_text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">assertion_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>        <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span>       <span class="o">|</span><span class="n">assertion</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
<span class="o">|</span><span class="n">colorectal</span> <span class="n">cancer</span><span class="o">|</span><span class="mi">33</span>   <span class="o">|</span><span class="mi">49</span> <span class="o">|</span><span class="n">Cancer_Dx</span>       <span class="o">|</span><span class="n">Possible</span> <span class="o">|</span><span class="mf">0.5812815</span> <span class="o">|</span>
<span class="o">|</span><span class="n">Her</span>              <span class="o">|</span><span class="mi">52</span>   <span class="o">|</span><span class="mi">54</span> <span class="o">|</span><span class="n">Gender</span>          <span class="o">|</span><span class="n">Present</span>  <span class="o">|</span><span class="mf">0.9562998</span> <span class="o">|</span>
<span class="o">|</span><span class="n">cancers</span>          <span class="o">|</span><span class="mi">93</span>   <span class="o">|</span><span class="mi">99</span> <span class="o">|</span><span class="n">Cancer_Dx</span>       <span class="o">|</span><span class="n">Family</span>   <span class="o">|</span><span class="mf">0.23465642</span><span class="o">|</span>
<span class="o">|</span><span class="n">biopsy</span>           <span class="o">|</span><span class="mi">120</span>  <span class="o">|</span><span class="mi">125</span><span class="o">|</span><span class="n">Pathology_Test</span>  <span class="o">|</span><span class="n">Past</span>     <span class="o">|</span><span class="mf">0.95732147</span><span class="o">|</span>
<span class="o">|</span><span class="n">positive</span>         <span class="o">|</span><span class="mi">131</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="n">Pathology_Result</span><span class="o">|</span><span class="n">Present</span>  <span class="o">|</span><span class="mf">0.9564386</span> <span class="o">|</span>
<span class="o">|</span><span class="n">CT</span> <span class="n">scan</span>          <span class="o">|</span><span class="mi">143</span>  <span class="o">|</span><span class="mi">149</span><span class="o">|</span><span class="n">Imaging_Test</span>    <span class="o">|</span><span class="n">Past</span>     <span class="o">|</span><span class="mf">0.9571699</span> <span class="o">|</span>
<span class="o">|</span><span class="n">metastases</span>       <span class="o">|</span><span class="mi">175</span>  <span class="o">|</span><span class="mi">184</span><span class="o">|</span><span class="n">Metastasis</span>      <span class="o">|</span><span class="n">Possible</span> <span class="o">|</span><span class="mf">0.54986554</span><span class="o">|</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nc">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setSplitChars</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"-"</span><span class="o">,</span> <span class="s">"/"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerOncology</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_oncology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_oncology"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerOncologyConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_oncology"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">fewShotAssertionConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FewShotAssertionSentenceConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">e5Embeddings</span> <span class="k">=</span> <span class="n">E5Embeddings</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"e5_base_v2_embeddings_medical_assertion_oncology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"assertion_sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_embedding"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">fewShotAssertionClassifier</span> <span class="k">=</span> <span class="nc">FewShotAssertionClassifierModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"fewhot_assertion_oncology_e5_base_v2_oncology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"assertion_embedding"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_fewshot"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
        <span class="n">documentAssembler</span><span class="o">,</span>
        <span class="n">sentenceDetector</span><span class="o">,</span>
        <span class="n">tokenizer</span><span class="o">,</span>
        <span class="n">wordEmbeddings</span><span class="o">,</span>
        <span class="n">nerOncology</span><span class="o">,</span>
        <span class="n">nerOncologyConverter</span><span class="o">,</span>
        <span class="n">fewShotAssertionConverter</span><span class="o">,</span>
        <span class="n">e5Embeddings</span><span class="o">,</span>
        <span class="n">fewShotAssertionClassifier</span>
    <span class="o">))</span>

<span class="k">val</span> <span class="nv">sampleText</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The patient is suspected to have colorectal cancer. Her family history is positive for other cancers.
The result of the biopsy was positive. A CT scan was ordered to rule out metastases."</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">sampleText</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Result       </span>

<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>        <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span>       <span class="o">|</span><span class="n">assertion</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
<span class="o">|</span><span class="n">colorectal</span> <span class="n">cancer</span><span class="o">|</span><span class="mi">33</span>   <span class="o">|</span><span class="mi">49</span> <span class="o">|</span><span class="nc">Cancer_Dx</span>       <span class="o">|</span><span class="nc">Possible</span> <span class="o">|</span><span class="mf">0.5812815</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">Her</span>              <span class="o">|</span><span class="mi">52</span>   <span class="o">|</span><span class="mi">54</span> <span class="o">|</span><span class="nc">Gender</span>          <span class="o">|</span><span class="nc">Present</span>  <span class="o">|</span><span class="mf">0.9562998</span> <span class="o">|</span>
<span class="o">|</span><span class="n">cancers</span>          <span class="o">|</span><span class="mi">93</span>   <span class="o">|</span><span class="mi">99</span> <span class="o">|</span><span class="nc">Cancer_Dx</span>       <span class="o">|</span><span class="nc">Family</span>   <span class="o">|</span><span class="mf">0.23465642</span><span class="o">|</span>
<span class="o">|</span><span class="n">biopsy</span>           <span class="o">|</span><span class="mi">120</span>  <span class="o">|</span><span class="mi">125</span><span class="o">|</span><span class="nc">Pathology_Test</span>  <span class="o">|</span><span class="nc">Past</span>     <span class="o">|</span><span class="mf">0.95732147</span><span class="o">|</span>
<span class="o">|</span><span class="n">positive</span>         <span class="o">|</span><span class="mi">131</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="nc">Pathology_Result</span><span class="o">|</span><span class="nc">Present</span>  <span class="o">|</span><span class="mf">0.9564386</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">CT</span> <span class="n">scan</span>          <span class="o">|</span><span class="mi">143</span>  <span class="o">|</span><span class="mi">149</span><span class="o">|</span><span class="nc">Imaging_Test</span>    <span class="o">|</span><span class="nc">Past</span>     <span class="o">|</span><span class="mf">0.9571699</span> <span class="o">|</span>
<span class="o">|</span><span class="n">metastases</span>       <span class="o">|</span><span class="mi">175</span>  <span class="o">|</span><span class="mi">184</span><span class="o">|</span><span class="nc">Metastasis</span>      <span class="o">|</span><span class="nc">Possible</span> <span class="o">|</span><span class="mf">0.54986554</span><span class="o">|</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Trains a TensorFlow model for few shot assertion classifier.</p>

    <p>To train a custom few shot assertion classifier model, you need to first create a Tensorflow graph using either the <code class="language-plaintext highlighter-rouge">TfGraphBuilder</code> annotator or the <code class="language-plaintext highlighter-rouge">tf_graph</code> module. Then, set the path to the Tensorflow graph using the method <code class="language-plaintext highlighter-rouge">.setModelFile("path/to/tensorflow_graph.pb")</code>.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">batchSize</code>: (int) Batch size</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dropout</code>: (float) Dropout coefficient</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">epochsN</code>: (int) Maximum number of epochs to train</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">featureScaling</code>: (str) Feature scaling method. Possible values are ‘zscore’, ‘minmax’ or empty (no scaling)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">fixImbalance</code>: (boolean) Fix the imbalance in the training set by replicating examples of under represented categories</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">labelColumn</code>: (str) Column with label per each document</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">learningRate</code>: (float) Learning Rate</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">modelFile</code>: (str) Location of file of the model used for classification</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">multiClass</code>: (boolean) If multiClass is set, the model will return all the labels with corresponding scores. By default, multiClass is false.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputLogsPath</code>: (str) Folder path to save training logs. If no path is specified, the logs won’t be stored in disk. The path can be a local file path, a distributed file path (HDFS, DBFS), or a cloud storage (S3).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">validationSplit</code>: (float) The proportion of training dataset to be used as validation set.The model will be validated against this dataset on each Epoch and will not be used for training. The value should be between 0.0 and 1.0.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">datasetInfo</code> <em>(Str)</em>: Descriptive information about the dataset being used.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ASSERTION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/few_shot_assertion_classifier/index.html">FewShotAssertionClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/FewShotAssertionClassifierApproach.html">FewShotAssertionClassifierApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.2.FewShot_Assertion_Classifier.ipynb">FewShotAssertionClassifierNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="kn">from</span> <span class="nn">sparknlp_jsl.annotator</span> <span class="kn">import</span> <span class="n">TFGraphBuilder</span>

<span class="n">graph_folder</span> <span class="o">=</span> <span class="s">"./tf_graphs"</span>
<span class="n">graph_name</span> <span class="o">=</span> <span class="s">"assertion_graph.pb"</span>

<span class="n">assertion_graph_builder</span> <span class="o">=</span> <span class="n">TFGraphBuilder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setModelName</span><span class="p">(</span><span class="s">"fewshot_assertion"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"assertion_embedding"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="n">graph_name</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setHiddenUnitsNumber</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>

<span class="n">fewshot_assertion_approach</span> <span class="o">=</span> <span class="n">FewShotAssertionClassifierApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"assertion_embedding"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">graph_folder</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">graph_name</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>

<span class="n">clinical_assertion_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">assertion_graph_builder</span><span class="p">,</span>
        <span class="n">fewshot_assertion_approach</span>
    <span class="p">])</span>

<span class="n">assertion_model</span> <span class="o">=</span> <span class="n">clinical_assertion_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">assertion_train_data</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Defining pipeline stages to extract entities first</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiDocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span> <span class="s">"span"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"span_document"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Doc2Chunk</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"span_document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"span_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">assertionConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FewShotAssertionSentenceConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"span_chunk"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceEmbeddings</span> <span class="k">=</span> <span class="nc">MPNetEmbeddings</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"assertion_sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_embedding"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">fewShotAssertionApproach</span> <span class="k">=</span> <span class="nc">FewShotAssertionClassifierApproach</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"assertion_embedding"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMultiClass</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.01f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span>
  <span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">chunker</span><span class="o">,</span>
    <span class="n">assertionConverter</span><span class="o">,</span>
    <span class="n">sentenceEmbeddings</span><span class="o">,</span>
    <span class="n">fewShotAssertionApproach</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="fewshotassertionsentenceconverter">FewShotAssertionSentenceConverter</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>It is a util annotator that is used in some datasets to train a new FewShotAssertionClassifierModel.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">scopeWindow</code> :  The scope window of the assertion expression</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">TOKEN</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/assertion/fewshot_assertion_sentence_converter/index.html">FewShotAssertionSentenceConverter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/assertion/FewShotAssertionSentenceConverter.html">FewShotAssertionSentenceConverter</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setSplitChars</span><span class="p">([</span><span class="s">"-"</span><span class="p">,</span> <span class="s">"\/"</span><span class="p">])</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># ner_oncology
</span><span class="n">ner_oncology</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_oncology"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_oncology"</span><span class="p">)</span>

<span class="n">ner_oncology_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_oncology"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">few_shot_assertion_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FewShotAssertionSentenceConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_sentence"</span><span class="p">)</span>

<span class="n">e5_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">E5Embeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"e5_base_v2_embeddings_medical_assertion_oncology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"assertion_sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_embedding"</span><span class="p">)</span>

<span class="n">few_shot_assertion_classifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FewShotAssertionClassifierModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"fewhot_assertion_oncology_e5_base_v2_oncology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"assertion_embedding"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"assertion_fewshot"</span><span class="p">)</span>

<span class="n">assertion_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">ner_oncology</span><span class="p">,</span>
        <span class="n">ner_oncology_converter</span><span class="p">,</span>
        <span class="n">few_shot_assertion_converter</span><span class="p">,</span>
        <span class="n">e5_embeddings</span><span class="p">,</span>
        <span class="n">few_shot_assertion_classifier</span>
    <span class="p">])</span>

<span class="n">sample_text</span><span class="o">=</span> <span class="p">[</span>
<span class="s">"""The patient is suspected to have colorectal cancer. Her family history is positive for other cancers.
The result of the biopsy was positive. A CT scan was ordered to rule out metastases."""</span>
<span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="n">sample_text</span><span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">assertion_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">assertion_fewshot</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span>
                        <span class="n">result</span><span class="p">.</span><span class="n">assertion_fewshot</span><span class="p">.</span><span class="n">begin</span><span class="p">,</span>
                        <span class="n">result</span><span class="p">.</span><span class="n">assertion_fewshot</span><span class="p">.</span><span class="n">end</span><span class="p">,</span>
                        <span class="n">result</span><span class="p">.</span><span class="n">assertion_fewshot</span><span class="p">.</span><span class="n">result</span><span class="p">,)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
                        <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['ner_chunk']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">),</span>
                        <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"begin"</span><span class="p">),</span>
                        <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"end"</span><span class="p">),</span>
                        <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['ner_label']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">),</span>
                        <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['3']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"assertion"</span><span class="p">),</span>
                        <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">)</span> <span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>



<span class="c1">## Result
</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>        <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span>       <span class="o">|</span><span class="n">assertion</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
<span class="o">|</span><span class="n">colorectal</span> <span class="n">cancer</span><span class="o">|</span><span class="mi">33</span>   <span class="o">|</span><span class="mi">49</span> <span class="o">|</span><span class="n">Cancer_Dx</span>       <span class="o">|</span><span class="n">Possible</span> <span class="o">|</span><span class="mf">0.5812815</span> <span class="o">|</span>
<span class="o">|</span><span class="n">Her</span>              <span class="o">|</span><span class="mi">52</span>   <span class="o">|</span><span class="mi">54</span> <span class="o">|</span><span class="n">Gender</span>          <span class="o">|</span><span class="n">Present</span>  <span class="o">|</span><span class="mf">0.9562998</span> <span class="o">|</span>
<span class="o">|</span><span class="n">cancers</span>          <span class="o">|</span><span class="mi">93</span>   <span class="o">|</span><span class="mi">99</span> <span class="o">|</span><span class="n">Cancer_Dx</span>       <span class="o">|</span><span class="n">Family</span>   <span class="o">|</span><span class="mf">0.23465642</span><span class="o">|</span>
<span class="o">|</span><span class="n">biopsy</span>           <span class="o">|</span><span class="mi">120</span>  <span class="o">|</span><span class="mi">125</span><span class="o">|</span><span class="n">Pathology_Test</span>  <span class="o">|</span><span class="n">Past</span>     <span class="o">|</span><span class="mf">0.95732147</span><span class="o">|</span>
<span class="o">|</span><span class="n">positive</span>         <span class="o">|</span><span class="mi">131</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="n">Pathology_Result</span><span class="o">|</span><span class="n">Present</span>  <span class="o">|</span><span class="mf">0.9564386</span> <span class="o">|</span>
<span class="o">|</span><span class="n">CT</span> <span class="n">scan</span>          <span class="o">|</span><span class="mi">143</span>  <span class="o">|</span><span class="mi">149</span><span class="o">|</span><span class="n">Imaging_Test</span>    <span class="o">|</span><span class="n">Past</span>     <span class="o">|</span><span class="mf">0.9571699</span> <span class="o">|</span>
<span class="o">|</span><span class="n">metastases</span>       <span class="o">|</span><span class="mi">175</span>  <span class="o">|</span><span class="mi">184</span><span class="o">|</span><span class="n">Metastasis</span>      <span class="o">|</span><span class="n">Possible</span> <span class="o">|</span><span class="mf">0.54986554</span><span class="o">|</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nc">SentenceDetectorDLModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setSplitChars</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"-"</span><span class="o">,</span> <span class="s">"/"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerOncology</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_oncology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_oncology"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerOncologyConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_oncology"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">fewShotAssertionConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FewShotAssertionSentenceConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">e5Embeddings</span> <span class="k">=</span> <span class="n">E5Embeddings</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"e5_base_v2_embeddings_medical_assertion_oncology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"assertion_sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_embedding"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">fewShotAssertionClassifier</span> <span class="k">=</span> <span class="nc">FewShotAssertionClassifierModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"fewhot_assertion_oncology_e5_base_v2_oncology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"assertion_embedding"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"assertion_fewshot"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
        <span class="n">documentAssembler</span><span class="o">,</span>
        <span class="n">sentenceDetector</span><span class="o">,</span>
        <span class="n">tokenizer</span><span class="o">,</span>
        <span class="n">wordEmbeddings</span><span class="o">,</span>
        <span class="n">nerOncology</span><span class="o">,</span>
        <span class="n">nerOncologyConverter</span><span class="o">,</span>
        <span class="n">fewShotAssertionConverter</span><span class="o">,</span>
        <span class="n">e5Embeddings</span><span class="o">,</span>
        <span class="n">fewShotAssertionClassifier</span>
    <span class="o">))</span>

<span class="k">val</span> <span class="nv">sampleText</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The patient is suspected to have colorectal cancer. Her family history is positive for other cancers. 
The result of the biopsy was positive. A CT scan was ordered to rule out metastases."</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">sampleText</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="o">#</span><span class="k">#</span> <span class="nc">Result</span>

<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
<span class="o">|</span><span class="n">ner_chunk</span>        <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span>       <span class="o">|</span><span class="n">assertion</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
<span class="o">|</span><span class="n">colorectal</span> <span class="n">cancer</span><span class="o">|</span><span class="mi">33</span>   <span class="o">|</span><span class="mi">49</span> <span class="o">|</span><span class="nc">Cancer_Dx</span>       <span class="o">|</span><span class="nc">Possible</span> <span class="o">|</span><span class="mf">0.5812815</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">Her</span>              <span class="o">|</span><span class="mi">52</span>   <span class="o">|</span><span class="mi">54</span> <span class="o">|</span><span class="nc">Gender</span>          <span class="o">|</span><span class="nc">Present</span>  <span class="o">|</span><span class="mf">0.9562998</span> <span class="o">|</span>
<span class="o">|</span><span class="n">cancers</span>          <span class="o">|</span><span class="mi">93</span>   <span class="o">|</span><span class="mi">99</span> <span class="o">|</span><span class="nc">Cancer_Dx</span>       <span class="o">|</span><span class="nc">Family</span>   <span class="o">|</span><span class="mf">0.23465642</span><span class="o">|</span>
<span class="o">|</span><span class="n">biopsy</span>           <span class="o">|</span><span class="mi">120</span>  <span class="o">|</span><span class="mi">125</span><span class="o">|</span><span class="nc">Pathology_Test</span>  <span class="o">|</span><span class="nc">Past</span>     <span class="o">|</span><span class="mf">0.95732147</span><span class="o">|</span>
<span class="o">|</span><span class="n">positive</span>         <span class="o">|</span><span class="mi">131</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="nc">Pathology_Result</span><span class="o">|</span><span class="nc">Present</span>  <span class="o">|</span><span class="mf">0.9564386</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">CT</span> <span class="n">scan</span>          <span class="o">|</span><span class="mi">143</span>  <span class="o">|</span><span class="mi">149</span><span class="o">|</span><span class="nc">Imaging_Test</span>    <span class="o">|</span><span class="nc">Past</span>     <span class="o">|</span><span class="mf">0.9571699</span> <span class="o">|</span>
<span class="o">|</span><span class="n">metastases</span>       <span class="o">|</span><span class="mi">175</span>  <span class="o">|</span><span class="mi">184</span><span class="o">|</span><span class="nc">Metastasis</span>      <span class="o">|</span><span class="nc">Possible</span> <span class="o">|</span><span class="mf">0.54986554</span><span class="o">|</span>
<span class="o">+-----------------+-----+---+----------------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="fewshotclassifier">FewShotClassifier</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">FewShotClassifier</code> annotators specifically target few-shot classification tasks, which involve training a model to make accurate predictions with limited labeled data.</p>

    <p>These annotators provide a valuable capability for handling scenarios where labeled data is scarce or expensive to obtain. By effectively utilizing limited labeled examples, the few-shot classification approach enables the creation of models that can generalize and classify new instances accurately, even with minimal training data.</p>

    <p>The FewShotClassifier is designed to process sentence embeddings as input. It generates category annotations, providing labels along with confidence scores that range from 0 to 1.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/few_shot_classifier/index.html#sparknlp_jsl.annotator.classification.few_shot_classifier.FewShotClassifierModel">FewShotClassifierModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/FewShotClassifierModel.html">FewShotClassifierModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">bert_sent</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">few_shot_classifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FewShotClassifierModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"few_shot_classifier_age_group_sbiobert_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">clf_Pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">bert_sent</span><span class="p">,</span>
    <span class="n">few_shot_classifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">[</span><span class="s">"""A patient presented with complaints of chest pain and shortness of breath. The medical history revealed the patient had a smoking habit for over 30 years, and was diagnosed with hypertension two years ago. After a detailed physical examination, the doctor found a noticeable wheeze on lung auscultation and prescribed a spirometry test, which showed irreversible airway obstruction. The patient was diagnosed with Chronic obstructive pulmonary disease (COPD) caused by smoking."""</span><span class="p">],</span>
 <span class="p">[</span><span class="s">"""Hi, wondering if anyone has had a similar situation. My 1 year old daughter has the following; loose stools/ pale stools, elevated liver enzymes, low iron.  5 months and still no answers from drs. """</span><span class="p">],</span>
 <span class="p">[</span><span class="s">"""Hi have chronic gastritis from 4 month(confirmed by endoscopy).I do not have acid reflux.Only dull ache above abdomen and left side of chest.I am on reberprozole and librax.My question is whether chronic gastritis is curable or is it a lifetime condition?I am loosing hope because this dull ache is not going away.Please please reply"""</span><span class="p">]</span>
    <span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">clf_Pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'prediction.result'</span><span class="p">,</span><span class="s">'text'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

<span class="o">+---------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>   <span class="n">result</span><span class="o">|</span>                                                                                                                                                  <span class="n">text</span><span class="o">|</span>
<span class="o">+---------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>  <span class="p">[</span><span class="n">Adult</span><span class="p">]</span><span class="o">|</span><span class="n">A</span> <span class="n">patient</span> <span class="n">presented</span> <span class="k">with</span> <span class="n">complaints</span> <span class="n">of</span> <span class="n">chest</span> <span class="n">pain</span> <span class="ow">and</span> <span class="n">shortness</span> <span class="n">of</span> <span class="n">breath</span><span class="p">.</span> <span class="n">The</span> <span class="n">medical</span> <span class="n">history</span> <span class="n">revealed</span> <span class="n">the</span> <span class="n">patient</span> <span class="n">had</span> <span class="n">a</span> <span class="n">smoking</span> <span class="n">habit</span> <span class="k">for</span> <span class="n">over</span> <span class="mf">30.</span><span class="p">..</span><span class="o">|</span>
<span class="o">|</span>  <span class="p">[</span><span class="n">Child</span><span class="p">]</span><span class="o">|</span><span class="n">Hi</span><span class="p">,</span> <span class="n">wondering</span> <span class="k">if</span> <span class="n">anyone</span> <span class="n">has</span> <span class="n">had</span> <span class="n">a</span> <span class="n">similar</span> <span class="n">situation</span><span class="p">.</span> <span class="n">My</span> <span class="mi">1</span> <span class="n">year</span> <span class="n">old</span> <span class="n">daughter</span> <span class="n">has</span> <span class="n">the</span> <span class="n">following</span><span class="p">;</span> <span class="n">loose</span> <span class="n">stools</span><span class="o">/</span> <span class="n">pale</span> <span class="n">stools</span><span class="p">,</span> <span class="n">elevated</span> <span class="n">liver</span> <span class="n">enzymes</span><span class="p">,</span> <span class="n">l</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">Unknown</span><span class="p">]</span><span class="o">|</span><span class="n">Hi</span> <span class="n">have</span> <span class="n">chronic</span> <span class="n">gastritis</span> <span class="k">from</span> <span class="mi">4</span> <span class="n">month</span><span class="p">(</span><span class="n">confirmed</span> <span class="n">by</span> <span class="n">endoscopy</span><span class="p">).</span><span class="n">I</span> <span class="n">do</span> <span class="ow">not</span> <span class="n">have</span> <span class="n">acid</span> <span class="n">reflux</span><span class="p">.</span><span class="n">Only</span> <span class="n">dull</span> <span class="n">ache</span> <span class="n">above</span> <span class="n">abdomen</span> <span class="ow">and</span> <span class="n">left</span> <span class="n">side</span> <span class="n">of</span> <span class="n">chest</span><span class="p">.</span><span class="n">I</span> <span class="n">am</span> <span class="n">o</span><span class="p">...</span><span class="o">|</span>
<span class="o">+---------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">bert_sent</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">few_shot_classifier</span> <span class="k">=</span> <span class="nv">FewShotClassifierModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"few_shot_classifier_age_group_sbiobert_cased_mli"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span> 
    
<span class="k">val</span> <span class="nv">clf_Pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">bert_sent</span><span class="o">,</span> 
    <span class="n">few_shot_classifier</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
    <span class="o">(</span><span class="s">"""A patient presented with complaints of chest pain and shortness of breath. The medical history revealed the patient had a smoking habit for over 30 years, and was diagnosed with hypertension two years ago. After a detailed physical examination, the doctor found a noticeable wheeze on lung auscultation and prescribed a spirometry test, which showed irreversible airway obstruction. The patient was diagnosed with Chronic obstructive pulmonary disease (COPD) caused by smoking."""</span><span class="o">),</span>
 <span class="o">(</span><span class="s">"""Hi, wondering if anyone has had a similar situation. My 1 year old daughter has the following; loose stools/ pale stools, elevated liver enzymes, low iron.  5 months and still no answers from drs. """</span><span class="o">),</span>
 <span class="o">(</span><span class="s">"""Hi have chronic gastritis from 4 month(confirmed by endoscopy).I do not have acid reflux.Only dull ache above abdomen and left side of chest.I am on reberprozole and librax.My question is whether chronic gastritis is curable or is it a lifetime condition?I am loosing hope because this dull ache is not going away.Please please reply"""</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">clf_Pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>


<span class="o">+---------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>   <span class="n">result</span><span class="o">|</span>                                                                                                                                                  <span class="n">text</span><span class="o">|</span>
<span class="o">+---------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span>  <span class="o">[</span><span class="kt">Adult</span><span class="o">]|</span><span class="n">A</span> <span class="n">patient</span> <span class="n">presented</span> <span class="k">with</span> <span class="n">complaints</span> <span class="n">of</span> <span class="n">chest</span> <span class="n">pain</span> <span class="n">and</span> <span class="n">shortness</span> <span class="n">of</span> <span class="n">breath</span><span class="o">.</span> <span class="nc">The</span> <span class="n">medical</span> <span class="n">history</span> <span class="n">revealed</span> <span class="n">the</span> <span class="n">patient</span> <span class="n">had</span> <span class="n">a</span> <span class="n">smoking</span> <span class="n">habit</span> <span class="k">for</span> <span class="n">over</span> <span class="mf">30.</span><span class="o">..|</span>
<span class="o">|</span>  <span class="o">[</span><span class="kt">Child</span><span class="o">]|</span><span class="nc">Hi</span><span class="o">,</span> <span class="n">wondering</span> <span class="k">if</span> <span class="n">anyone</span> <span class="n">has</span> <span class="n">had</span> <span class="n">a</span> <span class="n">similar</span> <span class="n">situation</span><span class="o">.</span> <span class="nc">My</span> <span class="mi">1</span> <span class="n">year</span> <span class="n">old</span> <span class="n">daughter</span> <span class="n">has</span> <span class="n">the</span> <span class="n">following</span><span class="o">;</span> <span class="n">loose</span> <span class="n">stools</span><span class="o">/</span> <span class="n">pale</span> <span class="n">stools</span><span class="o">,</span> <span class="n">elevated</span> <span class="n">liver</span> <span class="n">enzymes</span><span class="o">,</span> <span class="n">l</span><span class="o">...|</span>
<span class="o">|[</span><span class="kt">Unknown</span><span class="o">]|</span><span class="nc">Hi</span> <span class="n">have</span> <span class="n">chronic</span> <span class="n">gastritis</span> <span class="n">from</span> <span class="mi">4</span> <span class="nf">month</span><span class="o">(</span><span class="n">confirmed</span> <span class="n">by</span> <span class="n">endoscopy</span><span class="o">).</span><span class="py">I</span> <span class="k">do</span> <span class="n">not</span> <span class="n">have</span> <span class="n">acid</span> <span class="nv">reflux</span><span class="o">.</span><span class="py">Only</span> <span class="n">dull</span> <span class="n">ache</span> <span class="n">above</span> <span class="n">abdomen</span> <span class="n">and</span> <span class="n">left</span> <span class="n">side</span> <span class="n">of</span> <span class="nv">chest</span><span class="o">.</span><span class="py">I</span> <span class="n">am</span> <span class="n">o</span><span class="o">...|</span>
<span class="o">+---------+------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">FewShotClassifier</code> annotators specifically target few-shot classification tasks, which involve training a model to make accurate predictions with limited labeled data.</p>

    <p>These annotators provide a valuable capability for handling scenarios where labeled data is scarce or expensive to obtain. By effectively utilizing limited labeled examples, the few-shot classification approach enables the creation of models that can generalize and classify new instances accurately, even with minimal training data.</p>

    <p>The FewShotClassifier is designed to process sentence embeddings as input. It generates category annotations, providing labels along with confidence scores that range from 0 to 1.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/few_shot_classifier/index.html#sparknlp_jsl.annotator.classification.few_shot_classifier.FewShotClassifierApproach">FewShotClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/FewShotClassifierApproach.html">FewShotClassifierApproach</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 

<span class="n">document_asm</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span>\
<span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">graph_builder</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">TFGraphBuilder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setModelName</span><span class="p">(</span><span class="s">"fewshot_classifier"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="s">"/tmp"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="s">"log_reg_graph.pb"</span><span class="p">)</span>\

<span class="n">few_shot_approach</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FewShotClassifierApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="sa">f</span><span class="s">"/tmp/log_reg_graph.pb"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_asm</span><span class="p">,</span>
        <span class="n">sentence_embeddings</span><span class="p">,</span>
        <span class="n">graph_builder</span><span class="p">,</span>
        <span class="n">few_shot_approach</span>
    <span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">few_shot_approach</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FewShotClassifierApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"tmp/log_reg_graph.pb"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.001</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_asm</span><span class="o">,</span> 
    <span class="n">sentence_embeddings</span><span class="o">,</span> 
    <span class="n">few_shot_approach</span> <span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">train_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="flattener">Flattener</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The <code class="language-plaintext highlighter-rouge">Flattener</code> converts annotation results into a format that easier to use. This annotator produces a DataFrame with flattened and exploded columns containing annotation results, making it easier to interpret and analyze the information.
It is particularly useful for extracting and organizing the results obtained from Spark NLP Pipelines.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">inputCols</code>: Input annotations.</li>
      <li><code class="language-plaintext highlighter-rouge">cleanAnnotations</code>: Whether to remove annotation columns, by default <code class="language-plaintext highlighter-rouge">True</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">explodeSelectedFields</code>: Dict of input columns to their corresponding selected fields.</li>
      <li><code class="language-plaintext highlighter-rouge">flattenExplodedColumns</code>: Whether to flatten exploded columns(default : <code class="language-plaintext highlighter-rouge">True</code>).</li>
      <li><code class="language-plaintext highlighter-rouge">orderByColumn</code>: Specify the column by which the DataFrame should be ordered..</li>
      <li><code class="language-plaintext highlighter-rouge">orderDescending</code>: Specifying whether to order the DataFrame in descending order.(default : <code class="language-plaintext highlighter-rouge">True</code>).</li>
      <li><code class="language-plaintext highlighter-rouge">keepOriginalColumns</code> : Array of column names that should be kept in the DataFrame after the flattening process.</li>
    </ul>

    <p>See <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/41.Flattener.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">ANY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/flattener/index.html">Flattener</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/Flattener.html">Flattener</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Flattener.ipynb">FlattenerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setLabelCasing</span><span class="p">(</span><span class="s">"upper"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"SYMPTOM"</span><span class="p">,</span><span class="s">"VS_FINDING"</span><span class="p">,</span><span class="s">"DISEASE_SYNDROME_DISORDER"</span><span class="p">,</span><span class="s">"ADMISSION_DISCHARGE"</span><span class="p">,</span><span class="s">"PROCEDURE"</span><span class="p">])</span>

<span class="n">flattener</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Flattener</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setExplodeSelectedFields</span><span class="p">({</span><span class="s">"ner_chunk"</span><span class="p">:</span> <span class="p">[</span><span class="s">"result as ner_chunks"</span><span class="p">,</span>
                                             <span class="s">"begin as begins"</span><span class="p">,</span>
                                             <span class="s">"end as ends"</span><span class="p">,</span>
                                             <span class="s">"metadata.entity as entities"</span><span class="p">]})</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">flattener</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""
GENERAL: He is an elderly gentleman in no acute distress. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.
HEENT: Sclerae showed mild arcus senilis in the right. Left was clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.
NECK: Supple. Trachea is midline. No jugular venous pressure distention is noted. No adenopathy in the cervical, supraclavicular, or axillary areas.
ABDOMEN: Soft and not tender. There may be some fullness in the left upper quadrant, although I do not appreciate a true spleen with inspiration.
EXTREMITIES: There is some edema, but no cyanosis and clubbing .
"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># result
</span><span class="o">+----------------------------------+------+----+-------------------------+</span>
<span class="o">|</span><span class="n">ner_chunks</span>                        <span class="o">|</span><span class="n">begins</span><span class="o">|</span><span class="n">ends</span><span class="o">|</span><span class="n">entities</span>                 <span class="o">|</span>
<span class="o">+----------------------------------+------+----+-------------------------+</span>
<span class="o">|</span><span class="n">distress</span>                          <span class="o">|</span><span class="mi">49</span>    <span class="o">|</span><span class="mi">56</span>  <span class="o">|</span><span class="n">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">arcus</span> <span class="n">senilis</span>                     <span class="o">|</span><span class="mi">196</span>   <span class="o">|</span><span class="mi">208</span> <span class="o">|</span><span class="n">DISEASE_SYNDROME_DISORDER</span><span class="o">|</span>
<span class="o">|</span><span class="n">jugular</span> <span class="n">venous</span> <span class="n">pressure</span> <span class="n">distention</span><span class="o">|</span><span class="mi">380</span>   <span class="o">|</span><span class="mi">413</span> <span class="o">|</span><span class="n">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">adenopathy</span>                        <span class="o">|</span><span class="mi">428</span>   <span class="o">|</span><span class="mi">437</span> <span class="o">|</span><span class="n">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">tender</span>                            <span class="o">|</span><span class="mi">514</span>   <span class="o">|</span><span class="mi">519</span> <span class="o">|</span><span class="n">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">fullness</span>                          <span class="o">|</span><span class="mi">540</span>   <span class="o">|</span><span class="mi">547</span> <span class="o">|</span><span class="n">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">edema</span>                             <span class="o">|</span><span class="mi">665</span>   <span class="o">|</span><span class="mi">669</span> <span class="o">|</span><span class="n">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">cyanosis</span>                          <span class="o">|</span><span class="mi">679</span>   <span class="o">|</span><span class="mi">686</span> <span class="o">|</span><span class="n">VS_FINDING</span>               <span class="o">|</span>
<span class="o">|</span><span class="n">clubbing</span>                          <span class="o">|</span><span class="mi">692</span>   <span class="o">|</span><span class="mi">699</span> <span class="o">|</span><span class="n">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">+----------------------------------+------+----+-------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinicalNer</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCasing</span><span class="o">(</span><span class="s">"upper"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"SYMPTOM"</span><span class="o">,</span> <span class="s">"VS_FINDING"</span><span class="o">,</span> <span class="s">"DISEASE_SYNDROME_DISORDER"</span><span class="o">,</span> <span class="s">"ADMISSION_DISCHARGE"</span><span class="o">,</span> <span class="s">"PROCEDURE"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">flattener</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Flattener</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setExplodeSelectedFields</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"ner_chunk"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"result"</span><span class="o">,</span> <span class="s">"begin"</span><span class="o">,</span> <span class="s">"end"</span><span class="o">,</span> <span class="s">"metadata.entity"</span><span class="o">)))</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">wordEmbeddings</span><span class="o">,</span>
  <span class="n">clinicalNer</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">,</span>
  <span class="n">flattener</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""
GENERAL: He is an elderly gentleman in no acute distress. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.
HEENT: Sclerae showed mild arcus senilis in the right. Left was clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.
NECK: Supple. Trachea is midline. No jugular venous pressure distention is noted. No adenopathy in the cervical, supraclavicular, or axillary areas.
ABDOMEN: Soft and not tender. There may be some fullness in the left upper quadrant, although I do not appreciate a true spleen with inspiration.
EXTREMITIES: There is some edema, but no cyanosis and clubbing .
"""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">#</span> <span class="n">result</span>
<span class="o">+----------------------------------+------+----+-------------------------+</span>
<span class="o">|</span><span class="n">ner_chunks</span>                        <span class="o">|</span><span class="n">begins</span><span class="o">|</span><span class="n">ends</span><span class="o">|</span><span class="n">entities</span>                 <span class="o">|</span>
<span class="o">+----------------------------------+------+----+-------------------------+</span>
<span class="o">|</span><span class="n">distress</span>                          <span class="o">|</span><span class="mi">49</span>    <span class="o">|</span><span class="mi">56</span>  <span class="o">|</span><span class="nc">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">arcus</span> <span class="n">senilis</span>                     <span class="o">|</span><span class="mi">196</span>   <span class="o">|</span><span class="mi">208</span> <span class="o">|</span><span class="nc">DISEASE_SYNDROME_DISORDER</span><span class="o">|</span>
<span class="o">|</span><span class="n">jugular</span> <span class="n">venous</span> <span class="n">pressure</span> <span class="n">distention</span><span class="o">|</span><span class="mi">380</span>   <span class="o">|</span><span class="mi">413</span> <span class="o">|</span><span class="nc">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">adenopathy</span>                        <span class="o">|</span><span class="mi">428</span>   <span class="o">|</span><span class="mi">437</span> <span class="o">|</span><span class="nc">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">tender</span>                            <span class="o">|</span><span class="mi">514</span>   <span class="o">|</span><span class="mi">519</span> <span class="o">|</span><span class="nc">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">fullness</span>                          <span class="o">|</span><span class="mi">540</span>   <span class="o">|</span><span class="mi">547</span> <span class="o">|</span><span class="nc">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">edema</span>                             <span class="o">|</span><span class="mi">665</span>   <span class="o">|</span><span class="mi">669</span> <span class="o">|</span><span class="nc">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">|</span><span class="n">cyanosis</span>                          <span class="o">|</span><span class="mi">679</span>   <span class="o">|</span><span class="mi">686</span> <span class="o">|</span><span class="nc">VS_FINDING</span>               <span class="o">|</span>
<span class="o">|</span><span class="n">clubbing</span>                          <span class="o">|</span><span class="mi">692</span>   <span class="o">|</span><span class="mi">699</span> <span class="o">|</span><span class="nc">SYMPTOM</span>                  <span class="o">|</span>
<span class="o">+----------------------------------+------+----+-------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="genericclassifier">GenericClassifier</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Creates a generic single-label classifier which uses pre-generated Tensorflow graphs.
The model operates on FEATURE_VECTOR annotations which can be produced using FeatureAssembler.
Requires the FeaturesAssembler to create the input.</p>

    <p>Parameter:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">multiClass</code> <em>(Boolean)</em>: Whether to return all clases or only the one with highest score (Default: False)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">datasetInfo</code> <em>(Str)</em>: Descriptive information about the dataset being used.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/generic_classifier/generic_classifier/index.html#sparknlp_jsl.annotator.generic_classifier.generic_classifier.GenericClassifierModel">GenericClassifierModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/generic_classifier/GenericClassifierModel.html">GenericClassifierModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/GenericClassifierModel.ipynb">GenericClassifierModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">features_asm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">generic_classifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">GenericClassifierModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"genericclassifier_sdoh_economics_binary_sbiobert_cased_mli"</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"classes"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_embeddings</span><span class="p">,</span>
        <span class="n">features_asm</span><span class="p">,</span>
        <span class="n">generic_classifier</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""Patient works as a building inspector and remodeler. Married with 2 children. He is a current smoker, 1PPD for 25years. He drinks to beers/night, but has not had any alcohol in past 4 days. No IVDU."""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="s">"classes.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+</span>
<span class="o">|</span><span class="n">text</span>                                                                                                                                                                                                  <span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+</span>
<span class="o">|</span><span class="n">Patient</span> <span class="n">works</span> <span class="k">as</span> <span class="n">a</span> <span class="n">building</span> <span class="n">inspector</span> <span class="ow">and</span> <span class="n">remodeler</span><span class="p">.</span> <span class="n">Married</span> <span class="k">with</span> <span class="mi">2</span> <span class="n">children</span><span class="p">.</span> <span class="n">He</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">current</span> <span class="n">smoker</span><span class="p">,</span> <span class="mi">1</span><span class="n">PPD</span> <span class="k">for</span> <span class="mi">25</span><span class="n">years</span><span class="p">.</span> <span class="n">He</span> <span class="n">drinks</span> <span class="n">to</span> <span class="n">beers</span><span class="o">/</span><span class="n">night</span><span class="p">,</span> <span class="n">but</span> <span class="n">has</span> <span class="ow">not</span> <span class="n">had</span> <span class="nb">any</span> <span class="n">alcohol</span> <span class="ow">in</span> <span class="n">past</span> <span class="mi">4</span> <span class="n">days</span><span class="p">.</span> <span class="n">No</span> <span class="n">IVDU</span><span class="p">.</span><span class="o">|</span><span class="p">[</span><span class="bp">True</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">generic_classifier</span> <span class="k">=</span> <span class="nv">GenericClassifierModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"genericclassifier_sdoh_economics_binary_sbiobert_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"features"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"classes"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
                                            <span class="n">document_assembler</span><span class="o">,</span> 
                                            <span class="n">sentence_embeddings</span><span class="o">,</span> 
                                            <span class="n">features_asm</span><span class="o">,</span> 
                                            <span class="n">generic_classifier</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"Patient works as a building inspector and remodeler. Married with 2 children. He is a current smoker,1PPD for 25years. He drinks to beers/night,but has not had any alcohol in past 4 days. No IVDU."</span> 

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>   

<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+</span>
<span class="o">|</span><span class="n">text</span>                                                                                                                                                                                                  <span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+</span>
<span class="o">|</span><span class="nc">Patient</span> <span class="n">works</span> <span class="n">as</span> <span class="n">a</span> <span class="n">building</span> <span class="n">inspector</span> <span class="n">and</span> <span class="n">remodeler</span><span class="o">.</span> <span class="nc">Married</span> <span class="k">with</span> <span class="mi">2</span> <span class="n">children</span><span class="o">.</span> <span class="nc">He</span> <span class="n">is</span> <span class="n">a</span> <span class="n">current</span> <span class="n">smoker</span><span class="o">,</span> <span class="mi">1</span><span class="nc">PPD</span> <span class="k">for</span> <span class="mi">25</span><span class="n">years</span><span class="o">.</span> <span class="nc">He</span> <span class="n">drinks</span> <span class="n">to</span> <span class="n">beers</span><span class="o">/</span><span class="n">night</span><span class="o">,</span> <span class="n">but</span> <span class="n">has</span> <span class="n">not</span> <span class="n">had</span> <span class="n">any</span> <span class="n">alcohol</span> <span class="n">in</span> <span class="n">past</span> <span class="mi">4</span> <span class="n">days</span><span class="o">.</span> <span class="nc">No</span> <span class="nc">IVDU</span><span class="o">.|[</span><span class="kt">True</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Trains a TensorFlow model for generic classification of feature vectors. It takes FEATURE_VECTOR annotations from
<code class="language-plaintext highlighter-rouge">FeaturesAssembler</code> as input, classifies them and outputs CATEGORY annotations.
Please see the Parameters section for required training parameters.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">batchSize</code>: (int) Batch size</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dropout</code>: (float) Dropout coefficient</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">epochsN</code>: (int) Maximum number of epochs to train</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">featureScaling</code>: (str) Feature scaling method. Possible values are ‘zscore’, ‘minmax’ or empty (no scaling)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">fixImbalance</code>: (boolean) Fix the imbalance in the training set by replicating examples of under represented categories</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">labelColumn</code>: (str) Column with label per each document</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">learningRate</code>: (float) Learning Rate</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">modelFile</code>: (str) Location of file of the model used for classification</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">multiClass</code>: (boolean) If multiClass is set, the model will return all the labels with corresponding scores. By default, multiClass is false.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputLogsPath</code>: (str) Folder path to save training logs. If no path is specified, the logs won’t be stored in disk. The path can be a local file path, a distributed file path (HDFS, DBFS), or a cloud storage (S3).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">validationSplit</code>: (float) The proportion of training dataset to be used as validation set.The model will be validated against this dataset on each Epoch and will not be used for training. The value should be between 0.0 and 1.0.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">datasetInfo</code> <em>(Str)</em>: Descriptive information about the dataset being used.</p>
      </li>
    </ul>

    <p>For a more extensive example please see the
<a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/8.Generic_Classifier.ipynb">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/generic_classifier/generic_classifier/index.html#sparknlp_jsl.annotator.generic_classifier.generic_classifier.GenericClassifierApproach">GenericClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/generic_classifier/GenericClassifierApproach.html">GenericClassifierApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/GenericClassifierApproach.ipynb">GenericClassifierApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">features_asm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setlearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">features_asm</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setlearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">features_asm</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_1"</span><span class="p">,</span> <span class="s">"feature_2"</span><span class="p">,</span> <span class="s">"..."</span><span class="p">,</span> <span class="s">"feature_n"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">GenericClassifierApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFeatureScaling</span><span class="p">(</span><span class="s">"zscore"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setlearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">"logs"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span> <span class="c1"># keep 20% of the data for validation purposes
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gen_clf</span>
<span class="p">])</span>

<span class="n">clf_model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"feature_1"</span><span class="o">,</span> <span class="s">"feature_2"</span><span class="o">,</span> <span class="s">"..."</span><span class="o">,</span> <span class="s">"feature_n"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GenericClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"/path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">50</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFeatureScaling</span><span class="o">(</span><span class="s">"zscore"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="s">"logs"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.2f</span><span class="o">)</span> <span class="c1">// keep 20% of the data for validation purposes</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">features_asm</span><span class="o">,</span>
  <span class="n">gen_clf</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">clf_model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="genericlogregclassifier">GenericLogRegClassifier</h2>

  <div class="annotator_type tac mont">Approach</div>

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">GenericLogRegClassifier</code> is a derivative of GenericClassifier which implements a multinomial logistic regression. This is a single layer neural network with the logistic function at the output. The input to the model is FeatureVector and the output is category annotations with labels and corresponding confidence scores varying between 0 and 1.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">LabelColumn</code>: This parameter sets the name of the column in your input data that contains the labels (categories) for the classification task. The classifier will use this column to learn from the data and make predictions.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ModelFile</code>: This parameter specifies the path to the pre-trained model file for the logistic regression classifier. It should be a protobuf file containing the model graph and trained weights.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">EpochsNumber</code>: This parameter sets the number of epochs (iterations) the classifier will go through during the training process. An epoch represents one complete pass through the entire training dataset.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">BatchSize</code>: This parameter sets the batch size used during training. The training data is divided into batches, and the model’s weights are updated after processing each batch. A larger batch size may speed up training, but it requires more memory.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">LearningRate</code>: This parameter sets the learning rate for the optimization algorithm used during training. The learning rate determines how much the model’s weights are updated based on the computed gradients. A higher learning rate may lead to faster convergence but risks overshooting the optimal solution.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">OutputLogsPath</code>: This parameter specifies the path where the logs related to the training process will be stored. These logs can include information such as training loss, accuracy, and other metrics.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">Dropout</code>: Dropout is a regularization technique used to prevent overfitting in neural networks. This parameter sets the dropout rate, which determines the probability that each neuron’s output will be temporarily ignored during training.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">FixImbalance</code>: Imbalance refers to the situation when some classes have significantly more training examples than others. Setting this parameter to True indicates that the classifier will handle class imbalance during training to help ensure that the model doesn’t become biased towards the majority class.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ValidationSplit</code>: This line seems to be commented out, but it’s worth mentioning its purpose. If uncommented and set to a value between 0 and 1, it would specify the fraction of the training data to be used for validation during the training process. The remaining data would be used for actual training.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/generic_log_reg_classifier/index.html#sparknlp_jsl.annotator.classification.generic_log_reg_classifier.GenericLogRegClassifierApproach">GenericLogRegClassifierApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/GenericLogRegClassifierApproach.html">GenericLogRegClassifierApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/GenericLogRegClassifierApproach.ipynb">GenericLogRegClassifierApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">features_asm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"feature_vector"</span><span class="p">)</span>

<span class="n">graph_folder</span> <span class="o">=</span> <span class="s">"gc_graph"</span>

<span class="n">gc_logreg_graph_builder</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">TFGraphBuilder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setModelName</span><span class="p">(</span><span class="s">"logreg_classifier"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_vector"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="s">"log_reg_graph.pb"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">GenericLogRegClassifierApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"feature_vector"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">graph_folder</span><span class="si">}</span><span class="s">/log_reg_graph.pb"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="n">log_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="c1"># .setValidationSplit(0.1)
</span>
<span class="n">clf_Pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gc_logreg_graph_builder</span><span class="p">,</span>
    <span class="n">gen_clf</span><span class="p">])</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
  
<span class="k">val</span> <span class="nv">features_asm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"feature_vector"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gc_logreg_graph_builder</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TFGraphBuilder</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setModelName</span><span class="o">(</span><span class="s">"logreg_classifier"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"feature_vector"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setGraphFolder</span><span class="o">(</span><span class="s">"gc_graph"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setGraphFile</span><span class="o">(</span><span class="s">"log_reg_graph.pb"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">gen_clf</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GenericLogRegClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"category"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"feature_vector"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"gc_graph/log_reg_graph.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">128</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLearningRate</span><span class="o">(</span><span class="mf">0.01</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputLogsPath</span><span class="o">(</span><span class="n">log_folder</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDropout</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="c1">// .setValidationSplit(0.1)</span>

<span class="k">val</span> <span class="nv">clf_Pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">features_asm</span><span class="o">,</span> <span class="n">gc_logreg_graph_builder</span><span class="o">,</span> <span class="n">gen_clf</span><span class="o">))</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="genericremodel">GenericREModel</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Instantiated RelationExtractionModel for extracting relationships between any entities.
This class is not intended to be directly used, please use the RelationExtractionModel instead.
Pairs of entities should be specified using setRelationPairs.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_extraction/index.html#sparknlp_jsl.annotator.re.relation_extraction.RelationExtractionModel">RelationExtractionModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionModel.html">RelationExtractionModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/RelationExtractionModel.ipynb">RelationExtractionModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">reModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"generic_re"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"problem-test"</span><span class="p">,</span>
                       <span class="s">"problem-treatment"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">words_embedder</span><span class="p">,</span>
    <span class="n">pos_tagger</span><span class="p">,</span>
    <span class="n">ner_tagger</span><span class="p">,</span>
    <span class="n">ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">reModel</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""
A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to
presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis
three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index
( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and
vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a
respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin
and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical
examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was
benign with no tenderness , guarding , or rigidity .
"""</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span>
                              <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                              <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
<span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relations"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------+-------------+-------+-------+------------+----------+</span>
<span class="o">|</span><span class="n">chunk1</span>           <span class="o">|</span><span class="n">chunk2</span>       <span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span><span class="n">relations</span>   <span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+-----------------+-------------+-------+-------+------------+----------+</span>
<span class="o">|</span><span class="n">obesity</span>          <span class="o">|</span><span class="n">BMI</span>          <span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">TEST</span>   <span class="o">|</span><span class="n">PROBLEM</span><span class="o">-</span><span class="n">TEST</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">a</span> <span class="n">body</span> <span class="n">mass</span> <span class="n">index</span><span class="o">|</span><span class="n">BMI</span>          <span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">TEST</span>   <span class="o">|</span><span class="n">PROBLEM</span><span class="o">-</span><span class="n">TEST</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">BMI</span>              <span class="o">|</span><span class="n">polyuria</span>     <span class="o">|</span><span class="n">TEST</span>   <span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">TEST</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">BMI</span>              <span class="o">|</span><span class="n">polydipsia</span>   <span class="o">|</span><span class="n">TEST</span>   <span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">TEST</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">BMI</span>              <span class="o">|</span><span class="n">poor</span> <span class="n">appetite</span><span class="o">|</span><span class="n">TEST</span>   <span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">TEST</span><span class="o">-</span><span class="n">PROBLEM</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">+-----------------+-------------+-------+-------+------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_tagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"ner_tags"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"pos_tags"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">reModel</span> <span class="k">=</span> <span class="nv">RelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"generic_re"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span><span class="s">"pos_tags"</span><span class="o">,</span><span class="s">"ner_chunks"</span><span class="o">,</span><span class="s">"dependencies"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"problem-test"</span><span class="o">,</span><span class="s">"problem-treatment"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
    

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                             <span class="n">documenter</span><span class="o">,</span> 
                                             <span class="n">sentencer</span><span class="o">,</span> 
                                             <span class="n">tokenizer</span><span class="o">,</span>
                                             <span class="n">words_embedder</span><span class="o">,</span> 
                                             <span class="n">pos_tagger</span><span class="o">,</span> 
                                             <span class="n">ner_tagger</span><span class="o">,</span> 
                                             <span class="n">ner_chunker</span><span class="o">,</span> 
                                             <span class="n">dependency_parser</span><span class="o">,</span> 
                                             <span class="n">reModel</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to "</span> <span class="o">+</span>
<span class="s">"presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis "</span> <span class="o">+</span>
<span class="s">"three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index "</span> <span class="o">+</span>
<span class="s">"( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and "</span> <span class="o">+</span>
<span class="s">"vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a "</span> <span class="o">+</span>
<span class="s">"respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin "</span> <span class="o">+</span>
<span class="s">"and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical "</span> <span class="o">+</span>
<span class="s">"examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was "</span> <span class="o">+</span>
<span class="s">"benign with no tenderness , guarding , or rigidity."</span>

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// Show results</span>

<span class="o">+-----------------+-------------+-------+-------+------------+----------+</span>
<span class="o">|</span><span class="n">chunk1</span>           <span class="o">|</span><span class="n">chunk2</span>       <span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span><span class="n">relations</span>   <span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+-----------------+-------------+-------+-------+------------+----------+</span>
<span class="o">|</span><span class="n">obesity</span>          <span class="o">|</span><span class="nc">BMI</span>          <span class="o">|</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="nc">TEST</span>   <span class="o">|</span><span class="nc">PROBLEM</span><span class="o">-</span><span class="nc">TEST</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">a</span> <span class="n">body</span> <span class="n">mass</span> <span class="n">index</span><span class="o">|</span><span class="nc">BMI</span>          <span class="o">|</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="nc">TEST</span>   <span class="o">|</span><span class="nc">PROBLEM</span><span class="o">-</span><span class="nc">TEST</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">BMI</span>              <span class="o">|</span><span class="n">polyuria</span>     <span class="o">|</span><span class="nc">TEST</span>   <span class="o">|</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="nc">TEST</span><span class="o">-</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">BMI</span>              <span class="o">|</span><span class="n">polydipsia</span>   <span class="o">|</span><span class="nc">TEST</span>   <span class="o">|</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="nc">TEST</span><span class="o">-</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">BMI</span>              <span class="o">|</span><span class="n">poor</span> <span class="n">appetite</span><span class="o">|</span><span class="nc">TEST</span>   <span class="o">|</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="nc">TEST</span><span class="o">-</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">+-----------------+-------------+-------+-------+------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="genericsvmclassifier">GenericSVMClassifier</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Creates a generic single-label classifier which uses pre-generated Tensorflow graphs. The model operates on FEATURE_VECTOR annotations which can be produced using FeatureAssembler. Requires the FeaturesAssembler to create the input.</p>

    <p>Parameters:</p>

    <p><code class="language-plaintext highlighter-rouge">featureScaling</code>: Feature scaling method. Possible values are ‘zscore’, ‘minmax’ or empty (no scaling) (default:’’)</p>

    <p><code class="language-plaintext highlighter-rouge">multiClass</code>: Whether to return only the label with the highest confidence score or all labels (default: False)</p>

    <p><code class="language-plaintext highlighter-rouge">inputCols</code>: previous annotations columns, if renamed (default: [‘features’])</p>

    <p><code class="language-plaintext highlighter-rouge">outputCol</code>: output annotation column. can be left default. (default: class)</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/generic_svm_classifier/index.html#sparknlp_jsl.annotator.classification.generic_svm_classifier.GenericSVMClassifierModel">GenericSVMClassifier</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/GenericSVMClassifierModel.html">GenericSVMClassifier</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/GenericSVMClassifierModel.ipynb">GenericSVMClassifierNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">features_asm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">generic_classifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">GenericSVMClassifierModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"generic_svm_classifier_ade"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"features"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"class"</span><span class="p">)</span>

<span class="n">clf_Pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">sentence_embeddings</span><span class="p">,</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">generic_classifier</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"""None of the patients required treatment for the overdose."""</span><span class="p">],</span> 
 <span class="p">[</span><span class="s">"""I feel a bit drowsy &amp; have a little blurred vision after taking an insulin"""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">clf_Pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>  <span class="c1"># sample df
</span>
<span class="o">+----------------------------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span>                                                                                                <span class="n">text</span><span class="o">|</span> <span class="n">result</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span>                       <span class="n">Multicentric</span> <span class="n">canine</span> <span class="n">lymphoma</span> <span class="ow">in</span> <span class="n">a</span> <span class="mi">12</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span> <span class="n">keeshond</span><span class="p">:</span> <span class="n">chemotherapy</span> <span class="n">options</span><span class="p">.</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span>                             <span class="n">Pyomyositis</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">rare</span> <span class="n">disease</span><span class="p">,</span> <span class="n">encountered</span> <span class="n">mainly</span> <span class="ow">in</span> <span class="n">tropical</span> <span class="n">climates</span><span class="p">.</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span> <span class="n">Both</span> <span class="n">patients</span> <span class="n">subsequently</span> <span class="n">developed</span> <span class="n">markedly</span> <span class="n">elevated</span> <span class="n">EBV</span><span class="o">-</span><span class="n">DNA</span> <span class="n">titers</span> <span class="ow">in</span> <span class="n">association</span> <span class="k">with</span> <span class="n">monocl</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">Bortezomib</span><span class="o">-</span><span class="n">induced</span> <span class="n">paralytic</span> <span class="n">ileus</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">potential</span> <span class="n">gastrointestinal</span> <span class="n">side</span> <span class="n">effect</span> <span class="n">of</span> <span class="n">this</span> <span class="n">first</span><span class="o">-</span><span class="ow">in</span><span class="o">-</span><span class="n">c</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">However</span><span class="p">,</span> <span class="n">given</span> <span class="n">the</span> <span class="n">clinically</span> <span class="n">significant</span> <span class="n">result</span> <span class="n">to</span> <span class="n">the</span> <span class="n">interaction</span> <span class="n">between</span> <span class="n">tolazoline</span> <span class="ow">and</span> <span class="n">cimeti</span><span class="p">...</span><span class="o">|</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span>                                              <span class="n">How</span> <span class="n">much</span> <span class="n">do</span> <span class="n">novel</span> <span class="n">antipsychotics</span> <span class="n">benefit</span> <span class="n">the</span> <span class="n">patients</span><span class="err">?</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span> <span class="n">We</span> <span class="n">hypothesize</span> <span class="n">that</span> <span class="n">during</span> <span class="n">interferon</span> <span class="n">therapy</span><span class="p">,</span> <span class="n">melanocytes</span> <span class="n">may</span> <span class="n">produce</span> <span class="n">more</span> <span class="n">melanin</span> <span class="n">pigment</span> <span class="ow">in</span> <span class="n">t</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">They</span> <span class="n">seemed</span> <span class="n">to</span> <span class="n">involve</span> <span class="n">multiple</span> <span class="n">aetiological</span> <span class="n">factors</span><span class="p">,</span> <span class="n">such</span> <span class="k">as</span> <span class="n">autoimmune</span> <span class="n">thyroid</span> <span class="n">disease</span><span class="p">,</span> <span class="n">the</span> <span class="n">tox</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span>               <span class="n">Two</span> <span class="n">days</span> <span class="n">after</span> <span class="n">completing</span> <span class="n">this</span> <span class="n">regimen</span><span class="p">,</span> <span class="n">the</span> <span class="n">patient</span> <span class="n">developed</span> <span class="n">a</span> <span class="n">rash</span> <span class="k">with</span> <span class="n">blistering</span><span class="p">.</span><span class="o">|</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">A</span> <span class="n">diagnosis</span> <span class="n">of</span> <span class="n">masked</span> <span class="n">theophylline</span> <span class="n">poisoning</span> <span class="n">should</span> <span class="n">be</span> <span class="n">considered</span> <span class="ow">in</span> <span class="n">similar</span> <span class="n">situations</span> <span class="n">involving</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span> <span class="n">The</span> <span class="n">overall</span> <span class="n">response</span> <span class="n">rate</span> <span class="n">of</span> <span class="n">these</span> <span class="mi">24</span> <span class="n">refractory</span> <span class="n">lymphomas</span> <span class="n">to</span> <span class="n">gemcitabine</span><span class="o">-</span><span class="n">containing</span> <span class="n">regimens</span> <span class="n">wa</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">Development</span> <span class="n">of</span> <span class="n">sarcoidosis</span> <span class="n">during</span> <span class="n">interferon</span> <span class="n">alpha</span> <span class="mi">2</span><span class="n">b</span> <span class="ow">and</span> <span class="n">ribavirin</span> <span class="n">combination</span> <span class="n">therapy</span> <span class="k">for</span> <span class="n">chron</span><span class="p">...</span><span class="o">|</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">A</span> <span class="n">patient</span> <span class="k">with</span> <span class="n">coccidioidal</span> <span class="n">meningitis</span> <span class="n">was</span> <span class="n">treated</span> <span class="k">with</span> <span class="n">intrathecally</span> <span class="n">administered</span> <span class="n">amphotericin</span> <span class="n">B</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span>                                                <span class="n">Renal</span> <span class="n">failure</span> <span class="n">associated</span> <span class="k">with</span> <span class="n">the</span> <span class="n">use</span> <span class="n">of</span> <span class="n">dextran</span><span class="o">-</span><span class="mf">40.</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span> <span class="n">However</span><span class="p">,</span> <span class="k">with</span> <span class="n">increased</span> <span class="n">experience</span> <span class="ow">in</span> <span class="n">applying</span> <span class="n">BCG</span><span class="p">,</span> <span class="n">the</span> <span class="n">side</span> <span class="n">effects</span> <span class="n">now</span> <span class="n">appear</span> <span class="n">to</span> <span class="n">be</span> <span class="n">less</span> <span class="n">promi</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span>                        <span class="n">Hepatotoxicity</span> <span class="n">after</span> <span class="n">high</span><span class="o">-</span><span class="n">dose</span> <span class="n">methylprednisolone</span> <span class="k">for</span> <span class="n">demyelinating</span> <span class="n">disease</span><span class="p">.</span><span class="o">|</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span> <span class="n">Histopathological</span> <span class="n">findings</span> <span class="n">included</span> <span class="n">signs</span> <span class="n">of</span> <span class="n">orthokeratotic</span> <span class="n">hyperkeratosis</span><span class="p">,</span> <span class="n">moderate</span> <span class="n">follicular</span> <span class="p">...</span><span class="o">|</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span> <span class="n">Acute</span> <span class="n">spontaneous</span> <span class="n">TLS</span> <span class="ow">is</span> <span class="n">rare</span><span class="p">,</span> <span class="ow">and</span> <span class="n">it</span> <span class="n">has</span> <span class="n">been</span> <span class="n">described</span> <span class="ow">in</span> <span class="n">leukemia</span> <span class="ow">and</span> <span class="n">lymphoma</span> <span class="ow">and</span> <span class="ow">in</span> <span class="n">some</span> <span class="n">pa</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">We</span> <span class="n">present</span> <span class="n">a</span> <span class="n">fatal</span> <span class="n">case</span> <span class="n">of</span> <span class="n">subacute</span> <span class="n">methanol</span> <span class="n">toxicity</span> <span class="k">with</span> <span class="n">associated</span> <span class="n">diffuse</span> <span class="n">brain</span> <span class="n">involvement</span><span class="p">,</span> <span class="p">...</span><span class="o">|</span> <span class="p">[</span><span class="bp">True</span><span class="p">]</span><span class="o">|</span>
<span class="o">|</span> <span class="n">The</span> <span class="n">reaction</span> <span class="n">was</span> <span class="n">thought</span> <span class="n">to</span> <span class="n">be</span> <span class="n">triggered</span> <span class="n">by</span> <span class="n">the</span> <span class="n">combination</span> <span class="n">of</span> <span class="n">radiation</span> <span class="ow">and</span> <span class="n">epidermal</span> <span class="n">growth</span> <span class="n">fa</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="bp">False</span><span class="p">]</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------+-------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceEmbeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"word_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPoolingStrategy</span><span class="o">(</span><span class="s">"AVERAGE"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">featuresAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">genericClassifier</span> <span class="k">=</span> <span class="nc">PretrainedPipeline</span><span class="o">(</span><span class="s">"generic_svm_classifier_ade"</span><span class="o">,</span> <span class="n">lang</span> <span class="k">=</span> <span class="s">"en"</span><span class="o">,</span> <span class="n">remoteLoc</span> <span class="k">=</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"features"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"class"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">wordEmbeddings</span><span class="o">,</span>
  <span class="n">sentenceEmbeddings</span><span class="o">,</span>
  <span class="n">featuresAssembler</span><span class="o">,</span>
  <span class="n">genericClassifier</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="s">"""None of the patients required treatment for the overdose."""</span><span class="o">),</span>
  <span class="o">(</span><span class="s">"""I feel a bit drowsy &amp; have a little blurred vision after taking an insulin"""</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">data</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>


<span class="o">+----------------------------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span>                                                                                                <span class="n">text</span><span class="o">|</span> <span class="n">result</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------+-------+</span>
<span class="o">|</span>                       <span class="nc">Multicentric</span> <span class="n">canine</span> <span class="n">lymphoma</span> <span class="n">in</span> <span class="n">a</span> <span class="mi">12</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span> <span class="n">keeshond</span><span class="k">:</span> <span class="kt">chemotherapy</span> <span class="kt">options.|</span><span class="err">[</span><span class="kt">False</span><span class="err">]</span><span class="kt">|</span>
<span class="kt">|</span>                             <span class="kt">Pyomyositis</span> <span class="kt">is</span> <span class="kt">a</span> <span class="kt">rare</span> <span class="kt">disease</span><span class="o">,</span> <span class="n">encountered</span> <span class="n">mainly</span> <span class="n">in</span> <span class="n">tropical</span> <span class="n">climates</span><span class="o">.|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span> <span class="nc">Both</span> <span class="n">patients</span> <span class="n">subsequently</span> <span class="n">developed</span> <span class="n">markedly</span> <span class="n">elevated</span> <span class="nc">EBV</span><span class="o">-</span><span class="nc">DNA</span> <span class="n">titers</span> <span class="n">in</span> <span class="n">association</span> <span class="k">with</span> <span class="n">monocl</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span><span class="nc">Bortezomib</span><span class="o">-</span><span class="n">induced</span> <span class="n">paralytic</span> <span class="n">ileus</span> <span class="n">is</span> <span class="n">a</span> <span class="n">potential</span> <span class="n">gastrointestinal</span> <span class="n">side</span> <span class="n">effect</span> <span class="n">of</span> <span class="k">this</span> <span class="n">first</span><span class="o">-</span><span class="n">in</span><span class="o">-</span><span class="n">c</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span><span class="nc">However</span><span class="o">,</span> <span class="n">given</span> <span class="n">the</span> <span class="n">clinically</span> <span class="n">significant</span> <span class="n">result</span> <span class="n">to</span> <span class="n">the</span> <span class="n">interaction</span> <span class="n">between</span> <span class="n">tolazoline</span> <span class="n">and</span> <span class="n">cimeti</span><span class="o">...|</span> <span class="o">[</span><span class="kt">True</span><span class="o">]|</span>
<span class="o">|</span>                                              <span class="nc">How</span> <span class="n">much</span> <span class="k">do</span> <span class="n">novel</span> <span class="n">antipsychotics</span> <span class="n">benefit</span> <span class="n">the</span> <span class="n">patients</span><span class="o">?|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span> <span class="nc">We</span> <span class="n">hypothesize</span> <span class="n">that</span> <span class="n">during</span> <span class="n">interferon</span> <span class="n">therapy</span><span class="o">,</span> <span class="n">melanocytes</span> <span class="n">may</span> <span class="n">produce</span> <span class="n">more</span> <span class="n">melanin</span> <span class="n">pigment</span> <span class="n">in</span> <span class="n">t</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span><span class="nc">They</span> <span class="n">seemed</span> <span class="n">to</span> <span class="n">involve</span> <span class="n">multiple</span> <span class="n">aetiological</span> <span class="n">factors</span><span class="o">,</span> <span class="n">such</span> <span class="n">as</span> <span class="n">autoimmune</span> <span class="n">thyroid</span> <span class="n">disease</span><span class="o">,</span> <span class="n">the</span> <span class="n">tox</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span>               <span class="nc">Two</span> <span class="n">days</span> <span class="n">after</span> <span class="n">completing</span> <span class="k">this</span> <span class="n">regimen</span><span class="o">,</span> <span class="n">the</span> <span class="n">patient</span> <span class="n">developed</span> <span class="n">a</span> <span class="n">rash</span> <span class="k">with</span> <span class="n">blistering</span><span class="o">.|</span> <span class="o">[</span><span class="kt">True</span><span class="o">]|</span>
<span class="o">|</span><span class="n">A</span> <span class="n">diagnosis</span> <span class="n">of</span> <span class="n">masked</span> <span class="n">theophylline</span> <span class="n">poisoning</span> <span class="n">should</span> <span class="n">be</span> <span class="n">considered</span> <span class="n">in</span> <span class="n">similar</span> <span class="n">situations</span> <span class="n">involving</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span> <span class="nc">The</span> <span class="n">overall</span> <span class="n">response</span> <span class="n">rate</span> <span class="n">of</span> <span class="n">these</span> <span class="mi">24</span> <span class="n">refractory</span> <span class="n">lymphomas</span> <span class="n">to</span> <span class="n">gemcitabine</span><span class="o">-</span><span class="n">containing</span> <span class="n">regimens</span> <span class="n">wa</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span><span class="nc">Development</span> <span class="n">of</span> <span class="n">sarcoidosis</span> <span class="n">during</span> <span class="n">interferon</span> <span class="n">alpha</span> <span class="mi">2</span><span class="n">b</span> <span class="n">and</span> <span class="n">ribavirin</span> <span class="n">combination</span> <span class="n">therapy</span> <span class="k">for</span> <span class="n">chron</span><span class="o">...|</span> <span class="o">[</span><span class="kt">True</span><span class="o">]|</span>
<span class="o">|</span><span class="n">A</span> <span class="n">patient</span> <span class="k">with</span> <span class="n">coccidioidal</span> <span class="n">meningitis</span> <span class="n">was</span> <span class="n">treated</span> <span class="k">with</span> <span class="n">intrathecally</span> <span class="n">administered</span> <span class="n">amphotericin</span> <span class="n">B</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span>                                                <span class="nc">Renal</span> <span class="n">failure</span> <span class="n">associated</span> <span class="k">with</span> <span class="n">the</span> <span class="n">use</span> <span class="n">of</span> <span class="n">dextran</span><span class="o">-</span><span class="mf">40.</span><span class="o">|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span> <span class="nc">However</span><span class="o">,</span> <span class="k">with</span> <span class="n">increased</span> <span class="n">experience</span> <span class="n">in</span> <span class="n">applying</span> <span class="nc">BCG</span><span class="o">,</span> <span class="n">the</span> <span class="n">side</span> <span class="n">effects</span> <span class="n">now</span> <span class="n">appear</span> <span class="n">to</span> <span class="n">be</span> <span class="n">less</span> <span class="n">promi</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span>                        <span class="nc">Hepatotoxicity</span> <span class="n">after</span> <span class="n">high</span><span class="o">-</span><span class="n">dose</span> <span class="n">methylprednisolone</span> <span class="k">for</span> <span class="n">demyelinating</span> <span class="n">disease</span><span class="o">.|</span> <span class="o">[</span><span class="kt">True</span><span class="o">]|</span>
<span class="o">|</span> <span class="nc">Histopathological</span> <span class="n">findings</span> <span class="n">included</span> <span class="n">signs</span> <span class="n">of</span> <span class="n">orthokeratotic</span> <span class="n">hyperkeratosis</span><span class="o">,</span> <span class="n">moderate</span> <span class="n">follicular</span> <span class="o">...|</span> <span class="o">[</span><span class="kt">True</span><span class="o">]|</span>
<span class="o">|</span> <span class="nc">Acute</span> <span class="n">spontaneous</span> <span class="nc">TLS</span> <span class="n">is</span> <span class="n">rare</span><span class="o">,</span> <span class="n">and</span> <span class="n">it</span> <span class="n">has</span> <span class="n">been</span> <span class="n">described</span> <span class="n">in</span> <span class="n">leukemia</span> <span class="n">and</span> <span class="n">lymphoma</span> <span class="n">and</span> <span class="n">in</span> <span class="n">some</span> <span class="n">pa</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">|</span><span class="nc">We</span> <span class="n">present</span> <span class="n">a</span> <span class="n">fatal</span> <span class="k">case</span> <span class="n">of</span> <span class="n">subacute</span> <span class="n">methanol</span> <span class="n">toxicity</span> <span class="k">with</span> <span class="n">associated</span> <span class="n">diffuse</span> <span class="n">brain</span> <span class="n">involvement</span><span class="o">,</span> <span class="o">...|</span> <span class="o">[</span><span class="kt">True</span><span class="o">]|</span>
<span class="o">|</span> <span class="nc">The</span> <span class="n">reaction</span> <span class="n">was</span> <span class="n">thought</span> <span class="n">to</span> <span class="n">be</span> <span class="n">triggered</span> <span class="n">by</span> <span class="n">the</span> <span class="n">combination</span> <span class="n">of</span> <span class="n">radiation</span> <span class="n">and</span> <span class="n">epidermal</span> <span class="n">growth</span> <span class="n">fa</span><span class="o">...|[</span><span class="kt">False</span><span class="o">]|</span>
<span class="o">+----------------------------------------------------------------------------------------------------+-------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">GenericSVMClassifier</code> is a derivative of GenericClassifier which implements SVM (Support Vector Machine) classification. The input to the model is FeatureVector and the output is category annotations with labels and corresponding confidence scores. The scores are standardized using the logistic function so that they vary between 0 and 1.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">batchSize</code>: (int) Batch size</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dropout</code>: (float) Dropout coefficient</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">epochsNumber</code>: (int) Maximum number of epochs to train</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">featureScaling</code>: (str) Feature scaling method. Possible values are ‘zscore’, ‘minmax’ or empty (no scaling)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">fixImbalance</code>: (boolean) Fix the imbalance in the training set by replicating examples of under represented categories</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">labelColumn</code>: (str) Column with label per each document</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">learningRate</code>: (float) Learning Rate</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">modelFile</code>: (str) Location of file of the model used for classification</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">multiClass</code>: (boolean) If multiClass is set, the model will return all the labels with corresponding scores. By default, multiClass is false.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputLogsPath</code>: (str) Folder path to save training logs. If no path is specified, the logs won’t be stored in disk. The path can be a local file path, a distributed file path (HDFS, DBFS), or a cloud storage (S3).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">validationSplit</code>: (float) The proportion of training dataset to be used as validation set.The model will be validated against this dataset on each Epoch and will not be used for training. The value should be between 0.0 and 1.0.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">FEATURE_VECTOR</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/generic_svm_classifier/index.html#sparknlp_jsl.annotator.classification.generic_svm_classifier.GenericSVMClassifierApproach">GenericSVMClassifier</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/classification/GenericSVMClassifierApproach.html">GenericSVMClassifier</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/Healthcare_MOOC/Spark_NLP_Udemy_MOOC/Healthcare_NLP/GenericSVMClassifierApproach.ipynb">GenericSVMClassifierNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">jojnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_healthcare_100d"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPoolingStrategy</span><span class="p">(</span><span class="s">"AVERAGE"</span><span class="p">)</span>

<span class="n">embeddings_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">sentence_embeddings</span><span class="p">,</span>
<span class="p">])</span>

<span class="n">trainingData_with_embeddings</span> <span class="o">=</span> <span class="n">embeddings_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
<span class="n">trainingData_with_embeddings</span> <span class="o">=</span> <span class="n">trainingData_with_embeddings</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span><span class="s">"category"</span><span class="p">,</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">graph_folder</span> <span class="o">=</span> <span class="s">"graph_folder"</span>

<span class="n">gc_svm_graph_builder</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">TFGraphBuilder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setModelName</span><span class="p">(</span><span class="s">"svm_classifier"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"feature_vector"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="s">"svm_graph.pb"</span><span class="p">)</span>

<span class="n">features_asm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">FeaturesAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"feature_vector"</span><span class="p">)</span>

<span class="n">gen_clf</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">GenericSVMClassifierApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"category"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"feature_vector"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">graph_folder</span><span class="si">}</span><span class="s">/svm_graph.pb"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.015</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="n">log_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="c1"># .setValidationSplit(0.1)
</span>
<span class="n">clf_Pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">features_asm</span><span class="p">,</span>
    <span class="n">gc_svm_graph_builder</span><span class="p">,</span>
    <span class="n">gen_clf</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">clf_Pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData_with_embeddings</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">stages</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">write</span><span class="p">().</span><span class="n">overwrite</span><span class="p">().</span><span class="n">save</span><span class="p">(</span><span class="s">'/model_path/model_name'</span><span class="p">)</span>

<span class="c1">#sample training data
</span>    <span class="n">text</span>	                                            <span class="n">category</span>
<span class="mi">0</span>	<span class="n">Clioquinol</span> <span class="n">intoxication</span> <span class="n">occurring</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">trea</span><span class="p">...</span>	<span class="n">neg</span>
<span class="mi">1</span>	<span class="s">"Retinoic acid syndrome"</span> <span class="n">was</span> <span class="n">prevented</span> <span class="k">with</span> <span class="n">s</span><span class="p">...</span>	<span class="n">neg</span>
<span class="mi">2</span>	<span class="n">BACKGROUND</span><span class="p">:</span> <span class="n">External</span> <span class="n">beam</span> <span class="n">radiation</span> <span class="n">therapy</span> <span class="n">o</span><span class="p">...</span>	<span class="n">neg</span>
<span class="mi">3</span>	<span class="n">Although</span> <span class="n">the</span> <span class="n">enuresis</span> <span class="n">ceased</span><span class="p">,</span> <span class="n">she</span> <span class="n">developed</span> <span class="n">t</span><span class="p">...</span>	<span class="n">neg</span>
<span class="mi">4</span>	<span class="n">A</span> <span class="mi">42</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span> <span class="n">woman</span> <span class="n">had</span> <span class="n">uneventful</span> <span class="n">bilateral</span> <span class="p">...</span>	<span class="n">neg</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  
<span class="k">val</span> <span class="nv">sentenceEmbeddings</span> <span class="k">=</span> <span class="nc">BertSentenceEmbeddings</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embedding"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">featuresAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FeaturesAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence_embedding"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"feature_vector"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">svmClassifier</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GenericSVMClassifierApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"feature_vector"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"src/test/resources/classification/svm_graph.pb"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMultiClass</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.01f</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceEmbeddings</span><span class="o">,</span>
  <span class="n">featuresAssembler</span><span class="o">,</span>
  <span class="n">svmClassifier</span><span class="o">,</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="iobtagger">IOBTagger</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The IOBTagger chunk tag (Chunk based) outputs, namely NerConverter and ChunkMerger, serve the purpose of converting token tags into Named Entity Recognition (NER) tags (token-based). These tags help to identify and categorize specific entities within a given text, enabling valuable information and context to be extracted from tokens.
For example output columns as inputs from
<a href="/docs/en/annotators#nerconverter">NerConverter</a>
and <a href="/docs/en/annotators#tokenizer">Tokenizer</a> can be used to merge.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">TOKEN, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/iob_tagger/index.html#sparknlp_jsl.annotator.ner.iob_tagger.IOBTagger">IOBTagger</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/IOBTagger.html">IOBTagger</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/IOBTagger.ipynb">IOBTaggerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 
<span class="c1"># Pipeline stages are defined where NER is done. NER is converted to chunks.
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">)</span>

<span class="n">nerModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology_greedy"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Define the IOB tagger, which needs tokens and chunks as input. Show results.
</span><span class="n">iobTagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">IOBTagger</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">docAssembler</span><span class="p">,</span>
                            <span class="n">sentenceDetector</span><span class="p">,</span>
                            <span class="n">tokenizer</span><span class="p">,</span>
                            <span class="n">embeddings</span><span class="p">,</span>
                            <span class="n">nerModel</span><span class="p">,</span>
                            <span class="n">nerConverter</span><span class="p">,</span>
                            <span class="n">iobTagger</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO."</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># chunk level result
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_chunk) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span>
              <span class="s">"a.end"</span><span class="p">,</span>
              <span class="s">"a.result as ner_chunk"</span><span class="p">,</span>
              <span class="s">"a.metadata.entity as ner_label"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----+---+-------------------------------------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_chunk</span>                                  <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-----+---+-------------------------------------------+---------+</span>
<span class="o">|</span><span class="mi">27</span>   <span class="o">|</span><span class="mi">50</span> <span class="o">|</span><span class="mi">1</span> <span class="n">capsule</span> <span class="n">of</span> <span class="n">Advil</span> <span class="mi">10</span> <span class="n">mg</span>                   <span class="o">|</span><span class="n">DRUG</span>     <span class="o">|</span>
<span class="o">|</span><span class="mi">52</span>   <span class="o">|</span><span class="mi">61</span> <span class="o">|</span><span class="k">for</span> <span class="mi">5</span> <span class="n">days</span>                                 <span class="o">|</span><span class="n">DURATION</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">67</span>   <span class="o">|</span><span class="mi">109</span><span class="o">|</span><span class="n">magnesium</span> <span class="n">hydroxide</span> <span class="mi">100</span><span class="n">mg</span><span class="o">/</span><span class="mi">1</span><span class="n">ml</span> <span class="n">suspension</span> <span class="n">PO</span><span class="o">|</span><span class="n">DRUG</span>     <span class="o">|</span>
<span class="o">+-----+---+-------------------------------------------+---------+</span>

<span class="c1"># token level result
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_label) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span>
              <span class="s">"a.end"</span><span class="p">,</span>
              <span class="s">"a.metadata.word as word"</span><span class="p">,</span>
              <span class="s">"a.result as chunk"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----+---+----------+----------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">word</span>      <span class="o">|</span><span class="n">chunk</span>     <span class="o">|</span>
<span class="o">+-----+---+----------+----------+</span>
<span class="o">|</span><span class="mi">0</span>    <span class="o">|</span><span class="mi">2</span>  <span class="o">|</span><span class="n">The</span>       <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">4</span>    <span class="o">|</span><span class="mi">10</span> <span class="o">|</span><span class="n">patient</span>   <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">12</span>   <span class="o">|</span><span class="mi">14</span> <span class="o">|</span><span class="n">was</span>       <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">16</span>   <span class="o">|</span><span class="mi">25</span> <span class="o">|</span><span class="n">prescribed</span><span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">27</span>   <span class="o">|</span><span class="mi">27</span> <span class="o">|</span><span class="mi">1</span>         <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">29</span>   <span class="o">|</span><span class="mi">35</span> <span class="o">|</span><span class="n">capsule</span>   <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">37</span>   <span class="o">|</span><span class="mi">38</span> <span class="o">|</span><span class="n">of</span>        <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">40</span>   <span class="o">|</span><span class="mi">44</span> <span class="o">|</span><span class="n">Advil</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">46</span>   <span class="o">|</span><span class="mi">47</span> <span class="o">|</span><span class="mi">10</span>        <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">49</span>   <span class="o">|</span><span class="mi">50</span> <span class="o">|</span><span class="n">mg</span>        <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">52</span>   <span class="o">|</span><span class="mi">54</span> <span class="o">|</span><span class="k">for</span>       <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">DURATION</span><span class="o">|</span>
<span class="o">|</span><span class="mi">56</span>   <span class="o">|</span><span class="mi">56</span> <span class="o">|</span><span class="mi">5</span>         <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DURATION</span><span class="o">|</span>
<span class="o">|</span><span class="mi">58</span>   <span class="o">|</span><span class="mi">61</span> <span class="o">|</span><span class="n">days</span>      <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DURATION</span><span class="o">|</span>
<span class="o">|</span><span class="mi">63</span>   <span class="o">|</span><span class="mi">65</span> <span class="o">|</span><span class="ow">and</span>       <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">67</span>   <span class="o">|</span><span class="mi">75</span> <span class="o">|</span><span class="n">magnesium</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">77</span>   <span class="o">|</span><span class="mi">85</span> <span class="o">|</span><span class="n">hydroxide</span> <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">87</span>   <span class="o">|</span><span class="mi">95</span> <span class="o">|</span><span class="mi">100</span><span class="n">mg</span><span class="o">/</span><span class="mi">1</span><span class="n">ml</span> <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">97</span>   <span class="o">|</span><span class="mi">106</span><span class="o">|</span><span class="n">suspension</span><span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">108</span>  <span class="o">|</span><span class="mi">109</span><span class="o">|</span><span class="n">PO</span>        <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">110</span><span class="o">|</span><span class="p">.</span>         <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">+-----+---+----------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>
<span class="c1"># Pipeline stages are defined where NER is done. NER is converted to chunks.
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">)</span>

<span class="n">nerModel</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Define the IOB tagger, which needs tokens and chunks as input. Show results.
</span><span class="n">iobTagger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">IOBTagger</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">docAssembler</span><span class="p">,</span>
                            <span class="n">sentenceDetector</span><span class="p">,</span>
                            <span class="n">tokenizer</span><span class="p">,</span>
                            <span class="n">embeddings</span><span class="p">,</span>
                            <span class="n">nerModel</span><span class="p">,</span>
                            <span class="n">nerConverter</span><span class="p">,</span>
                            <span class="n">iobTagger</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""In 2020, we acquired certain assets of Spell Security Private Limited (also known as "Spell Security"). More specifically, their Compliance product - Policy Compliance (PC)")."""</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>  

<span class="c1"># chunk level result
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_chunk) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span>
              <span class="s">"a.end"</span><span class="p">,</span>
              <span class="s">"a.result as ner_chunk"</span><span class="p">,</span>
              <span class="s">"a.metadata.entity as ner_label"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----+---+------------------------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_chunk</span>                     <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-----+---+------------------------------+---------+</span>
<span class="o">|</span><span class="mi">39</span>   <span class="o">|</span><span class="mi">68</span> <span class="o">|</span><span class="n">Spell</span> <span class="n">Security</span> <span class="n">Private</span> <span class="n">Limited</span><span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">86</span>   <span class="o">|</span><span class="mi">99</span> <span class="o">|</span><span class="n">Spell</span> <span class="n">Security</span>                <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">129</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="n">Compliance</span>                    <span class="o">|</span><span class="n">PRODUCT</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">150</span>  <span class="o">|</span><span class="mi">166</span><span class="o">|</span><span class="n">Policy</span> <span class="n">Compliance</span>             <span class="o">|</span><span class="n">PRODUCT</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">169</span>  <span class="o">|</span><span class="mi">170</span><span class="o">|</span><span class="n">PC</span>                            <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">+-----+---+------------------------------+---------+</span>

<span class="c1"># token level result
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_label) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span>
              <span class="s">"a.end"</span><span class="p">,</span>
              <span class="s">"a.metadata.word as word"</span><span class="p">,</span>
              <span class="s">"a.result as chunk"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----+---+------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">word</span>        <span class="o">|</span><span class="n">chunk</span>    <span class="o">|</span>
<span class="o">+-----+---+------------+---------+</span>
<span class="o">|</span><span class="mi">0</span>    <span class="o">|</span><span class="mi">1</span>  <span class="o">|</span><span class="n">In</span>          <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">3</span>    <span class="o">|</span><span class="mi">6</span>  <span class="o">|</span><span class="mi">2020</span>        <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">7</span>    <span class="o">|</span><span class="mi">7</span>  <span class="o">|</span><span class="p">,</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">9</span>    <span class="o">|</span><span class="mi">10</span> <span class="o">|</span><span class="n">we</span>          <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">12</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">acquired</span>    <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">21</span>   <span class="o">|</span><span class="mi">27</span> <span class="o">|</span><span class="n">certain</span>     <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">29</span>   <span class="o">|</span><span class="mi">34</span> <span class="o">|</span><span class="n">assets</span>      <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">36</span>   <span class="o">|</span><span class="mi">37</span> <span class="o">|</span><span class="n">of</span>          <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">39</span>   <span class="o">|</span><span class="mi">43</span> <span class="o">|</span><span class="n">Spell</span>       <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ORG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">45</span>   <span class="o">|</span><span class="mi">52</span> <span class="o">|</span><span class="n">Security</span>    <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">54</span>   <span class="o">|</span><span class="mi">60</span> <span class="o">|</span><span class="n">Private</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">62</span>   <span class="o">|</span><span class="mi">68</span> <span class="o">|</span><span class="n">Limited</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">70</span>   <span class="o">|</span><span class="mi">70</span> <span class="o">|</span><span class="p">(</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">71</span>   <span class="o">|</span><span class="mi">74</span> <span class="o">|</span><span class="n">also</span>        <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">76</span>   <span class="o">|</span><span class="mi">80</span> <span class="o">|</span><span class="n">known</span>       <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">82</span>   <span class="o">|</span><span class="mi">83</span> <span class="o">|</span><span class="k">as</span>          <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">85</span>   <span class="o">|</span><span class="mi">85</span> <span class="o">|</span><span class="s">"           |0        |
|86   |90 |Spell       |B-ALIAS  |
|92   |99 |Security    |I-ALIAS  |
|100  |102|"</span><span class="p">).</span>         <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">104</span>  <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="n">More</span>        <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">109</span>  <span class="o">|</span><span class="mi">120</span><span class="o">|</span><span class="n">specifically</span><span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">121</span>  <span class="o">|</span><span class="mi">121</span><span class="o">|</span><span class="p">,</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">123</span>  <span class="o">|</span><span class="mi">127</span><span class="o">|</span><span class="n">their</span>       <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">129</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="n">Compliance</span>  <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">PRODUCT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">140</span>  <span class="o">|</span><span class="mi">146</span><span class="o">|</span><span class="n">product</span>     <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">148</span>  <span class="o">|</span><span class="mi">148</span><span class="o">|-</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">150</span>  <span class="o">|</span><span class="mi">155</span><span class="o">|</span><span class="n">Policy</span>      <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">PRODUCT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">157</span>  <span class="o">|</span><span class="mi">166</span><span class="o">|</span><span class="n">Compliance</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">PRODUCT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">168</span>  <span class="o">|</span><span class="mi">168</span><span class="o">|</span><span class="p">(</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">169</span>  <span class="o">|</span><span class="mi">170</span><span class="o">|</span><span class="n">PC</span>          <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ALIAS</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">171</span>  <span class="o">|</span><span class="mi">174</span><span class="o">|</span><span class="p">)</span><span class="s">").        |0        |
+-----+---+------------+---------+
</span></code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span> 
<span class="c1"># Pipeline stages are defined where NER is done. NER is converted to chunks.
</span>
<span class="n">docAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embs"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embs"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="c1"># Define the IOB tagger, which needs tokens and chunks as input. Show results.
</span><span class="n">iobTagger</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">IOBTagger</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">docAssembler</span><span class="p">,</span> 
                            <span class="n">sentenceDetector</span><span class="p">,</span> 
                            <span class="n">tokenizer</span><span class="p">,</span> 
                            <span class="n">embeddings</span><span class="p">,</span> 
                            <span class="n">ner_model</span><span class="p">,</span> 
                            <span class="n">nerConverter</span><span class="p">,</span> 
                            <span class="n">iobTagger</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""This INTELLECTUAL PROPERTY AGREEMENT (this "Agreement"), dated as of December 31, 2018 (the "Effective Date") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ("Seller") and AFI Licensing LLC, a Delaware limited liability company ("Licensing" and together with Seller, "Arizona") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand, a "Party" and collectively, the "Parties").
"""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span> 

<span class="c1"># chunk level result
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_chunk) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span>
              <span class="s">"a.end"</span><span class="p">,</span>
              <span class="s">"a.result as ner_chunk"</span><span class="p">,</span>
              <span class="s">"a.metadata.entity as ner_label"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----+---+-----------------------------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_chunk</span>                          <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-----+---+-----------------------------------+---------+</span>
<span class="o">|</span><span class="mi">141</span>  <span class="o">|</span><span class="mi">165</span><span class="o">|</span><span class="n">Armstrong</span> <span class="n">Flooring</span><span class="p">,</span> <span class="n">Inc</span><span class="p">.,</span>          <span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">192</span>  <span class="o">|</span><span class="mi">197</span><span class="o">|</span><span class="n">Seller</span>                             <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">205</span>  <span class="o">|</span><span class="mi">221</span><span class="o">|</span><span class="n">AFI</span> <span class="n">Licensing</span> <span class="n">LLC</span>                  <span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">263</span>  <span class="o">|</span><span class="mi">271</span><span class="o">|</span><span class="n">Licensing</span>                          <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">292</span>  <span class="o">|</span><span class="mi">297</span><span class="o">|</span><span class="n">Seller</span>                             <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">301</span>  <span class="o">|</span><span class="mi">307</span><span class="o">|</span><span class="n">Arizona</span>                            <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">315</span>  <span class="o">|</span><span class="mi">330</span><span class="o">|</span><span class="n">AHF</span> <span class="n">Holding</span><span class="p">,</span> <span class="n">Inc</span>                   <span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">399</span>  <span class="o">|</span><span class="mi">403</span><span class="o">|</span><span class="n">Buyer</span>                              <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">411</span>  <span class="o">|</span><span class="mi">445</span><span class="o">|</span><span class="n">Armstrong</span> <span class="n">Hardwood</span> <span class="n">Flooring</span> <span class="n">Company</span><span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">478</span>  <span class="o">|</span><span class="mi">484</span><span class="o">|</span><span class="n">Company</span>                            <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">505</span>  <span class="o">|</span><span class="mi">509</span><span class="o">|</span><span class="n">Buyer</span>                              <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">516</span>  <span class="o">|</span><span class="mi">529</span><span class="o">|</span><span class="n">Buyer</span> <span class="n">Entities</span>                     <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">542</span>  <span class="o">|</span><span class="mi">548</span><span class="o">|</span><span class="n">Arizona</span>                            <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">574</span>  <span class="o">|</span><span class="mi">587</span><span class="o">|</span><span class="n">Buyer</span> <span class="n">Entities</span>                     <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">611</span>  <span class="o">|</span><span class="mi">615</span><span class="o">|</span><span class="n">Party</span>                              <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">641</span>  <span class="o">|</span><span class="mi">647</span><span class="o">|</span><span class="n">Parties</span>                            <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">+-----+---+-----------------------------------+---------+</span>

<span class="c1"># token level result
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(ner_label) as a"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"a.begin"</span><span class="p">,</span>
              <span class="s">"a.end"</span><span class="p">,</span>
              <span class="s">"a.metadata.word as word"</span><span class="p">,</span>
              <span class="s">"a.result as chunk"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----+---+------------+-------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">word</span>        <span class="o">|</span><span class="n">chunk</span>  <span class="o">|</span>
<span class="o">+-----+---+------------+-------+</span>
<span class="o">|</span><span class="mi">0</span>    <span class="o">|</span><span class="mi">3</span>  <span class="o">|</span><span class="n">This</span>        <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">16</span> <span class="o">|</span><span class="n">INTELLECTUAL</span><span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">18</span>   <span class="o">|</span><span class="mi">25</span> <span class="o">|</span><span class="n">PROPERTY</span>    <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">27</span>   <span class="o">|</span><span class="mi">35</span> <span class="o">|</span><span class="n">AGREEMENT</span>   <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">37</span>   <span class="o">|</span><span class="mi">37</span> <span class="o">|</span><span class="p">(</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">38</span>   <span class="o">|</span><span class="mi">41</span> <span class="o">|</span><span class="n">this</span>        <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">43</span>   <span class="o">|</span><span class="mi">43</span> <span class="o">|</span><span class="s">"           |0      |
|44   |52 |Agreement   |0      |
|53   |55 |"</span><span class="p">),</span>         <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">57</span>   <span class="o">|</span><span class="mi">61</span> <span class="o">|</span><span class="n">dated</span>       <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">63</span>   <span class="o">|</span><span class="mi">64</span> <span class="o">|</span><span class="k">as</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">66</span>   <span class="o">|</span><span class="mi">67</span> <span class="o">|</span><span class="n">of</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">69</span>   <span class="o">|</span><span class="mi">76</span> <span class="o">|</span><span class="n">December</span>    <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">78</span>   <span class="o">|</span><span class="mi">79</span> <span class="o">|</span><span class="mi">31</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">80</span>   <span class="o">|</span><span class="mi">80</span> <span class="o">|</span><span class="p">,</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">82</span>   <span class="o">|</span><span class="mi">85</span> <span class="o">|</span><span class="mi">2018</span>        <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">87</span>   <span class="o">|</span><span class="mi">87</span> <span class="o">|</span><span class="p">(</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">88</span>   <span class="o">|</span><span class="mi">90</span> <span class="o">|</span><span class="n">the</span>         <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">92</span>   <span class="o">|</span><span class="mi">92</span> <span class="o">|</span><span class="s">"           |0      |
|93   |101|Effective   |0      |
|103  |106|Date        |0      |
|107  |108|"</span><span class="p">)</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">111</span><span class="o">|</span><span class="ow">is</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">113</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">entered</span>     <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">121</span>  <span class="o">|</span><span class="mi">124</span><span class="o">|</span><span class="n">into</span>        <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">126</span>  <span class="o">|</span><span class="mi">127</span><span class="o">|</span><span class="n">by</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">129</span>  <span class="o">|</span><span class="mi">131</span><span class="o">|</span><span class="ow">and</span>         <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">133</span>  <span class="o">|</span><span class="mi">139</span><span class="o">|</span><span class="n">between</span>     <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">141</span>  <span class="o">|</span><span class="mi">149</span><span class="o">|</span><span class="n">Armstrong</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">151</span>  <span class="o">|</span><span class="mi">158</span><span class="o">|</span><span class="n">Flooring</span>    <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">159</span>  <span class="o">|</span><span class="mi">159</span><span class="o">|</span><span class="p">,</span>           <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">161</span>  <span class="o">|</span><span class="mi">163</span><span class="o">|</span><span class="n">Inc</span>         <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">164</span>  <span class="o">|</span><span class="mi">165</span><span class="o">|</span><span class="p">.,</span>          <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">167</span>  <span class="o">|</span><span class="mi">167</span><span class="o">|</span><span class="n">a</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">169</span>  <span class="o">|</span><span class="mi">176</span><span class="o">|</span><span class="n">Delaware</span>    <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">178</span>  <span class="o">|</span><span class="mi">188</span><span class="o">|</span><span class="n">corporation</span> <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">190</span>  <span class="o">|</span><span class="mi">191</span><span class="o">|</span><span class="p">(</span><span class="s">"          |0      |
|192  |197|Seller      |B-ALIAS|
|198  |199|"</span><span class="p">)</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">201</span>  <span class="o">|</span><span class="mi">203</span><span class="o">|</span><span class="ow">and</span>         <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">205</span>  <span class="o">|</span><span class="mi">207</span><span class="o">|</span><span class="n">AFI</span>         <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">209</span>  <span class="o">|</span><span class="mi">217</span><span class="o">|</span><span class="n">Licensing</span>   <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">219</span>  <span class="o">|</span><span class="mi">221</span><span class="o">|</span><span class="n">LLC</span>         <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">222</span>  <span class="o">|</span><span class="mi">222</span><span class="o">|</span><span class="p">,</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">224</span>  <span class="o">|</span><span class="mi">224</span><span class="o">|</span><span class="n">a</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">226</span>  <span class="o">|</span><span class="mi">233</span><span class="o">|</span><span class="n">Delaware</span>    <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">235</span>  <span class="o">|</span><span class="mi">241</span><span class="o">|</span><span class="n">limited</span>     <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">243</span>  <span class="o">|</span><span class="mi">251</span><span class="o">|</span><span class="n">liability</span>   <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">253</span>  <span class="o">|</span><span class="mi">259</span><span class="o">|</span><span class="n">company</span>     <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">261</span>  <span class="o">|</span><span class="mi">262</span><span class="o">|</span><span class="p">(</span><span class="s">"          |0      |
+-----+---+------------+-------+
only showing top 50 rows
</span></code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Pipeline stages are defined where NER is done. NER is converted to chunks. </span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology_greedy"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embs"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
  
<span class="c1">// Define the IOB tagger,which needs tokens and chunks as input. Show results. </span>
<span class="k">val</span> <span class="nv">iobTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IOBTagger</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_label"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                              <span class="n">docAssembler</span><span class="o">,</span>
                                              <span class="n">sentenceDetector</span><span class="o">,</span>
                                              <span class="n">tokenizer</span><span class="o">,</span>
                                              <span class="n">embeddings</span><span class="o">,</span> 
                                              <span class="n">nerModel</span><span class="o">,</span>
                                              <span class="n">nerConverter</span><span class="o">,</span>
                                              <span class="n">iobTagger</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"The patient was prescribed 1 capsule of Advil 10 mg for 5 days and magnesium hydroxide 100mg/1ml suspension PO."</span> 
<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// chunk level result</span>
<span class="o">+-----+---+-------------------------------------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_chunk</span>                                  <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-----+---+-------------------------------------------+---------+</span>
<span class="o">|</span><span class="mi">27</span>   <span class="o">|</span><span class="mi">50</span> <span class="o">|</span><span class="mi">1</span> <span class="n">capsule</span> <span class="n">of</span> <span class="nc">Advil</span> <span class="mi">10</span> <span class="n">mg</span>                   <span class="o">|</span><span class="nc">DRUG</span>     <span class="o">|</span>
<span class="o">|</span><span class="mi">52</span>   <span class="o">|</span><span class="mi">61</span> <span class="o">|</span><span class="k">for</span> <span class="mi">5</span> <span class="n">days</span>                                 <span class="o">|</span><span class="nc">DURATION</span> <span class="o">|</span>
<span class="o">|</span><span class="mi">67</span>   <span class="o">|</span><span class="mi">109</span><span class="o">|</span><span class="n">magnesium</span> <span class="n">hydroxide</span> <span class="mi">100</span><span class="n">mg</span><span class="o">/</span><span class="mi">1</span><span class="n">ml</span> <span class="n">suspension</span> <span class="nc">PO</span><span class="o">|</span><span class="nc">DRUG</span>     <span class="o">|</span>
<span class="o">+-----+---+-------------------------------------------+---------+</span>

<span class="c1">// token level result</span>
<span class="o">+-----+---+----------+----------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">word</span>      <span class="o">|</span><span class="n">chunk</span>     <span class="o">|</span>
<span class="o">+-----+---+----------+----------+</span>
<span class="o">|</span><span class="mi">0</span>    <span class="o">|</span><span class="mi">2</span>  <span class="o">|</span><span class="nc">The</span>       <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">4</span>    <span class="o">|</span><span class="mi">10</span> <span class="o">|</span><span class="n">patient</span>   <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">12</span>   <span class="o">|</span><span class="mi">14</span> <span class="o">|</span><span class="n">was</span>       <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">16</span>   <span class="o">|</span><span class="mi">25</span> <span class="o">|</span><span class="n">prescribed</span><span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">27</span>   <span class="o">|</span><span class="mi">27</span> <span class="o">|</span><span class="mi">1</span>         <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">29</span>   <span class="o">|</span><span class="mi">35</span> <span class="o">|</span><span class="n">capsule</span>   <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">37</span>   <span class="o">|</span><span class="mi">38</span> <span class="o">|</span><span class="n">of</span>        <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">40</span>   <span class="o">|</span><span class="mi">44</span> <span class="o">|</span><span class="nc">Advil</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">46</span>   <span class="o">|</span><span class="mi">47</span> <span class="o">|</span><span class="mi">10</span>        <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">49</span>   <span class="o">|</span><span class="mi">50</span> <span class="o">|</span><span class="n">mg</span>        <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">52</span>   <span class="o">|</span><span class="mi">54</span> <span class="o">|</span><span class="k">for</span>       <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">DURATION</span><span class="o">|</span>
<span class="o">|</span><span class="mi">56</span>   <span class="o">|</span><span class="mi">56</span> <span class="o">|</span><span class="mi">5</span>         <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DURATION</span><span class="o">|</span>
<span class="o">|</span><span class="mi">58</span>   <span class="o">|</span><span class="mi">61</span> <span class="o">|</span><span class="n">days</span>      <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DURATION</span><span class="o">|</span>
<span class="o">|</span><span class="mi">63</span>   <span class="o">|</span><span class="mi">65</span> <span class="o">|</span><span class="n">and</span>       <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">|</span><span class="mi">67</span>   <span class="o">|</span><span class="mi">75</span> <span class="o">|</span><span class="n">magnesium</span> <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">77</span>   <span class="o">|</span><span class="mi">85</span> <span class="o">|</span><span class="n">hydroxide</span> <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">87</span>   <span class="o">|</span><span class="mi">95</span> <span class="o">|</span><span class="mi">100</span><span class="n">mg</span><span class="o">/</span><span class="mi">1</span><span class="n">ml</span> <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">97</span>   <span class="o">|</span><span class="mi">106</span><span class="o">|</span><span class="n">suspension</span><span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">108</span>  <span class="o">|</span><span class="mi">109</span><span class="o">|</span><span class="nc">PO</span>        <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">DRUG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">110</span><span class="o">|.</span>         <span class="o">|</span><span class="mi">0</span>         <span class="o">|</span>
<span class="o">+-----+---+----------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Pipeline stages are defined where NER is done. NER is converted to chunks. </span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embs"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="c1">// Define the IOB tagger,which needs tokens and chunks as input. Show results. </span>
<span class="k">val</span> <span class="nv">iobTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IOBTagger</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_label"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                              <span class="n">docAssembler</span><span class="o">,</span>
                                              <span class="n">sentenceDetector</span><span class="o">,</span>
                                              <span class="n">tokenizer</span><span class="o">,</span>
                                              <span class="n">embeddings</span><span class="o">,</span> 
                                              <span class="n">nerModel</span><span class="o">,</span> 
                                              <span class="n">nerConverter</span><span class="o">,</span>
                                              <span class="n">iobTagger</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""In 2020, we acquired certain assets of Spell Security Private Limited (also known as "Spell Security") . More specifically,their Compliance product - Policy Compliance (PC))."""</span> 
<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// chunk level result</span>
<span class="o">+-----+---+------------------------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_chunk</span>                     <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-----+---+------------------------------+---------+</span>
<span class="o">|</span><span class="mi">39</span>   <span class="o">|</span><span class="mi">68</span> <span class="o">|</span><span class="nc">Spell</span> <span class="nc">Security</span> <span class="nc">Private</span> <span class="nc">Limited</span><span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">86</span>   <span class="o">|</span><span class="mi">99</span> <span class="o">|</span><span class="nc">Spell</span> <span class="nc">Security</span>                <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">129</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="nc">Compliance</span>                    <span class="o">|</span><span class="nc">PRODUCT</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">150</span>  <span class="o">|</span><span class="mi">166</span><span class="o">|</span><span class="nc">Policy</span> <span class="nc">Compliance</span>             <span class="o">|</span><span class="nc">PRODUCT</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">169</span>  <span class="o">|</span><span class="mi">170</span><span class="o">|</span><span class="nc">PC</span>                            <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">+-----+---+------------------------------+---------+</span>

<span class="c1">// token level result</span>
<span class="o">+-----+---+------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">word</span>        <span class="o">|</span><span class="n">chunk</span>    <span class="o">|</span>
<span class="o">+-----+---+------------+---------+</span>
<span class="o">|</span><span class="mi">0</span>    <span class="o">|</span><span class="mi">1</span>  <span class="o">|</span><span class="nc">In</span>          <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">3</span>    <span class="o">|</span><span class="mi">6</span>  <span class="o">|</span><span class="mi">2020</span>        <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">7</span>    <span class="o">|</span><span class="mi">7</span>  <span class="o">|,</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">9</span>    <span class="o">|</span><span class="mi">10</span> <span class="o">|</span><span class="n">we</span>          <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">12</span>   <span class="o">|</span><span class="mi">19</span> <span class="o">|</span><span class="n">acquired</span>    <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">21</span>   <span class="o">|</span><span class="mi">27</span> <span class="o">|</span><span class="n">certain</span>     <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">29</span>   <span class="o">|</span><span class="mi">34</span> <span class="o">|</span><span class="n">assets</span>      <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">36</span>   <span class="o">|</span><span class="mi">37</span> <span class="o">|</span><span class="n">of</span>          <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">39</span>   <span class="o">|</span><span class="mi">43</span> <span class="o">|</span><span class="nc">Spell</span>       <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ORG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">45</span>   <span class="o">|</span><span class="mi">52</span> <span class="o">|</span><span class="nc">Security</span>    <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">54</span>   <span class="o">|</span><span class="mi">60</span> <span class="o">|</span><span class="nc">Private</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">62</span>   <span class="o">|</span><span class="mi">68</span> <span class="o">|</span><span class="nc">Limited</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">70</span>   <span class="o">|</span><span class="mi">70</span> <span class="o">|(</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">71</span>   <span class="o">|</span><span class="mi">74</span> <span class="o">|</span><span class="n">also</span>        <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">76</span>   <span class="o">|</span><span class="mi">80</span> <span class="o">|</span><span class="n">known</span>       <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">82</span>   <span class="o">|</span><span class="mi">83</span> <span class="o">|</span><span class="n">as</span>          <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">85</span>   <span class="o">|</span><span class="mi">85</span> <span class="o">|</span><span class="s">"           |0        |
|86   |90 |Spell       |B-ALIAS  |
|92   |99 |Security    |I-ALIAS  |
|100  |102|"</span><span class="o">).</span>         <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">104</span>  <span class="o">|</span><span class="mi">107</span><span class="o">|</span><span class="nc">More</span>        <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">109</span>  <span class="o">|</span><span class="mi">120</span><span class="o">|</span><span class="n">specifically</span><span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">121</span>  <span class="o">|</span><span class="mi">121</span><span class="o">|,</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">123</span>  <span class="o">|</span><span class="mi">127</span><span class="o">|</span><span class="n">their</span>       <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">129</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="nc">Compliance</span>  <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">PRODUCT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">140</span>  <span class="o">|</span><span class="mi">146</span><span class="o">|</span><span class="n">product</span>     <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">148</span>  <span class="o">|</span><span class="mi">148</span><span class="o">|-</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">150</span>  <span class="o">|</span><span class="mi">155</span><span class="o">|</span><span class="nc">Policy</span>      <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">PRODUCT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">157</span>  <span class="o">|</span><span class="mi">166</span><span class="o">|</span><span class="nc">Compliance</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">PRODUCT</span><span class="o">|</span>
<span class="o">|</span><span class="mi">168</span>  <span class="o">|</span><span class="mi">168</span><span class="o">|(</span>           <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">|</span><span class="mi">169</span>  <span class="o">|</span><span class="mi">170</span><span class="o">|</span><span class="nc">PC</span>          <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ALIAS</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">171</span>  <span class="o">|</span><span class="mi">174</span><span class="o">|)</span><span class="err">"</span><span class="o">).</span>        <span class="o">|</span><span class="mi">0</span>        <span class="o">|</span>
<span class="o">+-----+---+------------+---------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Pipeline stages are defined where NER is done. NER is converted to chunks. </span>
<span class="k">val</span> <span class="nv">docAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embs"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_orgs_prods_alias"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embs"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
  
<span class="c1">// Define the IOB tagger,which needs tokens and chunks as input. Show results. </span>
<span class="k">val</span> <span class="nv">iobTagger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">IOBTagger</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_label"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                              <span class="n">docAssembler</span><span class="o">,</span>
                                              <span class="n">sentenceDetector</span><span class="o">,</span>
                                              <span class="n">tokenizer</span><span class="o">,</span>
                                              <span class="n">embeddings</span><span class="o">,</span> 
                                              <span class="n">ner_model</span><span class="o">,</span>
                                              <span class="n">nerConverter</span><span class="o">,</span>
                                              <span class="n">iobTagger</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""This
 INTELLECTUAL PROPERTY AGREEMENT (this "Agreement") ,dated as of December 31,2018 (the "Effective Date") is entered into by and between Armstrong Flooring,Inc.,a Delaware corporation ("Seller") and AFI Licensing LLC,a Delaware limited liability company ("Licensing" and together with Seller,"Arizona") and AHF Holding,Inc. (formerly known as Tarzan HoldCo,Inc.) ,a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company,a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand,a "Party" and collectively,the "Parties") ."""</span> 
<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="c1">// chunk level result</span>
<span class="o">+-----+---+-----------------------------------+---------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_chunk</span>                          <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-----+---+-----------------------------------+---------+</span>
<span class="o">|</span><span class="mi">141</span>  <span class="o">|</span><span class="mi">165</span><span class="o">|</span><span class="nc">Armstrong</span> <span class="nc">Flooring</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">.,</span>          <span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">192</span>  <span class="o">|</span><span class="mi">197</span><span class="o">|</span><span class="nc">Seller</span>                             <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">205</span>  <span class="o">|</span><span class="mi">221</span><span class="o">|</span><span class="nc">AFI</span> <span class="nc">Licensing</span> <span class="nc">LLC</span>                  <span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">263</span>  <span class="o">|</span><span class="mi">271</span><span class="o">|</span><span class="nc">Licensing</span>                          <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">292</span>  <span class="o">|</span><span class="mi">297</span><span class="o">|</span><span class="nc">Seller</span>                             <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">301</span>  <span class="o">|</span><span class="mi">307</span><span class="o">|</span><span class="nc">Arizona</span>                            <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">315</span>  <span class="o">|</span><span class="mi">330</span><span class="o">|</span><span class="nc">AHF</span> <span class="nc">Holding</span><span class="o">,</span> <span class="nc">Inc</span>                   <span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">399</span>  <span class="o">|</span><span class="mi">403</span><span class="o">|</span><span class="nc">Buyer</span>                              <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">411</span>  <span class="o">|</span><span class="mi">445</span><span class="o">|</span><span class="nc">Armstrong</span> <span class="nc">Hardwood</span> <span class="nc">Flooring</span> <span class="nc">Company</span><span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">478</span>  <span class="o">|</span><span class="mi">484</span><span class="o">|</span><span class="nc">Company</span>                            <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">505</span>  <span class="o">|</span><span class="mi">509</span><span class="o">|</span><span class="nc">Buyer</span>                              <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">516</span>  <span class="o">|</span><span class="mi">529</span><span class="o">|</span><span class="nc">Buyer</span> <span class="nc">Entities</span>                     <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">542</span>  <span class="o">|</span><span class="mi">548</span><span class="o">|</span><span class="nc">Arizona</span>                            <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">574</span>  <span class="o">|</span><span class="mi">587</span><span class="o">|</span><span class="nc">Buyer</span> <span class="nc">Entities</span>                     <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">611</span>  <span class="o">|</span><span class="mi">615</span><span class="o">|</span><span class="nc">Party</span>                              <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">641</span>  <span class="o">|</span><span class="mi">647</span><span class="o">|</span><span class="nc">Parties</span>                            <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">+-----+---+-----------------------------------+---------+</span>

<span class="c1">// token level result</span>
<span class="o">+-----+---+------------+-------+</span>
<span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">word</span>        <span class="o">|</span><span class="n">chunk</span>  <span class="o">|</span>
<span class="o">+-----+---+------------+-------+</span>
<span class="o">|</span><span class="mi">0</span>    <span class="o">|</span><span class="mi">3</span>  <span class="o">|</span><span class="nc">This</span>        <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">5</span>    <span class="o">|</span><span class="mi">16</span> <span class="o">|</span><span class="nc">INTELLECTUAL</span><span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">18</span>   <span class="o">|</span><span class="mi">25</span> <span class="o">|</span><span class="nc">PROPERTY</span>    <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">27</span>   <span class="o">|</span><span class="mi">35</span> <span class="o">|</span><span class="nc">AGREEMENT</span>   <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">37</span>   <span class="o">|</span><span class="mi">37</span> <span class="o">|(</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">38</span>   <span class="o">|</span><span class="mi">41</span> <span class="o">|</span><span class="k">this</span>        <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">43</span>   <span class="o">|</span><span class="mi">43</span> <span class="o">|</span><span class="s">"           |0      |
|44   |52 |Agreement   |0      |
|53   |55 |"</span><span class="o">),</span>         <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">57</span>   <span class="o">|</span><span class="mi">61</span> <span class="o">|</span><span class="n">dated</span>       <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">63</span>   <span class="o">|</span><span class="mi">64</span> <span class="o">|</span><span class="n">as</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">66</span>   <span class="o">|</span><span class="mi">67</span> <span class="o">|</span><span class="n">of</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">69</span>   <span class="o">|</span><span class="mi">76</span> <span class="o">|</span><span class="nc">December</span>    <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">78</span>   <span class="o">|</span><span class="mi">79</span> <span class="o">|</span><span class="mi">31</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">80</span>   <span class="o">|</span><span class="mi">80</span> <span class="o">|,</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">82</span>   <span class="o">|</span><span class="mi">85</span> <span class="o">|</span><span class="mi">2018</span>        <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">87</span>   <span class="o">|</span><span class="mi">87</span> <span class="o">|(</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">88</span>   <span class="o">|</span><span class="mi">90</span> <span class="o">|</span><span class="n">the</span>         <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">92</span>   <span class="o">|</span><span class="mi">92</span> <span class="o">|</span><span class="s">"           |0      |
|93   |101|Effective   |0      |
|103  |106|Date        |0      |
|107  |108|"</span><span class="o">)</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">110</span>  <span class="o">|</span><span class="mi">111</span><span class="o">|</span><span class="n">is</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">113</span>  <span class="o">|</span><span class="mi">119</span><span class="o">|</span><span class="n">entered</span>     <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">121</span>  <span class="o">|</span><span class="mi">124</span><span class="o">|</span><span class="n">into</span>        <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">126</span>  <span class="o">|</span><span class="mi">127</span><span class="o">|</span><span class="n">by</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">129</span>  <span class="o">|</span><span class="mi">131</span><span class="o">|</span><span class="n">and</span>         <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">133</span>  <span class="o">|</span><span class="mi">139</span><span class="o">|</span><span class="n">between</span>     <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">141</span>  <span class="o">|</span><span class="mi">149</span><span class="o">|</span><span class="nc">Armstrong</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">151</span>  <span class="o">|</span><span class="mi">158</span><span class="o">|</span><span class="nc">Flooring</span>    <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">159</span>  <span class="o">|</span><span class="mi">159</span><span class="o">|,</span>           <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">161</span>  <span class="o">|</span><span class="mi">163</span><span class="o">|</span><span class="nc">Inc</span>         <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">164</span>  <span class="o">|</span><span class="mi">165</span><span class="o">|.,</span>          <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">167</span>  <span class="o">|</span><span class="mi">167</span><span class="o">|</span><span class="n">a</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">169</span>  <span class="o">|</span><span class="mi">176</span><span class="o">|</span><span class="nc">Delaware</span>    <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">178</span>  <span class="o">|</span><span class="mi">188</span><span class="o">|</span><span class="n">corporation</span> <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">190</span>  <span class="o">|</span><span class="mi">191</span><span class="o">|(</span><span class="s">"          |0      |
|192  |197|Seller      |B-ALIAS|
|198  |199|"</span><span class="o">)</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">201</span>  <span class="o">|</span><span class="mi">203</span><span class="o">|</span><span class="n">and</span>         <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">205</span>  <span class="o">|</span><span class="mi">207</span><span class="o">|</span><span class="nc">AFI</span>         <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">209</span>  <span class="o">|</span><span class="mi">217</span><span class="o">|</span><span class="nc">Licensing</span>   <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">219</span>  <span class="o">|</span><span class="mi">221</span><span class="o">|</span><span class="nc">LLC</span>         <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ORG</span>  <span class="o">|</span>
<span class="o">|</span><span class="mi">222</span>  <span class="o">|</span><span class="mi">222</span><span class="o">|,</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">224</span>  <span class="o">|</span><span class="mi">224</span><span class="o">|</span><span class="n">a</span>           <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">226</span>  <span class="o">|</span><span class="mi">233</span><span class="o">|</span><span class="nc">Delaware</span>    <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">235</span>  <span class="o">|</span><span class="mi">241</span><span class="o">|</span><span class="n">limited</span>     <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">243</span>  <span class="o">|</span><span class="mi">251</span><span class="o">|</span><span class="n">liability</span>   <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">253</span>  <span class="o">|</span><span class="mi">259</span><span class="o">|</span><span class="n">company</span>     <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">261</span>  <span class="o">|</span><span class="mi">262</span><span class="o">|(</span><span class="err">"</span>          <span class="o">|</span><span class="mi">0</span>      <span class="o">|</span>
<span class="o">+-----+---+------------+-------+</span>
<span class="n">only</span> <span class="n">showing</span> <span class="n">top</span> <span class="mi">50</span> <span class="n">rows</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="internaldocumentsplitter">InternalDocumentSplitter</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">InternalDocumentSplitter</code> splits large documents into small documents. <code class="language-plaintext highlighter-rouge">InternalDocumentSplitter</code> has setSplitMode method to decide how to split documents.</p>

    <p>If splitMode is <code class="language-plaintext highlighter-rouge">recursive</code>, It takes the separators in order and splits subtexts if they are over the chunk length, considering optional overlap of the chunks.</p>

    <p>Additionally, you can set</p>
    <ul>
      <li>custom patterns with setSplitPatterns</li>
      <li>whether patterns should be interpreted as regex with setPatternsAreRegex</li>
      <li>whether to keep the separators with setKeepSeparators</li>
      <li>whether to trim whitespaces with setTrimWhitespace</li>
      <li>whether to explode the splits to individual rows with setExplodeSplits</li>
    </ul>

    <p>Parametres:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">chunkSize</code>: Size of each chunk of text. This param is applicable only for “recursive” splitMode.</li>
      <li><code class="language-plaintext highlighter-rouge">chunkOverlap</code>: Length of the overlap between text chunks, by default <code class="language-plaintext highlighter-rouge">0</code>. This param is applicable only for <code class="language-plaintext highlighter-rouge">recursive</code> splitMode.</li>
      <li><code class="language-plaintext highlighter-rouge">splitPatterns</code>: Patterns to split the document.
patternsAreRegex. Whether to interpret the split patterns as regular expressions, by default <code class="language-plaintext highlighter-rouge">True</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">keepSeparators</code>: Whether to keep the separators in the final result , by default <code class="language-plaintext highlighter-rouge">True</code>. This param is applicable only for “recursive” splitMode.</li>
      <li><code class="language-plaintext highlighter-rouge">explodeSplits</code>: Whether to explode split chunks to separate rows , by default <code class="language-plaintext highlighter-rouge">False</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">trimWhitespace</code>: Whether to trim whitespaces of extracted chunks , by default <code class="language-plaintext highlighter-rouge">True</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">splitMode</code>: The split mode to determine how text should be segmented. Default: ‘regex’. It should be one of the following values:
        <ul>
          <li>“char”: Split text based on individual characters.</li>
          <li>“token”: Split text based on tokens. You should supply tokens from inputCols.</li>
          <li>“sentence”: Split text based on sentences. You should supply sentences from inputCols.</li>
          <li>“recursive”: Split text recursively using a specific algorithm.</li>
          <li>“regex”: Split text based on a regular expression pattern.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">sentenceAwareness</code>: Whether to split the document by sentence awareness if possible.
        <ul>
          <li>If true, it can stop the split process before maxLength.</li>
          <li>If true, you should supply sentences from inputCols. Default: False.</li>
          <li>This param is not applicable only for <code class="language-plaintext highlighter-rouge">regex</code> and <code class="language-plaintext highlighter-rouge">recursive</code> splitMode.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">maxLength</code>: The maximum length allowed for spitting. The mode in which the maximum length is specified:
        <ul>
          <li>“char”: Maximum length is measured in characters. Default: <code class="language-plaintext highlighter-rouge">512</code></li>
          <li>“token”: Maximum length is measured in tokens. Default: <code class="language-plaintext highlighter-rouge">128</code></li>
          <li>“sentence”: Maximum length is measured in sentences. Default: <code class="language-plaintext highlighter-rouge">8</code></li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">customBoundsStrategy</code>: The custom bounds strategy for text splitting using regular expressions. This param is applicable only for <code class="language-plaintext highlighter-rouge">regex</code> splitMode.</li>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code>: Whether to use case sensitive when matching regex, by default <code class="language-plaintext highlighter-rouge">False</code>. This param is applicable only for <code class="language-plaintext highlighter-rouge">regex</code> splitMode.</li>
      <li><code class="language-plaintext highlighter-rouge">metaDataFields</code>: Metadata fields to add specified data in columns to the metadata of the split documents.         You should set column names to read columns.</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/InternalDocumentSplitter.ipynb">InternalDocumentSplitterNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">document_splitter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">InternalDocumentSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"splits"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setSplitMode</span><span class="p">(</span><span class="s">"recursive"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkSize</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setChunkOverlap</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setExplodeSplits</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPatternsAreRegex</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setSplitPatterns</span><span class="p">([</span><span class="s">"</span><span class="se">\n\n</span><span class="s">"</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">" "</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setKeepSeparators</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTrimWhitespace</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">document_splitter</span>
<span class="p">])</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[(</span>
    <span class="s">"The patient is a 28-year-old, who is status post gastric bypass surgery"</span>
    <span class="s">" nearly one year ago. </span><span class="se">\n</span><span class="s">He has lost about 200 pounds and was otherwise doing well"</span>
    <span class="s">" until yesterday evening around 7:00-8:00 when he developed nausea and right upper quadrant pain,"</span>
    <span class="s">" which apparently wrapped around toward his right side and back. He feels like he was on it"</span>
    <span class="s">" but has not done so. He has overall malaise and a low-grade temperature of 100.3."</span>
    <span class="s">" </span><span class="se">\n\n</span><span class="s">He denies any prior similar or lesser symptoms. His last normal bowel movement was yesterday."</span>
    <span class="s">" He denies any outright chills or blood per rectum."</span>
<span class="p">)]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>


<span class="n">pipeline_df</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">select</span><span class="p">(</span><span class="s">"splits"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">splits</span>                                                                                                                                                         <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">92</span><span class="p">,</span> <span class="n">The</span> <span class="n">patient</span> <span class="ow">is</span> <span class="n">a</span> <span class="mi">28</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span><span class="p">,</span> <span class="n">who</span> <span class="ow">is</span> <span class="n">status</span> <span class="n">post</span> <span class="n">gastric</span> <span class="n">bypass</span> <span class="n">surgery</span> <span class="n">nearly</span> <span class="n">one</span> <span class="n">year</span> <span class="n">ago</span><span class="p">.,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">document</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span>          <span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">94</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="n">He</span> <span class="n">has</span> <span class="n">lost</span> <span class="n">about</span> <span class="mi">200</span> <span class="n">pounds</span> <span class="ow">and</span> <span class="n">was</span> <span class="n">otherwise</span> <span class="n">doing</span> <span class="n">well</span> <span class="n">until</span> <span class="n">yesterday</span> <span class="n">evening</span> <span class="n">around</span> <span class="mi">7</span><span class="p">:</span><span class="mi">00</span><span class="o">-</span><span class="mi">8</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">document</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">},</span> <span class="p">[]}]</span>  <span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">193</span><span class="p">,</span> <span class="mi">291</span><span class="p">,</span> <span class="n">when</span> <span class="n">he</span> <span class="n">developed</span> <span class="n">nausea</span> <span class="ow">and</span> <span class="n">right</span> <span class="n">upper</span> <span class="n">quadrant</span> <span class="n">pain</span><span class="p">,</span> <span class="n">which</span> <span class="n">apparently</span> <span class="n">wrapped</span> <span class="n">around</span> <span class="n">toward</span> <span class="n">his</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">document</span> <span class="o">-&gt;</span> <span class="mi">2</span><span class="p">},</span> <span class="p">[]}]</span> <span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">288</span><span class="p">,</span> <span class="mi">387</span><span class="p">,</span> <span class="n">his</span> <span class="n">right</span> <span class="n">side</span> <span class="ow">and</span> <span class="n">back</span><span class="p">.</span> <span class="n">He</span> <span class="n">feels</span> <span class="n">like</span> <span class="n">he</span> <span class="n">was</span> <span class="n">on</span> <span class="n">it</span> <span class="n">but</span> <span class="n">has</span> <span class="ow">not</span> <span class="n">done</span> <span class="n">so</span><span class="p">.</span> <span class="n">He</span> <span class="n">has</span> <span class="n">overall</span> <span class="n">malaise</span> <span class="ow">and</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">document</span> <span class="o">-&gt;</span> <span class="mi">3</span><span class="p">},</span> <span class="p">[]}]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">421</span><span class="p">,</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">low</span><span class="o">-</span><span class="n">grade</span> <span class="n">temperature</span> <span class="n">of</span> <span class="mf">100.3</span><span class="p">.,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">document</span> <span class="o">-&gt;</span> <span class="mi">4</span><span class="p">},</span> <span class="p">[]}]</span>                                                              <span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">424</span><span class="p">,</span> <span class="mi">520</span><span class="p">,</span> <span class="n">He</span> <span class="n">denies</span> <span class="nb">any</span> <span class="n">prior</span> <span class="n">similar</span> <span class="ow">or</span> <span class="n">lesser</span> <span class="n">symptoms</span><span class="p">.</span> <span class="n">His</span> <span class="n">last</span> <span class="n">normal</span> <span class="n">bowel</span> <span class="n">movement</span> <span class="n">was</span> <span class="n">yesterday</span><span class="p">.</span> <span class="n">He</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">document</span> <span class="o">-&gt;</span> <span class="mi">5</span><span class="p">},</span> <span class="p">[]}]</span>   <span class="o">|</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">518</span><span class="p">,</span> <span class="mi">568</span><span class="p">,</span> <span class="n">He</span> <span class="n">denies</span> <span class="nb">any</span> <span class="n">outright</span> <span class="n">chills</span> <span class="ow">or</span> <span class="n">blood</span> <span class="n">per</span> <span class="n">rectum</span><span class="p">.,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">document</span> <span class="o">-&gt;</span> <span class="mi">6</span><span class="p">},</span> <span class="p">[]}]</span>                                                 <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">document_splitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">InternalDocumentSplitter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"splits"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setSplitMode</span><span class="o">(</span><span class="s">"recursive"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setChunkSize</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setChunkOverlap</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setExplodeSplits</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPatternsAreRegex</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setSplitPatterns</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"\n\n"</span><span class="o">,</span> <span class="s">"\n"</span><span class="o">,</span> <span class="s">" "</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setKeepSeparators</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setTrimWhitespace</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">document_splitter</span> <span class="o">))</span>


<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span> <span class="s">"The patient is a 28-year-old, who is status post gastric bypass surgery"</span>
    <span class="s">" nearly one year ago. \nHe has lost about 200 pounds and was otherwise doing well"</span>
    <span class="s">" until yesterday evening around 7:00-8:00 when he developed nausea and right upper quadrant pain,"</span>
    <span class="s">" which apparently wrapped around toward his right side and back. He feels like he was on it"</span>
    <span class="s">" but has not done so. He has overall malaise and a low-grade temperature of 100.3."</span>
    <span class="s">" \n\nHe denies any prior similar or lesser symptoms. His last normal bowel movement was yesterday."</span>
    <span class="s">" He denies any outright chills or blood per rectum."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">mapperPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span>

<span class="c1">// Show results</span>

<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">splits</span>                                                                                                                                                         <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">0</span>, <span class="err">92</span>, <span class="kt">The</span> <span class="kt">patient</span> <span class="kt">is</span> <span class="kt">a</span> <span class="err">28</span><span class="kt">-year-old</span>, <span class="kt">who</span> <span class="kt">is</span> <span class="kt">status</span> <span class="kt">post</span> <span class="kt">gastric</span> <span class="kt">bypass</span> <span class="kt">surgery</span> <span class="kt">nearly</span> <span class="kt">one</span> <span class="kt">year</span> <span class="kt">ago.</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">document</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]</span>          <span class="o">|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">94</span>, <span class="err">192</span>, <span class="kt">He</span> <span class="kt">has</span> <span class="kt">lost</span> <span class="kt">about</span> <span class="err">200</span> <span class="kt">pounds</span> <span class="kt">and</span> <span class="kt">was</span> <span class="kt">otherwise</span> <span class="kt">doing</span> <span class="kt">well</span> <span class="kt">until</span> <span class="kt">yesterday</span> <span class="kt">evening</span> <span class="kt">around</span> <span class="err">7</span><span class="kt">:</span><span class="err">00</span><span class="kt">-</span><span class="err">8</span><span class="kt">:</span><span class="err">00</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">document</span> <span class="kt">-&gt;</span> <span class="err">1</span><span class="o">}</span>, <span class="o">[]}]</span>  <span class="o">|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">193</span>, <span class="err">291</span>, <span class="kt">when</span> <span class="kt">he</span> <span class="kt">developed</span> <span class="kt">nausea</span> <span class="kt">and</span> <span class="kt">right</span> <span class="kt">upper</span> <span class="kt">quadrant</span> <span class="kt">pain</span>, <span class="kt">which</span> <span class="kt">apparently</span> <span class="kt">wrapped</span> <span class="kt">around</span> <span class="kt">toward</span> <span class="kt">his</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">document</span> <span class="kt">-&gt;</span> <span class="err">2</span><span class="o">}</span>, <span class="o">[]}]</span> <span class="o">|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">288</span>, <span class="err">387</span>, <span class="kt">his</span> <span class="kt">right</span> <span class="kt">side</span> <span class="kt">and</span> <span class="kt">back.</span> <span class="kt">He</span> <span class="kt">feels</span> <span class="kt">like</span> <span class="kt">he</span> <span class="kt">was</span> <span class="kt">on</span> <span class="kt">it</span> <span class="kt">but</span> <span class="kt">has</span> <span class="kt">not</span> <span class="kt">done</span> <span class="kt">so.</span> <span class="kt">He</span> <span class="kt">has</span> <span class="kt">overall</span> <span class="kt">malaise</span> <span class="kt">and</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">document</span> <span class="kt">-&gt;</span> <span class="err">3</span><span class="o">}</span>, <span class="o">[]}]|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">384</span>, <span class="err">421</span>, <span class="kt">and</span> <span class="kt">a</span> <span class="kt">low-grade</span> <span class="kt">temperature</span> <span class="kt">of</span> <span class="err">100</span><span class="kt">.</span><span class="err">3</span><span class="kt">.</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">document</span> <span class="kt">-&gt;</span> <span class="err">4</span><span class="o">}</span>, <span class="o">[]}]</span>                                                              <span class="o">|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">424</span>, <span class="err">520</span>, <span class="kt">He</span> <span class="kt">denies</span> <span class="kt">any</span> <span class="kt">prior</span> <span class="kt">similar</span> <span class="kt">or</span> <span class="kt">lesser</span> <span class="kt">symptoms.</span> <span class="kt">His</span> <span class="kt">last</span> <span class="kt">normal</span> <span class="kt">bowel</span> <span class="kt">movement</span> <span class="kt">was</span> <span class="kt">yesterday.</span> <span class="kt">He</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">document</span> <span class="kt">-&gt;</span> <span class="err">5</span><span class="o">}</span>, <span class="o">[]}]</span>   <span class="o">|</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">518</span>, <span class="err">568</span>, <span class="kt">He</span> <span class="kt">denies</span> <span class="kt">any</span> <span class="kt">outright</span> <span class="kt">chills</span> <span class="kt">or</span> <span class="kt">blood</span> <span class="kt">per</span> <span class="kt">rectum.</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span>, <span class="kt">document</span> <span class="kt">-&gt;</span> <span class="err">6</span><span class="o">}</span>, <span class="o">[]}]</span>                                                 <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="llmloader">LLMLoader</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>LLMLoader is designed to interact with a LLMs that are converted into gguf format. This module allows using John Snow Labs’ licensed LLMs at
various sizes that are finetuned on medical context for certain tasks. It provides various methods for setting parameters, loading models,
generating text, and retrieving metadata. The LLMLoader includes methods for setting various parameters such as input prefix, suffix,
cache prompt, number of tokens to predict, sampling techniques, temperature, penalties, and more. Overall, the LLMLoader provides a
flexible and extensible framework for interacting with language models in a Python and Scala environment using PySpark and Java.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">inputPrefix</code> :  Prefix for infilling (default: empty)</li>
      <li><code class="language-plaintext highlighter-rouge">inputSuffix</code> :  Suffix for infilling (default: empty)</li>
      <li><code class="language-plaintext highlighter-rouge">cachePrompt</code> :  Whether to remember the prompt to avoid reprocessing it</li>
      <li><code class="language-plaintext highlighter-rouge">nPredict</code>    :  Number of tokens to predict (default: -1, -1 = infinity, -2 = until context filled)</li>
      <li><code class="language-plaintext highlighter-rouge">topK</code> :  Top-k sampling (default: 40, 0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">topP</code> :  Top-p sampling (default: 0.9, 1.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">minP</code> :  Min-p sampling (default: 0.1, 0.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">tfsZ</code> :  Tail free sampling, parameter z (default: 1.0, 1.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">typicalP</code> :  Locally typical sampling, parameter p (default: 1.0, 1.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">temperature</code> :  The temperature (default: 0.8)</li>
      <li><code class="language-plaintext highlighter-rouge">dynatempRange</code> :   Dynamic temperature range (default: 0.0, 0.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">dynatempExponent</code> :  Dynamic temperature exponent (default: 1.0)</li>
      <li><code class="language-plaintext highlighter-rouge">repeatLastN</code> :  Last n tokens to consider for penalties (default: 64, 0 = disabled, -1 = ctx_size)</li>
      <li><code class="language-plaintext highlighter-rouge">repeatPenalty</code> :  Penalty of repeated sequences of tokens (default: 1.0, 1.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">frequencyPenalty</code> :  Repetition alpha frequency penalty (default: 0.0, 0.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">presencePenalty</code> :  Repetition alpha presence penalty (default: 0.0, 0.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">mirostatTau</code> :  MiroStat target entropy, parameter tau (default: 5.0)</li>
      <li><code class="language-plaintext highlighter-rouge">mirostatEta</code> :  MiroStat learning rate, parameter eta (default: 0.1)</li>
      <li><code class="language-plaintext highlighter-rouge">penalizeNl</code> :  Whether to penalize newline tokens</li>
      <li><code class="language-plaintext highlighter-rouge">nKeep</code> :  Number of tokens to keep from the initial prompt (default: 0, -1 = all)</li>
      <li><code class="language-plaintext highlighter-rouge">seed</code> :  RNG seed (default: -1, use random seed for &lt; 0)</li>
      <li><code class="language-plaintext highlighter-rouge">nProbs</code> :  Amount top tokens probabilities to output if greater than 0.</li>
      <li><code class="language-plaintext highlighter-rouge">minKeep</code> :  Amount of tokens the samplers should return at least (0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">grammar</code> :  BNF-like grammar to constrain generations (see samples in grammars/ dir)</li>
      <li><code class="language-plaintext highlighter-rouge">penaltyPrompt</code> :  Override which part of the prompt is penalized for repetition. E.g. if original prompt is “Alice: Hello!” and penaltyPrompt is “Hello!”, only the latter will be penalized if repeated. See <a href="https://github.com/ggerganov/llama.cpp/pull/3727">pull request 3727</a> for more details.</li>
      <li><code class="language-plaintext highlighter-rouge">penaltyPromptTokens</code> :  PenaltyPromptTokens</li>
      <li><code class="language-plaintext highlighter-rouge">ignoreEos</code> :  Whether to ignore end of stream token and continue generating (implies –logit-bias 2-inf)</li>
      <li><code class="language-plaintext highlighter-rouge">stopStrings</code> :  Strings upon seeing which token generation is stopped</li>
      <li><code class="language-plaintext highlighter-rouge">useChatTemplate</code> :  Whether or not generate should apply a chat template (default: false)</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/llm/llm_loader/index.html">LLMLoader</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/ml/gguf/rag/LLMLoader.html">LLMLoader</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sparknlp_jsl.llm</span> <span class="kn">import</span> <span class="n">LLMLoader</span>

<span class="n">llm_loader_pretrained</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">LLMLoader</span><span class="p">(</span><span class="n">spark</span><span class="p">).</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"JSL_MedS_q16_v1"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>

<span class="n">llm_loader_pretrained</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span><span class="s">"What is the indication for the drug Methadone?"</span><span class="p">)</span>



<span class="c1">## Result
</span>
<span class="s">'Methadone is used to treat opioid addiction. It is a long-acting opioid agonist that is used to help individuals who are addicted to short-acting opioids such as heroin or other illicit opioids. It is also used to treat chronic pain in patients who have developed tolerance to other opioids.'</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">llmLoader</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">LLMLoader</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setSparkSession</span><span class="o">(</span><span class="n">spark</span><span class="o">)</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"JSL_MedS_q16_v1"</span><span class="o">,</span> <span class="n">remoteLoc</span><span class="o">=</span><span class="s">"clinical/models"</span><span class="o">,</span> <span class="n">lang</span> <span class="k">=</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTemperature</span><span class="o">(</span><span class="mf">0.0f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNPredict</span><span class="o">(</span><span class="mi">20</span><span class="o">)</span>



<span class="k">val</span> <span class="nv">prompt</span> <span class="k">=</span> <span class="s">"What is the indication for the drug Methadone?"</span>

<span class="k">val</span> <span class="nv">output</span> <span class="k">=</span> <span class="nv">llmLoader</span><span class="o">.</span><span class="py">setUseChatTemplate</span><span class="o">(</span><span class="kc">false</span><span class="o">).</span><span class="py">setStopStrings</span><span class="o">(</span><span class="nv">Array</span><span class="o">.</span><span class="py">empty</span><span class="o">[</span><span class="kt">String</span><span class="o">]).</span><span class="py">generate</span><span class="o">(</span><span class="n">prompt</span><span class="o">)</span>

<span class="nf">println</span><span class="o">(</span><span class="n">output</span><span class="o">)</span>

<span class="o">#</span><span class="k">#</span> <span class="nc">Result</span>

<span class="ss">'Methadone</span> <span class="n">is</span> <span class="n">used</span> <span class="n">to</span> <span class="n">treat</span> <span class="n">opioid</span> <span class="n">addiction</span><span class="o">.</span> <span class="nc">It</span> <span class="n">is</span> <span class="n">a</span> <span class="n">long</span><span class="o">-</span><span class="n">acting</span> <span class="n">opioid</span> <span class="n">agonist</span> <span class="n">that</span> <span class="n">is</span> <span class="n">used</span> <span class="n">to</span> <span class="n">help</span> <span class="n">individuals</span> <span class="n">who</span> <span class="n">are</span> <span class="n">addicted</span> <span class="n">to</span> <span class="n">short</span><span class="o">-</span><span class="n">acting</span> <span class="n">opioids</span> <span class="n">such</span> <span class="n">as</span> <span class="n">heroin</span> <span class="n">or</span> <span class="n">other</span> <span class="n">illicit</span> <span class="n">opioids</span><span class="o">.</span> <span class="nc">It</span> <span class="n">is</span> <span class="n">also</span> <span class="n">used</span> <span class="n">to</span> <span class="n">treat</span> <span class="n">chronic</span> <span class="n">pain</span> <span class="n">in</span> <span class="n">patients</span> <span class="n">who</span> <span class="n">have</span> <span class="n">developed</span> <span class="n">tolerance</span> <span class="n">to</span> <span class="n">other</span> <span class="n">opioids</span><span class="o">.'</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="largefewshotclassifier">LargeFewShotClassifier</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The  LargeFewShotClassifierModel annotator is designed to work effectively with minimal labeled data, offering flexibility and adaptability to new, unseen classes. Key parameters include batch size, case sensitivity, and maximum sentence length.Large Few-Shot Classifier Model can achieve impressive performance even with minimal labeled data.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read either a String column or an Array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/classification/large_few_shot_classifier/index.html#">LargeFewShotClassifier</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/LargeFewShotClassifier.html">LargeFewShotClassifier</a></td>
          <td><strong>Notebook:</strong> <a href="https://https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Healthcare/30.4.Text_Classification_with_LargeFewShotClassifier.ipynb">Mapper2Chunk</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">large_few_shot_classifier</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">LargeFewShotClassifierModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"large_fewshot_classifier_ade"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prediction"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">large_few_shot_classifier</span>
<span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span><span class="s">"The patient developed severe liver toxicity after taking the medication for three weeks"</span><span class="p">,</span>
                              <span class="s">"He experienced no complications during the treatment and reported feeling much better."</span><span class="p">,</span>
                              <span class="s">"She experienced a sudden drop in blood pressure after the administration of the new drug."</span><span class="p">,</span>
                              <span class="s">"The doctor recommended a daily dosage of the vitamin supplement to improve her health."</span><span class="p">],</span> <span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"text"</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s">"prediction.result"</span><span class="p">).</span><span class="n">getItem</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"result"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+-----------------------------------------------------------------------------------------+------+</span>
<span class="o">|</span><span class="n">text</span>                                                                                     <span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------+------+</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">developed</span> <span class="n">severe</span> <span class="n">liver</span> <span class="n">toxicity</span> <span class="n">after</span> <span class="n">taking</span> <span class="n">the</span> <span class="n">medication</span> <span class="k">for</span> <span class="n">three</span> <span class="n">weeks</span>  <span class="o">|</span><span class="n">ADE</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">He</span> <span class="n">experienced</span> <span class="n">no</span> <span class="n">complications</span> <span class="n">during</span> <span class="n">the</span> <span class="n">treatment</span> <span class="ow">and</span> <span class="n">reported</span> <span class="n">feeling</span> <span class="n">much</span> <span class="n">better</span><span class="p">.</span>   <span class="o">|</span><span class="n">noADE</span> <span class="o">|</span>
<span class="o">|</span><span class="n">She</span> <span class="n">experienced</span> <span class="n">a</span> <span class="n">sudden</span> <span class="n">drop</span> <span class="ow">in</span> <span class="n">blood</span> <span class="n">pressure</span> <span class="n">after</span> <span class="n">the</span> <span class="n">administration</span> <span class="n">of</span> <span class="n">the</span> <span class="n">new</span> <span class="n">drug</span><span class="p">.</span><span class="o">|</span><span class="n">ADE</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">doctor</span> <span class="n">recommended</span> <span class="n">a</span> <span class="n">daily</span> <span class="n">dosage</span> <span class="n">of</span> <span class="n">the</span> <span class="n">vitamin</span> <span class="n">supplement</span> <span class="n">to</span> <span class="n">improve</span> <span class="n">her</span> <span class="n">health</span><span class="p">.</span>   <span class="o">|</span><span class="n">noADE</span> <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------+------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">largeFewShotClassifier</span> <span class="k">=</span> <span class="nc">LargeFewShotClassifierModel</span><span class="o">()</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"large_fewshot_classifier_ade"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prediction"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">largeFewShotClassifier</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">textList</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
    <span class="o">(</span><span class="s">"The patient developed severe liver toxicity after taking the medication for three weeks"</span><span class="o">),</span>
    <span class="o">(</span><span class="s">"He experienced no complications during the treatment and reported feeling much better."</span><span class="o">),</span>
    <span class="o">(</span><span class="s">"She experienced a sudden drop in blood pressure after the administration of the new drug."</span><span class="o">),</span>
    <span class="o">(</span><span class="s">"The doctor recommended a daily dosage of the vitamin supplement to improve her health."</span><span class="o">)</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="n">textList</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="nf">col</span><span class="o">(</span><span class="s">"text"</span><span class="o">),</span> <span class="nf">col</span><span class="o">(</span><span class="s">"prediction.result"</span><span class="o">).</span><span class="py">getItem</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="py">alias</span><span class="o">(</span><span class="s">"result"</span><span class="o">)).</span><span class="py">show</span><span class="o">(</span><span class="n">truncate</span> <span class="k">=</span> <span class="kc">false</span><span class="o">)</span>

<span class="c1">// Result</span>

<span class="o">+-----------------------------------------------------------------------------------------+------+</span>
<span class="o">|</span><span class="n">text</span>                                                                                     <span class="o">|</span><span class="n">result</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------+------+</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">developed</span> <span class="n">severe</span> <span class="n">liver</span> <span class="n">toxicity</span> <span class="n">after</span> <span class="n">taking</span> <span class="n">the</span> <span class="n">medication</span> <span class="k">for</span> <span class="n">three</span> <span class="n">weeks</span>  <span class="o">|</span><span class="nc">ADE</span>   <span class="o">|</span>
<span class="o">|</span><span class="nc">He</span> <span class="n">experienced</span> <span class="n">no</span> <span class="n">complications</span> <span class="n">during</span> <span class="n">the</span> <span class="n">treatment</span> <span class="n">and</span> <span class="n">reported</span> <span class="n">feeling</span> <span class="n">much</span> <span class="n">better</span><span class="o">.</span>   <span class="o">|</span><span class="n">noADE</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">She</span> <span class="n">experienced</span> <span class="n">a</span> <span class="n">sudden</span> <span class="n">drop</span> <span class="n">in</span> <span class="n">blood</span> <span class="n">pressure</span> <span class="n">after</span> <span class="n">the</span> <span class="n">administration</span> <span class="n">of</span> <span class="n">the</span> <span class="k">new</span> <span class="n">drug</span><span class="o">.|</span><span class="nc">ADE</span>   <span class="o">|</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">doctor</span> <span class="n">recommended</span> <span class="n">a</span> <span class="n">daily</span> <span class="n">dosage</span> <span class="n">of</span> <span class="n">the</span> <span class="n">vitamin</span> <span class="n">supplement</span> <span class="n">to</span> <span class="n">improve</span> <span class="n">her</span> <span class="n">health</span><span class="o">.</span>   <span class="o">|</span><span class="n">noADE</span> <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------+------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="lightdeidentification">LightDeIdentification</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Light DeIdentification is a light version of DeIdentification. It replaces sensitive information
in a text with obfuscated or masked fakers. It is designed to work with healthcare data,
and it can be used to de-identify patient names, dates, and other sensitive information.
It can also be used to obfuscate or mask any other type of sensitive information, such as doctor names, hospital
names, and other types of sensitive information.
Additionally, it supports millions of embedded fakers
and If desired, custom external fakers can be set with setCustomFakers function.
It also supports multiple languages such as English, Spanish, French, German, and Arabic.
And it supports multi-mode de-Identification with setSelectiveObfuscationModes function at the same time.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">mode</code> <em>(str)</em>: Mode for Anonimizer [‘mask’,’obfuscate’]</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dateEntities</code> <em>(list[str])</em>: List of date entities. Default: [‘DATE’, ‘DOB’, ‘DOD’]</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">obfuscateDate</code> <em>(Bool)</em>: When mode==’obfuscate’ whether to obfuscate dates or not. This param helps in consistency to make dateFormats more visible.
When setting to <code class="language-plaintext highlighter-rouge">True</code>, make sure dateFormats param fits the needs.
If the value is True and obfuscation is failed, then unnormalizedDateMode param will be activated.
When setting to ‘False’, then the date will be masked to <DATE>.
Default: False</DATE></p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">unnormalizedDateMode</code> <em>(str)</em>: The mode to use if the date is not formatted. Options: [mask, obfuscate, skip]. Default: obfuscate.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">days</code> (IntParam): Number of days to obfuscate the dates by displacement.If not provided a random integer between 1 and 60 will be used.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">useShiftDays</code> <em>(Bool)</em>: Whether to use the random shift day when the document has this in its metadata. Default: False</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dateFormats</code> (list[str]): List of date formats to automatically displace if parsed.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">region</code> <em>(str)</em>:  The region to use for date parsing. This property is especially used when obfuscating dates.
You can decide whether the first part of 11/11/2023 is a day or the second part is a day when obfuscating dates.
Options: ‘eu’ for European Union, ‘us’ for the USA, Default: ‘eu’</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">obfuscateRefSource</code> <em>(str)</em>: The source of obfuscation of to obfuscate the entities. For dates entities, This property is invalid.
The values ar the following:
custom: Takes the entities from the setCustomFakers function.
faker: Takes the entities from the Faker module
both : Takes the entities from the setCustomFakers function and the faker module randomly</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">language</code> <em>(str)</em>:   The language used to select the regex file and some faker entities.
The values are the following:
‘en’(English), ‘de’(German), ‘es’(Spanish), ‘fr’(French), ‘ar’(Arabic) or ‘ro’(Romanian). Default:’en’.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">seed</code> <em>(Int)</em>:  It is the seed to select the entities on obfuscate mode. With the seed,
you can reply to an execution several times with the same output.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maskingPolicy</code> <em>(str)</em>:  Select the masking policy:
same_length_chars: Replace the obfuscated entity with a masking sequence composed of asterisks and surrounding squared brackets, being the total length of the masking sequence of the same length as the original sequence.
Example, Smith -&gt; [***].
If the entity is less than 3 chars (like Jo, or 5), asterisks without brackets will be returned.
entity_labels: Replace the values with the corresponding entity labels.
fixed_length_chars: Replace the obfuscated entity with a masking sequence composed of a fixed number of asterisk.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">fixedMaskLength</code> <em>(Int)</em>:  The length of the masking sequence in case of fixed_length_chars masking policy.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">sameLengthFormattedEntities</code> (list[str]):  List of formatted entities to generate the same length outputs as original ones during obfuscation.
The supported and default formatted entities are: PHONE, FAX, ID, IDNUM, BIOID, MEDICALRECORD, ZIP, VIN, SSN, DLN, LICENSE, PLATE.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">genderAwareness</code> <em>(Bool)</em>:  Whether to use gender-aware names or not during obfuscation. This param effects only names.
If the value is true, it might decrease performance. Default: False</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ageRanges</code> (list[str]):   list of integer specifying limits of the age groups to preserve during obfuscation.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">selectiveObfuscationModes</code> <em>(dict[str, dict[str]])</em>:   The dictionary of modes to enable multi-mode deIdentification.
‘obfuscate’: Replace the values with random values.
‘mask_same_length_chars’: Replace the name with the asterisks with same length minus two plus brackets on both end.
‘mask_entity_labels’: Replace the values with the entity value.
‘mask_fixed_length_chars’: Replace the name with the asterisks with fixed length. You can also invoke “setFixedMaskLength()”
‘skip’: Skip the values (intact)
The entities which have not been given in dictionary will deidentify according to :param:<code class="language-plaintext highlighter-rouge">mode</code></p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">customFakers</code> <em>(dict[str, dict[str]])</em>:   The dictionary of custom fakers to specify the obfuscation terms for the entities.
You can specify the entity and the terms to be used for obfuscation.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">keepYear</code>: (BooleanParam) Whether to keep the year intact when obfuscating date entities.
If True, the year will remain unchanged during the obfuscation process.
If False, the year will be modified along with the month and day.
Default: False.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">keepMonth</code> : Whether to keep the month intact when obfuscating date entities.
If True, the month will remain unchanged during the obfuscation process.
If False, the month will be modified along with the year and day.
Default: False.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/LightDeIdentification/index.html">LightDeIdentification</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/LightDeIdentification.html">LightDeIdentification</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.6.Light_Deidentification.ipynb">LightDeIdentification</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="c1"># Sentence Detector annotator, processes various sentences per line
</span><span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Clinical word embeddings trained on PubMED dataset
</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)
</span><span class="n">ner_subentity</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_subentity"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_subentity"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">light_deidentification</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">LightDeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"obfuscated"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"obfuscate"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateDate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDateFormats</span><span class="p">([</span><span class="s">"MM/dd/yyyy"</span><span class="p">,</span><span class="s">"yyyy-MM-dd"</span><span class="p">,</span> <span class="s">"MM/dd/yy"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setDays</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">'custom'</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCustomFakers</span><span class="p">({</span><span class="s">"Doctor"</span><span class="p">:</span> <span class="p">[</span><span class="s">"John"</span><span class="p">,</span> <span class="s">"Joe"</span><span class="p">],</span>
                      <span class="s">"Patient"</span><span class="p">:</span> <span class="p">[</span><span class="s">"James"</span><span class="p">,</span> <span class="s">"Michael"</span><span class="p">],</span>
                      <span class="s">"Hospital"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Medical Center"</span><span class="p">],</span>
                      <span class="s">"Street"</span> <span class="p">:</span> <span class="p">[</span><span class="s">"Main Street"</span><span class="p">],</span>
                      <span class="s">"Age"</span><span class="p">:[</span><span class="s">"1"</span><span class="p">,</span><span class="s">"10"</span><span class="p">,</span> <span class="s">"20"</span><span class="p">,</span> <span class="s">"40"</span><span class="p">,</span><span class="s">"80"</span><span class="p">],</span>
                      <span class="s">"PHONE"</span><span class="p">:[</span><span class="s">"555-555-0000"</span><span class="p">]})</span> \
    <span class="p">.</span><span class="n">setAgeRanges</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">80</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setLanguage</span><span class="p">(</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDateEntities</span><span class="p">([</span><span class="s">"DATE"</span><span class="p">,</span> <span class="s">"DOB"</span><span class="p">,</span>  <span class="s">"DOD"</span><span class="p">])</span> \

<span class="n">flattener</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Flattener</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"obfuscated"</span><span class="p">,</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setExplodeSelectedFields</span><span class="p">({</span><span class="s">"obfuscated"</span><span class="p">:</span> <span class="p">[</span><span class="s">"result"</span><span class="p">],</span>  <span class="s">"sentence"</span><span class="p">:</span> <span class="p">[</span><span class="s">"result"</span><span class="p">]})</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
                <span class="n">documentAssembler</span><span class="p">,</span>
                <span class="n">sentenceDetector</span><span class="p">,</span>
                <span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">word_embeddings</span><span class="p">,</span>
                <span class="n">ner_subentity</span><span class="p">,</span>
                <span class="n">ner_converter</span><span class="p">,</span>
                <span class="n">light_deidentification</span><span class="p">,</span>
                <span class="n">flattener</span>
                <span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span><span class="s">'''
    Record date : 2093-01-13 , David Hale , M.D . ,
    Name : Hendrickson Ora , MR # 7194334 Date : 01/13/93 .
    PCP : Oliveira , 95 years-old , Record date : 2079-11-09 .
    Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555.
    '''</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>
<span class="n">result</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+----------------------------------------------------------------------+-----------------------------------------------------+</span>
<span class="o">|</span><span class="n">sentence_result</span>                                                       <span class="o">|</span><span class="n">obfuscated_result</span>                                    <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------+-----------------------------------------------------+</span>
<span class="o">|</span><span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">13</span> <span class="p">,</span> <span class="n">David</span> <span class="n">Hale</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span>                         <span class="o">|</span><span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">20</span> <span class="p">,</span> <span class="n">John</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span>              <span class="o">|</span>
<span class="o">|</span><span class="p">,</span>\<span class="n">nName</span> <span class="p">:</span> <span class="n">Hendrickson</span> <span class="n">Ora</span> <span class="p">,</span> <span class="n">MR</span> <span class="c1"># 7194334 Date : 01/13/93 .            |,\nName : Michael , MR # 1478295 Date : 01/20/93 .   |
</span><span class="o">|</span><span class="n">PCP</span> <span class="p">:</span> <span class="n">Oliveira</span> <span class="p">,</span> <span class="mi">95</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2079</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">09</span> <span class="p">.</span>            <span class="o">|</span><span class="n">PCP</span> <span class="p">:</span> <span class="n">Joe</span> <span class="p">,</span> <span class="mi">95</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2079</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">16</span> <span class="p">.</span><span class="o">|</span>
<span class="o">|</span><span class="n">Cocke</span> <span class="n">County</span> <span class="n">Baptist</span> <span class="n">Hospital</span> <span class="p">,</span> <span class="mi">0295</span> <span class="n">Keats</span> <span class="n">Street</span> <span class="p">,</span> <span class="n">Phone</span> <span class="mi">55</span><span class="o">-</span><span class="mi">555</span><span class="o">-</span><span class="mf">5555.</span><span class="o">|</span><span class="n">Medical</span> <span class="n">Center</span> <span class="p">,</span> <span class="n">Main</span> <span class="n">Street</span> <span class="p">,</span> <span class="n">Phone</span> <span class="mi">62</span><span class="o">-</span><span class="mi">130</span><span class="o">-</span><span class="mf">8657.</span>    <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------+-----------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerSubEntity</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_subentity_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_subentity"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_subentity"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">lightDeidentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">LightDeIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"obfuscated"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"obfuscate"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setObfuscateDate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDateFormats</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"MM/dd/yyyy"</span><span class="o">,</span> <span class="s">"yyyy-MM-dd"</span><span class="o">,</span> <span class="s">"MM/dd/yy"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setDays</span><span class="o">(</span><span class="mi">7</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"custom"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCustomFakers</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"Doctor"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"John"</span><span class="o">,</span> <span class="s">"Joe"</span><span class="o">),</span>
    <span class="s">"Patient"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"James"</span><span class="o">,</span> <span class="s">"Michael"</span><span class="o">),</span>
    <span class="s">"Hospital"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"Medical Center"</span><span class="o">),</span>
    <span class="s">"Street"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"Main Street"</span><span class="o">),</span>
    <span class="s">"Age"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"1"</span><span class="o">,</span> <span class="s">"10"</span><span class="o">,</span> <span class="s">"20"</span><span class="o">,</span> <span class="s">"40"</span><span class="o">,</span> <span class="s">"80"</span><span class="o">),</span>
    <span class="s">"PHONE"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"555-555-0000"</span><span class="o">)))</span>
  <span class="o">.</span><span class="py">setAgeRanges</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">,</span> <span class="mi">12</span><span class="o">,</span> <span class="mi">20</span><span class="o">,</span> <span class="mi">40</span><span class="o">,</span> <span class="mi">60</span><span class="o">,</span> <span class="mi">80</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setLanguage</span><span class="o">(</span><span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setSeed</span><span class="o">(</span><span class="mi">42</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDateEntities</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"DATE"</span><span class="o">,</span> <span class="s">"DOB"</span><span class="o">,</span> <span class="s">"DOD"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">flattener</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Flattener</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"obfuscated"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setExplodeSelectedFields</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"obfuscated"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"result"</span><span class="o">),</span> <span class="s">"sentence"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"result"</span><span class="o">)))</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">wordEmbeddings</span><span class="o">,</span>
      <span class="n">nerSubEntity</span><span class="o">,</span>
      <span class="n">nerConverter</span><span class="o">,</span>
      <span class="n">lightDeidentification</span><span class="o">,</span>
      <span class="n">flattener</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">emptyData</span> <span class="k">=</span><span class="nc">Seq</span><span class="o">((</span><span class="s">""</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyData</span><span class="o">)</span>

<span class="c1">// Result</span>

<span class="o">+----------------------------------------------------------------------+-----------------------------------------------------+</span>
<span class="o">|</span><span class="n">sentence_result</span>                                                       <span class="o">|</span><span class="n">obfuscated_result</span>                                    <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------+-----------------------------------------------------+</span>
<span class="o">|</span><span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">13</span> <span class="o">,</span> <span class="nc">David</span> <span class="nc">Hale</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span>                         <span class="o">|</span><span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">20</span> <span class="o">,</span> <span class="nc">John</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span>              <span class="o">|</span>
<span class="o">|,\</span><span class="n">nName</span> <span class="k">:</span> <span class="kt">Hendrickson</span> <span class="kt">Ora</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">7194334</span> <span class="nc">Date</span> <span class="k">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">13</span><span class="kt">/</span><span class="err">93</span> <span class="kt">.</span>            <span class="kt">|</span><span class="o">,\</span><span class="n">nName</span> <span class="k">:</span> <span class="kt">Michael</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">1478295</span> <span class="nc">Date</span> <span class="k">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">20</span><span class="kt">/</span><span class="err">93</span> <span class="kt">.</span>   <span class="kt">|</span>
<span class="kt">|PCP</span> <span class="kt">:</span> <span class="kt">Oliveira</span> <span class="o">,</span> <span class="mi">95</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">09</span> <span class="kt">.</span>            <span class="kt">|PCP</span> <span class="kt">:</span> <span class="kt">Joe</span> <span class="o">,</span> <span class="mi">95</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">16</span> <span class="kt">.|</span>
<span class="kt">|Cocke</span> <span class="kt">County</span> <span class="kt">Baptist</span> <span class="kt">Hospital</span> <span class="o">,</span> <span class="mi">0295</span> <span class="nc">Keats</span> <span class="nc">Street</span> <span class="o">,</span> <span class="nc">Phone</span> <span class="mi">55</span><span class="o">-</span><span class="mi">555</span><span class="o">-</span><span class="mf">5555.</span><span class="o">|</span><span class="nc">Medical</span> <span class="nc">Center</span> <span class="o">,</span> <span class="nc">Main</span> <span class="nc">Street</span> <span class="o">,</span> <span class="nc">Phone</span> <span class="mi">62</span><span class="o">-</span><span class="mi">130</span><span class="o">-</span><span class="mf">8657.</span>    <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------+-----------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="mapper2chunk">Mapper2Chunk</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator converts ‘LABELED_DEPENDENCY’ type annotations coming from [[ChunkMapper]] into ‘CHUNK’ type to create new chunk-type column, compatible with annotators that use chunk type as input.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">filterNoneValues</code>: (Bool) Filter ‘NONE’ values</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">LABELED_DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/mapper2_chunk/index.html#">Mapper2Chunk</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/Mapper2Chunk.html">Mapper2Chunk</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Mapper2Chunk.ipynb">Mapper2Chunk</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># Annotator that transforms a text column from dataframe into an Annotation ready for NLP
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\

<span class="c1"># Clinical word embeddings trained on PubMED dataset
</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets
</span><span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter_name</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">chunkMapper</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"drug_action_treatment_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"action"</span><span class="p">])</span>

<span class="n">mapper2chunk</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Mapper2Chunk</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"relations"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFilterNoneValues</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span> 
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter_name</span><span class="p">,</span>
    <span class="n">chunkMapper</span><span class="p">,</span>
    <span class="n">mapper2chunk</span>
    <span class="p">])</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating"</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+--------------------------+--------------+</span>
<span class="o">|</span><span class="n">result</span>                    <span class="o">|</span><span class="n">annotatorType</span> <span class="o">|</span>
<span class="o">+--------------------------+--------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">bactericidal</span><span class="p">,</span> <span class="n">antiemetic</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">chunk</span><span class="p">,</span> <span class="n">chunk</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------+--------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_name</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkMapper</span> <span class="k">=</span> <span class="nv">ChunkMapperModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"drug_action_treatment_mapper"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="s">"action"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">mapper2chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Mapper2Chunk</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setFilterNoneValues</span><span class="o">(</span><span class="nc">True</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">word_embeddings</span><span class="o">,</span> 
    <span class="n">clinical_ner</span><span class="o">,</span> 
    <span class="n">ner_converter_name</span><span class="o">,</span> 
    <span class="n">chunkMapper</span><span class="o">,</span> 
    <span class="n">mapper2chunk</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"""Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating"""</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">mapperPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span>

<span class="c1">// Show results</span>

<span class="o">+--------------------------+--------------+</span>
<span class="o">|</span><span class="n">result</span>                    <span class="o">|</span><span class="n">annotatorType</span> <span class="o">|</span>
<span class="o">+--------------------------+--------------+</span>
<span class="o">|[</span><span class="kt">bactericidal</span>, <span class="kt">antiemetic</span><span class="o">]|[</span><span class="kt">chunk</span>, <span class="kt">chunk</span><span class="o">]|</span>
<span class="o">+--------------------------+--------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="medicalllm">MedicalLLM</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>MedicalLLM was designed to load and run large language models (LLMs) in GGUF format with scalable performance. 
Ideal for clinical and healthcare applications, MedicalLLM supports tasks like medical entity extraction, summarization,
Q&amp;A, Retrieval Augmented Generation (RAG), and conversational AI. With simple integration into Spark NLP pipelines,
it allows for customizable batch sizes, prediction settings, and chat templates. GPU optimization is also available,
enhancing its capabilities for high-performance environments. MedicalLLM empowers users to link medical entities and
perform complex NLP tasks with efficiency and precision.</p>

    <p>To use GPU inference with this annotator, make sure to use the Spark NLP GPU package and set the number of GPU layers
with the setNGpuLayers method. When using larger models, we recommend adjusting GPU usage with setNCtx and setNGpuLayers 
according to your hardware to avoid out-of-memory errors.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">inputPrefix</code> :  Prefix for infilling (default: empty)</li>
      <li><code class="language-plaintext highlighter-rouge">inputSuffix</code> :  Suffix for infilling (default: empty)</li>
      <li><code class="language-plaintext highlighter-rouge">cachePrompt</code> :  Whether to remember the prompt to avoid reprocessing it</li>
      <li><code class="language-plaintext highlighter-rouge">nPredict</code>    :  Number of tokens to predict (default: -1, -1 = infinity, -2 = until context filled)</li>
      <li><code class="language-plaintext highlighter-rouge">topK</code> :  Top-k sampling (default: 40, 0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">topP</code> :  Top-p sampling (default: 0.9, 1.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">minP</code> :  Min-p sampling (default: 0.1, 0.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">tfsZ</code> :  Tail free sampling, parameter z (default: 1.0, 1.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">typicalP</code> :  Locally typical sampling, parameter p (default: 1.0, 1.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">temperature</code> :  The temperature (default: 0.8)</li>
      <li><code class="language-plaintext highlighter-rouge">dynatempRange</code> :   Dynamic temperature range (default: 0.0, 0.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">dynatempExponent</code> :  Dynamic temperature exponent (default: 1.0)</li>
      <li><code class="language-plaintext highlighter-rouge">repeatLastN</code> :  Last n tokens to consider for penalties (default: 64, 0 = disabled, -1 = ctx_size)</li>
      <li><code class="language-plaintext highlighter-rouge">repeatPenalty</code> :  Penalty of repeated sequences of tokens (default: 1.0, 1.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">frequencyPenalty</code> :  Repetition alpha frequency penalty (default: 0.0, 0.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">presencePenalty</code> :  Repetition alpha presence penalty (default: 0.0, 0.0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">mirostatTau</code> :  MiroStat target entropy, parameter tau (default: 5.0)</li>
      <li><code class="language-plaintext highlighter-rouge">mirostatEta</code> :  MiroStat learning rate, parameter eta (default: 0.1)</li>
      <li><code class="language-plaintext highlighter-rouge">penalizeNl</code> :  Whether to penalize newline tokens</li>
      <li><code class="language-plaintext highlighter-rouge">nKeep</code> :  Number of tokens to keep from the initial prompt (default: 0, -1 = all)</li>
      <li><code class="language-plaintext highlighter-rouge">seed</code> :  RNG seed (default: -1, use random seed for &lt; 0)</li>
      <li><code class="language-plaintext highlighter-rouge">nProbs</code> :  Amount top tokens probabilities to output if greater than 0.</li>
      <li><code class="language-plaintext highlighter-rouge">minKeep</code> :  Amount of tokens the samplers should return at least (0 = disabled)</li>
      <li><code class="language-plaintext highlighter-rouge">grammar</code> :  BNF-like grammar to constrain generations (see samples in grammars/ dir)</li>
      <li><code class="language-plaintext highlighter-rouge">penaltyPrompt</code> :  Override which part of the prompt is penalized for repetition. E.g. if original prompt is “Alice: Hello!” and penaltyPrompt is “Hello!”, only the latter will be penalized if repeated. See <a href="https://github.com/ggerganov/llama.cpp/pull/3727">pull request 3727</a> for more details.</li>
      <li><code class="language-plaintext highlighter-rouge">penaltyPromptTokens</code> :  PenaltyPromptTokens</li>
      <li><code class="language-plaintext highlighter-rouge">ignoreEos</code> :  Whether to ignore end of stream token and continue generating (implies –logit-bias 2-inf)</li>
      <li><code class="language-plaintext highlighter-rouge">stopStrings</code> :  Strings upon seeing which token generation is stopped</li>
      <li><code class="language-plaintext highlighter-rouge">useChatTemplate</code> :  Whether or not generate should apply a chat template (default: false)</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/medical_llm/MedicalLLM.html">MedicalLLM</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/seq2seq/medicalLLM.html">MedicalLLM</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/46.Loading_Medical_and_Open-Souce_LLMs.ipynb">MedicalLLMNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">medical_llm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">AutoGGUFModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"jsl_meds_ner_q4_v2"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"completions"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setNPredict</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setUseChatTemplate</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTemperature</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
    <span class="c1">#.setNGpuLayers(100) # if you have GPU
</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">medical_llm</span>
    <span class="p">])</span>

<span class="n">med_ner_prompt</span> <span class="o">=</span> <span class="s">"""
    ### Template:
    {
    "drugs": [
    {
    "name": "",
    "reactions": []
    }
    ]
    }
    ### Text:
    I feel a bit drowsy &amp; have a little blurred vision , and some gastric problems .
    I 've been on Arthrotec 50 for over 10 years on and off , only taking it when I needed it .
    Due to my arthritis getting progressively worse , to the point where I am in tears with the agony.
    Gp 's started me on 75 twice a day and I have to take it every day for the next month to see how I get on , here goes .
    So far its been very good , pains almost gone , but I feel a bit weird , did n't have that when on 50.
    """</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">med_ner_prompt</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>



<span class="c1">## Result
</span>
    <span class="p">{</span>
    <span class="s">"drugs"</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
    <span class="s">"name"</span><span class="p">:</span> <span class="s">"Arthrotec"</span><span class="p">,</span>
    <span class="s">"reactions"</span><span class="p">:</span> <span class="p">[</span>
    <span class="s">"drowsy"</span><span class="p">,</span>
    <span class="s">"blurred vision"</span><span class="p">,</span>
    <span class="s">"gastric problems"</span>
    <span class="p">]</span>
    <span class="p">}</span>
    <span class="p">]</span>
    <span class="p">}</span>
    <span class="o">&lt;/</span><span class="n">s</span><span class="o">&gt;</span> <span class="c1">#### Template:
</span>    <span class="p">{</span><span class="s">"drugs"</span><span class="p">:</span> <span class="p">[{</span><span class="s">"name"</span><span class="p">:</span> <span class="s">""</span><span class="p">,</span> <span class="s">"reaction"</span><span class="p">:</span> <span class="p">[]}]}</span>
    <span class="c1">#### Text:
</span>    <span class="n">The</span> <span class="n">patient</span> <span class="ow">is</span> <span class="n">a</span> <span class="mi">65</span><span class="o">-</span><span class="n">year</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.base.DocumentAssembler</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.annotators.seq2seq.MedicalLLM</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.Pipeline</span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">medicalLLM</span> <span class="k">=</span> <span class="nv">MedicalLLM</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"jsl_meds_ner_q4_v2"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"completions"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNPredict</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setUseChatTemplate</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setTemperature</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="c1">//  .setNGpuLayers(100)  if you have GPU</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span>
    <span class="nc">Array</span><span class="o">(</span>
        <span class="n">documentAssembler</span><span class="o">,</span>
        <span class="n">medicalLLM</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">medPrompt</span> <span class="k">=</span>
    <span class="s">"""
    |### Template:
    |{
    |"drugs": [
    |{
    |"name": "",
    |"reactions": []
    |}
    |]
    |}
    |### Text:
    |I feel a bit drowsy &amp; have a little blurred vision , and some gastric problems .
    |I 've been on Arthrotec 50 for over 10 years on and off , only taking it when I needed it .
    |Due to my arthritis getting progressively worse , to the point where I am in tears with the agony.
    |Gp 's started me on 75 twice a day and I have to take it every day for the next month to see how I get on , here goes .
    |So far its been very good , pains almost gone , but I feel a bit weird , did n't have that when on 50.
    |"""</span><span class="o">.</span><span class="py">stripMargin</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">medPrompt</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="nv">data</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"completions.result"</span><span class="o">).</span><span class="py">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>


<span class="o">#</span><span class="k">#</span> <span class="nc">Result</span>

    <span class="o">{</span>
    <span class="s">"drugs"</span><span class="k">:</span> <span class="err">[</span>
    <span class="o">{</span>
    <span class="err">"</span><span class="kt">name</span><span class="err">"</span><span class="kt">:</span> <span class="err">"</span><span class="kt">Arthrotec</span><span class="err">"</span><span class="o">,</span>
    <span class="err">"</span><span class="kt">reactions</span><span class="err">"</span><span class="kt">:</span> <span class="err">[</span>
    <span class="err">"</span><span class="kt">drowsy</span><span class="err">"</span><span class="o">,</span>
    <span class="s">"blurred vision"</span><span class="o">,</span>
    <span class="s">"gastric problems"</span>
    <span class="err">]</span>
    <span class="o">}</span>
    <span class="err">]</span>
    <span class="o">}</span>
    <span class="o">&lt;/</span><span class="n">s</span><span class="o">&gt;</span> <span class="o">###</span><span class="k">#</span> <span class="nc">Template</span><span class="k">:</span>
    <span class="o">{</span><span class="err">"</span><span class="kt">drugs</span><span class="err">"</span><span class="kt">:</span> <span class="err">[</span><span class="o">{</span><span class="err">"</span><span class="kt">name</span><span class="err">"</span><span class="kt">:</span> <span class="err">""</span><span class="o">,</span> <span class="err">"</span><span class="kt">reaction</span><span class="err">"</span><span class="kt">:</span> <span class="err">[]</span><span class="o">}</span><span class="err">]</span><span class="o">}</span>
    <span class="o">###</span><span class="k">#</span> <span class="nc">Text</span><span class="k">:</span>
    <span class="kt">The</span> <span class="kt">patient</span> <span class="kt">is</span> <span class="kt">a</span> <span class="err">65</span><span class="kt">-year</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="multichunk2doc">MultiChunk2Doc</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>MultiChunk2Doc annotator merges a given chunks to create a document.
During document creation, a specific whitelist and blacklist filter can be applied, and case sensitivity can be adjusted.
Additionally, specified prefix and suffix texts can be placed before and after the merged chunks in the resulting document.
And a separator can be placed between the chunks.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">separator</code> <em>(str)</em>: Separator to add between the chunks</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">prefix</code> <em>(str)</em>: Prefix to add to the result</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">suffix</code> <em>(str)</em>: Suffix to add to the result</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">blackList</code> <em>(list[str])</em>: If defined, list of entities to ignore. The rest will be processed. Do not include IOB prefix on labels</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">whiteList</code> <em>(list[str])</em>: If defined, list of entities to process. The rest will be ignored. Do not include IOB prefix on labels</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">caseSensitive</code> <em>(Bool)</em>: Determines whether the definitions of the white listed entities are case sensitive or not.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/multi_chunk2_doc/index.html">MultiChunk2Doc</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/MultiChunk2Doc.html">MultiChunk2Doc</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical_large_langtest"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">multi_chunk2_doc</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">MultiChunk2Doc</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"new_document"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"test"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPrefix</span><span class="p">(</span><span class="s">"&lt;"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setSeparator</span><span class="p">(</span><span class="s">"&gt;&lt;"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setSuffix</span><span class="p">(</span><span class="s">"&gt;"</span><span class="p">)</span> \

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">multi_chunk2_doc</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
<span class="p">[</span><span class="s">"""A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation
and subsequent type two diabetes mellitus (T2DM),
one prior episode of HTG-induced pancreatitis three years prior to presentation,
and associated with an acute hepatitis, presented with a one-week history of polyuria, poor appetite, and vomiting.
She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG.
She had been on dapagliflozin for six months at the time of presentation.
Physical examination on presentation was significant for dry oral mucosa ;
significantly , her abdominal examination was benign with no tenderness, guarding, or rigidity."""</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------------------------+----------------------------+</span>
<span class="o">|</span><span class="n">new_doc_result</span>                                                                                                                 <span class="o">|</span><span class="n">new_doc_begin</span><span class="o">|</span><span class="n">new_doc_end</span><span class="o">|</span><span class="n">new_doc_metadata_document</span><span class="o">|</span><span class="n">new_doc_metadata_chunk_count</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------------------------+----------------------------+</span>
<span class="o">|&lt;</span><span class="n">Physical</span> <span class="n">examination</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">her</span> <span class="n">abdominal</span> <span class="n">examination</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">serum</span> <span class="n">glucose</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">creatinine</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">triglycerides</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">total</span> <span class="n">cholesterol</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">venous</span> <span class="n">pH</span><span class="o">&gt;|</span><span class="mi">0</span>            <span class="o">|</span><span class="mi">126</span>        <span class="o">|</span><span class="mi">0</span>                        <span class="o">|</span><span class="mi">7</span>                           <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------------------------+----------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical_large_langtest"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">multi_chunk2_doc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MultiChunk2Doc</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">).</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"new_doc"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"test"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPrefix</span><span class="o">(</span><span class="s">"&lt;"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setSuffix</span><span class="o">(</span><span class="s">"&gt;"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setSeparator</span><span class="o">(</span><span class="s">"&gt; &lt;"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">sentence_detector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">word_embeddings</span><span class="o">,</span>
    <span class="n">ner</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">multi_chunk2_doc</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"""A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, and associated with an acute hepatitis, presented with a one-week history of polyuria, poor appetite, and vomiting. She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation. Physical examination on presentation was significant for dry oral mucosa; significantly, her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent laboratory findings on admission were: serum glucose 111 mg/dl,  creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, and venous pH 7.27."""</span><span class="o">).</span><span class="py">toDS</span><span class="o">().</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">emptyDF</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Result</span>

<span class="o">+-------------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------------------------+----------------------------+</span>
<span class="o">|</span><span class="n">new_doc_result</span>                                                                                                                 <span class="o">|</span><span class="n">new_doc_begin</span><span class="o">|</span><span class="n">new_doc_end</span><span class="o">|</span><span class="n">new_doc_metadata_document</span><span class="o">|</span><span class="n">new_doc_metadata_chunk_count</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------------------------+----------------------------+</span>
<span class="o">|&lt;</span><span class="nc">Physical</span> <span class="n">examination</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">her</span> <span class="n">abdominal</span> <span class="n">examination</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">serum</span> <span class="n">glucose</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">creatinine</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">triglycerides</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">total</span> <span class="n">cholesterol</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">venous</span> <span class="n">pH</span><span class="o">&gt;|</span><span class="mi">0</span>            <span class="o">|</span><span class="mi">126</span>        <span class="o">|</span><span class="mi">0</span>                        <span class="o">|</span><span class="mi">7</span>                           <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------+-------------+-----------+-------------------------+----------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="namechunkobfuscator">NameChunkObfuscator</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">NameChunkObfuscator</code> annotator allows to transform a dataset with an Input Annotation of type CHUNK, into its obfuscated version of by obfuscating the given CHUNKS. This module can replace name entities with consistent fakers, remain others same.</p>

    <p>Obfuscation, refers to the process of de-identifying or removing sensitive patient information from clinical notes or other healthcare documents. The purpose of PHI obfuscation is to protect patient privacy and comply with regulations such as the Health Insurance Portability and Accountability Act (HIPAA).</p>

    <p>It is important to note that the obfuscation should be done carefully to ensure that the de-identified data cannot be re-identified. Organizations must follow best practices and adhere to applicable regulations to protect patient privacy and maintain data security.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">seed</code>:  The seed to select the names on obfuscation. With the seed, you can reply an execution several times with the same output..</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">obfuscateRefSource</code>: Sets mode for select obfuscate source [‘both’, ’faker’, ‘file’] Default: ‘both’.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">language</code>: The language used to select some faker names. The values are the following: ‘en’(english),’de’(german), ‘es’(Spanish), ‘fr’(french) or ‘ro’(romanian) Default:’en’.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">sameLength</code>: The sameLength used to select the same length names as original ones during obfuscation. Example: ‘John’ –&gt; ‘Mike’. Default: true.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">nameEntities</code>: The nameEntities used to select entities during obfuscation. The supported name entities are NAME, PATIENT, and DOCTOR. Default: ‘NAME’</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">genderAwareness</code>: Whether to use gender-aware names or not during obfuscation. This param effects only names.
Default: False</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/name_obfuscator/index.html#sparknlp_jsl.annotator.deid.name_obfuscator.NameChunkObfuscator">NameChunkObfuscator</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/NameChunkObfuscator.html">NameChunkObfuscator</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/NameChunkObfuscator.ipynb">NameChunkObfuscatorNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">medical</span><span class="p">,</span> <span class="n">nlp</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">nameChunkObfuscator</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NameChunkObfuscator</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"replacement"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"faker"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setNameEntities</span><span class="p">([</span><span class="s">"DOCTOR"</span><span class="p">,</span> <span class="s">"PATIENT"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setGenderAwareness</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">replacer_name</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Replacer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"replacement"</span><span class="p">,</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"obfuscated_sentence_name"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setUseReplacement</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>
      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">nameChunkObfuscator</span><span class="p">,</span>
      <span class="n">replacer_name</span><span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="c1">## sample data
</span><span class="n">text</span> <span class="o">=</span><span class="s">'''
Record date : 2093-01-13 , David Hale , M.D . , Patient name : Michael  , MR # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555. Analyzed by Dr. Jennifer  .
'''</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">sentence</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                     <span class="n">result</span><span class="p">.</span><span class="n">obfuscated_sentence_name</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span> 
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"obfuscated_sentence_name"</span><span class="p">))</span>


<span class="o">|</span> <span class="n">sentence</span>                                          <span class="o">|</span> <span class="n">obfuscated_sentence_name</span>                                  <span class="o">|</span>
<span class="o">|</span> <span class="o">-------------------------------------------------</span> <span class="o">|</span> <span class="o">---------------------------------------------------------</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">13</span> <span class="p">,</span> <span class="n">David</span> <span class="n">Hale</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span>     <span class="o">|</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">13</span> <span class="p">,</span> <span class="n">Richardson</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span>             <span class="o">|</span>
<span class="o">|</span> <span class="p">,</span> <span class="n">Patient</span> <span class="n">name</span> <span class="p">:</span> <span class="n">Michael</span> <span class="p">,</span> <span class="n">MR</span> <span class="c1"># 7194334 Date ...	| , Patient name : Thaxter , MR # 7194334 Date ...          |
</span><span class="o">|</span> <span class="n">PCP</span> <span class="p">:</span> <span class="n">Oliveira</span> <span class="p">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="p">...</span> <span class="o">|</span> <span class="n">PCP</span> <span class="p">:</span> <span class="n">Adelaida</span> <span class="p">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="p">...</span>         <span class="o">|</span>
<span class="o">|</span> <span class="n">Cocke</span> <span class="n">County</span> <span class="n">Baptist</span> <span class="n">Hospital</span> <span class="p">,</span> <span class="mi">0295</span> <span class="n">Keats</span> <span class="n">Str</span><span class="p">...</span> <span class="o">|</span> <span class="n">Cocke</span> <span class="n">County</span> <span class="n">Baptist</span> <span class="n">Hospital</span> <span class="p">,</span> <span class="mi">0295</span> <span class="n">Keats</span> <span class="n">Str</span><span class="p">...</span>         <span class="o">|</span>
<span class="o">|</span> <span class="n">Analyzed</span> <span class="n">by</span> <span class="n">Dr</span><span class="p">.</span> <span class="n">Jennifer</span> <span class="p">.</span>                        <span class="o">|</span> <span class="n">Analyzed</span> <span class="n">by</span> <span class="n">Dr</span><span class="p">.</span> <span class="n">Morganne</span> <span class="p">.</span>                                <span class="o">|</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nameChunkObfuscator</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NameChunkObfuscator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"replacement"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"faker"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNameEntities</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"DOCTOR"</span><span class="o">,</span> <span class="s">"PATIENT"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setGenderAwareness</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">replacer_name</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Replacer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"replacement"</span><span class="o">,</span><span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"obfuscated_sentence_name"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setUseReplacement</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
      <span class="n">documentAssembler</span><span class="o">,</span>
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">word_embeddings</span><span class="o">,</span>
      <span class="n">clinical_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">nameChunkObfuscator</span><span class="o">,</span>
      <span class="n">replacer_name</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson Ora , MR # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555 ."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transfrom</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>


<span class="o">|</span> <span class="n">sentence</span>                                          <span class="o">|</span> <span class="n">obfuscated_sentence_name</span>                                  <span class="o">|</span>
<span class="o">|</span> <span class="o">-------------------------------------------------</span> <span class="o">|</span> <span class="o">---------------------------------------------------------</span> <span class="o">|</span>
<span class="o">|</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">13</span> <span class="o">,</span> <span class="nc">David</span> <span class="nc">Hale</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span>     <span class="o">|</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">13</span> <span class="o">,</span> <span class="nc">Richardson</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span>             <span class="o">|</span>
<span class="o">|</span> <span class="o">,</span> <span class="nc">Patient</span> <span class="n">name</span> <span class="k">:</span> <span class="kt">Michael</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">7194334</span> <span class="nc">Date</span> <span class="o">...</span>	<span class="o">|</span> <span class="o">,</span> <span class="nc">Patient</span> <span class="n">name</span> <span class="k">:</span> <span class="kt">Thaxter</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">7194334</span> <span class="nc">Date</span> <span class="o">...</span>          <span class="o">|</span>
<span class="o">|</span> <span class="nc">PCP</span> <span class="k">:</span> <span class="kt">Oliveira</span> <span class="o">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="kt">...</span> <span class="kt">|</span> <span class="kt">PCP</span> <span class="kt">:</span> <span class="kt">Adelaida</span> <span class="o">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="kt">...</span>         <span class="kt">|</span>
<span class="kt">|</span> <span class="kt">Cocke</span> <span class="kt">County</span> <span class="kt">Baptist</span> <span class="kt">Hospital</span> <span class="o">,</span> <span class="mi">0295</span> <span class="nc">Keats</span> <span class="nc">Str</span><span class="o">...</span> <span class="o">|</span> <span class="nc">Cocke</span> <span class="nc">County</span> <span class="nc">Baptist</span> <span class="nc">Hospital</span> <span class="o">,</span> <span class="mi">0295</span> <span class="nc">Keats</span> <span class="nc">Str</span><span class="o">...</span>         <span class="o">|</span>
<span class="o">|</span> <span class="nc">Analyzed</span> <span class="n">by</span> <span class="nc">Dr</span><span class="o">.</span> <span class="nc">Jennifer</span> <span class="o">.</span>                        <span class="o">|</span> <span class="nc">Analyzed</span> <span class="n">by</span> <span class="nc">Dr</span><span class="o">.</span> <span class="nc">Morganne</span> <span class="o">.</span>                                <span class="o">|</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">NameChunkObfuscator</code> annotator that can be used in deidentification tasks for replacing doctor and patient names with fake names using a reference document.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/name_obfuscator/index.html#sparknlp_jsl.annotator.deid.name_obfuscator.NameChunkObfuscatorApproach">NameChunkObfuscatorApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/NameChunkObfuscatorApproach.html">NameChunkObfuscatorApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/NameChunkObfuscatorApproach.ipynb">NameChunkObfuscatorApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">medical</span><span class="p">,</span> <span class="n">nlp</span>

<span class="n">names</span> <span class="o">=</span> <span class="s">"""Mitchell-NAME
Clifford-NAME
Jeremiah-NAME
Lawrence-NAME
Brittany-NAME
Patricia-NAME
Jennifer-NAME
Jackson-NAME
Leonard-NAME
Randall-NAME
Camacho-NAME
Ferrell-NAME
Mueller-NAME
Bowman-NAME
Hansen-NAME
"""</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'names_test2.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">nameChunkObfuscator</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NameChunkObfuscatorApproach</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"replacement"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">"names_test2.txt"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setObfuscateRefSource</span><span class="p">(</span><span class="s">"file"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setRefFileFormat</span><span class="p">(</span><span class="s">"csv"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setRefSep</span><span class="p">(</span><span class="s">"-"</span><span class="p">)</span>

<span class="n">replacer_name</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Replacer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"replacement"</span><span class="p">,</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"obfuscated_sentence_name"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setUseReplacement</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>
      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">nameChunkObfuscator</span><span class="p">,</span>
      <span class="n">replacer_name</span><span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="c1">## Results
</span><span class="n">text</span> <span class="o">=</span><span class="s">'''
M.D . , Patient name : Michael  , MR # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555. Analyzed by Dr. Jennifer  .
'''</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">))</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">sentence</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">obfuscated_sentence_name</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span> \
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span> <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"obfuscated_sentence_name"</span><span class="p">))</span>

<span class="o">|</span> <span class="n">sentence</span>                                          <span class="o">|</span> <span class="n">obfuscated_sentence_name</span>                          <span class="o">|</span> 
<span class="o">|</span> <span class="o">-------------------------------------------------</span> <span class="o">|</span> <span class="o">-------------------------------------------------</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span>                                             <span class="o">|</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span>                                             <span class="o">|</span>
<span class="o">|</span> <span class="p">,</span> <span class="n">Patient</span> <span class="n">name</span> <span class="p">:</span> <span class="n">Michael</span> <span class="p">,</span> <span class="n">MR</span> <span class="c1"># 7194334 Date ...  | , Patient name : Ferrell , MR # 7194334 Date ...  |
</span><span class="o">|</span> <span class="n">PCP</span> <span class="p">:</span> <span class="n">Oliveira</span> <span class="p">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="p">...</span>	<span class="o">|</span> <span class="n">PCP</span> <span class="p">:</span> <span class="n">Clifford</span> <span class="p">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="p">...</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">Cocke</span> <span class="n">County</span> <span class="n">Baptist</span> <span class="n">Hospital</span> <span class="p">,</span> <span class="mi">0295</span> <span class="n">Keats</span> <span class="n">Str</span><span class="p">...</span> <span class="o">|</span> <span class="n">Cocke</span> <span class="n">County</span> <span class="n">Baptist</span> <span class="n">Hospital</span> <span class="p">,</span> <span class="mi">0295</span> <span class="n">Keats</span> <span class="n">Str</span><span class="p">...</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">Analyzed</span> <span class="n">by</span> <span class="n">Dr</span><span class="p">.</span> <span class="n">Jennifer</span> <span class="p">.</span>                        <span class="o">|</span> <span class="n">Analyzed</span> <span class="n">by</span> <span class="n">Dr</span><span class="p">.</span> <span class="n">Jennifer</span> <span class="p">.</span>                        <span class="o">|</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">names</span> <span class="k">=</span> <span class="s">"""Mitchell-NAME
Clifford-NAME
Jeremiah-NAME
Lawrence-NAME
Brittany-NAME
Patricia-NAME
Jennifer-NAME
Jackson-NAME
Leonard-NAME
Randall-NAME
Camacho-NAME
Ferrell-NAME
Mueller-NAME
Bowman-NAME
Hansen-NAME
"""</span>
<span class="cm">/*
with open("names_test2.txt", 'w') as file:
    file.write(names)
*/</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nameChunkObfuscator</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NameChunkObfuscatorApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"replacement"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"names_test2.txt"</span><span class="o">)\</span>
    <span class="o">.</span><span class="py">setObfuscateRefSource</span><span class="o">(</span><span class="s">"file"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRefFileFormat</span><span class="o">(</span><span class="s">"csv"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRefSep</span><span class="o">(</span><span class="s">"-"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">replacer_name</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Replacer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"replacement"</span><span class="o">,</span><span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"obfuscated_sentence_name"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setUseReplacement</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">((</span>
      <span class="n">documentAssembler</span><span class="o">,</span> 
      <span class="n">sentenceDetector</span><span class="o">,</span>
      <span class="n">tokenizer</span><span class="o">,</span>
      <span class="n">word_embeddings</span><span class="o">,</span>
      <span class="n">clinical_ner</span><span class="o">,</span>
      <span class="n">ner_converter</span><span class="o">,</span>
      <span class="n">nameChunkObfuscator</span><span class="o">,</span>
      <span class="n">replacer_nam</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"M.D . , Patient name : Michael  , MR # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555. Analyzed by Dr. Jennifer  ."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">|</span> <span class="n">sentence</span>                                          <span class="o">|</span> <span class="n">obfuscated_sentence_name</span>                          <span class="o">|</span> 
<span class="o">|</span> <span class="o">-------------------------------------------------</span> <span class="o">|</span> <span class="o">-------------------------------------------------</span> <span class="o">|</span>
<span class="o">|</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span>                                             <span class="o">|</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span>                                             <span class="o">|</span>
<span class="o">|</span> <span class="o">,</span> <span class="nc">Patient</span> <span class="n">name</span> <span class="k">:</span> <span class="kt">Michael</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">7194334</span> <span class="nc">Date</span> <span class="o">...</span>  <span class="o">|</span> <span class="o">,</span> <span class="nc">Patient</span> <span class="n">name</span> <span class="k">:</span> <span class="kt">Ferrell</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">7194334</span> <span class="nc">Date</span> <span class="o">...</span>  <span class="o">|</span>
<span class="o">|</span> <span class="nc">PCP</span> <span class="k">:</span> <span class="kt">Oliveira</span> <span class="o">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="kt">...</span>	<span class="kt">|</span> <span class="kt">PCP</span> <span class="kt">:</span> <span class="kt">Clifford</span> <span class="o">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="kt">...</span> <span class="kt">|</span>
<span class="kt">|</span> <span class="kt">Cocke</span> <span class="kt">County</span> <span class="kt">Baptist</span> <span class="kt">Hospital</span> <span class="o">,</span> <span class="mi">0295</span> <span class="nc">Keats</span> <span class="nc">Str</span><span class="o">...</span> <span class="o">|</span> <span class="nc">Cocke</span> <span class="nc">County</span> <span class="nc">Baptist</span> <span class="nc">Hospital</span> <span class="o">,</span> <span class="mi">0295</span> <span class="nc">Keats</span> <span class="nc">Str</span><span class="o">...</span> <span class="o">|</span>
<span class="o">|</span> <span class="nc">Analyzed</span> <span class="n">by</span> <span class="nc">Dr</span><span class="o">.</span> <span class="nc">Jennifer</span> <span class="o">.</span>                        <span class="o">|</span> <span class="nc">Analyzed</span> <span class="n">by</span> <span class="nc">Dr</span><span class="o">.</span> <span class="nc">Jennifer</span> <span class="o">.</span>                        <span class="o">|</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="nerchunker">NerChunker</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Extracts phrases that fits into a known pattern using the NER tags. Useful for entity groups with neighboring tokens
when there is no pretrained NER model to address certain issues. A Regex needs to be provided to extract the tokens
between entities.</p>

    <p>Parameter:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">setRegexParsers</code>: Array of grammar based chunk parsers.</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, NAMED_ENTITY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/ner_chunker/index.html#sparknlp_jsl.annotator.ner.ner_chunker.NerChunker">NerChunker</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/NerChunker.html">NerChunker</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/NerChunker.ipynb">NerChunkerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="c1"># Defining pipeline stages for NER
</span>
<span class="n">documentAssembler</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setUseAbbreviations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_radiology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Define the NerChunker to combine to chunks
</span><span class="n">chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerChunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"&lt;ImagingFindings&gt;.*&lt;BodyPart&gt;"</span><span class="p">])</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner</span><span class="p">,</span>
  <span class="n">chunker</span>
<span class="p">])</span>

<span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"She has cystic cyst on her kidney."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results:
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(arrays_zip(ner.metadata , ner.result))"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"col['0'].word as word"</span> <span class="p">,</span> <span class="s">"col['1'] as ner"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+------+-----------------+</span>
<span class="o">|</span><span class="n">word</span>  <span class="o">|</span><span class="n">ner</span>              <span class="o">|</span>
<span class="o">+------+-----------------+</span>
<span class="o">|</span><span class="n">She</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">has</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">cystic</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ImagingFindings</span><span class="o">|</span>
<span class="o">|</span><span class="n">cyst</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ImagingFindings</span><span class="o">|</span>
<span class="o">|</span><span class="n">on</span>    <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">her</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">kidney</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">BodyPart</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">.</span>     <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">+------+-----------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="n">result</span>                     <span class="o">|</span>
<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">cystic</span> <span class="n">cyst</span> <span class="n">on</span> <span class="n">her</span> <span class="n">kidney</span><span class="p">]</span><span class="o">|</span>
<span class="o">+---------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span> 
<span class="c1"># Defining pipeline stages for NER
</span>
<span class="n">documentAssembler</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> 

<span class="n">tokenizer</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setContextChars</span><span class="p">([</span><span class="s">'.'</span><span class="p">,</span> <span class="s">','</span><span class="p">,</span> <span class="s">';'</span><span class="p">,</span> <span class="s">':'</span><span class="p">,</span> <span class="s">'!'</span><span class="p">,</span> <span class="s">'?'</span><span class="p">,</span> <span class="s">'*'</span><span class="p">,</span> <span class="s">'-'</span><span class="p">,</span> <span class="s">'('</span><span class="p">,</span> <span class="s">')'</span><span class="p">,</span> <span class="s">'"'</span><span class="p">,</span> <span class="s">"'"</span><span class="p">,</span> <span class="s">'%'</span><span class="p">,</span> <span class="s">'&amp;'</span><span class="p">])</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_responsibility_reports_md"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="c1"># Define the NerChunker to combine to chunks
</span><span class="n">chunker</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerChunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"&lt;ENVIRONMENTAL_KPI&gt;.*&lt;AMOUNT&gt;"</span><span class="p">])</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">chunker</span>
<span class="p">])</span>

<span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"""The company has reduced its direct GHG emissions from 12,135 million tonnes of CO2e in 2017 to 4 million tonnes of CO2e in 2021. The indirect GHG emissions (scope 2) are mainly from imported energy, including electricity, heat, steam, and cooling, and the company has reduced its scope 2 emissions from 3 million tonnes of CO2e in 2017-2018 to 4 million tonnes of CO2e in 2020-2021. The scope 3 emissions are mainly from the use of sold products, and the emissions have increased from 377 million tonnes of CO2e in 2017 to 408 million tonnes of CO2e in 2021."""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results:
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(arrays_zip(ner.metadata , ner.result))"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"col['0'].word as word"</span> <span class="p">,</span> <span class="s">"col['1'] as ner"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------+--------------------+</span>
<span class="o">|</span><span class="n">word</span>     <span class="o">|</span><span class="n">ner</span>                 <span class="o">|</span>
<span class="o">+---------+--------------------+</span>
<span class="o">|</span><span class="n">The</span>      <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">company</span>  <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">has</span>      <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">reduced</span>  <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">its</span>      <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">direct</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ENVIRONMENTAL_KPI</span> <span class="o">|</span>
<span class="o">|</span><span class="n">GHG</span>      <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ENVIRONMENTAL_KPI</span> <span class="o">|</span>
<span class="o">|</span><span class="n">emissions</span><span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ENVIRONMENTAL_KPI</span> <span class="o">|</span>
<span class="o">|</span><span class="k">from</span>     <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="mi">12</span><span class="p">,</span><span class="mi">135</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">AMOUNT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">million</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">AMOUNT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">tonnes</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ENVIRONMENTAL_UNIT</span><span class="o">|</span>
<span class="o">|</span><span class="n">of</span>       <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ENVIRONMENTAL_UNIT</span><span class="o">|</span>
<span class="o">|</span><span class="n">CO2e</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">ENVIRONMENTAL_UNIT</span><span class="o">|</span>
<span class="o">|</span><span class="ow">in</span>       <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="mi">2017</span>     <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">DATE_PERIOD</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">to</span>       <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="mi">4</span>        <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">AMOUNT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">million</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">AMOUNT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">tonnes</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ENVIRONMENTAL_UNIT</span><span class="o">|</span>
<span class="o">+---------+--------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                           <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">direct</span> <span class="n">GHG</span> <span class="n">emissions</span> <span class="k">from</span> <span class="mi">12</span><span class="p">,</span><span class="mi">135</span> <span class="n">million</span> <span class="n">tonnes</span> <span class="n">of</span> <span class="n">CO2e</span> <span class="ow">in</span> <span class="mi">2017</span> <span class="n">to</span> <span class="mi">4</span> <span class="n">million</span><span class="p">,</span> <span class="n">indirect</span> <span class="n">GHG</span> <span class="n">emissions</span> <span class="p">(</span><span class="n">scope</span> <span class="mi">2</span><span class="p">)</span> <span class="n">are</span> <span class="n">mainly</span> <span class="k">from</span> <span class="n">imported</span> <span class="n">energy</span><span class="p">,</span> <span class="n">including</span> <span class="n">electricity</span><span class="p">,</span> <span class="n">heat</span><span class="p">,</span> <span class="n">steam</span><span class="p">,</span> <span class="ow">and</span> <span class="n">cooling</span><span class="p">,</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">company</span> <span class="n">has</span> <span class="n">reduced</span> <span class="n">its</span> <span class="n">scope</span> <span class="mi">2</span> <span class="n">emissions</span> <span class="k">from</span> <span class="mi">3</span> <span class="n">million</span> <span class="n">tonnes</span> <span class="n">of</span> <span class="n">CO2e</span> <span class="ow">in</span> <span class="mi">2017</span><span class="o">-</span><span class="mi">2018</span> <span class="n">to</span> <span class="mi">4</span> <span class="n">million</span><span class="p">,</span> <span class="n">scope</span> <span class="mi">3</span> <span class="n">emissions</span> <span class="n">are</span> <span class="n">mainly</span> <span class="k">from</span> <span class="n">the</span> <span class="n">use</span> <span class="n">of</span> <span class="n">sold</span> <span class="n">products</span><span class="p">,</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">emissions</span> <span class="n">have</span> <span class="n">increased</span> <span class="k">from</span> <span class="mi">377</span> <span class="n">million</span> <span class="n">tonnes</span> <span class="n">of</span> <span class="n">CO2e</span> <span class="ow">in</span> <span class="mi">2017</span> <span class="n">to</span> <span class="mi">408</span> <span class="n">million</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span> 
<span class="c1"># Defining pipeline stages for NER
</span>
<span class="n">documentAssembler</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_org_per_role_date"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="c1"># Define the NerChunker to combine to chunks
</span><span class="n">chunker</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerChunker</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setRegexParsers</span><span class="p">([</span><span class="s">"&lt;PERSON&gt;.*&lt;ROLE&gt;"</span><span class="p">])</span>

<span class="n">pipeline</span><span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">embeddings</span><span class="p">,</span>
  <span class="n">ner_model</span><span class="p">,</span>
  <span class="n">chunker</span>
<span class="p">])</span>

<span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"""Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon"""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Show results:
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(arrays_zip(ner.metadata , ner.result))"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"col['0'].word as word"</span> <span class="p">,</span> <span class="s">"col['1'] as ner"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------------+--------+</span>
<span class="o">|</span><span class="n">word</span>        <span class="o">|</span><span class="n">ner</span>     <span class="o">|</span>
<span class="o">+------------+--------+</span>
<span class="o">|</span><span class="n">Jeffrey</span>     <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">Preston</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">Bezos</span>       <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="n">PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="ow">is</span>          <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">an</span>          <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">American</span>    <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">entrepreneur</span><span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">,</span>           <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">founder</span>     <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ROLE</span>  <span class="o">|</span>
<span class="o">|</span><span class="ow">and</span>         <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">CEO</span>         <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ROLE</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">of</span>          <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">Amazon</span>      <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="n">ORG</span>   <span class="o">|</span>
<span class="o">+------------+--------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"ner_chunk.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                              <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Jeffrey</span> <span class="n">Preston</span> <span class="n">Bezos</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">American</span> <span class="n">entrepreneur</span><span class="p">,</span> <span class="n">founder</span> <span class="ow">and</span> <span class="n">CEO</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Defining pipeline stages for NER</span>
<span class="k">val</span> <span class="nv">data</span><span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"She has cystic cyst on her kidney."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setUseAbbreviations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_radiology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="nc">True</span><span class="o">)</span>

<span class="c1">// Define the NerChunker to combine to chunks</span>
<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerChunker</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;ImagingFindings&gt;.&lt;BodyPart&gt;"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner</span><span class="o">,</span>
  <span class="n">chunker</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"""She has cystic cyst on her kidney."""</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>

<span class="o">+------+-----------------+</span>
<span class="o">|</span><span class="n">word</span>  <span class="o">|</span><span class="n">ner</span>              <span class="o">|</span>
<span class="o">+------+-----------------+</span>
<span class="o">|</span><span class="nc">She</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">has</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">cystic</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ImagingFindings</span><span class="o">|</span>
<span class="o">|</span><span class="n">cyst</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ImagingFindings</span><span class="o">|</span>
<span class="o">|</span><span class="n">on</span>    <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">her</span>   <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">kidney</span><span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">BodyPart</span>       <span class="o">|</span>
<span class="o">|.</span>     <span class="o">|</span><span class="n">O</span>                <span class="o">|</span>
<span class="o">+------+-----------------+</span>

<span class="o">+---------------------------+</span>
<span class="o">|</span><span class="n">result</span>                     <span class="o">|</span>
<span class="o">+---------------------------+</span>
<span class="o">|[</span><span class="kt">cystic</span> <span class="kt">cyst</span> <span class="kt">on</span> <span class="kt">her</span> <span class="kt">kidney</span><span class="o">]|</span>
<span class="o">+---------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Defining pipeline stages for NER</span>
<span class="k">val</span> <span class="nv">documentAssembler</span><span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span><span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_responsibility_reports_md"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="c1">// Define the NerChunker to combine to chunks</span>
<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerChunker</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;ENVIRONMENTAL_KPI&gt;.*&lt;AMOUNT&gt;"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner</span><span class="o">,</span>
  <span class="n">chunker</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"""The company has reduced its direct GHG emissions from 12,135 million tonnes of CO2e in 2017 to 4 million tonnes of CO2e in 2021. The indirect GHG emissions (scope 2) are mainly from imported energy, including electricity, heat, steam, and cooling, and the company has reduced its scope 2 emissions from 3 million tonnes of CO2e in 2017-2018 to 4 million tonnes of CO2e in 2020-2021. The scope 3 emissions are mainly from the use of sold products, and the emissions have increased from 377 million tonnes of CO2e in 2017 to 408 million tonnes of CO2e in 2021."""</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>

<span class="o">+---------+--------------------+</span>
<span class="o">|</span><span class="n">word</span>     <span class="o">|</span><span class="n">ner</span>                 <span class="o">|</span>
<span class="o">+---------+--------------------+</span>
<span class="o">|</span><span class="nc">The</span>      <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">company</span>  <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">has</span>      <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">reduced</span>  <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">its</span>      <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="n">direct</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ENVIRONMENTAL_KPI</span> <span class="o">|</span>
<span class="o">|</span><span class="nc">GHG</span>      <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ENVIRONMENTAL_KPI</span> <span class="o">|</span>
<span class="o">|</span><span class="n">emissions</span><span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ENVIRONMENTAL_KPI</span> <span class="o">|</span>
<span class="o">|</span><span class="n">from</span>     <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="mi">12</span><span class="o">,</span><span class="mi">135</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">AMOUNT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">million</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">AMOUNT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">tonnes</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ENVIRONMENTAL_UNIT</span><span class="o">|</span>
<span class="o">|</span><span class="n">of</span>       <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ENVIRONMENTAL_UNIT</span><span class="o">|</span>
<span class="o">|</span><span class="nc">CO2e</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">ENVIRONMENTAL_UNIT</span><span class="o">|</span>
<span class="o">|</span><span class="n">in</span>       <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="mi">2017</span>     <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">DATE_PERIOD</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">to</span>       <span class="o">|</span><span class="n">O</span>                   <span class="o">|</span>
<span class="o">|</span><span class="mi">4</span>        <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">AMOUNT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">million</span>  <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">AMOUNT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">tonnes</span>   <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ENVIRONMENTAL_UNIT</span><span class="o">|</span>
<span class="o">+---------+--------------------+</span>


<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                           <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">direct</span> <span class="kt">GHG</span> <span class="kt">emissions</span> <span class="kt">from</span> <span class="err">12</span>,<span class="err">135</span> <span class="kt">million</span> <span class="kt">tonnes</span> <span class="kt">of</span> <span class="kt">CO2e</span> <span class="kt">in</span> <span class="err">2017</span> <span class="kt">to</span> <span class="err">4</span> <span class="kt">million</span>, <span class="kt">indirect</span> <span class="kt">GHG</span> <span class="kt">emissions</span> <span class="o">(</span><span class="kt">scope</span> <span class="err">2</span><span class="o">)</span> <span class="kt">are</span> <span class="kt">mainly</span> <span class="kt">from</span> <span class="kt">imported</span> <span class="kt">energy</span>, <span class="kt">including</span> <span class="kt">electricity</span>, <span class="kt">heat</span>, <span class="kt">steam</span>, <span class="kt">and</span> <span class="kt">cooling</span>, <span class="kt">and</span> <span class="kt">the</span> <span class="kt">company</span> <span class="kt">has</span> <span class="kt">reduced</span> <span class="kt">its</span> <span class="kt">scope</span> <span class="err">2</span> <span class="kt">emissions</span> <span class="kt">from</span> <span class="err">3</span> <span class="kt">million</span> <span class="kt">tonnes</span> <span class="kt">of</span> <span class="kt">CO2e</span> <span class="kt">in</span> <span class="err">2017</span><span class="kt">-</span><span class="err">2018</span> <span class="kt">to</span> <span class="err">4</span> <span class="kt">million</span>, <span class="kt">scope</span> <span class="err">3</span> <span class="kt">emissions</span> <span class="kt">are</span> <span class="kt">mainly</span> <span class="kt">from</span> <span class="kt">the</span> <span class="kt">use</span> <span class="kt">of</span> <span class="kt">sold</span> <span class="kt">products</span>, <span class="kt">and</span> <span class="kt">the</span> <span class="kt">emissions</span> <span class="kt">have</span> <span class="kt">increased</span> <span class="kt">from</span> <span class="err">377</span> <span class="kt">million</span> <span class="kt">tonnes</span> <span class="kt">of</span> <span class="kt">CO2e</span> <span class="kt">in</span> <span class="err">2017</span> <span class="kt">to</span> <span class="err">408</span> <span class="kt">million</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="c1">// Defining pipeline stages for NER</span>

<span class="k">val</span> <span class="nv">documentAssembler</span><span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span><span class="s">"xx"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span><span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_org_per_role_date"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="c1">// Define the NerChunker to combine to chunks</span>
<span class="k">val</span> <span class="nv">chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerChunker</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setRegexParsers</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"&lt;PERSON&gt;.*&lt;ROLE&gt;"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">ner</span><span class="o">,</span>
  <span class="n">chunker</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"""Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon"""</span>
<span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results:</span>

<span class="o">+------------+--------+</span>
<span class="o">|</span><span class="n">word</span>        <span class="o">|</span><span class="n">ner</span>     <span class="o">|</span>
<span class="o">+------------+--------+</span>
<span class="o">|</span><span class="nc">Jeffrey</span>     <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Preston</span>     <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Bezos</span>       <span class="o">|</span><span class="n">I</span><span class="o">-</span><span class="nc">PERSON</span><span class="o">|</span>
<span class="o">|</span><span class="n">is</span>          <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">an</span>          <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">American</span>    <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">entrepreneur</span><span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|,</span>           <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">founder</span>     <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ROLE</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">and</span>         <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">CEO</span>         <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ROLE</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">of</span>          <span class="o">|</span><span class="n">O</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">Amazon</span>      <span class="o">|</span><span class="n">B</span><span class="o">-</span><span class="nc">ORG</span>   <span class="o">|</span>
<span class="o">+------------+--------+</span>


<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                              <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Jeffrey</span> <span class="kt">Preston</span> <span class="kt">Bezos</span> <span class="kt">is</span> <span class="kt">an</span> <span class="kt">American</span> <span class="kt">entrepreneur</span>, <span class="kt">founder</span> <span class="kt">and</span> <span class="kt">CEO</span><span class="o">]|</span>
<span class="o">+--------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="nerconverterinternal">NerConverterInternal</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Converts a IOB or IOB2 representation of NER to a user-friendly one,
by associating the tokens of recognized entities and their label.
Chunks with no associated entity (tagged “O”) are filtered out.</p>

    <p>Parameters;</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setThreshold</code>: Confidence threshold.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setWhiteList</code>: If defined, list of entities to process.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setBlackList</code>:  If defined, list of entities to ignore.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setReplaceLabels</code>: If defined, contains a dictionary for entity replacement.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setPreservePosition</code>: Whether to preserve the original position of the tokens in the original document or use the modified tokens.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setReplaceDictResource</code>: If defined, path to the file containing a dictionary for entity replacement.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setIgnoreStopWords</code>: If defined, list of stop words to ignore.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setGreedyMode</code>: (Boolean) Whether to ignore B tags for contiguous tokens of same entity same .</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">resetSentenceIndices</code>: Whether to reset sentence indices to treat the entire output as if it originates from a single document. Default: False.</p>
      </li>
    </ul>

    <p>This licensed annotator adds extra functionality to the open-source version by adding the following parameters: <code class="language-plaintext highlighter-rouge">blackList</code>, <code class="language-plaintext highlighter-rouge">greedyMode</code>,  <code class="language-plaintext highlighter-rouge">threshold</code>, and <code class="language-plaintext highlighter-rouge">ignoreStopWords</code> that are not available in the <a href="https://nlp.johnsnowlabs.com/docs/en/annotators#nerconverter">NerConverter</a> annotator.</p>

    <p>See also <a href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)">Inside–outside–beginning (tagging)</a> for more information.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, NAMED_ENTITY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/ner_converter_internal/index.html#sparknlp_jsl.annotator.ner.ner_converter_internal.NerConverterInternal">NerConverterInternal</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/NerConverterInternal.html">NerConverterInternal</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/NerConverterInternal.ipynb">Notebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Annotator that transforms a text column from dataframe into an Annotation ready for NLP
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="c1"># Clinical word embeddings trained on PubMED dataset
</span><span class="n">embeddings</span>  <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># NER model
</span><span class="n">nerModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="c1"># NER Converter
</span><span class="n">nerConverter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
   <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
   <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span> <span class="o">=</span> <span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span>
                              <span class="n">sentence_detector</span><span class="p">,</span>
                              <span class="n">tokenizer</span><span class="p">,</span>
                              <span class="n">embeddings</span><span class="p">,</span>
                              <span class="n">nerModel</span><span class="p">,</span>
                              <span class="n">nerConverter</span>
                              <span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""The patient was prescribed 1 capsule of Advil for 5 days.
He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, metformin 1000 mg two times a day.
"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span> <span class="s">'ner.result'</span><span class="p">,</span> <span class="s">'ner_chunk.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>

<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span>                                              <span class="n">text</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">prescribed</span> <span class="mi">1</span> <span class="n">capsule</span> <span class="n">of</span> <span class="n">Advil</span> <span class="n">f</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">DOSAGE</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">FORM</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">DRUG</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">DUR</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">capsule</span><span class="p">,</span> <span class="n">Advil</span><span class="p">,</span> <span class="k">for</span> <span class="mi">5</span> <span class="n">days</span><span class="p">,</span> <span class="mi">40</span> <span class="n">units</span><span class="p">,</span> <span class="n">insul</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Annotator that transforms a text column from dataframe into an Annotation ready for NLP
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setContextChars</span><span class="p">([</span><span class="s">'.'</span><span class="p">,</span> <span class="s">','</span><span class="p">,</span> <span class="s">';'</span><span class="p">,</span> <span class="s">':'</span><span class="p">,</span> <span class="s">'!'</span><span class="p">,</span> <span class="s">'?'</span><span class="p">,</span> <span class="s">'*'</span><span class="p">,</span> <span class="s">'-'</span><span class="p">,</span> <span class="s">'('</span><span class="p">,</span> <span class="s">')'</span><span class="p">,</span> <span class="s">'"'</span><span class="p">,</span> <span class="s">"'"</span><span class="p">,</span> <span class="s">'%'</span><span class="p">,</span> <span class="s">'&amp;'</span><span class="p">])</span>

<span class="n">embeddings</span>  <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># NER model
</span><span class="n">nerModel</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_responsibility_reports_md"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="c1"># NER Converter
</span><span class="n">nerConverter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
   <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
   <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span> <span class="o">=</span> <span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span>
                              <span class="n">sentence_detector</span><span class="p">,</span>
                              <span class="n">tokenizer</span><span class="p">,</span>
                              <span class="n">embeddings</span><span class="p">,</span>
                              <span class="n">nerModel</span><span class="p">,</span>
                              <span class="n">nerConverter</span>
                              <span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""The company has reduced its direct GHG emissions from 12,135 million tonnes of CO2e in 2017 to 4 million tonnes of CO2e in 2021. The indirect GHG emissions (scope 2) are mainly from imported energy, including electricity, heat, steam, and cooling, and the company has reduced its scope 2 emissions from 3 million tonnes of CO2e in 2017-2018 to 4 million tonnes of CO2e in 2020-2021. The scope 3 emissions are mainly from the use of sold products, and the emissions have increased from 377 million tonnes of CO2e in 2017 to 408 million tonnes of CO2e in 2021.
"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span> <span class="s">'ner.result'</span><span class="p">,</span> <span class="s">'ner_chunk.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>

<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span>                                              <span class="n">text</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="n">The</span> <span class="n">company</span> <span class="n">has</span> <span class="n">reduced</span> <span class="n">its</span> <span class="n">direct</span> <span class="n">GHG</span> <span class="n">emission</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="o">-</span><span class="n">ENVIRONMENTAL_KPI</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">ENVIRONM</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="n">direct</span> <span class="n">GHG</span> <span class="n">emissions</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span><span class="mi">135</span> <span class="n">million</span><span class="p">,</span> <span class="n">tonnes</span> <span class="n">o</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="c1"># Annotator that transforms a text column from dataframe into an Annotation ready for NLP
</span><span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span>  <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># NER model
</span><span class="n">nerModel</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_org_per_role_date"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="c1"># NER Converter
</span><span class="n">nerConverter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
   <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
   <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span> <span class="o">=</span> <span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span>
                              <span class="n">sentence_detector</span><span class="p">,</span>
                              <span class="n">tokenizer</span><span class="p">,</span>
                              <span class="n">embeddings</span><span class="p">,</span>
                              <span class="n">nerModel</span><span class="p">,</span>
                              <span class="n">nerConverter</span>
                              <span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""Jeffrey Preston Bezos is an American entrepreneur, founder and CEO of Amazon
"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'text'</span><span class="p">,</span> <span class="s">'ner.result'</span><span class="p">,</span> <span class="s">'ner_chunk.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>

<span class="o">+--------------------------------------------------+--------------------------------------------------+---------------------------------------------+</span>
<span class="o">|</span>                                              <span class="n">text</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>                                       <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+---------------------------------------------+</span>
<span class="o">|</span><span class="n">Jeffrey</span> <span class="n">Preston</span> <span class="n">Bezos</span> <span class="ow">is</span> <span class="n">an</span> <span class="n">American</span> <span class="n">entreprene</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="n">B</span><span class="o">-</span><span class="n">PERSON</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PERSON</span><span class="p">,</span> <span class="n">I</span><span class="o">-</span><span class="n">PERSON</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">O</span><span class="p">,</span> <span class="n">B</span><span class="p">...</span><span class="o">|</span><span class="p">[</span><span class="n">Jeffrey</span> <span class="n">Preston</span> <span class="n">Bezos</span><span class="p">,</span> <span class="n">founder</span><span class="p">,</span> <span class="n">CEO</span><span class="p">,</span> <span class="n">Amazon</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+---------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Annotator that transforms a text column from dataframe into an Annotation ready for NLP </span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
 
<span class="c1">// Tokenizer splits words in a relevant format for NLP </span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 
 
<span class="c1">// Clinical word embeddings trained on PubMED dataset </span>
<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 
 
<span class="c1">// NER model </span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
 
<span class="c1">// NER Converter </span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">sentence_detector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">embeddings</span><span class="o">,</span> 
    <span class="n">nerModel</span><span class="o">,</span> 
    <span class="n">nerConverter</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">empty_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">empty_data</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sample_text</span> <span class="k">=</span> <span class="s">"The patient was prescribed 1 capsule of Advil for 5 days.He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night,12 units of insulin lispro with meals,metformin 1000 mg two times a day."</span> 

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">sample_text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span> <span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span><span class="s">"ner.result"</span><span class="o">,</span><span class="s">"ner_chunk.result"</span><span class="o">)</span> 

<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span>                                              <span class="n">text</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">prescribed</span> <span class="mi">1</span> <span class="n">capsule</span> <span class="n">of</span> <span class="nc">Advil</span> <span class="n">f</span><span class="o">...|[</span><span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-DOSAGE</span>, <span class="kt">B-FORM</span>, <span class="kt">O</span>, <span class="kt">B-DRUG</span>, <span class="kt">B-DUR...|</span><span class="o">[</span><span class="err">1</span>, <span class="kt">capsule</span>, <span class="kt">Advil</span>, <span class="kt">for</span> <span class="err">5</span> <span class="kt">days</span>, <span class="err">40</span> <span class="kt">units</span>, <span class="kt">insul...|</span>
<span class="kt">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Annotator that transforms a text column from dataframe into an Annotation ready for NLP </span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="c1">// Tokenizer splits words in a relevant format for NLP </span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setContextChars</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"."</span><span class="o">,</span><span class="s">","</span><span class="o">,</span><span class="s">";"</span><span class="o">,</span><span class="s">":"</span><span class="o">,</span><span class="s">"!"</span><span class="o">,</span><span class="s">"?"</span><span class="o">,</span><span class="s">"*"</span><span class="o">,</span><span class="s">"-"</span><span class="o">,</span><span class="s">"("</span><span class="o">,</span><span class="s">") "</span><span class="o">,</span><span class="s">""","""</span><span class="o">,</span><span class="s">"%"</span><span class="o">,</span><span class="s">"&amp;"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="c1">// NER model </span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_responsibility_reports_md"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
 
<span class="c1">// NER Converter </span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">sentence_detector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">nerModel</span><span class="o">,</span> 
    <span class="n">nerConverter</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">empty_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">empty_data</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sample_text</span> <span class="k">=</span> <span class="s">"The company has reduced its direct GHG emissions from 12,135 million tonnes of CO2e in 2017 to 4 million tonnes of CO2e in 2021. The indirect GHG emissions (scope 2) are mainly from imported energy,including electricity,heat,steam,and cooling,and the company has reduced its scope 2 emissions from 3 million tonnes of CO2e in 2017-2018 to 4 million tonnes of CO2e in 2020-2021. The scope 3 emissions are mainly from the use of sold products,and the emissions have increased from 377 million tonnes of CO2e in 2017 to 408 million tonnes of CO2e in 2021."</span> 
<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">sample_text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span> <span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span><span class="s">"ner.result"</span><span class="o">,</span><span class="s">"ner_chunk.result"</span><span class="o">)</span> 

<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span>                                              <span class="n">text</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">company</span> <span class="n">has</span> <span class="n">reduced</span> <span class="n">its</span> <span class="n">direct</span> <span class="nc">GHG</span> <span class="n">emission</span><span class="o">...|[</span><span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B-ENVIRONMENTAL_KPI</span>, <span class="kt">I-ENVIRONM...|</span><span class="o">[</span><span class="kt">direct</span> <span class="kt">GHG</span> <span class="kt">emissions</span>, <span class="err">12</span>,<span class="err">135</span> <span class="kt">million</span>, <span class="kt">tonnes</span> <span class="kt">o...|</span>
<span class="kt">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Annotator that transforms a text column from dataframe into an Annotation ready for NLP </span>
<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="c1">// Tokenizer splits words in a relevant format for NLP </span>
<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 
 
<span class="c1">// NER model </span>
<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_org_per_role_date"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"legal/models"</span><span class="o">)</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 
 
<span class="c1">// NER Converter </span>
<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
 <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
 <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">embeddings</span><span class="o">,</span> 
    <span class="n">nerModel</span><span class="o">,</span> 
    <span class="n">nerConverter</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">empty_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">empty_data</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sample_text</span> <span class="k">=</span> <span class="s">"Jeffrey Preston Bezos is an American entrepreneur,founder and CEO of Amazon"</span> 

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">sample_text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">model</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span> <span class="nv">result</span><span class="o">.</span><span class="py">select</span><span class="o">(</span><span class="s">"text"</span><span class="o">,</span><span class="s">"ner.result"</span><span class="o">,</span><span class="s">"ner_chunk.result"</span><span class="o">)</span> 

<span class="o">+--------------------------------------------------+--------------------------------------------------+---------------------------------------------+</span>
<span class="o">|</span>                                              <span class="n">text</span><span class="o">|</span>                                            <span class="n">result</span><span class="o">|</span>                                       <span class="n">result</span><span class="o">|</span>
<span class="o">+--------------------------------------------------+--------------------------------------------------+---------------------------------------------+</span>
<span class="o">|</span><span class="nc">Jeffrey</span> <span class="nc">Preston</span> <span class="nc">Bezos</span> <span class="n">is</span> <span class="n">an</span> <span class="nc">American</span> <span class="n">entreprene</span><span class="o">...|[</span><span class="kt">B-PERSON</span>, <span class="kt">I-PERSON</span>, <span class="kt">I-PERSON</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">O</span>, <span class="kt">B...|</span><span class="o">[</span><span class="kt">Jeffrey</span> <span class="kt">Preston</span> <span class="kt">Bezos</span>, <span class="kt">founder</span>, <span class="kt">CEO</span>, <span class="kt">Amazon</span><span class="o">]</span><span class="kt">|</span>
<span class="kt">+--------------------------------------------------+--------------------------------------------------+---------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="nerdisambiguator">NerDisambiguator</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.
Instantiated / pretrained model of the NerDisambiguator.
Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">embeddingTypeParam</code>: (String) ‘bow’ for word embeddings or ‘sentence’ for sentences.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">numFirstChars</code>: (Int) number of characters to be considered for initial prefix search in the knowledge base.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">tokenSearch</code>: (BooleanParam) mechanism of search - by token or by - chunk in knowledge base (token is recommended ==&gt; Default value: True).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">narrowWithApproximateMatching</code>: (BooleanParam) narrow down the prefix search results with Levenshtein distance based matching (True is recommended).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">levenshteinDistanceThresholdParam</code>: (Float) value of the
Levenshtein distance threshold to narrow results from prefix search (default value: 0.1).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">nearMatchingGapParam</code>: (Int) allows to define a limit on the string length (by trimming the candidate chunks) during Levenshtein distance-based narrowing,  {len(candidate) - len(entity chunk) &gt; nearMatchingGap} (default value: 4).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">predictionsLimit</code>: (BooleanParam) allows to limit the number of predictions N for top N predictions.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">s3KnowledgeBaseName</code>: (String) the name of the Knowledge Base name in S3.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DISAMBIGUATION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/disambiguation/ner_disambiguator/index.html#sparknlp_jsl.annotator.disambiguation.ner_disambiguator.NerDisambiguatorModel">NerDisambiguatorModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/disambiguation/NerDisambiguatorModel.html">NerDisambiguatorModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/NerDisambiguatorModel.ipynb">NerDisambiguatorModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span>  <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">sentence_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceEmbeddings</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PER"</span><span class="p">])</span>

<span class="n">disambiguator</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerDisambiguator</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setS3KnowledgeBaseName</span><span class="p">(</span><span class="s">"i-per"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"disambiguation"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setTokenSearch</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">sentence_embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">disambiguator</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""The show also had a contestant named Donald Trump who later defeated Christina Aguilera ..."""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>


<span class="c1"># Result
</span><span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"explode(disambiguation)"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"col.metadata.chunk as chunk"</span><span class="p">,</span> <span class="s">"col.result as result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>             <span class="o">|</span><span class="n">result</span>                                                                                                                  <span class="o">|</span>
<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">Donald</span> <span class="n">Trump</span>      <span class="o">|</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">en</span><span class="p">.</span><span class="n">wikipedia</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="err">?</span><span class="n">curid</span><span class="o">=</span><span class="mi">55907961</span><span class="p">,</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">en</span><span class="p">.</span><span class="n">wikipedia</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="err">?</span><span class="n">curid</span><span class="o">=</span><span class="mi">31698421</span><span class="p">,</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">en</span><span class="p">.</span><span class="n">wikipedia</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="err">?</span><span class="n">curid</span><span class="o">=</span><span class="mi">4848272</span><span class="o">|</span>
<span class="o">|</span><span class="n">Christina</span> <span class="n">Aguilera</span><span class="o">|</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">en</span><span class="p">.</span><span class="n">wikipedia</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="err">?</span><span class="n">curid</span><span class="o">=</span><span class="mi">6636454</span><span class="p">,</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">en</span><span class="p">.</span><span class="n">wikipedia</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="err">?</span><span class="n">curid</span><span class="o">=</span><span class="mi">144171</span>                                           <span class="o">|</span>
<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentence_embeddings</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEmbeddings</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"PER"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">disambiguator</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerDisambiguator</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setS3KnowledgeBaseName</span><span class="o">(</span><span class="s">"i-per"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"sentence_embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"disambiguation"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setTokenSearch</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
                                              <span class="n">documentAssembler</span><span class="o">,</span> 
                                              <span class="n">sentenceDetector</span><span class="o">,</span> 
                                              <span class="n">tokenizer</span><span class="o">,</span> 
                                              <span class="n">word_embeddings</span><span class="o">,</span> 
                                              <span class="n">sentence_embeddings</span><span class="o">,</span> 
                                              <span class="n">ner_model</span><span class="o">,</span> 
                                              <span class="n">ner_converter</span><span class="o">,</span> 
                                              <span class="n">disambiguator</span><span class="o">))</span>
 
<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"The show also had a contestant named Donald Trump who later defeated Christina Aguilera ..."</span> 

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// Result </span>

<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>             <span class="o">|</span><span class="n">result</span>                                                                                                                  <span class="o">|</span>
<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">Donald</span> <span class="nc">Trump</span>      <span class="o">|</span><span class="n">http</span><span class="o">://</span><span class="nv">en</span><span class="o">.</span><span class="py">wikipedia</span><span class="o">.</span><span class="py">org</span><span class="o">/?</span><span class="n">curid</span><span class="k">=</span><span class="mi">55907961</span><span class="o">,</span> <span class="n">http</span><span class="o">://</span><span class="nv">en</span><span class="o">.</span><span class="py">wikipedia</span><span class="o">.</span><span class="py">org</span><span class="o">/?</span><span class="n">curid</span><span class="k">=</span><span class="mi">31698421</span><span class="o">,</span> <span class="n">http</span><span class="o">://</span><span class="nv">en</span><span class="o">.</span><span class="py">wikipedia</span><span class="o">.</span><span class="py">org</span><span class="o">/?</span><span class="n">curid</span><span class="k">=</span><span class="mi">4848272</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Christina</span> <span class="nc">Aguilera</span><span class="o">|</span><span class="n">http</span><span class="o">://</span><span class="nv">en</span><span class="o">.</span><span class="py">wikipedia</span><span class="o">.</span><span class="py">org</span><span class="o">/?</span><span class="n">curid</span><span class="k">=</span><span class="mi">6636454</span><span class="o">,</span> <span class="n">http</span><span class="o">://</span><span class="nv">en</span><span class="o">.</span><span class="py">wikipedia</span><span class="o">.</span><span class="py">org</span><span class="o">/?</span><span class="n">curid</span><span class="k">=</span><span class="mi">144171</span>                                           <span class="o">|</span>
<span class="o">+------------------+------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Links words of interest, such as names of persons, locations and companies, from an input text document to
a corresponding unique entity in a target Knowledge Base (KB). Words of interest are called Named Entities (NEs),
mentions, or surface forms.
The model needs extracted CHUNKS and SENTENCE_EMBEDDINGS type input from e.g.
<a href="/docs/en/annotators#sentenceembeddings">SentenceEmbeddings</a> and
<a href="/docs/en/annotators#nerconverter">NerConverter</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DISAMBIGUATION</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/disambiguation/ner_disambiguator/index.html#sparknlp_jsl.annotator.disambiguation.ner_disambiguator.NerDisambiguator">NerDisambiguator</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/disambiguation/NerDisambiguator.html">NerDisambiguator</a></td>
        </tr>
      </tbody>
    </table>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="nermodel">NerModel</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">NerModel</code> is the Named Entity Recognition (NER) annotator that allows to train generic NER model based on Neural Networks. The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets.</p>

    <p>Note that some pre-trained models require specific types of embeddings, depending on which they were trained.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setBatchSize</code>: (int) number of samples used in one iteration of training (Default: <code class="language-plaintext highlighter-rouge">32</code>).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setIncludeConfidence</code>: (Boolean) whether to include confidence scores in annotation metadata (<code class="language-plaintext highlighter-rouge">Default</code>: False).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setConfigProtoBytes</code>: (int) ConfigProto from tensorflow, serialized into byte array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setIncludeAllConfidenceScores</code>: (Boolean) whether to include confidence scores for all tags rather than just for the predicted one.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setMinProbability</code> (Float) define the minimum probability value.</p>
      </li>
    </ul>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition">Models Hub</a>.
Additionally, pretrained pipelines are available for this module, see the <a href="https://nlp.johnsnowlabs.com/docs/en/pipelines">Pipelines</a>.
For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master">Spark NLP Workshop</a></p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/medical_ner/index.html#sparknlp_jsl.annotator.ner.medical_ner.MedicalNerModel">MedicalNerModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/MedicalNerModel.html">MedicalNerModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/MedicalNerModel.ipynb">MedicalNerModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">jsl_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"jsl_ner"</span><span class="p">)</span>

<span class="n">jsl_ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"jsl_ner"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">jsl_ner_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">jsl_ner</span><span class="p">,</span>
    <span class="n">jsl_ner_converter</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">'''
A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, and associated with an acute hepatitis, presented with a one-week history of polyuria, poor appetite, and vomiting.
She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation.
Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent laboratory findings on admission were: serum glucose 111 mg/dl,  creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, and venous pH 7.27.
'''</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">jsl_ner_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------+----------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>                        <span class="o">|</span><span class="n">ner_label</span>                   <span class="o">|</span>
<span class="o">+-----------------------------+----------------------------+</span>
<span class="o">|</span><span class="mi">28</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span>                  <span class="o">|</span><span class="n">Age</span>                         <span class="o">|</span>
<span class="o">|</span><span class="n">female</span>                       <span class="o">|</span><span class="n">Gender</span>                      <span class="o">|</span>
<span class="o">|</span><span class="n">gestational</span> <span class="n">diabetes</span> <span class="n">mellitus</span><span class="o">|</span><span class="n">Diabetes</span>                    <span class="o">|</span>
<span class="o">|</span><span class="n">eight</span> <span class="n">years</span> <span class="n">prior</span>            <span class="o">|</span><span class="n">RelativeDate</span>                <span class="o">|</span>
<span class="o">|</span><span class="nb">type</span> <span class="n">two</span> <span class="n">diabetes</span> <span class="n">mellitus</span>   <span class="o">|</span><span class="n">Diabetes</span>                    <span class="o">|</span>
<span class="o">|</span><span class="n">T2DM</span>                         <span class="o">|</span><span class="n">Diabetes</span>                    <span class="o">|</span>
<span class="o">|</span><span class="n">HTG</span><span class="o">-</span><span class="n">induced</span> <span class="n">pancreatitis</span>     <span class="o">|</span><span class="n">Disease_Syndrome_Disorder</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">three</span> <span class="n">years</span> <span class="n">prior</span>            <span class="o">|</span><span class="n">RelativeDate</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">acute</span>                        <span class="o">|</span><span class="n">Modifier</span>                    <span class="o">|</span>
<span class="o">|</span><span class="n">hepatitis</span>                    <span class="o">|</span><span class="n">Disease_Syndrome_Disorder</span>   <span class="o">|</span>
<span class="o">|</span><span class="n">one</span><span class="o">-</span><span class="n">week</span>                     <span class="o">|</span><span class="n">Duration</span>                    <span class="o">|</span>
<span class="o">|</span><span class="n">polyuria</span>                     <span class="o">|</span><span class="n">Symptom</span>                     <span class="o">|</span>
<span class="o">|</span><span class="n">poor</span> <span class="n">appetite</span>                <span class="o">|</span><span class="n">Symptom</span>                     <span class="o">|</span>
<span class="o">|</span><span class="n">vomiting</span>                     <span class="o">|</span><span class="n">Symptom</span>                     <span class="o">|</span>
<span class="o">|</span><span class="n">She</span>                          <span class="o">|</span><span class="n">Gender</span>                      <span class="o">|</span>
<span class="o">|</span><span class="n">metformin</span>                    <span class="o">|</span><span class="n">Drug_Ingredient</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">glipizide</span>                    <span class="o">|</span><span class="n">Drug_Ingredient</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">dapagliflozin</span>                <span class="o">|</span><span class="n">Drug_Ingredient</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">T2DM</span>                         <span class="o">|</span><span class="n">Diabetes</span>                    <span class="o">|</span>
<span class="o">|</span><span class="n">atorvastatin</span>                 <span class="o">|</span><span class="n">Drug_Ingredient</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">gemfibrozil</span>                  <span class="o">|</span><span class="n">Drug_Ingredient</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">HTG</span>                          <span class="o">|</span><span class="n">Hyperlipidemia</span>              <span class="o">|</span>
<span class="o">|</span><span class="n">She</span>                          <span class="o">|</span><span class="n">Gender</span>                      <span class="o">|</span>
<span class="o">|</span><span class="n">dapagliflozin</span>                <span class="o">|</span><span class="n">Drug_Ingredient</span>             <span class="o">|</span>
<span class="o">|</span><span class="k">for</span> <span class="n">six</span> <span class="n">months</span>               <span class="o">|</span><span class="n">Duration</span>                    <span class="o">|</span>
<span class="o">|</span><span class="n">dry</span> <span class="n">oral</span> <span class="n">mucosa</span>              <span class="o">|</span><span class="n">Symptom</span>                     <span class="o">|</span>
<span class="o">|</span><span class="n">her</span>                          <span class="o">|</span><span class="n">Gender</span>                      <span class="o">|</span>
<span class="o">|</span><span class="n">abdominal</span>                    <span class="o">|</span><span class="n">External_body_part_or_region</span><span class="o">|</span>
<span class="o">|</span><span class="n">tenderness</span>                   <span class="o">|</span><span class="n">Symptom</span>                     <span class="o">|</span>
<span class="o">|</span><span class="n">guarding</span>                     <span class="o">|</span><span class="n">Symptom</span>                     <span class="o">|</span>
<span class="o">|</span><span class="n">rigidity</span>                     <span class="o">|</span><span class="n">Symptom</span>                     <span class="o">|</span>
<span class="o">|</span><span class="n">admission</span>                    <span class="o">|</span><span class="n">Admission_Discharge</span>         <span class="o">|</span>
<span class="o">|</span><span class="n">serum</span> <span class="n">glucose</span>                <span class="o">|</span><span class="n">Test</span>                        <span class="o">|</span>
<span class="o">|</span><span class="mi">111</span> <span class="n">mg</span><span class="o">/</span><span class="n">dl</span>                    <span class="o">|</span><span class="n">Test_Result</span>                 <span class="o">|</span>
<span class="o">|</span><span class="n">creatinine</span>                   <span class="o">|</span><span class="n">Test</span>                        <span class="o">|</span>
<span class="o">|</span><span class="mf">0.4</span> <span class="n">mg</span><span class="o">/</span><span class="n">dL</span>                    <span class="o">|</span><span class="n">Test_Result</span>                 <span class="o">|</span>
<span class="o">|</span><span class="n">triglycerides</span>                <span class="o">|</span><span class="n">Triglycerides</span>               <span class="o">|</span>
<span class="o">|</span><span class="mi">508</span> <span class="n">mg</span><span class="o">/</span><span class="n">dL</span>                    <span class="o">|</span><span class="n">Test_Result</span>                 <span class="o">|</span>
<span class="o">|</span><span class="n">total</span> <span class="n">cholesterol</span> <span class="mi">122</span> <span class="n">mg</span><span class="o">/</span><span class="n">dL</span>  <span class="o">|</span><span class="n">Total_Cholesterol</span>           <span class="o">|</span>
<span class="o">|</span><span class="n">venous</span> <span class="n">pH</span>                    <span class="o">|</span><span class="n">Test</span>                        <span class="o">|</span>
<span class="o">|</span><span class="mf">7.27</span>                         <span class="o">|</span><span class="n">Test_Result</span>                 <span class="o">|</span>
<span class="o">+-----------------------------+----------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>
    
<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span> <span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_legal_bert_base_uncased"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_sec_conll"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">'''December 2007 SUBORDINATED LOAN AGREEMENT. THIS LOAN AGREEMENT is made on 7th December, 2007 BETWEEN: (1) SILICIUM DE PROVENCE S.A.S., a private company with limited liability, incorporated under the laws of France, whose registered office is situated at Usine de Saint Auban, France, represented by Mr.Frank Wouters, hereinafter referred to as the "Borrower", and ( 2 ) EVERGREEN SOLAR INC., a company incorporated in Delaware, U.S.A., with registered number 2426798, whose registered office is situated at Bartlett Street, Marlboro, Massachusetts, U.S.A. represented by Richard Chleboski, hereinafter referred to as "Lender" '''</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="o">+--------------------------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                     <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+--------------------------+---------+</span>
<span class="o">|</span><span class="n">SILICIUM</span> <span class="n">DE</span> <span class="n">PROVENCE</span> <span class="n">S</span><span class="p">.</span><span class="n">A</span><span class="p">.</span><span class="n">S</span><span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">France</span>                    <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Usine</span> <span class="n">de</span> <span class="n">Saint</span> <span class="n">Auban</span>      <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">France</span>                    <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Mr</span><span class="p">.</span><span class="n">Frank</span> <span class="n">Wouters</span>          <span class="o">|</span><span class="n">PER</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Borrower</span>                  <span class="o">|</span><span class="n">PER</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">EVERGREEN</span> <span class="n">SOLAR</span> <span class="n">INC</span>       <span class="o">|</span><span class="n">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Delaware</span>                  <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">U</span><span class="p">.</span><span class="n">S</span><span class="p">.</span><span class="n">A</span>                     <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Bartlett</span> <span class="n">Street</span>           <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Marlboro</span>                  <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Massachusetts</span>             <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">U</span><span class="p">.</span><span class="n">S</span><span class="p">.</span><span class="n">A</span>                     <span class="o">|</span><span class="n">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Richard</span> <span class="n">Chleboski</span>         <span class="o">|</span><span class="n">PER</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">Lender</span>                    <span class="o">|</span><span class="n">PER</span>      <span class="o">|</span>
<span class="o">+--------------------------+---------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span><span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>\

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">])</span>
  
<span class="n">text</span> <span class="o">=</span> <span class="s">"""EXCLUSIVE DISTRIBUTOR AGREEMENT (" Agreement ") dated as April 15, 1994 by and between IMRS OPERATIONS INC., a Delaware corporation with its principal place of business at 777 Long Ridge Road, Stamford, Connecticut 06902, U.S.A. (hereinafter referred to as " Developer ") and Delteq Pte Ltd, a Singapore company (and a subsidiary of Wuthelam Industries (S) Pte LTD ) with its principal place of business at 215 Henderson Road , #101-03 Henderson Industrial Park , Singapore 0315 ( hereinafter referred to as " Distributor ")."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-------------------------------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                          <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-------------------------------+---------+</span>
<span class="o">|</span><span class="n">EXCLUSIVE</span> <span class="n">DISTRIBUTOR</span> <span class="n">AGREEMENT</span><span class="o">|</span><span class="n">DOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="n">April</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">1994</span>                 <span class="o">|</span><span class="n">EFFDATE</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">IMRS</span> <span class="n">OPERATIONS</span> <span class="n">INC</span>            <span class="o">|</span><span class="n">PARTY</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">Developer</span>                      <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">Delteq</span> <span class="n">Pte</span> <span class="n">Ltd</span>                 <span class="o">|</span><span class="n">PARTY</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">Distributor</span>                    <span class="o">|</span><span class="n">ALIAS</span>    <span class="o">|</span>
<span class="o">+-------------------------------+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetector</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">jslNer</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"jsl_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">jslNerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"jsl_ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">jslNerPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> 
                   <span class="n">sentenceDetector</span><span class="o">,</span> 
                   <span class="n">tokenizer</span><span class="o">,</span> 
                   <span class="n">wordEmbeddings</span><span class="o">,</span> 
                   <span class="n">jslNer</span><span class="o">,</span> 
                   <span class="n">jslNerConverter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, and associated with an acute hepatitis, presented with a one-week history of polyuria, poor appetite, and vomiting.
She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation.
Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent laboratory findings on admission were: serum glucose 111 mg/dl,  creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, and venous pH 7.27."</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">jslNerPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------+----------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>                        <span class="o">|</span><span class="n">ner_label</span>                   <span class="o">|</span>
<span class="o">+-----------------------------+----------------------------+</span>
<span class="o">|</span><span class="mi">28</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span>                  <span class="o">|</span><span class="nc">Age</span>                         <span class="o">|</span>
<span class="o">|</span><span class="n">female</span>                       <span class="o">|</span><span class="nc">Gender</span>                      <span class="o">|</span>
<span class="o">|</span><span class="n">gestational</span> <span class="n">diabetes</span> <span class="n">mellitus</span><span class="o">|</span><span class="nc">Diabetes</span>                    <span class="o">|</span>
<span class="o">|</span><span class="n">eight</span> <span class="n">years</span> <span class="n">prior</span>            <span class="o">|</span><span class="nc">RelativeDate</span>                <span class="o">|</span>
<span class="o">|</span><span class="k">type</span> <span class="kt">two</span> <span class="kt">diabetes</span> <span class="kt">mellitus</span>   <span class="kt">|Diabetes</span>                    <span class="kt">|</span>
<span class="kt">|T2DM</span>                         <span class="kt">|Diabetes</span>                    <span class="kt">|</span>
<span class="kt">|HTG-induced</span> <span class="kt">pancreatitis</span>     <span class="kt">|Disease_Syndrome_Disorder</span>   <span class="kt">|</span>
<span class="kt">|three</span> <span class="kt">years</span> <span class="kt">prior</span>            <span class="kt">|RelativeDate</span>                <span class="kt">|</span>
<span class="kt">|acute</span>                        <span class="kt">|Modifier</span>                    <span class="kt">|</span>
<span class="kt">|hepatitis</span>                    <span class="kt">|Disease_Syndrome_Disorder</span>   <span class="kt">|</span>
<span class="kt">|one-week</span>                     <span class="kt">|Duration</span>                    <span class="kt">|</span>
<span class="kt">|polyuria</span>                     <span class="kt">|Symptom</span>                     <span class="kt">|</span>
<span class="kt">|poor</span> <span class="kt">appetite</span>                <span class="kt">|Symptom</span>                     <span class="kt">|</span>
<span class="kt">|vomiting</span>                     <span class="kt">|Symptom</span>                     <span class="kt">|</span>
<span class="kt">|She</span>                          <span class="kt">|Gender</span>                      <span class="kt">|</span>
<span class="kt">|metformin</span>                    <span class="kt">|Drug_Ingredient</span>             <span class="kt">|</span>
<span class="kt">|glipizide</span>                    <span class="kt">|Drug_Ingredient</span>             <span class="kt">|</span>
<span class="kt">|dapagliflozin</span>                <span class="kt">|Drug_Ingredient</span>             <span class="kt">|</span>
<span class="kt">|T2DM</span>                         <span class="kt">|Diabetes</span>                    <span class="kt">|</span>
<span class="kt">|atorvastatin</span>                 <span class="kt">|Drug_Ingredient</span>             <span class="kt">|</span>
<span class="kt">|gemfibrozil</span>                  <span class="kt">|Drug_Ingredient</span>             <span class="kt">|</span>
<span class="kt">|HTG</span>                          <span class="kt">|Hyperlipidemia</span>              <span class="kt">|</span>
<span class="kt">|She</span>                          <span class="kt">|Gender</span>                      <span class="kt">|</span>
<span class="kt">|dapagliflozin</span>                <span class="kt">|Drug_Ingredient</span>             <span class="kt">|</span>
<span class="kt">|for</span> <span class="kt">six</span> <span class="kt">months</span>               <span class="kt">|Duration</span>                    <span class="kt">|</span>
<span class="kt">|dry</span> <span class="kt">oral</span> <span class="kt">mucosa</span>              <span class="kt">|Symptom</span>                     <span class="kt">|</span>
<span class="kt">|her</span>                          <span class="kt">|Gender</span>                      <span class="kt">|</span>
<span class="kt">|abdominal</span>                    <span class="kt">|External_body_part_or_region|</span>
<span class="kt">|tenderness</span>                   <span class="kt">|Symptom</span>                     <span class="kt">|</span>
<span class="kt">|guarding</span>                     <span class="kt">|Symptom</span>                     <span class="kt">|</span>
<span class="kt">|rigidity</span>                     <span class="kt">|Symptom</span>                     <span class="kt">|</span>
<span class="kt">|admission</span>                    <span class="kt">|Admission_Discharge</span>         <span class="kt">|</span>
<span class="kt">|serum</span> <span class="kt">glucose</span>                <span class="kt">|Test</span>                        <span class="kt">|</span>
<span class="kt">|</span><span class="err">111</span> <span class="kt">mg/dl</span>                    <span class="kt">|Test_Result</span>                 <span class="kt">|</span>
<span class="kt">|creatinine</span>                   <span class="kt">|Test</span>                        <span class="kt">|</span>
<span class="kt">|</span><span class="err">0</span><span class="kt">.</span><span class="err">4</span> <span class="kt">mg/dL</span>                    <span class="kt">|Test_Result</span>                 <span class="kt">|</span>
<span class="kt">|triglycerides</span>                <span class="kt">|Triglycerides</span>               <span class="kt">|</span>
<span class="kt">|</span><span class="err">508</span> <span class="kt">mg/dL</span>                    <span class="kt">|Test_Result</span>                 <span class="kt">|</span>
<span class="kt">|total</span> <span class="kt">cholesterol</span> <span class="err">122</span> <span class="kt">mg/dL</span>  <span class="kt">|Total_Cholesterol</span>           <span class="kt">|</span>
<span class="kt">|venous</span> <span class="kt">pH</span>                    <span class="kt">|Test</span>                        <span class="kt">|</span>
<span class="kt">|</span><span class="err">7</span><span class="kt">.</span><span class="err">27</span>                         <span class="kt">|Test_Result</span>                 <span class="kt">|</span>
<span class="kt">+-----------------------------+----------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span> <span class="s">"xx"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_legal_bert_base_uncased"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_sec_conll"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="sc">'''</span><span class="nc">December</span> <span class="mi">2007</span> <span class="nc">SUBORDINATED</span> <span class="nc">LOAN</span> <span class="nc">AGREEMENT</span><span class="o">.</span> <span class="nc">THIS</span> <span class="nc">LOAN</span> <span class="nc">AGREEMENT</span> <span class="n">is</span> <span class="n">made</span> <span class="n">on</span> <span class="mi">7</span><span class="n">th</span> <span class="nc">December</span><span class="o">,</span> <span class="mi">2007</span> <span class="nc">BETWEEN</span><span class="k">:</span> <span class="o">(</span><span class="err">1</span><span class="o">)</span> <span class="kt">SILICIUM</span> <span class="kt">DE</span> <span class="kt">PROVENCE</span> <span class="kt">S.A.S.</span><span class="o">,</span> <span class="n">a</span> <span class="k">private</span> <span class="n">company</span> <span class="k">with</span> <span class="n">limited</span> <span class="n">liability</span><span class="o">,</span> <span class="n">incorporated</span> <span class="n">under</span> <span class="n">the</span> <span class="n">laws</span> <span class="n">of</span> <span class="nc">France</span><span class="o">,</span> <span class="n">whose</span> <span class="n">registered</span> <span class="n">office</span> <span class="n">is</span> <span class="n">situated</span> <span class="n">at</span> <span class="nc">Usine</span> <span class="n">de</span> <span class="nc">Saint</span> <span class="nc">Auban</span><span class="o">,</span> <span class="nc">France</span><span class="o">,</span> <span class="n">represented</span> <span class="n">by</span> <span class="nv">Mr</span><span class="o">.</span><span class="py">Frank</span> <span class="nc">Wouters</span><span class="o">,</span> <span class="n">hereinafter</span> <span class="n">referred</span> <span class="n">to</span> <span class="n">as</span> <span class="n">the</span> <span class="s">"Borrower"</span><span class="o">,</span> <span class="nf">and</span> <span class="o">(</span> <span class="mi">2</span> <span class="o">)</span> <span class="nc">EVERGREEN</span> <span class="nc">SOLAR</span> <span class="nc">INC</span><span class="o">.,</span> <span class="n">a</span> <span class="n">company</span> <span class="n">incorporated</span> <span class="n">in</span> <span class="nc">Delaware</span><span class="o">,</span> <span class="nv">U</span><span class="o">.</span><span class="py">S</span><span class="o">.</span><span class="py">A</span><span class="o">.,</span> <span class="k">with</span> <span class="n">registered</span> <span class="n">number</span> <span class="mi">2426798</span><span class="o">,</span> <span class="n">whose</span> <span class="n">registered</span> <span class="n">office</span> <span class="n">is</span> <span class="n">situated</span> <span class="n">at</span> <span class="nc">Bartlett</span> <span class="nc">Street</span><span class="o">,</span> <span class="nc">Marlboro</span><span class="o">,</span> <span class="nc">Massachusetts</span><span class="o">,</span> <span class="nv">U</span><span class="o">.</span><span class="py">S</span><span class="o">.</span><span class="py">A</span><span class="o">.</span> <span class="n">represented</span> <span class="n">by</span> <span class="nc">Richard</span> <span class="nc">Chleboski</span><span class="o">,</span> <span class="n">hereinafter</span> <span class="n">referred</span> <span class="n">to</span> <span class="n">as</span> <span class="s">"Lender"</span> <span class="sc">'''</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="n">text</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------------------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                     <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+--------------------------+---------+</span>
<span class="o">|</span><span class="nc">SILICIUM</span> <span class="nc">DE</span> <span class="nc">PROVENCE</span> <span class="nv">S</span><span class="o">.</span><span class="py">A</span><span class="o">.</span><span class="py">S</span><span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">France</span>                    <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">Usine</span> <span class="n">de</span> <span class="nc">Saint</span> <span class="nc">Auban</span>      <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">France</span>                    <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nv">Mr</span><span class="o">.</span><span class="py">Frank</span> <span class="nc">Wouters</span>          <span class="o">|</span><span class="nc">PER</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">Borrower</span>                  <span class="o">|</span><span class="nc">PER</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">EVERGREEN</span> <span class="nc">SOLAR</span> <span class="nc">INC</span>       <span class="o">|</span><span class="nc">ORG</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">Delaware</span>                  <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nv">U</span><span class="o">.</span><span class="py">S</span><span class="o">.</span><span class="py">A</span>                     <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">Bartlett</span> <span class="nc">Street</span>           <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">Marlboro</span>                  <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">Massachusetts</span>             <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nv">U</span><span class="o">.</span><span class="py">S</span><span class="o">.</span><span class="py">A</span>                     <span class="o">|</span><span class="nc">LOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">Richard</span> <span class="nc">Chleboski</span>         <span class="o">|</span><span class="nc">PER</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">Lender</span>                    <span class="o">|</span><span class="nc">PER</span>      <span class="o">|</span>
<span class="o">+--------------------------+---------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span> <span class="s">"xx"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentenceDetector</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerModel</span><span class="o">,</span>
  <span class="n">nerConverter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""EXCLUSIVE DISTRIBUTOR AGREEMENT ("Agreement") dated as April 15, 1994 by and between IMRS OPERATIONS INC., a Delaware corporation with its principal place of business at 777 Long Ridge Road, Stamford, Connecticut 06902, U.S.A. (hereinafter referred to as "Developer") and Delteq Pte Ltd, a Singapore company (and a subsidiary of Wuthelam Industries (S) Pte LTD) with its principal place of business at 215 Henderson Road, #101-03 Henderson Industrial Park, Singapore 0315 (hereinafter referred to as "Distributor")."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-------------------------------+---------+</span>
<span class="o">|</span><span class="n">chunk</span>                          <span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+-------------------------------+---------+</span>
<span class="o">|</span><span class="nc">EXCLUSIVE</span> <span class="nc">DISTRIBUTOR</span> <span class="nc">AGREEMENT</span><span class="o">|</span><span class="nc">DOC</span>      <span class="o">|</span>
<span class="o">|</span><span class="nc">April</span> <span class="mi">15</span><span class="o">,</span> <span class="mi">1994</span>                 <span class="o">|</span><span class="nc">EFFDATE</span>  <span class="o">|</span>
<span class="o">|</span><span class="nc">IMRS</span> <span class="nc">OPERATIONS</span> <span class="nc">INC</span>            <span class="o">|</span><span class="nc">PARTY</span>    <span class="o">|</span>
<span class="o">|</span><span class="nc">Developer</span>                      <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">|</span><span class="nc">Delteq</span> <span class="nc">Pte</span> <span class="nc">Ltd</span>                 <span class="o">|</span><span class="nc">PARTY</span>    <span class="o">|</span>
<span class="o">|</span><span class="nc">Distributor</span>                    <span class="o">|</span><span class="nc">ALIAS</span>    <span class="o">|</span>
<span class="o">+-------------------------------+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>This Named Entity recognition annotator allows to train generic NER model based on Neural Networks.</p>

    <p>The architecture of the neural network is a Char CNNs - BiLSTM - CRF that achieves state-of-the-art in most datasets.</p>

    <p>For instantiated/pretrained models, see NerDLModel.</p>

    <p>The training data should be a labeled Spark Dataset, in the format of <a href="/docs/en/training#conll-dataset">CoNLL</a>
2003 IOB with <code class="language-plaintext highlighter-rouge">Annotation</code> type columns. The data should have columns of type <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code> and an
additional label column of annotator type <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code>.
Excluding the label, this can be done with for example</p>
    <ul>
      <li>a <a href="/docs/en/annotators#sentencedetector">SentenceDetector</a>,</li>
      <li>a <a href="/docs/en/annotators#tokenizer">Tokenizer</a> and</li>
      <li>a <a href="/docs/en/annotators#wordembeddings">WordEmbeddingsModel</a> with clinical embeddings
(any <a href="https://nlp.johnsnowlabs.com/models?task=Embeddings">clinical word embeddings</a> can be chosen).</li>
    </ul>

    <p>For extended examples of usage, see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.Clinical_Named_Entity_Recognition_Model.ipynb">Spark NLP Workshop</a>
(sections starting with <code class="language-plaintext highlighter-rouge">Training a Clinical NER</code>)</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN, WORD_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/medical_ner/index.html#sparknlp_jsl.annotator.ner.medical_ner.MedicalNerApproach">MedicalNerApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/MedicalNerApproach.html">MedicalNerApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/Healthcare_MOOC/Spark_NLP_Udemy_MOOC/Healthcare_NLP/MedicalNerApproach.ipynb">MedicalNerApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">clinical_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'embeddings_clinical'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerApproach</span><span class="p">()</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEvaluationLogExtended</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setEnableOutputLogs</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">'ner_logs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="s">'medical_ner_graphs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEnableMemoryOptimizer</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
<span class="n">documentAssembler</span><span class="p">,</span>
<span class="n">sentence</span><span class="p">,</span>
<span class="n">tokenizer</span><span class="p">,</span>
<span class="n">clinical_embeddings</span><span class="p">,</span>
<span class="n">nerTagger</span>
<span class="p">])</span>

<span class="c1"># We use the text and labels from the CoNLL dataset
</span><span class="n">conll</span> <span class="o">=</span> <span class="n">CoNLL</span><span class="p">()</span>
<span class="n">trainingData</span> <span class="o">=</span> <span class="n">conll</span><span class="p">.</span><span class="n">readDataset</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="p">)</span>

<span class="n">pipelineModel</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainingData</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">clinical_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'embeddings_clinical'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerApproach</span><span class="p">()</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEvaluationLogExtended</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setEnableOutputLogs</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">'ner_logs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="s">'medical_ner_graphs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEnableMemoryOptimizer</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
<span class="n">documentAssembler</span><span class="p">,</span>
<span class="n">sentence</span><span class="p">,</span>
<span class="n">tokenizer</span><span class="p">,</span>
<span class="n">clinical_embeddings</span><span class="p">,</span>
<span class="n">nerTagger</span>
<span class="p">])</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># First extract the prerequisites for the NerDLApproach
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">clinical_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'embeddings_clinical'</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># Then the training can start
</span><span class="n">nerTagger</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerApproach</span><span class="p">()</span>\
<span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
<span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setMaxEpochs</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">64</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setVerbose</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEvaluationLogExtended</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
<span class="p">.</span><span class="n">setEnableOutputLogs</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setIncludeConfidence</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setOutputLogsPath</span><span class="p">(</span><span class="s">'ner_logs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="s">'medical_ner_graphs'</span><span class="p">)</span>\
<span class="p">.</span><span class="n">setEnableMemoryOptimizer</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#&gt;&gt; if you have a limited memory and a large conll file, you can set this True to train batch by batch
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
<span class="n">documentAssembler</span><span class="p">,</span>
<span class="n">sentence</span><span class="p">,</span>
<span class="n">tokenizer</span><span class="p">,</span>
<span class="n">clinical_embeddings</span><span class="p">,</span>
<span class="n">nerTagger</span>
<span class="p">])</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'embeddings_clinica</span><span class="n">l</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=new</span> <span class="nc">MedicalNerApproach</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
<span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mf">0.003f</span><span class="o">)</span>
<span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">8</span><span class="o">)</span>
<span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEvaluationLogExtended</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEnableOutputLogs</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>

<span class="c1">// We use the text and labels from the CoNLL dataset</span>
<span class="k">val</span> <span class="nv">conll</span> <span class="k">=</span> <span class="nc">CoNLL</span><span class="o">()</span>
<span class="k">val</span> <span class="nv">trainingData</span> <span class="k">=</span> <span class="nv">conll</span><span class="o">.</span><span class="py">readDataset</span><span class="o">(</span><span class="n">spark</span><span class="o">,</span> <span class="s">"src/test/resources/conll2003/eng.train"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainingData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'embeddings_clinica</span><span class="n">l</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=new</span> <span class="nc">FinanceNerApproach</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
<span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mf">0.003f</span><span class="o">)</span>
<span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">8</span><span class="o">)</span>
<span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEvaluationLogExtended</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEnableOutputLogs</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// First extract the prerequisites for the NerDLApproach</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="ss">'embeddings_clinica</span><span class="n">l</span><span class="o">',</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="c1">// Then the training can start</span>
<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=new</span> <span class="nc">LegalNerApproach</span><span class="o">()</span>
<span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
<span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
<span class="o">.</span><span class="py">setMaxEpochs</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
<span class="o">.</span><span class="py">setLr</span><span class="o">(</span><span class="mf">0.003f</span><span class="o">)</span>
<span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">8</span><span class="o">)</span>
<span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
<span class="o">.</span><span class="py">setVerbose</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEvaluationLogExtended</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setEnableOutputLogs</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
<span class="o">.</span><span class="py">setIncludeConfidence</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">sentence</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">embeddings</span><span class="o">,</span>
  <span class="n">nerTagger</span>
<span class="o">))</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="nerquestiongenerator">NerQuestionGenerator</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">NerQuestionGenerator</code> takes an NER chunk (obtained by, e.g., <code class="language-plaintext highlighter-rouge">NerConverterInternal</code>) and generates a questions based on two entity types, a pronoun and a strategy.</p>

    <p>The question is generated in the form of <code class="language-plaintext highlighter-rouge">[QUESTIONPRONOUN] [ENTITY1] [ENTITY2] [QUESTIONMARK]</code>. The generated question can be used by <code class="language-plaintext highlighter-rouge">QuestionAnswerer</code> or <code class="language-plaintext highlighter-rouge">ZeroShotNer</code> annotators to answer the question or find NER entities.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">questionPronoun</code>: Pronoun to be used in the question. E.g., ‘When’, ‘Where’, ‘Why’, ‘How’, ‘Who’, ‘What’.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">strategyType</code>: Strategy for the proccess, either <code class="language-plaintext highlighter-rouge">Paired</code> (default) or <code class="language-plaintext highlighter-rouge">Combined</code>.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">questionMark</code>: Whether to add a question mark at the end of the question.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">entities1</code>: List with the entity types of entities that appear first in the question.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">entities2</code>: List with the entity types of entities that appear second in the question.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setQuestionPronoun(True)</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/qa/qa_ner_generator/index.html#sparknlp_jsl.annotator.qa.qa_ner_generator.NerQuestionGenerator">NerQuestionGenerator</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/qa/NerQuestionGenerator.html">NerQuestionGenerator</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/NerQuestionGenerator.ipynb">NerQuestionGeneratorNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">entities</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
    <span class="s">"label"</span><span class="p">:</span> <span class="s">"Person"</span><span class="p">,</span>
    <span class="s">"patterns"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Jon"</span><span class="p">,</span> <span class="s">"John"</span><span class="p">,</span> <span class="s">"John's"</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="p">{</span>
    <span class="s">"label"</span><span class="p">:</span> <span class="s">"Organization"</span><span class="p">,</span>
    <span class="s">"patterns"</span><span class="p">:</span> <span class="p">[</span><span class="s">"St. Mary's Hospital"</span><span class="p">,</span> <span class="s">"St. Mary's"</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s">"label"</span><span class="p">:</span> <span class="s">"Condition"</span><span class="p">,</span>
        <span class="s">"patterns"</span><span class="p">:</span> <span class="p">[</span><span class="s">"vital signs"</span><span class="p">,</span> <span class="s">"heartbeat"</span><span class="p">,</span> <span class="s">"oxygen saturation levels"</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'./entities.json'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">jsonfile</span><span class="p">:</span>
    <span class="n">json</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">entities</span><span class="p">,</span> <span class="n">jsonfile</span><span class="p">)</span>


<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">entity_ruler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">EntityRulerApproach</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setPatternsResource</span><span class="p">(</span><span class="s">"./entities.json"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">qagenerator</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerQuestionGenerator</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"entity"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"question"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setQuestionPronoun</span><span class="p">(</span><span class="s">"How is"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEntities1</span><span class="p">([</span><span class="s">"Person"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setEntities2</span><span class="p">([</span><span class="s">"Condition"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setStrategyType</span><span class="p">(</span><span class="s">"Paired"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setQuestionMark</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">prep_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">entity_ruler</span><span class="p">,</span>
    <span class="n">qagenerator</span>
<span class="p">])</span>

<span class="n">example_text</span> <span class="o">=</span> <span class="s">"""At St. Mary's Hospital, the healthcare team closely monitored John's vital signs with unwavering attention. They recorded his heartbeat and oxygen saturation levels, promptly addressing any deviations from normal. Their dedication and expertise at St. Mary's played a vital role in ensuring John's stability and fostering a swift recovery."""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">example_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">prep_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"question"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">question</span>                                                                                                                                    <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[{</span><span class="n">document</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="mi">79</span><span class="p">,</span> <span class="n">How</span> <span class="ow">is</span> <span class="n">John</span><span class="s">'s vital signs ?, {sentence -&gt; 0}, []}, {document, 291, 134, How is John'</span><span class="n">s</span> <span class="n">heartbeat</span> <span class="err">?</span><span class="p">,</span> <span class="p">{</span><span class="n">sentence</span> <span class="o">-&gt;</span> <span class="mi">0</span><span class="p">},</span> <span class="p">[]}]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="cm">/* entities.json file
entities = [
    {
    "label": "Person",
    "patterns": ["Jon", "John", "John's"]
    },
    {
    "label": "Organization",
    "patterns": ["St. Mary's Hospital", "St. Mary's"]
    },
    {
        "label": "Condition",
        "patterns": ["vital signs", "heartbeat", "oxygen saturation levels"]
    }
]
*/</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">entity_ruler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EntityRulerApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPatternsResource</span><span class="o">(</span><span class="s">"./entities.json"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">qagenerator</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerQuestionGenerator</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"question"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setQuestionPronoun</span><span class="o">(</span><span class="s">"How is"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEntities1</span><span class="o">(</span><span class="s">"Person"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setEntities2</span><span class="o">(</span><span class="s">"Condition"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setStrategyType</span><span class="o">(</span><span class="s">"Paired"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setQuestionMark</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">prep_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">entity_ruler</span><span class="o">,</span> 
    <span class="n">qagenerator</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"""At St. Mary's Hospital, the healthcare team closely monitored John's vital signs with unwavering attention. They recorded his heartbeat and oxygen saturation levels, promptly addressing any deviations from normal. Their dedication and expertise at St. Mary's played a vital role in ensuring John's stability and fostering a swift recovery."""</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">mapperPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span>

<span class="c1">// Show results</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">question</span>                                                                                                                                    <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[{</span><span class="kt">document</span>, <span class="err">62</span>, <span class="err">79</span>, <span class="kt">How</span> <span class="kt">is</span> <span class="kt">John's</span> <span class="kt">vital</span> <span class="kt">signs</span> <span class="kt">?</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}</span>, <span class="o">{</span><span class="kt">document</span>, <span class="err">291</span>, <span class="err">134</span>, <span class="kt">How</span> <span class="kt">is</span> <span class="kt">John's</span> <span class="kt">heartbeat</span> <span class="kt">?</span>, <span class="o">{</span><span class="kt">sentence</span> <span class="kt">-&gt;</span> <span class="err">0</span><span class="o">}</span>, <span class="o">[]}]|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="posologyremodel">PosologyREModel</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Instantiated RelationExtractionModel for extracting relationships between different recognized drug entitites.
This class is not intended to be directly used, please use the RelationExtractionModel instead.
Possible values are “DRUG-DOSAGE”, “DRUG-ADE”, “DRUG-FORM”, “DRUG-FREQUENCY”,
“DRUG-ROUTE”, “DRUG-REASON”, “DRUG-STRENGTH”, “DRUG-DURATION”.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_extraction/index.html#sparknlp_jsl.annotator.re.relation_extraction.RelationExtractionModel">RelationExtractionModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionModel.html">RelationExtractionModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/RelationExtractionModel.ipynb">RelationExtractionModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">reModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"posology_re"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">words_embedder</span><span class="p">,</span>
    <span class="n">pos_tagger</span><span class="p">,</span>
    <span class="n">ner_tagger</span><span class="p">,</span>
    <span class="n">ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">reModel</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""
The patient was prescribed 1 unit of Advil for 5 days after meals. The patient was also
given 1 unit of Metformin daily.
He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night ,
12 units of insulin lispro with meals , and metformin 1000 mg two times a day.
"""</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span>
                              <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                              <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
<span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relations"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
<span class="o">|</span><span class="n">chunk1</span>   <span class="o">|</span><span class="n">chunk2</span>          <span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2</span>  <span class="o">|</span><span class="n">relations</span>     <span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
<span class="o">|</span><span class="mi">1</span> <span class="n">unit</span>   <span class="o">|</span><span class="n">Advil</span>           <span class="o">|</span><span class="n">DOSAGE</span> <span class="o">|</span><span class="n">DRUG</span>     <span class="o">|</span><span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">Advil</span>    <span class="o">|</span><span class="k">for</span> <span class="mi">5</span> <span class="n">days</span>      <span class="o">|</span><span class="n">DRUG</span>   <span class="o">|</span><span class="n">DURATION</span> <span class="o">|</span><span class="n">DRUG</span><span class="o">-</span><span class="n">DURATION</span> <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">1</span> <span class="n">unit</span>   <span class="o">|</span><span class="n">Metformin</span>       <span class="o">|</span><span class="n">DOSAGE</span> <span class="o">|</span><span class="n">DRUG</span>     <span class="o">|</span><span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">Metformin</span><span class="o">|</span><span class="n">daily</span>           <span class="o">|</span><span class="n">DRUG</span>   <span class="o">|</span><span class="n">FREQUENCY</span><span class="o">|</span><span class="n">DRUG</span><span class="o">-</span><span class="n">FREQUENCY</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">40</span> <span class="n">units</span> <span class="o">|</span><span class="n">insulin</span> <span class="n">glargine</span><span class="o">|</span><span class="n">DOSAGE</span> <span class="o">|</span><span class="n">DRUG</span>     <span class="o">|</span><span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_tagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"ner_tags"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"pos_tags"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">reModel</span> <span class="k">=</span> <span class="nv">RelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"posology_re"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span><span class="s">"pos_tags"</span><span class="o">,</span><span class="s">"ner_chunks"</span><span class="o">,</span><span class="s">"dependencies"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                             <span class="n">documenter</span><span class="o">,</span> 
                                             <span class="n">sentencer</span><span class="o">,</span> 
                                             <span class="n">tokenizer</span><span class="o">,</span>
                                             <span class="n">words_embedder</span><span class="o">,</span> 
                                             <span class="n">pos_tagger</span><span class="o">,</span> 
                                             <span class="n">ner_tagger</span><span class="o">,</span> 
                                             <span class="n">ner_chunker</span><span class="o">,</span> 
                                             <span class="n">dependency_parser</span><span class="o">,</span> 
                                             <span class="n">reModel</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">" The patient was prescribed 1 unit of Advil for 5 days after meals. The patient was also given 1 unit of Metformin daily. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals ,and metformin 1000 mg two times a day. "</span> 

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// Show results</span>

<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
<span class="o">|</span><span class="n">chunk1</span>   <span class="o">|</span><span class="n">chunk2</span>          <span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2</span>  <span class="o">|</span><span class="n">relations</span>     <span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
<span class="o">|</span><span class="mi">1</span> <span class="n">unit</span>   <span class="o">|</span><span class="nc">Advil</span>           <span class="o">|</span><span class="nc">DOSAGE</span> <span class="o">|</span><span class="nc">DRUG</span>     <span class="o">|</span><span class="nc">DOSAGE</span><span class="o">-</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">Advil</span>    <span class="o">|</span><span class="k">for</span> <span class="mi">5</span> <span class="n">days</span>      <span class="o">|</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="nc">DURATION</span> <span class="o">|</span><span class="nc">DRUG</span><span class="o">-</span><span class="nc">DURATION</span> <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">1</span> <span class="n">unit</span>   <span class="o">|</span><span class="nc">Metformin</span>       <span class="o">|</span><span class="nc">DOSAGE</span> <span class="o">|</span><span class="nc">DRUG</span>     <span class="o">|</span><span class="nc">DOSAGE</span><span class="o">-</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">Metformin</span><span class="o">|</span><span class="n">daily</span>           <span class="o">|</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="nc">FREQUENCY</span><span class="o">|</span><span class="nc">DRUG</span><span class="o">-</span><span class="nc">FREQUENCY</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">40</span> <span class="n">units</span> <span class="o">|</span><span class="n">insulin</span> <span class="n">glargine</span><span class="o">|</span><span class="nc">DOSAGE</span> <span class="o">|</span><span class="nc">DRUG</span>     <span class="o">|</span><span class="nc">DOSAGE</span><span class="o">-</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="pretrainedzeroshotner">PretrainedZeroShotNER</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">Pretrained Zero-shot Named Entity Recognition (NER)</code> makes it easy to identify specific entities in text without needing 
pre-labeled datasets. It uses advanced pre-trained language models to recognize entities in different fields and languages,
saving time and effort.
This method is flexible, letting you define your own entity labels instead of relying on a fixed set of examples. 
For the best results, it’s helpful to choose labels similar to the provided examples, as they guide the model’s understanding.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">labels</code>:  A list of labels descriving the entities. For example: [“person”, “location”]</li>
      <li><code class="language-plaintext highlighter-rouge">predictionThreshold</code>:   Minimal confidence score to encode an entity (Default: 0.01f)</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/pretrained_zero_shot_ner/index.html">PretrainedZeroShotNER</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/ner/PretrainedZeroShotNER.html">PretrainedZeroShotNER</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/PretrainedZeroShotNER.ipynb">PretrainedZeroShotNER</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'DOCTOR'</span><span class="p">,</span> <span class="s">'PATIENT'</span><span class="p">,</span> <span class="s">'AGE'</span><span class="p">,</span> <span class="s">'DATE'</span><span class="p">,</span> <span class="s">'HOSPITAL'</span><span class="p">,</span> <span class="s">'CITY'</span><span class="p">,</span> <span class="s">'STREET'</span><span class="p">,</span> <span class="s">'STATE'</span><span class="p">,</span> <span class="s">'COUNTRY'</span><span class="p">,</span> <span class="s">'PHONE'</span><span class="p">,</span> <span class="s">'IDNUM'</span><span class="p">,</span> <span class="s">'EMAIL'</span><span class="p">,</span><span class="s">'ZIP'</span><span class="p">,</span> <span class="s">'ORGANIZATION'</span><span class="p">,</span> <span class="s">'PROFESSION'</span><span class="p">,</span> <span class="s">'USERNAME'</span><span class="p">]</span>

<span class="n">pretrained_zero_shot_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">PretrainedZeroShotNER</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"zeroshot_ner_deid_subentity_merged_medium"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setLabels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">sentence_detector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">pretrained_zero_shot_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span>
    <span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""Dr. John Lee, from Royal Medical Clinic in Chicago,  attended to the patient on 11/05/2024.
The patient’s medical record number is 56467890. The patient, Emma Wilson, is 50 years old,  her Contact number: 444-456-7890 .
Dr. John Taylor, ID: 982345, a cardiologist at St. Mary's Hospital in Boston, was contacted on 05/10/2023 regarding a 45-year-old.
"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="c1"># result
</span>
<span class="o">+--------------------+-----+---+----------+</span>
<span class="o">|</span><span class="n">chunk</span>               <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span> <span class="o">|</span>
<span class="o">+--------------------+-----+---+----------+</span>
<span class="o">|</span><span class="n">John</span> <span class="n">Lee</span>            <span class="o">|</span><span class="mi">4</span>    <span class="o">|</span><span class="mi">11</span> <span class="o">|</span><span class="n">DOCTOR</span>    <span class="o">|</span>
<span class="o">|</span><span class="n">Royal</span> <span class="n">Medical</span> <span class="n">Clinic</span><span class="o">|</span><span class="mi">19</span>   <span class="o">|</span><span class="mi">38</span> <span class="o">|</span><span class="n">HOSPITAL</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">Chicago</span>             <span class="o">|</span><span class="mi">43</span>   <span class="o">|</span><span class="mi">49</span> <span class="o">|</span><span class="n">CITY</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">11</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2024</span>          <span class="o">|</span><span class="mi">80</span>   <span class="o">|</span><span class="mi">89</span> <span class="o">|</span><span class="n">DATE</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">56467890</span>            <span class="o">|</span><span class="mi">131</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="n">IDNUM</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">Emma</span> <span class="n">Wilson</span>         <span class="o">|</span><span class="mi">154</span>  <span class="o">|</span><span class="mi">164</span><span class="o">|</span><span class="n">PATIENT</span>   <span class="o">|</span>
<span class="o">|</span><span class="mi">50</span>                  <span class="o">|</span><span class="mi">170</span>  <span class="o">|</span><span class="mi">171</span><span class="o">|</span><span class="n">AGE</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">444</span><span class="o">-</span><span class="mi">456</span><span class="o">-</span><span class="mi">7890</span>        <span class="o">|</span><span class="mi">205</span>  <span class="o">|</span><span class="mi">216</span><span class="o">|</span><span class="n">PHONE</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">John</span> <span class="n">Taylor</span>         <span class="o">|</span><span class="mi">224</span>  <span class="o">|</span><span class="mi">234</span><span class="o">|</span><span class="n">DOCTOR</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">982345</span>              <span class="o">|</span><span class="mi">241</span>  <span class="o">|</span><span class="mi">246</span><span class="o">|</span><span class="n">IDNUM</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">cardiologist</span>        <span class="o">|</span><span class="mi">251</span>  <span class="o">|</span><span class="mi">262</span><span class="o">|</span><span class="n">PROFESSION</span><span class="o">|</span>
<span class="o">|</span><span class="n">St</span><span class="p">.</span> <span class="n">Mary</span><span class="s">'s Hospital |267  |285|HOSPITAL  |
|Boston              |290  |295|CITY      |
|05/10/2023          |315  |324|DATE      |
|45-year-old         |338  |348|AGE       |
+--------------------+-----+---+----------+
</span></code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">labels</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span>
    <span class="s">"DOCTOR"</span><span class="o">,</span> <span class="s">"PATIENT"</span><span class="o">,</span> <span class="s">"AGE"</span><span class="o">,</span> <span class="s">"DATE"</span><span class="o">,</span> <span class="s">"HOSPITAL"</span><span class="o">,</span> <span class="s">"CITY"</span><span class="o">,</span> <span class="s">"STREET"</span><span class="o">,</span>
    <span class="s">"STATE"</span><span class="o">,</span> <span class="s">"COUNTRY"</span><span class="o">,</span> <span class="s">"PHONE"</span><span class="o">,</span> <span class="s">"IDNUM"</span><span class="o">,</span> <span class="s">"EMAIL"</span><span class="o">,</span> <span class="s">"ZIP"</span><span class="o">,</span>
    <span class="s">"ORGANIZATION"</span><span class="o">,</span> <span class="s">"PROFESSION"</span><span class="o">,</span> <span class="s">"USERNAME"</span>
    <span class="o">)</span>

<span class="k">val</span> <span class="nv">pretrainedZeroShotNer</span> <span class="k">=</span> <span class="nc">PretrainedZeroShotNER</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"zeroshot_ner_deid_subentity_merged_medium"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.5</span><span class="o">.</span><span class="py">toFloat</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setLabels</span><span class="o">(</span><span class="n">labels</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
        <span class="n">documentAssembler</span><span class="o">,</span>
        <span class="n">sentenceDetector</span><span class="o">,</span>
        <span class="n">tokenizer</span><span class="o">,</span>
        <span class="n">pretrainedZeroShotNer</span><span class="o">,</span>
        <span class="n">nerConverter</span>
    <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""Dr. John Lee, from Royal Medical Clinic in Chicago, attended to the patient on 11/05/2024.
The patient’s medical record number is 56467890. The patient, Emma Wilson, is 50 years old, her Contact number: 444-456-7890.
Dr. John Taylor, ID: 982345, a cardiologist at St. Mary's Hospital in Boston, was contacted on 05/10/2023 regarding a 45-year-old.
"""</span>


<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nv">spark</span><span class="o">.</span><span class="py">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">((</span><span class="n">text</span><span class="o">))).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">pipelineModel</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipelineModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>



<span class="k">#</span> <span class="n">result</span>

<span class="o">+--------------------+-----+---+----------+</span>
<span class="o">|</span><span class="n">chunk</span>               <span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span> <span class="o">|</span>
<span class="o">+--------------------+-----+---+----------+</span>
<span class="o">|</span><span class="nc">John</span> <span class="nc">Lee</span>            <span class="o">|</span><span class="mi">4</span>    <span class="o">|</span><span class="mi">11</span> <span class="o">|</span><span class="nc">DOCTOR</span>    <span class="o">|</span>
<span class="o">|</span><span class="nc">Royal</span> <span class="nc">Medical</span> <span class="nc">Clinic</span><span class="o">|</span><span class="mi">19</span>   <span class="o">|</span><span class="mi">38</span> <span class="o">|</span><span class="nc">HOSPITAL</span>  <span class="o">|</span>
<span class="o">|</span><span class="nc">Chicago</span>             <span class="o">|</span><span class="mi">43</span>   <span class="o">|</span><span class="mi">49</span> <span class="o">|</span><span class="nc">CITY</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">11</span><span class="o">/</span><span class="mi">05</span><span class="o">/</span><span class="mi">2024</span>          <span class="o">|</span><span class="mi">80</span>   <span class="o">|</span><span class="mi">89</span> <span class="o">|</span><span class="nc">DATE</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">56467890</span>            <span class="o">|</span><span class="mi">131</span>  <span class="o">|</span><span class="mi">138</span><span class="o">|</span><span class="nc">IDNUM</span>     <span class="o">|</span>
<span class="o">|</span><span class="nc">Emma</span> <span class="nc">Wilson</span>         <span class="o">|</span><span class="mi">154</span>  <span class="o">|</span><span class="mi">164</span><span class="o">|</span><span class="nc">PATIENT</span>   <span class="o">|</span>
<span class="o">|</span><span class="mi">50</span>                  <span class="o">|</span><span class="mi">170</span>  <span class="o">|</span><span class="mi">171</span><span class="o">|</span><span class="nc">AGE</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">444</span><span class="o">-</span><span class="mi">456</span><span class="o">-</span><span class="mi">7890</span>        <span class="o">|</span><span class="mi">205</span>  <span class="o">|</span><span class="mi">216</span><span class="o">|</span><span class="nc">PHONE</span>     <span class="o">|</span>
<span class="o">|</span><span class="nc">John</span> <span class="nc">Taylor</span>         <span class="o">|</span><span class="mi">224</span>  <span class="o">|</span><span class="mi">234</span><span class="o">|</span><span class="nc">DOCTOR</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">982345</span>              <span class="o">|</span><span class="mi">241</span>  <span class="o">|</span><span class="mi">246</span><span class="o">|</span><span class="nc">IDNUM</span>     <span class="o">|</span>
<span class="o">|</span><span class="n">cardiologist</span>        <span class="o">|</span><span class="mi">251</span>  <span class="o">|</span><span class="mi">262</span><span class="o">|</span><span class="nc">PROFESSION</span><span class="o">|</span>
<span class="o">|</span><span class="nc">St</span><span class="o">.</span> <span class="nc">Mary</span><span class="ss">'s</span> <span class="nc">Hospital</span> <span class="o">|</span><span class="mi">267</span>  <span class="o">|</span><span class="mi">285</span><span class="o">|</span><span class="nc">HOSPITAL</span>  <span class="o">|</span>
<span class="o">|</span><span class="nc">Boston</span>              <span class="o">|</span><span class="mi">290</span>  <span class="o">|</span><span class="mi">295</span><span class="o">|</span><span class="nc">CITY</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">05</span><span class="o">/</span><span class="mi">10</span><span class="o">/</span><span class="mi">2023</span>          <span class="o">|</span><span class="mi">315</span>  <span class="o">|</span><span class="mi">324</span><span class="o">|</span><span class="nc">DATE</span>      <span class="o">|</span>
<span class="o">|</span><span class="mi">45</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span>         <span class="o">|</span><span class="mi">338</span>  <span class="o">|</span><span class="mi">348</span><span class="o">|</span><span class="nc">AGE</span>       <span class="o">|</span>
<span class="o">+--------------------+-----+---+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="questionanswering">QuestionAnswering</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>QuestionAnswering is a GPT-based model for answering questions given a context. Unlike span-based models, it generates the answers to the questions, rather than selecting phrases from the given context. The model is capable of answering various types of questions, including yes-no or full-text ones. Types of questions are supported: <code class="language-plaintext highlighter-rouge">"short"</code> (producing yes/no/maybe) answers and <code class="language-plaintext highlighter-rouge">"long"</code> (full answers).</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">questionType</code>: Question type, e.g. “short” or “long”. The question types depend on the model.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxNewTokens</code>: Maximum number of of new tokens to generate, by default 30</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxContextLength</code>: Maximum length of context text</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">configProtoBytes</code>: ConfigProto from tensorflow, serialized into byte array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">doSample</code>: Whether or not to use sampling; use greedy decoding otherwise, by default False</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">topK</code>: The number of highest probability vocabulary tokens to consider, by default 1</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">noRepeatNgramSize</code>: The number of tokens that can’t be repeated in the same order. Useful for preventing loops. The default is 0.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ignoreTokenIds</code>: A list of token ids which are ignored in the decoder’s output, by default []</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">randomSeed</code>: Set to positive integer to get reproducible results, by default None.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">customPrompt</code>: Custom prompt template. Available variables {QUESTION} and {CONTEXT}</p>
      </li>
    </ul>

    <p>Available models can be found at the <a href="https://nlp.johnsnowlabs.com/models?task=Question+Answering">Models Hub</a></p>

    <p>For more extended examples on the document, pre-processing see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master">Spark NLP Workshop</a></p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/qa/medical_qa/index.html#sparknlp_jsl.annotator.qa.medical_qa.MedicalQuestionAnswering">MedicalQuestionAnswering</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/qa/MedicalQuestionAnswering.html">MedicalQuestionAnswering</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">MultiDocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">)</span>

<span class="n">med_qa</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">MedicalQuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"medical_qa_biogpt"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTopK</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setQuestionType</span><span class="p">(</span><span class="s">"long"</span><span class="p">)</span> <span class="c1"># "short"
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">med_qa</span><span class="p">])</span>

<span class="n">paper_abstract</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"In patients with Los Angeles (LA) grade C or D oesophagitis, a positive relationship has been established between the duration of intragastric acid suppression and healing.AIM: To determine whether there is an apparent optimal time of intragastric acid suppression for maximal healing of reflux oesophagitis. Post hoc analysis of data from a proof-of-concept, double-blind, randomized study of 134 adult patients treated with esomeprazole (10 or 40 mg od for 4 weeks) for LA grade C or D oesophagitis. A curve was fitted to pooled 24-h intragastric pH (day 5) and endoscopically assessed healing (4 weeks) data using piecewise quadratic logistic regression. Maximal reflux oesophagitis healing rates were achieved when intragastric pH&gt;4 was achieved for approximately 50-70% (12-17 h) of the 24-h period. Acid suppression above this threshold did not yield further increases in healing rates."</span>
<span class="p">]</span>

<span class="n">question</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Is there an optimal time of acid suppression for maximal healing?"</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span> <span class="p">[</span><span class="n">paper_abstract</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="n">question</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"context"</span><span class="p">,</span><span class="s">"question"</span><span class="p">)</span>

<span class="n">data</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="mi">60</span><span class="p">)</span>

<span class="o">+------------------------------------------------------------+------------------------------------------------------------+</span>
<span class="o">|</span>                                                     <span class="n">context</span><span class="o">|</span>                                                    <span class="n">question</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------+------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">In</span> <span class="n">patients</span> <span class="k">with</span> <span class="n">Los</span> <span class="n">Angeles</span> <span class="p">(</span><span class="n">LA</span><span class="p">)</span> <span class="n">grade</span> <span class="n">C</span> <span class="ow">or</span> <span class="n">D</span> <span class="n">oesophagit</span><span class="p">...</span><span class="o">|</span><span class="n">Is</span> <span class="n">there</span> <span class="n">an</span> <span class="n">optimal</span> <span class="n">time</span> <span class="n">of</span> <span class="n">acid</span> <span class="n">suppression</span> <span class="k">for</span> <span class="n">maximal</span> <span class="p">...</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------+------------------------------------------------------------+</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"document_question.result as Question"</span><span class="p">,</span> <span class="s">"answer.result as Long_Answer"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">Question</span>                                                           <span class="o">|</span><span class="n">Long_Answer</span>                                                                                                                                          <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Is</span> <span class="n">there</span> <span class="n">an</span> <span class="n">optimal</span> <span class="n">time</span> <span class="n">of</span> <span class="n">acid</span> <span class="n">suppression</span> <span class="k">for</span> <span class="n">maximal</span> <span class="n">healing</span><span class="err">?</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="ow">in</span> <span class="n">patients</span> <span class="k">with</span> <span class="n">reflux</span> <span class="n">oesophagitis</span><span class="p">,</span> <span class="n">maximal</span> <span class="n">healing</span> <span class="n">rates</span> <span class="n">are</span> <span class="n">obtained</span> <span class="n">when</span> <span class="n">intragastric</span> <span class="n">pH</span> <span class="ow">is</span> <span class="n">achieved</span> <span class="k">for</span> <span class="n">approximately</span> <span class="mi">50</span> <span class="o">-</span> <span class="mi">70</span> <span class="o">%</span> <span class="p">(</span> <span class="mi">12</span> <span class="o">-</span> <span class="mi">17</span> <span class="n">h</span> <span class="p">)]</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">MultiDocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">)</span>

<span class="n">fin_qa</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">QuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finqa_flant5_finetuned"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setCustomPrompt</span><span class="p">(</span><span class="s">"question: {QUESTION} context: {CONTEXT}"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">fin_qa</span><span class="p">])</span>

<span class="n">context</span> <span class="o">=</span> <span class="s">"""EXHIBIT 99.2 Page 1 of 3 DISTRIBUTOR AGREEMENT Agreement made this 19th day of March, 2020 Between: Co-Diagnostics, Inc. (herein referred to as "Principal") And PreCheck Health Services, Inc. (herein referred to as "Distributor"). In consideration of the mutual terms, conditions and covenants hereinafter set forth, Principal and Distributor acknowledge and agree to the following descriptions and conditions: DESCRIPTION OF PRINCIPAL The Principal is a company located in Utah, United States and is in the business of research and development of reagents. The Principal markets and sells it products globally through direct sales and distributors. DESCRIPTION OF DISTRIBUTOR The Distributor is a company operating or planning to operate in the United States of America, Latin America, Europe and Russia. The Distributor represents that the Distributor or a subsidiary of the Distributor is or will be fully licensed and registered in the Territory and will provide professional distribution services for the products of the Principal. CONDITIONS: 1. The Principal appoints the Distributor as a non-exclusive distributor, to sell Principal's qPCR infectious disease kits, Logix Smart COVID-19 PCR diagnostic test and Co-Dx Box™ instrument (the "Products"). The Products are described on Exhibit A to this Agreement. 2. The Principal grants Distributor non- exclusive rights to sell these products within the countries of Romania (the "Territory"), which may be amended by mutual written agreement."""</span>

<span class="n">questions</span> <span class="o">=</span> <span class="p">[</span><span class="s">"""Which company is referred to as 'Principal' in the Distributor Agreement?"""</span><span class="p">,</span>
             <span class="s">"""What is the date of the distributor agreement between Co-Diagnostics, Inc. and PreCheck Health Services, Inc.?"""</span><span class="p">,</span>
             <span class="s">"""What is the Territory in which the Distributor has non-exclusive rights to sell Principal's products according to the Agreement?"""</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="n">context</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="n">questions</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
        <span class="p">[</span><span class="n">context</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="n">questions</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
        <span class="p">[</span><span class="n">context</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="n">questions</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"context"</span><span class="p">,</span><span class="s">"question"</span><span class="p">)</span>

<span class="n">data</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="mi">80</span><span class="p">)</span>

<span class="o">+------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                          <span class="n">question</span><span class="o">|</span>                                                                         <span class="n">context</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>   <span class="n">What</span> <span class="n">are</span> <span class="n">the</span> <span class="n">key</span> <span class="n">components</span> <span class="n">of</span> <span class="n">the</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">described</span><span class="err">?</span><span class="o">|</span><span class="n">Our</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">has</span> <span class="n">been</span> <span class="n">to</span> <span class="n">develop</span> <span class="n">data</span> <span class="n">processing</span> <span class="ow">and</span> <span class="n">product</span> <span class="n">technol</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="n">What</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">immediate</span> <span class="n">strategy</span> <span class="k">for</span> <span class="n">scaling</span> <span class="n">the</span> <span class="n">IntentKey</span> <span class="n">platform</span><span class="err">?</span><span class="o">|</span><span class="n">Our</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">has</span> <span class="n">been</span> <span class="n">to</span> <span class="n">develop</span> <span class="n">data</span> <span class="n">processing</span> <span class="ow">and</span> <span class="n">product</span> <span class="n">technol</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="n">How</span> <span class="n">does</span> <span class="n">the</span> <span class="n">company</span> <span class="n">aim</span> <span class="n">to</span> <span class="n">provide</span> <span class="n">differentiation</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">market</span><span class="err">?</span><span class="o">|</span><span class="n">Our</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">has</span> <span class="n">been</span> <span class="n">to</span> <span class="n">develop</span> <span class="n">data</span> <span class="n">processing</span> <span class="ow">and</span> <span class="n">product</span> <span class="n">technol</span><span class="p">...</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'question'</span><span class="p">,</span> <span class="s">'answer.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">question</span>                                                          <span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                            <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">What</span> <span class="n">are</span> <span class="n">the</span> <span class="n">key</span> <span class="n">components</span> <span class="n">of</span> <span class="n">the</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">described</span><span class="err">?</span>   <span class="o">|</span><span class="p">[</span><span class="n">The</span> <span class="n">key</span> <span class="n">components</span> <span class="n">of</span> <span class="n">the</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">described</span> <span class="n">are</span> <span class="n">proprietary</span> <span class="n">demand</span> <span class="p">(</span><span class="n">media</span> <span class="n">spend</span><span class="p">)</span> <span class="ow">and</span> <span class="n">supply</span> <span class="n">side</span> <span class="p">(</span><span class="n">media</span> <span class="n">inventory</span><span class="p">)</span> <span class="n">technologies</span><span class="p">,</span> <span class="n">targeting</span> <span class="n">technologies</span><span class="p">,</span> <span class="n">on</span><span class="o">-</span><span class="n">page</span> <span class="ow">or</span> <span class="ow">in</span><span class="o">-</span><span class="n">app</span> <span class="n">ad</span><span class="o">-</span><span class="n">unit</span> <span class="n">technologies</span><span class="p">,</span> <span class="n">proprietary</span> <span class="n">data</span> <span class="ow">and</span> <span class="n">data</span> <span class="n">management</span> <span class="n">technologies</span><span class="p">,</span> <span class="ow">and</span> <span class="n">advertising</span> <span class="n">fraud</span> <span class="n">detection</span> <span class="n">technologies</span><span class="p">.</span> <span class="p">.</span> <span class="p">.</span> <span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="n">What</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">immediate</span> <span class="n">strategy</span> <span class="k">for</span> <span class="n">scaling</span> <span class="n">the</span> <span class="n">IntentKey</span> <span class="n">platform</span><span class="err">?</span><span class="o">|</span><span class="p">[</span><span class="n">The</span> <span class="n">immediate</span> <span class="n">strategy</span> <span class="k">for</span> <span class="n">scaling</span> <span class="n">the</span> <span class="n">IntentKey</span> <span class="n">platform</span> <span class="ow">is</span> <span class="n">to</span> <span class="n">scale</span> <span class="n">through</span> <span class="n">the</span> <span class="n">hiring</span> <span class="n">of</span> <span class="n">additional</span> <span class="n">sales</span> <span class="n">professionals</span><span class="p">,</span> <span class="n">growing</span> <span class="n">existing</span> <span class="n">accounts</span> <span class="ow">and</span> <span class="n">expanding</span> <span class="n">the</span> <span class="n">market</span> <span class="n">size</span> <span class="n">by</span> <span class="n">concurrently</span> <span class="n">selling</span> <span class="n">the</span> <span class="n">SaaS</span> <span class="n">version</span> <span class="n">of</span> <span class="n">the</span> <span class="n">IntentKey</span> <span class="n">beginning</span> <span class="ow">in</span> <span class="mf">2021.</span> <span class="p">]</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="n">How</span> <span class="n">does</span> <span class="n">the</span> <span class="n">company</span> <span class="n">aim</span> <span class="n">to</span> <span class="n">provide</span> <span class="n">differentiation</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">market</span><span class="err">?</span><span class="o">|</span><span class="p">[</span><span class="n">The</span> <span class="n">company</span> <span class="n">aims</span> <span class="n">to</span> <span class="n">provide</span> <span class="n">differentiation</span> <span class="n">through</span> <span class="n">the</span> <span class="n">AI</span> <span class="n">analytics</span> <span class="ow">and</span> <span class="n">data</span> <span class="n">products</span> <span class="n">they</span> <span class="n">own</span> <span class="ow">and</span> <span class="n">protect</span> <span class="n">through</span> <span class="n">patents</span><span class="p">.</span> <span class="p">]</span>                                                                                                                                                                                   <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">context</span> <span class="o">=</span> <span class="p">[</span><span class="s">"""EXHIBIT 99.2 Page 1 of 3 DISTRIBUTOR AGREEMENT Agreement made this 19th day of March, 2020 Between: Co-Diagnostics, Inc. (herein referred to as "Principal") And PreCheck Health Services, Inc. (herein referred to as "Distributor"). In consideration of the mutual terms, conditions and covenants hereinafter set forth, Principal and Distributor acknowledge and agree to the following descriptions and conditions: DESCRIPTION OF PRINCIPAL The Principal is a company located in Utah, United States and is in the business of research and development of reagents. The Principal markets and sells it products globally through direct sales and distributors. DESCRIPTION OF DISTRIBUTOR The Distributor is a company operating or planning to operate in the United States of America, Latin America, Europe and Russia. The Distributor represents that the Distributor or a subsidiary of the Distributor is or will be fully licensed and registered in the Territory and will provide professional distribution services for the products of the Principal. CONDITIONS: 1. The Principal appoints the Distributor as a non-exclusive distributor, to sell Principal's qPCR infectious disease kits, Logix Smart COVID-19 PCR diagnostic test and Co-Dx Box™ instrument (the "Products"). The Products are described on Exhibit A to this Agreement. 2. The Principal grants Distributor non- exclusive rights to sell these products within the countries of Romania (the "Territory"), which may be amended by mutual written agreement."""</span><span class="p">]</span>

<span class="n">questions</span> <span class="o">=</span> <span class="p">[</span><span class="s">"""Which company is referred to as 'Principal' in the Distributor Agreement?"""</span><span class="p">,</span>
             <span class="s">"""What is the date of the distributor agreement between Co-Diagnostics, Inc. and PreCheck Health Services, Inc.?"""</span><span class="p">,</span>
             <span class="s">"""What is the Territory in which the Distributor has non-exclusive rights to sell Principal's products according to the Agreement?"""</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="n">context</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="n">questions</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
        <span class="p">[</span><span class="n">context</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="n">questions</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
        <span class="p">[</span><span class="n">context</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>  <span class="n">questions</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span>
    <span class="p">]</span>
<span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"context"</span><span class="p">,</span><span class="s">"question"</span><span class="p">)</span>

<span class="n">data</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="mi">80</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                         <span class="n">context</span><span class="o">|</span>                                                                        <span class="n">question</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">EXHIBIT</span> <span class="mf">99.2</span> <span class="n">Page</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">3</span> <span class="n">DISTRIBUTOR</span> <span class="n">AGREEMENT</span> <span class="n">Agreement</span> <span class="n">made</span> <span class="n">this</span> <span class="mi">19</span><span class="n">th</span> <span class="n">day</span> <span class="n">o</span><span class="p">...</span><span class="o">|</span>       <span class="n">Which</span> <span class="n">company</span> <span class="ow">is</span> <span class="n">referred</span> <span class="n">to</span> <span class="k">as</span> <span class="s">'Principal'</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">Distributor</span> <span class="n">Agreement</span><span class="err">?</span><span class="o">|</span>
<span class="o">|</span><span class="n">EXHIBIT</span> <span class="mf">99.2</span> <span class="n">Page</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">3</span> <span class="n">DISTRIBUTOR</span> <span class="n">AGREEMENT</span> <span class="n">Agreement</span> <span class="n">made</span> <span class="n">this</span> <span class="mi">19</span><span class="n">th</span> <span class="n">day</span> <span class="n">o</span><span class="p">...</span><span class="o">|</span><span class="n">What</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">date</span> <span class="n">of</span> <span class="n">the</span> <span class="n">distributor</span> <span class="n">agreement</span> <span class="n">between</span> <span class="n">Co</span><span class="o">-</span><span class="n">Diagnostics</span><span class="p">,</span> <span class="n">Inc</span><span class="p">.</span> <span class="n">an</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="n">EXHIBIT</span> <span class="mf">99.2</span> <span class="n">Page</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">3</span> <span class="n">DISTRIBUTOR</span> <span class="n">AGREEMENT</span> <span class="n">Agreement</span> <span class="n">made</span> <span class="n">this</span> <span class="mi">19</span><span class="n">th</span> <span class="n">day</span> <span class="n">o</span><span class="p">...</span><span class="o">|</span><span class="n">What</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">Territory</span> <span class="ow">in</span> <span class="n">which</span> <span class="n">the</span> <span class="n">Distributor</span> <span class="n">has</span> <span class="n">non</span><span class="o">-</span><span class="n">exclusive</span> <span class="n">rights</span> <span class="n">to</span> <span class="n">se</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">MultiDocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"question"</span><span class="p">,</span> <span class="s">"context"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCols</span><span class="p">(</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">)</span>

<span class="n">leg_qa</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">QuestionAnswering</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legqa_flant5_finetuned"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document_question"</span><span class="p">,</span> <span class="s">"document_context"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setCustomPrompt</span><span class="p">(</span><span class="s">"question: {QUESTION} context: {CONTEXT}"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTopK</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">leg_qa</span><span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">"document_question.result as Question"</span><span class="p">,</span> <span class="s">"answer.result as Answer"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">Question</span>                                                                                                                          <span class="o">|</span><span class="n">Answer</span>                                                                                                                                  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Which</span> <span class="n">company</span> <span class="ow">is</span> <span class="n">referred</span> <span class="n">to</span> <span class="k">as</span> <span class="s">'Principal'</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">Distributor</span> <span class="n">Agreement</span><span class="err">?</span><span class="p">]</span>                                                       <span class="o">|</span><span class="p">[</span><span class="n">Co</span><span class="o">-</span><span class="n">Diagnostics</span><span class="p">,</span> <span class="n">Inc</span><span class="p">.</span> <span class="ow">is</span> <span class="n">referred</span> <span class="n">to</span> <span class="k">as</span> <span class="s">'Principal'</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">Distributor</span> <span class="n">Agreement</span><span class="p">.</span> <span class="p">]</span>                                                     <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">What</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">date</span> <span class="n">of</span> <span class="n">the</span> <span class="n">distributor</span> <span class="n">agreement</span> <span class="n">between</span> <span class="n">Co</span><span class="o">-</span><span class="n">Diagnostics</span><span class="p">,</span> <span class="n">Inc</span><span class="p">.</span> <span class="ow">and</span> <span class="n">PreCheck</span> <span class="n">Health</span> <span class="n">Services</span><span class="p">,</span> <span class="n">Inc</span><span class="p">.</span><span class="err">?</span><span class="p">]</span>                  <span class="o">|</span><span class="p">[</span><span class="n">The</span> <span class="n">date</span> <span class="n">of</span> <span class="n">the</span> <span class="n">distributor</span> <span class="n">agreement</span> <span class="n">between</span> <span class="n">Co</span><span class="o">-</span><span class="n">Diagnostics</span><span class="p">,</span> <span class="n">Inc</span><span class="p">.</span> <span class="ow">and</span> <span class="n">PreCheck</span> <span class="n">Health</span> <span class="n">Services</span><span class="p">,</span> <span class="n">Inc</span><span class="p">.</span> <span class="ow">is</span> <span class="n">the</span> <span class="mi">19</span><span class="n">th</span> <span class="n">day</span> <span class="n">of</span> <span class="n">March</span><span class="p">,</span> <span class="mf">2020.</span> <span class="p">]</span><span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">What</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">Territory</span> <span class="ow">in</span> <span class="n">which</span> <span class="n">the</span> <span class="n">Distributor</span> <span class="n">has</span> <span class="n">non</span><span class="o">-</span><span class="n">exclusive</span> <span class="n">rights</span> <span class="n">to</span> <span class="n">sell</span> <span class="n">Principal</span><span class="s">'s products according to the Agreement?]|[The Territory in which the Distributor has non-exclusive rights to sell Principal'</span><span class="n">s</span> <span class="n">products</span> <span class="n">according</span> <span class="n">to</span> <span class="n">the</span> <span class="n">Agreement</span> <span class="ow">is</span> <span class="n">Romania</span><span class="p">.</span> <span class="p">]</span>  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">medQA</span> <span class="k">=</span> <span class="nv">MedicalQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"medical_qa_biogpt"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">30</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTopK</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setQuestionType</span><span class="o">(</span><span class="s">"long"</span><span class="o">)</span> <span class="c1">// "short"</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                              <span class="n">documentAssembler</span><span class="o">,</span> 
                                              <span class="n">medQA</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">paperAbstract</span> <span class="k">=</span> <span class="s">"In patients with Los Angeles (LA) grade C or D oesophagitis, a positive relationship has been established between the duration of intragastric acid suppression and healing.AIM: To determine whether there is an apparent optimal time of intragastric acid suppression for maximal healing of reflux oesophagitis. Post hoc analysis of data from a proof-of-concept, double-blind, randomized study of 134 adult patients treated with esomeprazole (10 or 40 mg od for 4 weeks) for LA grade C or D oesophagitis. A curve was fitted to pooled 24-h intragastric pH (day 5) and endoscopically assessed healing (4 weeks) data using piecewise quadratic logistic regression. Maximal reflux oesophagitis healing rates were achieved when intragastric pH&gt;4 was achieved for approximately 50-70% (12-17 h) of the 24-h period. Acid suppression above this threshold did not yield further increases in healing rates."</span>

<span class="k">val</span> <span class="nv">question</span> <span class="k">=</span> <span class="s">"Is there an optimal time of acid suppression for maximal healing?"</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">paperAbstract</span><span class="o">,</span> <span class="n">question</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"context"</span><span class="o">,</span> <span class="s">"question"</span><span class="o">)</span>

<span class="o">+------------------------------------------------------------+------------------------------------------------------------+</span>
<span class="o">|</span>                                                     <span class="n">context</span><span class="o">|</span>                                                    <span class="n">question</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------+------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">In</span> <span class="n">patients</span> <span class="k">with</span> <span class="nc">Los</span> <span class="nc">Angeles</span> <span class="o">(</span><span class="nc">LA</span><span class="o">)</span> <span class="n">grade</span> <span class="n">C</span> <span class="n">or</span> <span class="n">D</span> <span class="n">oesophagit</span><span class="o">...|</span><span class="nc">Is</span> <span class="n">there</span> <span class="n">an</span> <span class="n">optimal</span> <span class="n">time</span> <span class="n">of</span> <span class="n">acid</span> <span class="n">suppression</span> <span class="k">for</span> <span class="n">maximal</span> <span class="o">...|</span>
<span class="o">+------------------------------------------------------------+------------------------------------------------------------+</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>


<span class="o">+-------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">Question</span>                                                           <span class="o">|</span><span class="nc">Long_Answer</span>                                                                                                                                          <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Is</span> <span class="kt">there</span> <span class="kt">an</span> <span class="kt">optimal</span> <span class="kt">time</span> <span class="kt">of</span> <span class="kt">acid</span> <span class="kt">suppression</span> <span class="kt">for</span> <span class="kt">maximal</span> <span class="kt">healing?</span><span class="o">]|[</span><span class="kt">in</span> <span class="kt">patients</span> <span class="kt">with</span> <span class="kt">reflux</span> <span class="kt">oesophagitis</span>, <span class="kt">maximal</span> <span class="kt">healing</span> <span class="kt">rates</span> <span class="kt">are</span> <span class="kt">obtained</span> <span class="kt">when</span> <span class="kt">intragastric</span> <span class="kt">pH</span> <span class="kt">is</span> <span class="kt">achieved</span> <span class="kt">for</span> <span class="kt">approximately</span> <span class="err">50</span> <span class="kt">-</span> <span class="err">70</span> <span class="kt">%</span> <span class="o">(</span> <span class="err">12</span> <span class="kt">-</span> <span class="err">17</span> <span class="kt">h</span> <span class="o">)]|</span>
<span class="o">+-------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">finQa</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">FinanceQuestionAnswering</span><span class="o">()</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finqa_flant5_finetuned"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setCustomPrompt</span><span class="o">(</span><span class="s">"question: {QUESTION} context: {CONTEXT}"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">100</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">finQa</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">context</span> <span class="k">=</span> <span class="s">"EXHIBIT 99.2 Page 1 of 3 DISTRIBUTOR AGREEMENT Agreement made this 19th day of March, 2020 Between: Co-Diagnostics, Inc. (herein referred to as "</span><span class="nc">Principal</span><span class="s">") And PreCheck Health Services, Inc. (herein referred to as "</span><span class="nc">Distributor</span><span class="s">"). In consideration of the mutual terms, conditions and covenants hereinafter set forth, Principal and Distributor acknowledge and agree to the following descriptions and conditions: DESCRIPTION OF PRINCIPAL The Principal is a company located in Utah, United States and is in the business of research and development of reagents. The Principal markets and sells it products globally through direct sales and distributors. DESCRIPTION OF DISTRIBUTOR The Distributor is a company operating or planning to operate in the United States of America, Latin America, Europe and Russia. The Distributor represents that the Distributor or a subsidiary of the Distributor is or will be fully licensed and registered in the Territory and will provide professional distribution services for the products of the Principal. CONDITIONS: 1. The Principal appoints the Distributor as a non-exclusive distributor, to sell Principal's qPCR infectious disease kits, Logix Smart COVID-19 PCR diagnostic test and Co-Dx Box™ instrument (the "</span><span class="nc">Products</span><span class="s">"). The Products are described on Exhibit A to this Agreement. 2. The Principal grants Distributor non- exclusive rights to sell these products within the countries of Romania (the "</span><span class="nc">Territory</span><span class="s">"), which may be amended by mutual written agreement."</span>

<span class="k">val</span> <span class="nv">questions</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"Which company is referred to as 'Principal' in the Distributor Agreement?"</span><span class="o">,</span>
  <span class="s">"What is the date of the distributor agreement between Co-Diagnostics, Inc. and PreCheck Health Services, Inc.?"</span><span class="o">,</span>
  <span class="s">"What is the Territory in which the Distributor has non-exclusive rights to sell Principal's products according to the Agreement?"</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nv">questions</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">q</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">context</span><span class="o">,</span> <span class="n">q</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"context"</span><span class="o">,</span> <span class="s">"question"</span><span class="o">)</span>

<span class="o">+------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                          <span class="n">question</span><span class="o">|</span>                                                                         <span class="n">context</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>   <span class="nc">What</span> <span class="n">are</span> <span class="n">the</span> <span class="n">key</span> <span class="n">components</span> <span class="n">of</span> <span class="n">the</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">described</span><span class="o">?|</span><span class="nc">Our</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">has</span> <span class="n">been</span> <span class="n">to</span> <span class="n">develop</span> <span class="n">data</span> <span class="n">processing</span> <span class="n">and</span> <span class="n">product</span> <span class="n">technol</span><span class="o">...|</span>
<span class="o">|</span><span class="nc">What</span> <span class="n">is</span> <span class="n">the</span> <span class="n">immediate</span> <span class="n">strategy</span> <span class="k">for</span> <span class="n">scaling</span> <span class="n">the</span> <span class="nc">IntentKey</span> <span class="n">platform</span><span class="o">?|</span><span class="nc">Our</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">has</span> <span class="n">been</span> <span class="n">to</span> <span class="n">develop</span> <span class="n">data</span> <span class="n">processing</span> <span class="n">and</span> <span class="n">product</span> <span class="n">technol</span><span class="o">...|</span>
<span class="o">|</span><span class="nc">How</span> <span class="n">does</span> <span class="n">the</span> <span class="n">company</span> <span class="n">aim</span> <span class="n">to</span> <span class="n">provide</span> <span class="n">differentiation</span> <span class="n">in</span> <span class="n">the</span> <span class="n">market</span><span class="o">?|</span><span class="nc">Our</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">has</span> <span class="n">been</span> <span class="n">to</span> <span class="n">develop</span> <span class="n">data</span> <span class="n">processing</span> <span class="n">and</span> <span class="n">product</span> <span class="n">technol</span><span class="o">...|</span>
<span class="o">+------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">question</span>                                                          <span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                            <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">What</span> <span class="n">are</span> <span class="n">the</span> <span class="n">key</span> <span class="n">components</span> <span class="n">of</span> <span class="n">the</span> <span class="n">business</span> <span class="n">strategy</span> <span class="n">described</span><span class="o">?</span>   <span class="o">|[</span><span class="kt">The</span> <span class="kt">key</span> <span class="kt">components</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">business</span> <span class="kt">strategy</span> <span class="kt">described</span> <span class="kt">are</span> <span class="kt">proprietary</span> <span class="kt">demand</span> <span class="o">(</span><span class="kt">media</span> <span class="kt">spend</span><span class="o">)</span> <span class="kt">and</span> <span class="kt">supply</span> <span class="kt">side</span> <span class="o">(</span><span class="kt">media</span> <span class="kt">inventory</span><span class="o">)</span> <span class="kt">technologies</span>, <span class="kt">targeting</span> <span class="kt">technologies</span>, <span class="kt">on-page</span> <span class="kt">or</span> <span class="kt">in-app</span> <span class="kt">ad-unit</span> <span class="kt">technologies</span>, <span class="kt">proprietary</span> <span class="kt">data</span> <span class="kt">and</span> <span class="kt">data</span> <span class="kt">management</span> <span class="kt">technologies</span>, <span class="kt">and</span> <span class="kt">advertising</span> <span class="kt">fraud</span> <span class="kt">detection</span> <span class="kt">technologies.</span> <span class="kt">.</span> <span class="kt">.</span> <span class="o">]|</span>
<span class="o">|</span><span class="nc">What</span> <span class="n">is</span> <span class="n">the</span> <span class="n">immediate</span> <span class="n">strategy</span> <span class="k">for</span> <span class="n">scaling</span> <span class="n">the</span> <span class="nc">IntentKey</span> <span class="n">platform</span><span class="o">?|[</span><span class="kt">The</span> <span class="kt">immediate</span> <span class="kt">strategy</span> <span class="kt">for</span> <span class="kt">scaling</span> <span class="kt">the</span> <span class="kt">IntentKey</span> <span class="kt">platform</span> <span class="kt">is</span> <span class="kt">to</span> <span class="kt">scale</span> <span class="kt">through</span> <span class="kt">the</span> <span class="kt">hiring</span> <span class="kt">of</span> <span class="kt">additional</span> <span class="kt">sales</span> <span class="kt">professionals</span>, <span class="kt">growing</span> <span class="kt">existing</span> <span class="kt">accounts</span> <span class="kt">and</span> <span class="kt">expanding</span> <span class="kt">the</span> <span class="kt">market</span> <span class="kt">size</span> <span class="kt">by</span> <span class="kt">concurrently</span> <span class="kt">selling</span> <span class="kt">the</span> <span class="kt">SaaS</span> <span class="kt">version</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">IntentKey</span> <span class="kt">beginning</span> <span class="kt">in</span> <span class="err">2021</span><span class="kt">.</span> <span class="o">]</span>                                               <span class="o">|</span>
<span class="o">|</span><span class="nc">How</span> <span class="n">does</span> <span class="n">the</span> <span class="n">company</span> <span class="n">aim</span> <span class="n">to</span> <span class="n">provide</span> <span class="n">differentiation</span> <span class="n">in</span> <span class="n">the</span> <span class="n">market</span><span class="o">?|[</span><span class="kt">The</span> <span class="kt">company</span> <span class="kt">aims</span> <span class="kt">to</span> <span class="kt">provide</span> <span class="kt">differentiation</span> <span class="kt">through</span> <span class="kt">the</span> <span class="kt">AI</span> <span class="kt">analytics</span> <span class="kt">and</span> <span class="kt">data</span> <span class="kt">products</span> <span class="kt">they</span> <span class="kt">own</span> <span class="kt">and</span> <span class="kt">protect</span> <span class="kt">through</span> <span class="kt">patents.</span> <span class="o">]</span>                                                                                                                                                                                   <span class="o">|</span>
<span class="o">+------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">val</span> <span class="nv">context</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"""EXHIBIT 99.2 Page 1 of 3 DISTRIBUTOR AGREEMENT Agreement made this 19th day of March, 2020 Between: Co-Diagnostics, Inc. (herein referred to as "Principal") And PreCheck Health Services, Inc. (herein referred to as "Distributor"). In consideration of the mutual terms, conditions and covenants hereinafter set forth, Principal and Distributor acknowledge and agree to the following descriptions and conditions: DESCRIPTION OF PRINCIPAL The Principal is a company located in Utah, United States and is in the business of research and development of reagents. The Principal markets and sells it products globally through direct sales and distributors. DESCRIPTION OF DISTRIBUTOR The Distributor is a company operating or planning to operate in the United States of America, Latin America, Europe and Russia. The Distributor represents that the Distributor or a subsidiary of the Distributor is or will be fully licensed and registered in the Territory and will provide professional distribution services for the products of the Principal. CONDITIONS: 1. The Principal appoints the Distributor as a non-exclusive distributor, to sell Principal's qPCR infectious disease kits, Logix Smart COVID-19 PCR diagnostic test and Co-Dx Box™ instrument (the "Products"). The Products are described on Exhibit A to this Agreement. 2. The Principal grants Distributor non- exclusive rights to sell these products within the countries of Romania (the "Territory"), which may be amended by mutual written agreement."""</span>
<span class="o">)</span>

<span class="k">val</span> <span class="nv">questions</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"""Which company is referred to as 'Principal' in the Distributor Agreement?"""</span><span class="o">,</span>
  <span class="s">"""What is the date of the distributor agreement between Co-Diagnostics, Inc. and PreCheck Health Services, Inc.?"""</span><span class="o">,</span>
  <span class="s">"""What is the Territory in which the Distributor has non-exclusive rights to sell Principal's products according to the Agreement?"""</span>
<span class="o">)</span>

<span class="c1">// val data = context.flatMap(c =&gt; questions.map(q =&gt; (c, q))).toDF("context", "question")</span>


<span class="o">+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span>                                                                         <span class="n">context</span><span class="o">|</span>                                                                        <span class="n">question</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">EXHIBIT</span> <span class="mf">99.2</span> <span class="nc">Page</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">3</span> <span class="nc">DISTRIBUTOR</span> <span class="nc">AGREEMENT</span> <span class="nc">Agreement</span> <span class="n">made</span> <span class="k">this</span> <span class="mi">19</span><span class="n">th</span> <span class="n">day</span> <span class="n">o</span><span class="o">...|</span>       <span class="nc">Which</span> <span class="n">company</span> <span class="n">is</span> <span class="n">referred</span> <span class="n">to</span> <span class="n">as</span> <span class="ss">'Principa</span><span class="n">l</span><span class="o">'</span> <span class="n">in</span> <span class="n">the</span> <span class="nc">Distributor</span> <span class="nc">Agreement</span><span class="o">?|</span>
<span class="o">|</span><span class="nc">EXHIBIT</span> <span class="mf">99.2</span> <span class="nc">Page</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">3</span> <span class="nc">DISTRIBUTOR</span> <span class="nc">AGREEMENT</span> <span class="nc">Agreement</span> <span class="n">made</span> <span class="k">this</span> <span class="mi">19</span><span class="n">th</span> <span class="n">day</span> <span class="n">o</span><span class="o">...|</span><span class="nc">What</span> <span class="n">is</span> <span class="n">the</span> <span class="n">date</span> <span class="n">of</span> <span class="n">the</span> <span class="n">distributor</span> <span class="n">agreement</span> <span class="n">between</span> <span class="nc">Co</span><span class="o">-</span><span class="nc">Diagnostics</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">.</span> <span class="n">an</span><span class="o">...|</span>
<span class="o">|</span><span class="nc">EXHIBIT</span> <span class="mf">99.2</span> <span class="nc">Page</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">3</span> <span class="nc">DISTRIBUTOR</span> <span class="nc">AGREEMENT</span> <span class="nc">Agreement</span> <span class="n">made</span> <span class="k">this</span> <span class="mi">19</span><span class="n">th</span> <span class="n">day</span> <span class="n">o</span><span class="o">...|</span><span class="nc">What</span> <span class="n">is</span> <span class="n">the</span> <span class="nc">Territory</span> <span class="n">in</span> <span class="n">which</span> <span class="n">the</span> <span class="nc">Distributor</span> <span class="n">has</span> <span class="n">non</span><span class="o">-</span><span class="n">exclusive</span> <span class="n">rights</span> <span class="n">to</span> <span class="n">se</span><span class="o">...|</span>
<span class="o">+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+</span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"question"</span><span class="o">,</span> <span class="s">"context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">legQA</span> <span class="k">=</span> <span class="nv">LegalQuestionAnswering</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legqa_flant5_finetuned"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_question"</span><span class="o">,</span> <span class="s">"document_context"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setCustomPrompt</span><span class="o">(</span><span class="s">"question: {QUESTION} context: {CONTEXT}"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">40</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTopK</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">legQA</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">Question</span>                                                                                                                          <span class="o">|</span><span class="nc">Answer</span>                                                                                                                                  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Which</span> <span class="kt">company</span> <span class="kt">is</span> <span class="kt">referred</span> <span class="kt">to</span> <span class="kt">as</span> <span class="kt">'Principal'</span> <span class="kt">in</span> <span class="kt">the</span> <span class="kt">Distributor</span> <span class="kt">Agreement?</span><span class="o">]</span>                                                       <span class="o">|[</span><span class="kt">Co-Diagnostics</span>, <span class="kt">Inc.</span> <span class="kt">is</span> <span class="kt">referred</span> <span class="kt">to</span> <span class="kt">as</span> <span class="kt">'Principal'</span> <span class="kt">in</span> <span class="kt">the</span> <span class="kt">Distributor</span> <span class="kt">Agreement.</span> <span class="o">]</span>                                                     <span class="o">|</span>
<span class="o">|[</span><span class="kt">What</span> <span class="kt">is</span> <span class="kt">the</span> <span class="kt">date</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">distributor</span> <span class="kt">agreement</span> <span class="kt">between</span> <span class="kt">Co-Diagnostics</span>, <span class="kt">Inc.</span> <span class="kt">and</span> <span class="kt">PreCheck</span> <span class="kt">Health</span> <span class="kt">Services</span>, <span class="kt">Inc.?</span><span class="o">]</span>                  <span class="o">|[</span><span class="kt">The</span> <span class="kt">date</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">distributor</span> <span class="kt">agreement</span> <span class="kt">between</span> <span class="kt">Co-Diagnostics</span>, <span class="kt">Inc.</span> <span class="kt">and</span> <span class="kt">PreCheck</span> <span class="kt">Health</span> <span class="kt">Services</span>, <span class="kt">Inc.</span> <span class="kt">is</span> <span class="kt">the</span> <span class="err">19</span><span class="kt">th</span> <span class="kt">day</span> <span class="kt">of</span> <span class="kt">March</span>, <span class="err">2020</span><span class="kt">.</span> <span class="o">]|</span>
<span class="o">|[</span><span class="kt">What</span> <span class="kt">is</span> <span class="kt">the</span> <span class="kt">Territory</span> <span class="kt">in</span> <span class="kt">which</span> <span class="kt">the</span> <span class="kt">Distributor</span> <span class="kt">has</span> <span class="kt">non-exclusive</span> <span class="kt">rights</span> <span class="kt">to</span> <span class="kt">sell</span> <span class="kt">Principal's</span> <span class="kt">products</span> <span class="kt">according</span> <span class="kt">to</span> <span class="kt">the</span> <span class="kt">Agreement?</span><span class="o">]|[</span><span class="kt">The</span> <span class="kt">Territory</span> <span class="kt">in</span> <span class="kt">which</span> <span class="kt">the</span> <span class="kt">Distributor</span> <span class="kt">has</span> <span class="kt">non-exclusive</span> <span class="kt">rights</span> <span class="kt">to</span> <span class="kt">sell</span> <span class="kt">Principal's</span> <span class="kt">products</span> <span class="kt">according</span> <span class="kt">to</span> <span class="kt">the</span> <span class="kt">Agreement</span> <span class="kt">is</span> <span class="kt">Romania.</span> <span class="o">]</span>  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="rechunkmerger">REChunkMerger</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">REChunkMerger</code> annotator merges relation chunks to create a new chunk.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">separator</code>: Separator to add between the chunks. Default: “ “.</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/merge/REChunkMerger.html">REChunkMerger</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/merge/REChunkMerger.html">REChunkMerger</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/REChunkMerger.ipynb">REChunkMergerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span> \

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">depency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionModel</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setCustomLabels</span><span class="p">({</span><span class="s">"TeRP"</span><span class="p">:</span> <span class="s">"CustomLabel_TeRP"</span><span class="p">,</span> <span class="s">"TrWP"</span><span class="p">:</span> <span class="s">"CustomLabel_TeWP"</span><span class="p">})</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_chunk"</span><span class="p">)</span>

<span class="n">re_chunk_merger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">REChunkMerger</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relation_chunks"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setSeparator</span><span class="p">(</span><span class="s">" &amp;&amp; "</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documenter</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">words_embedder</span><span class="p">,</span>
      <span class="n">pos_tagger</span><span class="p">,</span>
      <span class="n">ner_tagger</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">depency_parser</span><span class="p">,</span>
      <span class="n">re_model</span><span class="p">,</span>
      <span class="n">re_chunk_merger</span>
    <span class="p">])</span>

<span class="n">empty_data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">empty_data</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span><span class="s">''' 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to " +
"presentation and subsequent type two diabetes mellitus ( T2DM ). '''</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">))</span>

<span class="c1"># result
</span><span class="o">+----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">gestational</span> <span class="n">diabetes</span> <span class="n">mellitus</span> <span class="o">&amp;&amp;</span> <span class="n">subsequent</span> <span class="nb">type</span> <span class="n">two</span> <span class="n">diabetes</span> <span class="n">mellitus</span><span class="o">|</span>
<span class="o">|</span><span class="n">gestational</span> <span class="n">diabetes</span> <span class="n">mellitus</span> <span class="o">&amp;&amp;</span> <span class="n">T2DM</span>                                 <span class="o">|</span>
<span class="o">|</span><span class="n">subsequent</span> <span class="nb">type</span> <span class="n">two</span> <span class="n">diabetes</span> <span class="n">mellitus</span> <span class="o">&amp;&amp;</span> <span class="n">T2DM</span>                         <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nc">PerceptronModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_tagger</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">depency_parser</span> <span class="k">=</span> <span class="nc">DependencyParserModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nc">RelationExtractionModel</span>
    <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"re_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_chunk_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">REChunkMerger</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"re_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relation_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setSeparator</span><span class="o">(</span><span class="s">" &amp;&amp; "</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
        <span class="n">documenter</span><span class="o">,</span>
        <span class="n">tokenizer</span><span class="o">,</span>
        <span class="n">words_embedder</span><span class="o">,</span>
        <span class="n">pos_tagger</span><span class="o">,</span>
        <span class="n">ner_tagger</span><span class="o">,</span>
        <span class="n">ner_converter</span><span class="o">,</span>
        <span class="n">depency_parser</span><span class="o">,</span>
        <span class="n">re_model</span><span class="o">,</span>
        <span class="n">re_chunk_merger</span>
  <span class="o">))</span>
<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to "</span> <span class="o">+</span>
  <span class="s">"presentation and subsequent type two diabetes mellitus ( T2DM ). "</span>

<span class="k">val</span> <span class="nv">empty_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">""</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">empty_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">))</span>

<span class="k">#</span> <span class="n">result</span>
<span class="o">+----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">gestational</span> <span class="n">diabetes</span> <span class="n">mellitus</span> <span class="o">&amp;&amp;</span> <span class="n">subsequent</span> <span class="k">type</span> <span class="kt">two</span> <span class="kt">diabetes</span> <span class="kt">mellitus|</span>
<span class="kt">|gestational</span> <span class="kt">diabetes</span> <span class="kt">mellitus</span> <span class="kt">&amp;&amp;</span> <span class="kt">T2DM</span>                                 <span class="kt">|</span>
<span class="kt">|subsequent</span> <span class="k">type</span> <span class="kt">two</span> <span class="kt">diabetes</span> <span class="kt">mellitus</span> <span class="kt">&amp;&amp;</span> <span class="kt">T2DM</span>                         <span class="kt">|</span>
<span class="kt">+----------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="renerchunksfilter">RENerChunksFilter</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The <code class="language-plaintext highlighter-rouge">RENerChunksFilter</code> annotator filters desired relation pairs (defined by the parameter realtionPairs), and store those on the output column. Filtering the possible relations can be useful to perform additional analysis for a specific use case (e.g., checking adverse drug reactions and drug realations), which can be the input for further analysis using a pretrained <code class="language-plaintext highlighter-rouge">RelationExtractionDLModel</code>.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxSyntacticDistance</code> <em>(Int)</em>: Maximum syntactic distance between a pair of named entities to consider them as a relation. Increasing this value will increase recall, but also increase the number of false positives.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">relationPairs</code> <em>(List[Str])</em>: List of dash-separated pairs of named entities. For example, [“Biomarker-RelativeDay”] will process all relations between entities of type “Biomarker” and “RelativeDay”.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">relationPairsCaseSensitive</code> <em>(Boolean)</em>: Determines whether relation pairs are case sensitive.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">directionSensitive</code> <em>(Boolean)</em>: Specify direction sensitivity in processing relation pairs Default is ‘False’.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">filterByTokenDistance</code> <em>(Int)</em>: Filtering criterion based on number of token between entities (Default: 0)</p>
      </li>
    </ul>

    <p>For example, the <a href="https://nlp.johnsnowlabs.com/2021/03/31/ner_clinical_en.html">ner_clinical</a> NER model can identify <code class="language-plaintext highlighter-rouge">PROBLEM</code>, <code class="language-plaintext highlighter-rouge">TEST</code>, and <code class="language-plaintext highlighter-rouge">TREATMENT</code> entities. By using the <code class="language-plaintext highlighter-rouge">RENerChunksFilter</code>, one can filter only the relations between <code class="language-plaintext highlighter-rouge">PROBLEM</code> and <code class="language-plaintext highlighter-rouge">TREATMENT</code>  entities only, removing any relation between the other entities, to further analyze the  associations between clinical problems and treatments.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_ner_chunk_filter/index.html#sparknlp_jsl.annotator.re.relation_ner_chunk_filter.RENerChunksFilter">RENerChunksFilter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RENerChunksFilter.html">RENerChunksFilter</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/RENerChunksFilter.ipynb">RENerChunksFilter</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_ade_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">ade_re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"drug-ade, ade-drug"</span><span class="p">])</span>

<span class="n">ade_re_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'redl_ade_biobert'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunks"</span><span class="p">,</span> <span class="s">"sentences"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">words_embedder</span><span class="p">,</span>
    <span class="n">pos_tagger</span><span class="p">,</span>
    <span class="n">ner_tagger</span><span class="p">,</span>
    <span class="n">ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">ade_re_ner_chunk_filter</span><span class="p">,</span>
    <span class="n">ade_re_model</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">results</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">results</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>   <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>                                                   <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">25</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span> <span class="n">naproxen</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>          <span class="mi">137</span><span class="o">|</span>        <span class="mi">148</span><span class="o">|</span>                                             <span class="n">tense</span> <span class="n">bullae</span><span class="o">|</span>    <span class="n">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span> <span class="mf">0.9989047</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">25</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span> <span class="n">naproxen</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>          <span class="mi">154</span><span class="o">|</span>        <span class="mi">210</span><span class="o">|</span><span class="n">cutaneous</span> <span class="n">fragility</span> <span class="n">on</span> <span class="n">the</span> <span class="n">face</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">back</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hands</span><span class="o">|</span>    <span class="n">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span> <span class="mf">0.9989704</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">87</span><span class="o">|</span>         <span class="mi">95</span><span class="o">|</span><span class="n">oxaprozin</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>          <span class="mi">137</span><span class="o">|</span>        <span class="mi">148</span><span class="o">|</span>                                             <span class="n">tense</span> <span class="n">bullae</span><span class="o">|</span>    <span class="n">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span><span class="mf">0.99895453</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">87</span><span class="o">|</span>         <span class="mi">95</span><span class="o">|</span><span class="n">oxaprozin</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>          <span class="mi">154</span><span class="o">|</span>        <span class="mi">210</span><span class="o">|</span><span class="n">cutaneous</span> <span class="n">fragility</span> <span class="n">on</span> <span class="n">the</span> <span class="n">face</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">back</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hands</span><span class="o">|</span>    <span class="n">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span><span class="mf">0.99900633</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">TextSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model_date</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_sec_dates"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_dates"</span><span class="p">)</span>

<span class="n">ner_converter_date</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_dates"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_date"</span><span class="p">)</span>

<span class="n">ner_model_org</span><span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_orgs"</span><span class="p">)</span>

<span class="n">ner_converter_org</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_orgs"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_org"</span><span class="p">)</span>\

<span class="n">chunk_merger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'ner_chunk_org'</span><span class="p">,</span> <span class="s">"ner_chunk_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner_chunk'</span><span class="p">)</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">re_filter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"ORG-ORG"</span><span class="p">,</span> <span class="s">"ORG-DATE"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">reDL</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finre_acquisitions_subsidiaries_md'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'finance/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relation"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">text_splitter</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model_date</span><span class="p">,</span>
        <span class="n">ner_converter_date</span><span class="p">,</span>
        <span class="n">ner_model_org</span><span class="p">,</span>
        <span class="n">ner_converter_org</span><span class="p">,</span>
        <span class="n">chunk_merger</span><span class="p">,</span>
        <span class="n">pos</span><span class="p">,</span>
        <span class="n">dependency_parser</span><span class="p">,</span>
        <span class="n">re_filter</span><span class="p">,</span>
        <span class="n">reDL</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""In fiscal 2020, Cadence acquired all of the outstanding equity of AWR Corporation (“AWR”) and Integrand Software, Inc. (“Integrand”)."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">relation</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">relation</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="nb">filter</span><span class="p">(</span><span class="s">"relation != 'no_rel'"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                 <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>         <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>            <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>                <span class="n">Cadence</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="n">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span><span class="mf">0.99687237</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span>        <span class="n">AWR</span> <span class="n">Corporation</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="n">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span>  <span class="mf">0.993112</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="n">Integrand</span> <span class="n">Software</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="n">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span> <span class="mf">0.9741451</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span>        <span class="n">AWR</span> <span class="n">Corporation</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>        <span class="n">Cadence</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span>  <span class="mf">0.997124</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="n">Integrand</span> <span class="n">Software</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>        <span class="n">Cadence</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span><span class="mf">0.99910504</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="n">Integrand</span> <span class="n">Software</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span><span class="n">AWR</span> <span class="n">Corporation</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span><span class="mf">0.93245244</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">TextSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="n">ner_model</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">re_filter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">'PARTY-ALIAS'</span><span class="p">,</span> <span class="s">'DOC-PARTY'</span><span class="p">,</span> <span class="s">'DOC-EFFDATE'</span><span class="p">])</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="n">re_model</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunks"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">text_splitter</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">pos_tagger</span><span class="p">,</span>
        <span class="n">dependency_parser</span><span class="p">,</span>
        <span class="n">re_filter</span><span class="p">,</span>
        <span class="n">re_model</span>
        <span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""This INTELLECTUAL PROPERTY AGREEMENT (this "Agreement"), dated as of December 31, 2018 (the "Effective Date") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ("Seller") and AFI Licensing LLC, a Delaware limited liability company ("Licensing" and together with Seller, "Arizona") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand, a "Party" and collectively, the "Parties")."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="nb">filter</span><span class="p">(</span><span class="s">"relation != 'no_rel'"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+-------------------------------+-------+-------------+-----------+-----------------+-------+---------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                         <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>           <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span> <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-------------------------------+-------+-------------+-----------+-----------------+-------+---------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">5</span><span class="o">|</span>         <span class="mi">35</span><span class="o">|</span><span class="n">INTELLECTUAL</span> <span class="n">PROPERTY</span> <span class="n">AGREEMENT</span><span class="o">|</span>    <span class="n">DOC</span><span class="o">|</span>           <span class="mi">69</span><span class="o">|</span>         <span class="mi">85</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2018</span><span class="o">|</span><span class="n">EFFDATE</span><span class="o">|</span> <span class="n">dated_as</span><span class="o">|</span> <span class="mf">0.9856822</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>          <span class="mi">141</span><span class="o">|</span>        <span class="mi">163</span><span class="o">|</span>        <span class="n">Armstrong</span> <span class="n">Flooring</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>  <span class="n">PARTY</span><span class="o">|</span>          <span class="mi">192</span><span class="o">|</span>        <span class="mi">197</span><span class="o">|</span>           <span class="n">Seller</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span><span class="n">has_alias</span><span class="o">|</span><span class="mf">0.89620054</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-------------------------------+-------+-------------+-----------+-----------------+-------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordsEmbedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_ade_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerChunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependencyParser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">adeReNerChunkFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"drug-ade"</span><span class="o">,</span> <span class="s">"ade-drug"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">adeReModel</span> <span class="k">=</span> <span class="nv">RelationExtractionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"redl_ade_biobert"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">,</span> <span class="s">"sentences"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documenter</span><span class="o">,</span>
    <span class="n">sentencer</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">wordsEmbedder</span><span class="o">,</span>
    <span class="n">posTagger</span><span class="o">,</span>
    <span class="n">nerTagger</span><span class="o">,</span>
    <span class="n">nerChunker</span><span class="o">,</span>
    <span class="n">dependencyParser</span><span class="o">,</span>
    <span class="n">adeReNerChunkFilter</span><span class="o">,</span>
    <span class="n">adeReModel</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>   <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>                                                   <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">25</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span> <span class="n">naproxen</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>          <span class="mi">137</span><span class="o">|</span>        <span class="mi">148</span><span class="o">|</span>                                             <span class="n">tense</span> <span class="n">bullae</span><span class="o">|</span>    <span class="nc">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span> <span class="mf">0.9989047</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">25</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span> <span class="n">naproxen</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>          <span class="mi">154</span><span class="o">|</span>        <span class="mi">210</span><span class="o">|</span><span class="n">cutaneous</span> <span class="n">fragility</span> <span class="n">on</span> <span class="n">the</span> <span class="n">face</span> <span class="n">and</span> <span class="n">the</span> <span class="n">back</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hands</span><span class="o">|</span>    <span class="nc">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span> <span class="mf">0.9989704</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">87</span><span class="o">|</span>         <span class="mi">95</span><span class="o">|</span><span class="n">oxaprozin</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>          <span class="mi">137</span><span class="o">|</span>        <span class="mi">148</span><span class="o">|</span>                                             <span class="n">tense</span> <span class="n">bullae</span><span class="o">|</span>    <span class="nc">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span><span class="mf">0.99895453</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">87</span><span class="o">|</span>         <span class="mi">95</span><span class="o">|</span><span class="n">oxaprozin</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>          <span class="mi">154</span><span class="o">|</span>        <span class="mi">210</span><span class="o">|</span><span class="n">cutaneous</span> <span class="n">fragility</span> <span class="n">on</span> <span class="n">the</span> <span class="n">face</span> <span class="n">and</span> <span class="n">the</span> <span class="n">back</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hands</span><span class="o">|</span>    <span class="nc">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span><span class="mf">0.99900633</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">text_splitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextSplitter</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model_date</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_sec_dates"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_dates"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_date</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_dates"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_date"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model_org</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_orgs"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_org</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_orgs"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_org"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk_org"</span><span class="o">,</span> <span class="s">"ner_chunk_date"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ORG-ORG"</span><span class="o">,</span> <span class="s">"ORG-DATE"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reDL</span> <span class="k">=</span> <span class="nv">RelationExtractionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finre_acquisitions_subsidiaries_md"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relation"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">text_splitter</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">ner_model_date</span><span class="o">,</span>
    <span class="n">ner_converter_date</span><span class="o">,</span>
    <span class="n">ner_model_org</span><span class="o">,</span>
    <span class="n">ner_converter_org</span><span class="o">,</span>
    <span class="n">chunk_merger</span><span class="o">,</span>
    <span class="n">pos</span><span class="o">,</span>
    <span class="n">dependency_parser</span><span class="o">,</span>
    <span class="n">re_filter</span><span class="o">,</span>
    <span class="n">reDL</span>
  <span class="o">))</span>

<span class="n">text</span> <span class="k">=</span> <span class="s">"""In fiscal 2020, Cadence acquired all of the outstanding equity of AWR Corporation (“AWR”) and Integrand Software, Inc. (“Integrand”)."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                 <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>         <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>            <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>                <span class="nc">Cadence</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="nc">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span><span class="mf">0.99687237</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span>        <span class="nc">AWR</span> <span class="nc">Corporation</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="nc">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span>  <span class="mf">0.993112</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="nc">Integrand</span> <span class="nc">Software</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="nc">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span> <span class="mf">0.9741451</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span>        <span class="nc">AWR</span> <span class="nc">Corporation</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>        <span class="nc">Cadence</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span>  <span class="mf">0.997124</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="nc">Integrand</span> <span class="nc">Software</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>        <span class="nc">Cadence</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span><span class="mf">0.99910504</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="nc">Integrand</span> <span class="nc">Software</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span><span class="nc">AWR</span> <span class="nc">Corporation</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span><span class="mf">0.93245244</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">text_splitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextSplitter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSentenceLength</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nc">PerceptronModel</span><span class="o">().</span><span class="py">pretrained</span><span class="o">()</span> <span class="o">\</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">sentence</span><span class="err">"</span>, <span class="err">"</span><span class="kt">token</span><span class="err">"</span><span class="o">])\</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nc">DependencyParserModel</span><span class="o">()</span> <span class="o">\</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span> <span class="o">\</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">sentence</span><span class="err">"</span>, <span class="err">"</span><span class="kt">pos_tags</span><span class="err">"</span>, <span class="err">"</span><span class="kt">token</span><span class="err">"</span><span class="o">])</span> <span class="o">\</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()\</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">([</span><span class="err">"</span><span class="kt">ner_chunk</span><span class="err">"</span>, <span class="err">"</span><span class="kt">dependencies</span><span class="err">"</span><span class="o">])\</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)\</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">10</span><span class="o">)\</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">([</span><span class="kt">'PARTY-ALIAS'</span>, <span class="kt">'DOC-PARTY'</span>, <span class="kt">'DOC-EFFDATE'</span><span class="o">])</span>

<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nv">RelationExtractionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legre_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">text_splitter</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">pos_tagger</span><span class="o">,</span>
    <span class="n">dependency_parser</span><span class="o">,</span>
    <span class="n">re_filter</span><span class="o">,</span>
    <span class="n">re_model</span>
  <span class="o">))</span>

<span class="n">text</span> <span class="k">=</span> <span class="s">"""This INTELLECTUAL PROPERTY AGREEMENT (this "Agreement"), dated as of December 31, 2018 (the "Effective Date") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ("Seller") and AFI Licensing LLC, a Delaware limited liability company ("Licensing" and together with Seller, "Arizona") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand, a "Party" and collectively, the "Parties")."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------+-----------+-------------------------------+-------+-------------+-----------+-----------------+-------+---------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                         <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>           <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span> <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-------------------------------+-------+-------------+-----------+-----------------+-------+---------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">5</span><span class="o">|</span>         <span class="mi">35</span><span class="o">|</span><span class="nc">INTELLECTUAL</span> <span class="nc">PROPERTY</span> <span class="nc">AGREEMENT</span><span class="o">|</span>    <span class="nc">DOC</span><span class="o">|</span>           <span class="mi">69</span><span class="o">|</span>         <span class="mi">85</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2018</span><span class="o">|</span><span class="nc">EFFDATE</span><span class="o">|</span> <span class="n">dated_as</span><span class="o">|</span> <span class="mf">0.9856822</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>          <span class="mi">141</span><span class="o">|</span>        <span class="mi">163</span><span class="o">|</span>        <span class="nc">Armstrong</span> <span class="nc">Flooring</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>  <span class="nc">PARTY</span><span class="o">|</span>          <span class="mi">192</span><span class="o">|</span>        <span class="mi">197</span><span class="o">|</span>           <span class="nc">Seller</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span><span class="n">has_alias</span><span class="o">|</span><span class="mf">0.89620054</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-------------------------------+-------+-------------+-----------+-----------------+-------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="reidentification">ReIdentification</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator can reidentifies obfuscated entities by DeIdentification. It requires the outputs from the deidentification as input. Input columns need to be the deidentified document and the deidentification mappings set with <code class="language-plaintext highlighter-rouge">DeIdentification.setMappingsColumn</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT,CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/reIdentification/index.html#sparknlp_jsl.annotator.deid.reIdentification.ReIdentification">ReIdentification</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/ReIdentification.html">ReIdentification</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ReIdentification.ipynb">ReIdentificationNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">deidentification</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"mask"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReturnEntityMappings</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#  return a new column to save the mappings between the mask/obfuscated entities and original entities.
</span>    <span class="c1">#.setMappingsColumn("MappingCol") # change the name of the column, 'aux' is default
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span>
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">word_embeddings</span><span class="p">,</span>
      <span class="n">clinical_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">deidentification</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""
Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson Ora ,
MR # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 .
Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555 .
"""</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">sentence</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> 
                                     <span class="n">result</span><span class="p">.</span><span class="n">deidentified</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span> 
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">sentence</span>                                                               <span class="o">|</span><span class="n">deidentified</span>                                           <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">13</span> <span class="p">,</span> <span class="n">David</span> <span class="n">Hale</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span>                          <span class="o">|</span><span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="o">&lt;</span><span class="n">DATE</span><span class="o">&gt;</span> <span class="p">,</span> <span class="o">&lt;</span><span class="n">NAME</span><span class="o">&gt;</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.</span>                  <span class="o">|</span>
<span class="o">|</span><span class="p">,</span> <span class="n">Name</span> <span class="p">:</span> <span class="n">Hendrickson</span> <span class="n">Ora</span> <span class="p">,</span> <span class="n">MR</span> <span class="c1"># 7194334 Date : 01/13/93 .              |, Name : &lt;NAME&gt; , MR # &lt;ID&gt; Date : &lt;DATE&gt; .            |
</span><span class="o">|</span><span class="n">PCP</span> <span class="p">:</span> <span class="n">Oliveira</span> <span class="p">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2079</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">09</span> <span class="p">.</span>             <span class="o">|</span><span class="n">PCP</span> <span class="p">:</span> <span class="o">&lt;</span><span class="n">NAME</span><span class="o">&gt;</span> <span class="p">,</span> <span class="o">&lt;</span><span class="n">AGE</span><span class="o">&gt;</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="p">,</span> <span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="o">&lt;</span><span class="n">DATE</span><span class="o">&gt;</span> <span class="p">.</span><span class="o">|</span>
<span class="o">|</span><span class="n">Cocke</span> <span class="n">County</span> <span class="n">Baptist</span> <span class="n">Hospital</span> <span class="p">,</span> <span class="mi">0295</span> <span class="n">Keats</span> <span class="n">Street</span> <span class="p">,</span> <span class="n">Phone</span> <span class="mi">55</span><span class="o">-</span><span class="mi">555</span><span class="o">-</span><span class="mi">5555</span> <span class="p">.</span><span class="o">|&lt;</span><span class="n">LOCATION</span><span class="o">&gt;</span> <span class="p">,</span> <span class="o">&lt;</span><span class="n">LOCATION</span><span class="o">&gt;</span> <span class="p">,</span> <span class="n">Phone</span> <span class="o">&lt;</span><span class="n">CONTACT</span><span class="o">&gt;</span> <span class="p">.</span>            <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+</span>

<span class="n">reIdentification</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ReIdentification</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"aux"</span><span class="p">,</span><span class="s">"deidentified"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"original"</span><span class="p">)</span>

<span class="n">reid_result</span> <span class="o">=</span> <span class="n">reIdentification</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="n">reid_result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'original.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                         <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Record</span> <span class="n">date</span> <span class="p">:</span> <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">13</span> <span class="p">,</span> <span class="n">David</span> <span class="n">Hale</span> <span class="p">,</span> <span class="n">M</span><span class="p">.</span><span class="n">D</span> <span class="p">.,</span> <span class="p">,</span> <span class="n">Name</span> <span class="p">:</span> <span class="n">Hendrickson</span> <span class="n">Ora</span> <span class="p">,</span><span class="n">MR</span> <span class="c1"># 7194334 Date : 01/13/93 ., PCP : Oliveira , 25 years-old , Record date : 2079-11-09 ., Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555 .] |
</span><span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finner_sec_10k_summary'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'finance/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">deidentification</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"mask"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReturnEntityMappings</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#  return a new column to save the mappings between the mask/obfuscated entities and original entities. REquired for "ReIdentification"
</span>    <span class="c1">#.setMappingsColumn("MappingCol") # change the name of the column, 'aux' is default
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">ner_model</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">deidentification</span><span class="p">])</span>

<span class="n">text</span><span class="o">=</span> <span class="s">"""
Commission file number 000-15867 
_____________________________________
 
CADENCE DESIGN SYSTEMS, INC. 
(Exact name of registrant as specified in its charter)
____________________________________ 
Delaware
 
00-0000000
(State or Other Jurisdiction ofIncorporation or Organization)
 
(I.R.S. EmployerIdentification No.)
2655 Seely Avenue, Building 5,
San Jose,
California
 
95134
(Address of Principal Executive Offices)
 
(Zip Code)
(408)
-943-1234 
(Registrant’s Telephone Number, including Area Code) 
Securities registered pursuant to Section 12(b) of the Act:
Title of Each Class
Trading Symbol(s)
Names of Each Exchange on which Registered
Common Stock, $0.01 par value per share
CDNS
Nasdaq Global Select Market
Securities registered pursuant to Section 12(g) of the Act:"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"deidentified.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+-------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                       <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Commission</span> <span class="nb">file</span> <span class="n">number</span> <span class="o">&lt;</span><span class="n">CFN</span><span class="o">&gt;</span> 
<span class="n">_____________________________________</span>
 
<span class="o">&lt;</span><span class="n">ORG</span><span class="o">&gt;</span><span class="p">.,</span> <span class="p">(</span><span class="n">Exact</span> <span class="n">name</span> <span class="n">of</span> <span class="n">registrant</span> <span class="k">as</span> <span class="n">specified</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">charter</span><span class="p">)</span>
<span class="n">____________________________________</span> 
<span class="o">&lt;</span><span class="n">STATE</span><span class="o">&gt;</span>
 
<span class="o">&lt;</span><span class="n">IRS</span><span class="o">&gt;</span>
<span class="p">(</span><span class="n">State</span> <span class="ow">or</span> <span class="n">Other</span> <span class="n">Jurisdiction</span> <span class="n">ofIncorporation</span> <span class="ow">or</span> <span class="n">Organization</span><span class="p">)</span>
 
<span class="p">(</span><span class="n">I</span><span class="p">.</span><span class="n">R</span><span class="p">.</span><span class="n">S</span><span class="p">.,</span> <span class="n">EmployerIdentification</span> <span class="n">No</span><span class="p">.,</span> <span class="p">)</span>
<span class="o">&lt;</span><span class="n">ADDRESS</span><span class="o">&gt;</span>
 
<span class="mi">95134</span>
<span class="p">(</span><span class="n">Address</span> <span class="n">of</span> <span class="n">Principal</span> <span class="n">Executive</span> <span class="n">Offices</span><span class="p">)</span>
 
<span class="p">(</span><span class="n">Zip</span> <span class="n">Code</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">PHONE</span><span class="o">&gt;</span> 
<span class="p">(</span><span class="n">Registrant</span><span class="err">’</span><span class="n">s</span> <span class="n">Telephone</span> <span class="n">Number</span><span class="p">,</span> <span class="n">including</span> <span class="n">Area</span> <span class="n">Code</span><span class="p">)</span> 
<span class="n">Securities</span> <span class="n">registered</span> <span class="n">pursuant</span> <span class="n">to</span> <span class="n">Section</span> <span class="mi">12</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Act</span><span class="p">:</span>
<span class="n">Title</span> <span class="n">of</span> <span class="n">Each</span> <span class="n">Class</span>
<span class="n">Trading</span> <span class="n">Symbol</span><span class="p">,</span> <span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">Names</span> <span class="n">of</span> <span class="n">Each</span> <span class="n">Exchange</span> <span class="n">on</span> <span class="n">which</span> <span class="n">Registered</span>
<span class="o">&lt;</span><span class="n">TITLE_CLASS</span><span class="o">&gt;</span><span class="p">,</span> <span class="o">&lt;</span><span class="n">TITLE_CLASS_VALUE</span><span class="o">&gt;</span> <span class="n">par</span> <span class="n">value</span> <span class="n">per</span> <span class="n">share</span>
<span class="o">&lt;</span><span class="n">TICKER</span><span class="o">&gt;</span>
<span class="o">&lt;</span><span class="n">STOCK_EXCHANGE</span><span class="o">&gt;</span>
<span class="n">Securities</span> <span class="n">registered</span> <span class="n">pursuant</span> <span class="n">to</span> <span class="n">Section</span> <span class="mi">12</span><span class="p">,</span> <span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Act</span><span class="p">:]</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------+</span>

<span class="n">reIdentification</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ReIdentification</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"aux"</span><span class="p">,</span><span class="s">"deidentified"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"original"</span><span class="p">)</span>

<span class="n">reid_result</span> <span class="o">=</span> <span class="n">reIdentification</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="n">reid_result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'original.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                             <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Commission</span> <span class="nb">file</span> <span class="n">number</span> <span class="mi">000</span><span class="o">-</span><span class="mi">15867</span> 
<span class="n">_____________________________________</span>
 
<span class="n">CADENCE</span> <span class="n">DESIGN</span> <span class="n">SYSTEMS</span><span class="p">,</span> <span class="n">INC</span><span class="p">.,</span> <span class="p">(</span><span class="n">Exact</span> <span class="n">name</span> <span class="n">of</span> <span class="n">registrant</span> <span class="k">as</span> <span class="n">specified</span> <span class="ow">in</span> <span class="n">its</span> <span class="n">charter</span><span class="p">)</span>
<span class="n">____________________________________</span> 
<span class="n">Delaware</span>
 
<span class="mi">00</span><span class="o">-</span><span class="mi">0000000</span>
<span class="p">(</span><span class="n">State</span> <span class="ow">or</span> <span class="n">Other</span> <span class="n">Jurisdiction</span> <span class="n">ofIncorporation</span> <span class="ow">or</span> <span class="n">Organization</span><span class="p">)</span>
 
<span class="p">(</span><span class="n">I</span><span class="p">.</span><span class="n">R</span><span class="p">.</span><span class="n">S</span><span class="p">.,</span> <span class="n">EmployerIdentification</span> <span class="n">No</span><span class="p">.,</span> <span class="p">)</span>
<span class="mi">2655</span> <span class="n">Seely</span> <span class="n">Avenue</span><span class="p">,</span> <span class="n">Building</span> <span class="mi">5</span><span class="p">,</span>
<span class="n">San</span> <span class="n">Jose</span><span class="p">,</span>
<span class="n">California</span>
 
<span class="mi">95134</span>
<span class="p">(</span><span class="n">Address</span> <span class="n">of</span> <span class="n">Principal</span> <span class="n">Executive</span> <span class="n">Offices</span><span class="p">)</span>
 
<span class="p">(</span><span class="n">Zip</span> <span class="n">Code</span><span class="p">)</span><span class="o">&lt;</span><span class="p">(</span><span class="mi">408</span><span class="p">)</span>
<span class="o">-</span><span class="mi">943</span><span class="o">-</span><span class="mi">1234</span>
<span class="p">(</span><span class="n">Registrant</span><span class="err">’</span><span class="n">s</span> <span class="n">Telephone</span> <span class="n">Number</span><span class="p">,</span> <span class="n">including</span> <span class="n">Area</span> <span class="n">Code</span><span class="p">)</span> 
<span class="n">Securities</span> <span class="n">registered</span> <span class="n">pursuant</span> <span class="n">to</span> <span class="n">Section</span> <span class="mi">12</span><span class="p">,</span> <span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Act</span><span class="p">:</span>
<span class="n">Title</span> <span class="n">of</span> <span class="n">Each</span> <span class="n">Class</span>
<span class="n">Trading</span> <span class="n">Symbol</span><span class="p">,</span> <span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">Names</span> <span class="n">of</span> <span class="n">Each</span> <span class="n">Exchange</span> <span class="n">on</span> <span class="n">which</span> <span class="n">Registered</span>
<span class="n">Common</span> <span class="n">Stock</span><span class="p">,</span> <span class="err">$</span><span class="mf">0.01</span> <span class="n">par</span> <span class="n">value</span> <span class="n">per</span> <span class="n">share</span>
<span class="n">CDNS</span>
<span class="n">Nasdaq</span> <span class="n">Global</span> <span class="n">Select</span> <span class="n">Market</span>
<span class="n">Securities</span> <span class="n">registered</span> <span class="n">pursuant</span> <span class="n">to</span> <span class="n">Section</span> <span class="mi">12</span><span class="p">,</span> <span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="n">of</span> <span class="n">the</span> <span class="n">Act</span><span class="p">:]</span><span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">legal_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties_lg"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span> 

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReplaceLabels</span><span class="p">({</span><span class="s">"ALIAS"</span><span class="p">:</span> <span class="s">"PARTY"</span><span class="p">})</span> <span class="c1"># "ALIAS" are secondary names of companies, so let's extract them also as PARTY
</span>
<span class="n">deidentification</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">DeIdentification</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_chunk"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"deidentified"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setMode</span><span class="p">(</span><span class="s">"mask"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReturnEntityMappings</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> <span class="c1">#  return a new column to save the mappings between the mask/obfuscated entities and original entities. REquired for "ReIdentification"
</span>    <span class="c1">#.setMappingsColumn("MappingCol") # change the name of the column, 'aux' is default
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
      <span class="n">documentAssembler</span><span class="p">,</span> 
      <span class="n">sentenceDetector</span><span class="p">,</span>
      <span class="n">tokenizer</span><span class="p">,</span>
      <span class="n">embeddings</span><span class="p">,</span>
      <span class="n">legal_ner</span><span class="p">,</span>
      <span class="n">ner_converter</span><span class="p">,</span>
      <span class="n">deidentification</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""THIS STRATEGIC ALLIANCE AGREEMENT ("Agreement") is made and entered into as of December 14, 2016 , by and between Hyatt Franchising Latin America, L.L.C. a limited liability company organized and existing under the laws of the State of Delaware"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"deidentified.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">THIS</span> <span class="o">&lt;</span><span class="n">DOC</span><span class="o">&gt;</span> <span class="p">(</span><span class="s">"Agreement"</span><span class="p">)</span> <span class="ow">is</span> <span class="n">made</span> <span class="ow">and</span> <span class="n">entered</span> <span class="n">into</span> <span class="k">as</span> <span class="n">of</span> <span class="o">&lt;</span><span class="n">EFFDATE</span><span class="o">&gt;</span> <span class="p">,</span> <span class="n">by</span> <span class="ow">and</span> <span class="n">between</span> <span class="o">&lt;</span><span class="n">PARTY</span><span class="o">&gt;</span><span class="p">.</span> <span class="n">a</span> <span class="n">limited</span> <span class="n">liability</span> <span class="n">company</span> <span class="n">organized</span> <span class="ow">and</span> <span class="n">existing</span> <span class="n">under</span> <span class="n">the</span> <span class="n">laws</span> <span class="n">of</span> <span class="n">the</span> <span class="n">State</span> <span class="n">of</span> <span class="n">Delaware</span><span class="p">]</span><span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="n">reIdentification</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ReIdentification</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"aux"</span><span class="p">,</span><span class="s">"deidentified"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"original"</span><span class="p">)</span>

<span class="n">reid_result</span> <span class="o">=</span> <span class="n">reIdentification</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="n">reid_result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">'original.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">THIS</span> <span class="n">STRATEGIC</span> <span class="n">ALLIANCE</span> <span class="n">AGREEMENT</span> <span class="p">(</span><span class="s">"Agreement"</span><span class="p">)</span> <span class="ow">is</span> <span class="n">made</span> <span class="ow">and</span> <span class="n">entered</span> <span class="n">into</span> <span class="k">as</span> <span class="n">of</span> <span class="n">December</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">2016</span> <span class="p">,</span> <span class="n">by</span> <span class="ow">and</span> <span class="n">between</span> <span class="n">Hyatt</span> <span class="n">Franchising</span> <span class="n">Latin</span> <span class="n">America</span><span class="p">,</span> <span class="n">L</span><span class="p">.</span><span class="n">L</span><span class="p">.</span><span class="n">C</span><span class="p">.</span> <span class="n">a</span> <span class="n">limited</span> <span class="n">liability</span> <span class="n">company</span> <span class="n">organized</span> <span class="ow">and</span> <span class="n">existing</span> <span class="n">under</span> <span class="n">the</span> <span class="n">laws</span> <span class="n">of</span> <span class="n">the</span> <span class="n">State</span> <span class="n">of</span> <span class="n">Delaware</span><span class="p">]</span><span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordEmbeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinicalNer</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">deidentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deidentified"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"mask"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReturnEntityMappings</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">wordEmbeddings</span><span class="o">,</span>
    <span class="n">clinicalNer</span><span class="o">,</span>
    <span class="n">nerConverter</span><span class="o">,</span>
    <span class="n">deidentification</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""
Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson Ora ,
MR # 7194334 Date : 01/13/93 . PCP : Oliveira , 25 years-old , Record date : 2079-11-09 .
Cocke County Baptist Hospital , 0295 Keats Street , Phone 55-555-5555 .
"""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="n">text</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+</span>
<span class="o">|</span><span class="n">sentence</span>                                                               <span class="o">|</span><span class="n">deidentified</span>                                           <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">13</span> <span class="o">,</span> <span class="nc">David</span> <span class="nc">Hale</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span>                          <span class="o">|</span><span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="kt">&lt;DATE&gt;</span> <span class="o">,</span> <span class="o">&lt;</span><span class="nc">NAME</span><span class="o">&gt;</span> <span class="o">,</span> <span class="nv">M</span><span class="o">.</span><span class="py">D</span> <span class="o">.</span>                  <span class="o">|</span>
<span class="o">|,</span> <span class="nc">Name</span> <span class="k">:</span> <span class="kt">Hendrickson</span> <span class="kt">Ora</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="mi">7194334</span> <span class="nc">Date</span> <span class="k">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">13</span><span class="kt">/</span><span class="err">93</span> <span class="kt">.</span>              <span class="kt">|</span><span class="o">,</span> <span class="nc">Name</span> <span class="k">:</span> <span class="kt">&lt;NAME&gt;</span> <span class="o">,</span> <span class="nc">MR</span> <span class="k">#</span> <span class="o">&lt;</span><span class="nc">ID</span><span class="o">&gt;</span> <span class="nc">Date</span> <span class="k">:</span> <span class="kt">&lt;DATE&gt;</span> <span class="kt">.</span>            <span class="kt">|</span>
<span class="kt">|PCP</span> <span class="kt">:</span> <span class="kt">Oliveira</span> <span class="o">,</span> <span class="mi">25</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">09</span> <span class="kt">.</span>             <span class="kt">|PCP</span> <span class="kt">:</span> <span class="kt">&lt;NAME&gt;</span> <span class="o">,</span> <span class="o">&lt;</span><span class="nc">AGE</span><span class="o">&gt;</span> <span class="n">years</span><span class="o">-</span><span class="n">old</span> <span class="o">,</span> <span class="nc">Record</span> <span class="n">date</span> <span class="k">:</span> <span class="kt">&lt;DATE&gt;</span> <span class="kt">.|</span>
<span class="kt">|Cocke</span> <span class="kt">County</span> <span class="kt">Baptist</span> <span class="kt">Hospital</span> <span class="o">,</span> <span class="mi">0295</span> <span class="nc">Keats</span> <span class="nc">Street</span> <span class="o">,</span> <span class="nc">Phone</span> <span class="mi">55</span><span class="o">-</span><span class="mi">555</span><span class="o">-</span><span class="mi">5555</span> <span class="o">.|&lt;</span><span class="nc">LOCATION</span><span class="o">&gt;</span> <span class="o">,</span> <span class="o">&lt;</span><span class="nc">LOCATION</span><span class="o">&gt;</span> <span class="o">,</span> <span class="nc">Phone</span> <span class="o">&lt;</span><span class="nc">CONTACT</span><span class="o">&gt;</span> <span class="o">.</span>            <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------+-------------------------------------------------------+</span>

<span class="k">val</span> <span class="nv">reIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ReIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"aux"</span><span class="o">,</span> <span class="s">"deidentified"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"original"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reidResult</span> <span class="k">=</span> <span class="nv">reIdentification</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>

<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                         <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Record</span> <span class="kt">date</span> <span class="kt">:</span> <span class="err">2093</span><span class="kt">-</span><span class="err">01</span><span class="kt">-</span><span class="err">13</span> , <span class="kt">David</span> <span class="kt">Hale</span> , <span class="kt">M.D</span> <span class="kt">.</span>, , <span class="kt">Name</span> <span class="kt">:</span> <span class="kt">Hendrickson</span> <span class="kt">Ora</span> ,<span class="kt">MR</span> <span class="k">#</span> <span class="err">7194334</span> <span class="kt">Date</span> <span class="kt">:</span> <span class="err">01</span><span class="kt">/</span><span class="err">13</span><span class="kt">/</span><span class="err">93</span> <span class="kt">.</span>, <span class="kt">PCP</span> <span class="kt">:</span> <span class="kt">Oliveira</span> , <span class="err">25</span> <span class="kt">years-old</span> , <span class="kt">Record</span> <span class="kt">date</span> <span class="kt">:</span> <span class="err">2079</span><span class="kt">-</span><span class="err">11</span><span class="kt">-</span><span class="err">09</span> <span class="kt">.</span>, <span class="kt">Cocke</span> <span class="kt">County</span> <span class="kt">Baptist</span> <span class="kt">Hospital</span> , <span class="err">0295</span> <span class="kt">Keats</span> <span class="kt">Street</span> , <span class="kt">Phone</span> <span class="err">55</span><span class="kt">-</span><span class="err">555</span><span class="kt">-</span><span class="err">5555</span> <span class="kt">.</span><span class="o">]</span> <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_sec_10k_summary"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">deidentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deidentified"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"mask"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReturnEntityMappings</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">nerModel</span><span class="o">,</span>
    <span class="n">nerConverter</span><span class="o">,</span>
    <span class="n">deidentification</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"Commission file number 000-15867 
_____________________________________
 
CADENCE DESIGN SYSTEMS, INC. 
(Exact name of registrant as specified in its charter)
____________________________________ 
Delaware
 
00-0000000
(State or Other Jurisdiction ofIncorporation or Organization)
 
(I.R.S. EmployerIdentification No.)
2655 Seely Avenue, Building 5,
San Jose,
California
 
95134
(Address of Principal Executive Offices)
 
(Zip Code)
(408)
-943-1234 
(Registrant’s Telephone Number, including Area Code) 
Securities registered pursuant to Section 12(b) of the Act:
Title of Each Class
Trading Symbol(s)
Names of Each Exchange on which Registered
Common Stock, $0.01 par value per share
CDNS
Nasdaq Global Select Market
Securities registered pursuant to Section 12(g) of the Act:"</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+-------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                       <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Commission</span> <span class="kt">file</span> <span class="kt">number</span> <span class="kt">&lt;CFN&gt;</span> 
<span class="k">_____________________________________</span>
 
<span class="kt">&lt;ORG&gt;.</span>, <span class="o">(</span><span class="kt">Exact</span> <span class="kt">name</span> <span class="kt">of</span> <span class="kt">registrant</span> <span class="kt">as</span> <span class="kt">specified</span> <span class="kt">in</span> <span class="kt">its</span> <span class="kt">charter</span><span class="o">)</span>
<span class="k">____________________________________</span> 
<span class="kt">&lt;STATE&gt;</span>
 
<span class="kt">&lt;IRS&gt;</span>
<span class="o">(</span><span class="kt">State</span> <span class="kt">or</span> <span class="kt">Other</span> <span class="kt">Jurisdiction</span> <span class="kt">ofIncorporation</span> <span class="kt">or</span> <span class="kt">Organization</span><span class="o">)</span>
 
<span class="o">(</span><span class="kt">I.R.S.</span>, <span class="kt">EmployerIdentification</span> <span class="kt">No.</span>, <span class="o">)</span>
<span class="kt">&lt;ADDRESS&gt;</span>
 
<span class="err">95134</span>
<span class="o">(</span><span class="kt">Address</span> <span class="kt">of</span> <span class="kt">Principal</span> <span class="kt">Executive</span> <span class="kt">Offices</span><span class="o">)</span>
 
<span class="o">(</span><span class="kt">Zip</span> <span class="kt">Code</span><span class="o">)</span>
<span class="kt">&lt;PHONE&gt;</span> 
<span class="o">(</span><span class="kt">Registrant</span><span class="err">’</span><span class="kt">s</span> <span class="kt">Telephone</span> <span class="kt">Number</span>, <span class="kt">including</span> <span class="kt">Area</span> <span class="kt">Code</span><span class="o">)</span> 
<span class="kt">Securities</span> <span class="kt">registered</span> <span class="kt">pursuant</span> <span class="kt">to</span> <span class="kt">Section</span> <span class="err">12</span>, <span class="o">(</span><span class="kt">b</span><span class="o">)</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">Act:</span>
<span class="kt">Title</span> <span class="kt">of</span> <span class="kt">Each</span> <span class="kt">Class</span>
<span class="kt">Trading</span> <span class="kt">Symbol</span>, <span class="o">(</span><span class="kt">s</span><span class="o">)</span>
<span class="kt">Names</span> <span class="kt">of</span> <span class="kt">Each</span> <span class="kt">Exchange</span> <span class="kt">on</span> <span class="kt">which</span> <span class="kt">Registered</span>
<span class="kt">&lt;TITLE_CLASS&gt;</span>, <span class="kt">&lt;TITLE_CLASS_VALUE&gt;</span> <span class="kt">par</span> <span class="kt">value</span> <span class="kt">per</span> <span class="kt">share</span>
<span class="kt">&lt;TICKER&gt;</span>
<span class="kt">&lt;STOCK_EXCHANGE&gt;</span>
<span class="kt">Securities</span> <span class="kt">registered</span> <span class="kt">pursuant</span> <span class="kt">to</span> <span class="kt">Section</span> <span class="err">12</span>, <span class="o">(</span><span class="kt">g</span><span class="o">)</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">Act:</span><span class="o">]|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------+</span>

<span class="k">val</span> <span class="nv">reIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ReIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"aux"</span><span class="o">,</span> <span class="s">"deidentified"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"original"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reidResult</span> <span class="k">=</span> <span class="nv">reIdentification</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result</span><span class="o">)</span>

<span class="o">+---------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                             <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Commission</span> <span class="kt">file</span> <span class="kt">number</span> <span class="err">000</span><span class="kt">-</span><span class="err">15867</span> 
<span class="k">_____________________________________</span>
 
<span class="kt">CADENCE</span> <span class="kt">DESIGN</span> <span class="kt">SYSTEMS</span>, <span class="kt">INC.</span>, <span class="o">(</span><span class="kt">Exact</span> <span class="kt">name</span> <span class="kt">of</span> <span class="kt">registrant</span> <span class="kt">as</span> <span class="kt">specified</span> <span class="kt">in</span> <span class="kt">its</span> <span class="kt">charter</span><span class="o">)</span>
<span class="k">____________________________________</span> 
<span class="kt">Delaware</span>
 
<span class="err">00</span><span class="kt">-</span><span class="err">0000000</span>
<span class="o">(</span><span class="kt">State</span> <span class="kt">or</span> <span class="kt">Other</span> <span class="kt">Jurisdiction</span> <span class="kt">ofIncorporation</span> <span class="kt">or</span> <span class="kt">Organization</span><span class="o">)</span>
 
<span class="o">(</span><span class="kt">I.R.S.</span>, <span class="kt">EmployerIdentification</span> <span class="kt">No.</span>, <span class="o">)</span>
<span class="err">2655</span> <span class="kt">Seely</span> <span class="kt">Avenue</span>, <span class="kt">Building</span> <span class="err">5</span>,
<span class="kt">San</span> <span class="kt">Jose</span>,
<span class="kt">California</span>
 
<span class="err">95134</span>
<span class="o">(</span><span class="kt">Address</span> <span class="kt">of</span> <span class="kt">Principal</span> <span class="kt">Executive</span> <span class="kt">Offices</span><span class="o">)</span>
 
<span class="o">(</span><span class="kt">Zip</span> <span class="kt">Code</span><span class="o">)</span><span class="kt">&lt;</span><span class="o">(</span><span class="err">408</span><span class="o">)</span>
<span class="kt">-</span><span class="err">943</span><span class="kt">-</span><span class="err">1234</span>
<span class="o">(</span><span class="kt">Registrant</span><span class="err">’</span><span class="kt">s</span> <span class="kt">Telephone</span> <span class="kt">Number</span>, <span class="kt">including</span> <span class="kt">Area</span> <span class="kt">Code</span><span class="o">)</span> 
<span class="kt">Securities</span> <span class="kt">registered</span> <span class="kt">pursuant</span> <span class="kt">to</span> <span class="kt">Section</span> <span class="err">12</span>, <span class="o">(</span><span class="kt">b</span><span class="o">)</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">Act:</span>
<span class="kt">Title</span> <span class="kt">of</span> <span class="kt">Each</span> <span class="kt">Class</span>
<span class="kt">Trading</span> <span class="kt">Symbol</span>, <span class="o">(</span><span class="kt">s</span><span class="o">)</span>
<span class="kt">Names</span> <span class="kt">of</span> <span class="kt">Each</span> <span class="kt">Exchange</span> <span class="kt">on</span> <span class="kt">which</span> <span class="kt">Registered</span>
<span class="kt">Common</span> <span class="kt">Stock</span>, <span class="kt">$0.</span><span class="err">01</span> <span class="kt">par</span> <span class="kt">value</span> <span class="kt">per</span> <span class="kt">share</span>
<span class="kt">CDNS</span>
<span class="kt">Nasdaq</span> <span class="kt">Global</span> <span class="kt">Select</span> <span class="kt">Market</span>
<span class="kt">Securities</span> <span class="kt">registered</span> <span class="kt">pursuant</span> <span class="kt">to</span> <span class="kt">Section</span> <span class="err">12</span>, <span class="o">(</span><span class="kt">g</span><span class="o">)</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">Act:</span><span class="o">]|</span>
<span class="o">+---------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">legalNer</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties_lg"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReplaceLabels</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">"ALIAS"</span> <span class="o">-&gt;</span> <span class="s">"PARTY"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">deidentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DeIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_chunk"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"deidentified"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMode</span><span class="o">(</span><span class="s">"mask"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReturnEntityMappings</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">legalNer</span><span class="o">,</span>
    <span class="n">nerConverter</span><span class="o">,</span>
    <span class="n">deidentification</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"THIS STRATEGIC ALLIANCE AGREEMENT (\"Agreement\") is made and entered into as of December 14, 2016, by and between Hyatt Franchising Latin America, L.L.C. a limited liability company organized and existing under the laws of the State of Delaware"</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                  <span class="o">|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">THIS</span> <span class="kt">&lt;DOC&gt;</span> <span class="o">(</span><span class="err">"</span><span class="kt">Agreement</span><span class="err">"</span><span class="o">)</span> <span class="kt">is</span> <span class="kt">made</span> <span class="kt">and</span> <span class="kt">entered</span> <span class="kt">into</span> <span class="kt">as</span> <span class="kt">of</span> <span class="kt">&lt;EFFDATE&gt;</span> , <span class="kt">by</span> <span class="kt">and</span> <span class="kt">between</span> <span class="kt">&lt;PARTY&gt;.</span> <span class="kt">a</span> <span class="kt">limited</span> <span class="kt">liability</span> <span class="kt">company</span> <span class="kt">organized</span> <span class="kt">and</span> <span class="kt">existing</span> <span class="kt">under</span> <span class="kt">the</span> <span class="kt">laws</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">State</span> <span class="kt">of</span> <span class="kt">Delaware</span><span class="o">]|</span>
<span class="o">+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="k">val</span> <span class="nv">reIdentification</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ReIdentification</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"aux"</span><span class="o">,</span> <span class="s">"deidentified"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"original"</span><span class="o">)</span>



<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                <span class="o">|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">THIS</span> <span class="kt">STRATEGIC</span> <span class="kt">ALLIANCE</span> <span class="kt">AGREEMENT</span> <span class="o">(</span><span class="err">"</span><span class="kt">Agreement</span><span class="err">"</span><span class="o">)</span> <span class="kt">is</span> <span class="kt">made</span> <span class="kt">and</span> <span class="kt">entered</span> <span class="kt">into</span> <span class="kt">as</span> <span class="kt">of</span> <span class="kt">December</span> <span class="err">14</span>, <span class="err">2016</span> , <span class="kt">by</span> <span class="kt">and</span> <span class="kt">between</span> <span class="kt">Hyatt</span> <span class="kt">Franchising</span> <span class="kt">Latin</span> <span class="kt">America</span>, <span class="kt">L.L.C.</span> <span class="kt">a</span> <span class="kt">limited</span> <span class="kt">liability</span> <span class="kt">company</span> <span class="kt">organized</span> <span class="kt">and</span> <span class="kt">existing</span> <span class="kt">under</span> <span class="kt">the</span> <span class="kt">laws</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">State</span> <span class="kt">of</span> <span class="kt">Delaware</span><span class="o">]|</span>
<span class="o">+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="regexmatcherinternal">RegexMatcherInternal</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The <strong><code class="language-plaintext highlighter-rouge">RegexMatcherInternal</code></strong> class implements an internal annotator approach to match a set of regular expressions with a provided entity. This approach is utilized for associating specific patterns within text data with predetermined entities, such as dates, mentioned within the text.</p>

    <p>The class allows users to define rules using regular expressions paired with entities, offering flexibility in customization. These rules can either be directly set using the <code class="language-plaintext highlighter-rouge">setRules</code> method, with a specified delimiter, or loaded from an external file using the <code class="language-plaintext highlighter-rouge">setExternalRules</code> method.</p>

    <p>Additionally, users can specify parameters such as the matching strategy (<code class="language-plaintext highlighter-rouge">MATCH_FIRST</code>, <code class="language-plaintext highlighter-rouge">MATCH_ALL</code>, or <code class="language-plaintext highlighter-rouge">MATCH_COMPLETE</code>) to control how matches are handled. The output annotation type is <code class="language-plaintext highlighter-rouge">CHUNK</code>, with input annotation types supporting <code class="language-plaintext highlighter-rouge">DOCUMENT</code>. This class provides a versatile tool for implementing entity recognition based on user-defined patterns within text data.</p>

    <p>A rule consists of a regex pattern and an identifier, delimited by a character of choice. An example could be <code class="language-plaintext highlighter-rouge">"\\d{4}\\/\\d\\d\\/\\d\\d,date"</code> which will match strings like <code class="language-plaintext highlighter-rouge">"1970/01/01"</code> to the identifier <code class="language-plaintext highlighter-rouge">"date"</code>.</p>

    <p>Parametres:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">strategy</code>: Can be either <code class="language-plaintext highlighter-rouge">MATCH_FIRST</code>, <code class="language-plaintext highlighter-rouge">MATCH_ALL</code>, <code class="language-plaintext highlighter-rouge">MATCH_COMPLETE</code>, by default <code class="language-plaintext highlighter-rouge">MATCH_ALL</code>.</li>
      <li><code class="language-plaintext highlighter-rouge">rules</code>: Regex rules to match the identifier with.</li>
      <li><code class="language-plaintext highlighter-rouge">delimiter</code>: Delimiter for rules provided with setRules.</li>
      <li><code class="language-plaintext highlighter-rouge">externalRules</code>: external resource to rules, needs <code class="language-plaintext highlighter-rouge">delimiter</code> in options.</li>
    </ul>

    <p>See <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/40.Rule_Based_Entity_Matchers.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/regex/regex_matcher/index.html">RegexMatcherInternal</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/regex/RegexMatcherInternalModel.html">RegexMatcherInternal</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""Name : Hendrickson, Ora, Record date: 2093-01-13, MR #719435.
Dr. John Green, ID: 1231511863, IP 203.120.223.13
He is a 60-year-old male was admitted to the Day Hospital for cystectomy on 01/13/93
Patient's VIN : 1HGBH41JXMN109286, SSN #333-44-6666, Driver's license no: A334455B.
Phone (302) 786-5227, 0295 Keats Street, San Francisco, E-MAIL: smith@gmail.com."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">rules</span> <span class="o">=</span> <span class="s">'''
(\d{1,3}\.){3}\d{1,3}~IPADDR
\d{4}-\d{2}-\d{2}|\d{2}/\d{2}/\d{2}|\d{2}/\d{2}/\d{2}~DATE
'''</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'./rules/regex_rules.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">rules</span><span class="p">)</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">regex_matcher_internal</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RegexMatcherInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStrategy</span><span class="p">(</span><span class="s">"MATCH_ALL"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"regex_matches"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setExternalRules</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s">'./rules/regex_rules.txt'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">'~'</span><span class="p">)</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">regex_matcher_internal</span>
<span class="p">])</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># result
</span><span class="o">+--------------+-----+---+---------+</span>
<span class="o">|</span>  <span class="n">regex_result</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+--------------+-----+---+---------+</span>
<span class="o">|</span>    <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">13</span><span class="o">|</span>   <span class="mi">38</span><span class="o">|</span> <span class="mi">47</span><span class="o">|</span>     <span class="n">DATE</span><span class="o">|</span>
<span class="o">|</span><span class="mf">203.120</span><span class="p">.</span><span class="mf">223.13</span><span class="o">|</span>   <span class="mi">97</span><span class="o">|</span><span class="mi">110</span><span class="o">|</span>   <span class="n">IPADDR</span><span class="o">|</span>
<span class="o">|</span>      <span class="mi">01</span><span class="o">/</span><span class="mi">13</span><span class="o">/</span><span class="mi">93</span><span class="o">|</span>  <span class="mi">188</span><span class="o">|</span><span class="mi">195</span><span class="o">|</span>     <span class="n">DATE</span><span class="o">|</span>
<span class="o">+--------------+-----+---+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">//rules = '''</span>
<span class="c1">//(\d{1,3}\.){3}\d{1,3}~IPADDR</span>
<span class="c1">//\d{4}-\d{2}-\d{2}|\d{2}/\d{2}/\d{2}|\d{2}/\d{2}/\d{2}~DATE</span>
<span class="c1">//'''</span>
<span class="c1">//</span>
<span class="c1">//with open('./rules/regex_rules.txt', 'w') as f:</span>
<span class="c1">//    f.write(rules)</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""Name : Hendrickson, Ora, Record date: 2093-01-13, MR #719435.
  |Dr. John Green, ID: 1231511863, IP 203.120.223.13
  |He is a 60-year-old male was admitted to the Day Hospital for cystectomy on 01/13/93
  |Patient's VIN : 1HGBH41JXMN109286, SSN #333-44-6666, Driver's license no: A334455B.
  |Phone (302) 786-5227, 0295 Keats Street, San Francisco, E-MAIL: smith@gmail.com."""</span><span class="o">.</span><span class="py">stripMargin</span>

<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">regexMatcher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RegexMatcher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStrategy</span><span class="o">(</span><span class="s">"MATCH_ALL"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"regex_matches"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setExternalRulesPath</span><span class="o">(</span><span class="s">"./rules/regex_rules.txt"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDelimiter</span><span class="o">(</span><span class="s">"~"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">regexMatcher</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">nlpPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">#</span> <span class="n">result</span>
<span class="o">+--------------+-----+---+---------+</span>
<span class="o">|</span>  <span class="n">regex_result</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">ner_label</span><span class="o">|</span>
<span class="o">+--------------+-----+---+---------+</span>
<span class="o">|</span>    <span class="mi">2093</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">13</span><span class="o">|</span>   <span class="mi">38</span><span class="o">|</span> <span class="mi">47</span><span class="o">|</span>     <span class="nc">DATE</span><span class="o">|</span>
<span class="o">|</span><span class="mf">203.120</span><span class="o">.</span><span class="mf">223.13</span><span class="o">|</span>   <span class="mi">97</span><span class="o">|</span><span class="mi">110</span><span class="o">|</span>   <span class="nc">IPADDR</span><span class="o">|</span>
<span class="o">|</span>      <span class="mi">01</span><span class="o">/</span><span class="mi">13</span><span class="o">/</span><span class="mi">93</span><span class="o">|</span>  <span class="mi">188</span><span class="o">|</span><span class="mi">195</span><span class="o">|</span>     <span class="nc">DATE</span><span class="o">|</span>
<span class="o">+--------------+-----+---+---------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="relationextraction">RelationExtraction</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Extracts and classifies instances of relations between named entities.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">predictionThreshold</code> <em>(Float)</em>: Sets minimal activation of the target unit to encode a new relation instance.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">relationPairs</code> <em>(List[Str])</em>: List of dash-separated pairs of named entities. For example, [“Biomarker-RelativeDay”] will process all relations between entities of type “Biomarker” and “RelativeDay”.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">relationPairsCaseSensitive</code> <em>(Bool)</em>: Determines whether relation pairs are case sensitive.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">relationTypePerPair</code> <em>dict[str, list[str]]</em>: List of entity pairs per relations which limit the entities can form a relation. For example, {“CAUSE”: [“PROBLEM”, “SYMPTOM”]} which only let a “CAUSE” relation to hold between a problem (“PROBLEM) and a symptom (“SYMTOM”).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxSyntacticDistance</code> <em>(Int)</em>: Maximal syntactic distance, as threshold (Default: 0). Determine how far the “from entity” can be from the “to entity” in the text. Increasing this value will increase recall, but also increase the number of false positives.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">customLabels</code> <em>(dict[str, str])</em>: Custom relation labels.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">multiClass</code> <em>(Bool)</em>: If multiClass is set, the model will return all the labels with corresponding scores (Default: False)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">DoExceptionHandling</code>: If it is set as True, the annotator tries to process as usual and ff exception-causing data (e.g. corrupted record/ document) is passed to the annotator, an exception warning is emitted which has the exception message.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">scopeWindow</code> (IntArrayParam) The scope window of feature generation for relations. Given scope window list must contain two integers.</p>
      </li>
    </ul>

    <p>For pretrained models please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Relation+Extraction">Models Hub</a> for available models.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_extraction/index.html#sparknlp_jsl.annotator.re.relation_extraction.RelationExtractionModel">RelationExtractionModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionModel.html">RelationExtractionModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/RelationExtractionModel.ipynb">RelationExtractionModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">reModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"posology_re"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">words_embedder</span><span class="p">,</span>
    <span class="n">pos_tagger</span><span class="p">,</span>
    <span class="n">ner_tagger</span><span class="p">,</span>
    <span class="n">ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">reModel</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""
The patient was prescribed 1 unit of Advil for 5 days after meals. The patient was also
given 1 unit of Metformin daily.
He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night ,
12 units of insulin lispro with meals , and metformin 1000 mg two times a day.
"""</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Show results
</span><span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span>
                              <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                              <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
<span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relations"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
<span class="o">|</span><span class="n">chunk1</span>   <span class="o">|</span><span class="n">chunk2</span>          <span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2</span>  <span class="o">|</span><span class="n">relations</span>     <span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
<span class="o">|</span><span class="mi">1</span> <span class="n">unit</span>   <span class="o">|</span><span class="n">Advil</span>           <span class="o">|</span><span class="n">DOSAGE</span> <span class="o">|</span><span class="n">DRUG</span>     <span class="o">|</span><span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">Advil</span>    <span class="o">|</span><span class="k">for</span> <span class="mi">5</span> <span class="n">days</span>      <span class="o">|</span><span class="n">DRUG</span>   <span class="o">|</span><span class="n">DURATION</span> <span class="o">|</span><span class="n">DRUG</span><span class="o">-</span><span class="n">DURATION</span> <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">1</span> <span class="n">unit</span>   <span class="o">|</span><span class="n">Metformin</span>       <span class="o">|</span><span class="n">DOSAGE</span> <span class="o">|</span><span class="n">DRUG</span>     <span class="o">|</span><span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="n">Metformin</span><span class="o">|</span><span class="n">daily</span>           <span class="o">|</span><span class="n">DRUG</span>   <span class="o">|</span><span class="n">FREQUENCY</span><span class="o">|</span><span class="n">DRUG</span><span class="o">-</span><span class="n">FREQUENCY</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">40</span> <span class="n">units</span> <span class="o">|</span><span class="n">insulin</span> <span class="n">glargine</span><span class="o">|</span><span class="n">DOSAGE</span> <span class="o">|</span><span class="n">DRUG</span>     <span class="o">|</span><span class="n">DOSAGE</span><span class="o">-</span><span class="n">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">words_embedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pos_tagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_tagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_chunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">,</span><span class="s">"ner_tags"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span><span class="s">"pos_tags"</span><span class="o">,</span><span class="s">"tokens"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">reModel</span> <span class="k">=</span> <span class="nv">RelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"posology_re"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span><span class="s">"pos_tags"</span><span class="o">,</span><span class="s">"ner_chunks"</span><span class="o">,</span><span class="s">"dependencies"</span><span class="o">))</span> 
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span> 
    <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                             <span class="n">documenter</span><span class="o">,</span> 
                                             <span class="n">sentencer</span><span class="o">,</span> 
                                             <span class="n">tokenizer</span><span class="o">,</span>
                                             <span class="n">words_embedder</span><span class="o">,</span> 
                                             <span class="n">pos_tagger</span><span class="o">,</span> 
                                             <span class="n">ner_tagger</span><span class="o">,</span> 
                                             <span class="n">ner_chunker</span><span class="o">,</span> 
                                             <span class="n">dependency_parser</span><span class="o">,</span> 
                                             <span class="n">reModel</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">" The patient was prescribed 1 unit of Advil for 5 days after meals. The patient was also given 1 unit of Metformin daily. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals ,and metformin 1000 mg two times a day. "</span> 

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> <span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// Show results</span>

<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
<span class="o">|</span><span class="n">chunk1</span>   <span class="o">|</span><span class="n">chunk2</span>          <span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2</span>  <span class="o">|</span><span class="n">relations</span>     <span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
<span class="o">|</span><span class="mi">1</span> <span class="n">unit</span>   <span class="o">|</span><span class="nc">Advil</span>           <span class="o">|</span><span class="nc">DOSAGE</span> <span class="o">|</span><span class="nc">DRUG</span>     <span class="o">|</span><span class="nc">DOSAGE</span><span class="o">-</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">Advil</span>    <span class="o">|</span><span class="k">for</span> <span class="mi">5</span> <span class="n">days</span>      <span class="o">|</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="nc">DURATION</span> <span class="o">|</span><span class="nc">DRUG</span><span class="o">-</span><span class="nc">DURATION</span> <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">1</span> <span class="n">unit</span>   <span class="o">|</span><span class="nc">Metformin</span>       <span class="o">|</span><span class="nc">DOSAGE</span> <span class="o">|</span><span class="nc">DRUG</span>     <span class="o">|</span><span class="nc">DOSAGE</span><span class="o">-</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="nc">Metformin</span><span class="o">|</span><span class="n">daily</span>           <span class="o">|</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="nc">FREQUENCY</span><span class="o">|</span><span class="nc">DRUG</span><span class="o">-</span><span class="nc">FREQUENCY</span><span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">|</span><span class="mi">40</span> <span class="n">units</span> <span class="o">|</span><span class="n">insulin</span> <span class="n">glargine</span><span class="o">|</span><span class="nc">DOSAGE</span> <span class="o">|</span><span class="nc">DRUG</span>     <span class="o">|</span><span class="nc">DOSAGE</span><span class="o">-</span><span class="nc">DRUG</span>   <span class="o">|</span><span class="mf">1.0</span>       <span class="o">|</span>
<span class="o">+---------+----------------+-------+---------+--------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Trains a TensorFlow model for relation extraction.</p>

    <p>To train a custom relation extraction model, you need to first creat a Tensorflow graph using either the <code class="language-plaintext highlighter-rouge">TfGraphBuilder</code> annotator or the <code class="language-plaintext highlighter-rouge">tf_graph</code> module. Then, set the path to the Tensorflow graph using the method <code class="language-plaintext highlighter-rouge">.setModelFile("path/to/tensorflow_graph.pb")</code>.</p>

    <p>If the parameter <code class="language-plaintext highlighter-rouge">relationDirectionCol</code> is set, the model will be trained using the direction information (see the parameter decription for details). Otherwise, the model won’t have direction between the relation of the entities.</p>

    <p>After training a model (using the <code class="language-plaintext highlighter-rouge">.fit()</code> method), the resulting object is of class <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code>.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">FromEntity</code>: (begin_col: str, end_col: str, label_col: str) Sets from entity</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">begin_col</code> Column that has a reference of where the chunk begins</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">end_col</code>: Column that has a reference of where the chunk ends</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">label_col</code>: Column that has a reference what are the type of chunk</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ToEntity</code>: (begin_col: str, end_col: str, label_col: str) Sets to entity</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">begin_col</code> Column that has a reference of where the chunk begins</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">end_col</code>: Column that has a reference of where the chunk ends</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">label_col</code>: Column that has a reference what are the type of chunk</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">CustomLabels</code>: (labels: dict[str, str]) Sets custom relation labels</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">labels</code>: Dictionary which maps old to new labels</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">RelationDirectionCol</code>: (col: str) Relation direction column (possible values are: “none”, “left” or “right”). If this parameter is not set, the model will not have direction between the relation of the entities</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">col</code> Column contains the relation direction values</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">PretrainedModelPath</code> (value: str) Path to an already trained model saved to disk, which is used as a starting point for training the new model</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ОverrideExistingLabels</code> (bool) Whether to override already learned labels when using a pretrained model to initialize the new model. Default is ‘true’</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">batchSize</code>: (Int) Size for each batch in the optimization process</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">EpochsNumber</code> (Int) Maximum number of epochs to train</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">Dropout</code>: (Float) Dropout at the output of each layer</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">LearningRate</code>: (Float) Learning rate for the optimization process</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">OutputLogsPath</code>: (Str) Folder path to save training logs. If no path is specified, the logs won’t be stored in disk. The path can be a local file path, a distributed file path (HDFS, DBFS), or a cloud storage (S3).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ModelFile</code>: (Str) The path to the Tensorflow graph</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">FixImbalance</code> (Float) Fix the imbalance in the training set by replicating examples of under represented categories</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ValidationSplit</code> (Float) The proportion of training dataset to be used as validation set</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">OverrideExistingLabels</code> (Boolean) Controls whether to override already learned lebels when using a pretrained model to initialize the new model. A value of true will override existing labels</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">MultiClass</code> (Boolean) If multiClass is set, the model will return all the labels with corresponding scores. By default, multiClass is false.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ModelFile</code> (Str) Location of file of the model used for classification</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">MaxSyntacticDistance</code> (Int) Maximal syntactic distance, as threshold (Default: 0)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">directionSensitive</code> (Boolean) Specify direction sensitivity in processing relation pairs</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">filterByTokenDistance</code> (Int) Filtering criterion based on number of token between entities</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">scopeWindow</code> (IntArrayParam) The scope window of feature generation for relations. Given scope window list must contain two integers.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NONE</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_extraction/index.html#sparknlp_jsl.annotator.re.relation_extraction.RelationExtractionApproach">RelationExtractionApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionApproach.html">RelationExtractionApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/Healthcare_MOOC/Spark_NLP_Udemy_MOOC/Healthcare_NLP/RelationExtractionApproach.ipynb">RelationExtractionApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="c1"># Defining pipeline stages to extract entities first
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">posTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"posTags"</span><span class="p">)</span>

<span class="n">nerTagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">MedicalNerModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_events_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">nerConverter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"nerChunks"</span><span class="p">)</span>

<span class="n">depencyParser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span> \
  <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"posTags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="c1"># Then define `RelationExtractionApproach` and training parameters
</span><span class="n">re</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"embeddings"</span><span class="p">,</span> <span class="s">"posTags"</span><span class="p">,</span> <span class="s">"train_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations_t"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"target_rel"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setEpochsNumber</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setBatchSize</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLearningRate</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setModelFile</span><span class="p">(</span><span class="s">"path/to/graph_file.pb"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFixImbalance</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValidationSplit</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setFromEntity</span><span class="p">(</span><span class="s">"from_begin"</span><span class="p">,</span> <span class="s">"from_end"</span><span class="p">,</span> <span class="s">"from_label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setToEntity</span><span class="p">(</span><span class="s">"to_begin"</span><span class="p">,</span> <span class="s">"to_end"</span><span class="p">,</span> <span class="s">"to_label"</span><span class="p">)</span>

<span class="n">finisher</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Finisher</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"relations_t"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCols</span><span class="p">([</span><span class="s">"relations"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setValueSplitSymbol</span><span class="p">(</span><span class="s">","</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setAnnotationSplitSymbol</span><span class="p">(</span><span class="s">","</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputAsArray</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Define complete pipeline and start training
</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embedder</span><span class="p">,</span>
    <span class="n">posTagger</span><span class="p">,</span>
    <span class="n">nerTagger</span><span class="p">,</span>
    <span class="n">nerConverter</span><span class="p">,</span>
    <span class="n">depencyParser</span><span class="p">,</span>
    <span class="n">re</span><span class="p">,</span>
    <span class="n">finisher</span><span class="p">])</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainData</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Defining pipeline stages to extract entities first</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embedder</span> <span class="k">=</span> <span class="nc">WordEmbeddingsModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nc">PerceptronModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"posTags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nc">MedicalNerModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_events_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"nerChunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">depencyParser</span> <span class="k">=</span> <span class="nc">DependencyParserModel</span>
  <span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"posTags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="c1">// Then define `RelationExtractionApproach` and training parameters</span>
<span class="k">val</span> <span class="nv">re</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RelationExtractionApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">,</span> <span class="s">"posTags"</span><span class="o">,</span> <span class="s">"train_ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations_t"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelColumn</span><span class="o">(</span><span class="s">"target_rel"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEpochsNumber</span><span class="o">(</span><span class="mi">300</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setBatchSize</span><span class="o">(</span><span class="mi">200</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setlearningRate</span><span class="o">(</span><span class="mf">0.001f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setModelFile</span><span class="o">(</span><span class="s">"path/to/graph_file.pb"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFixImbalance</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValidationSplit</span><span class="o">(</span><span class="mf">0.05f</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setFromEntity</span><span class="o">(</span><span class="s">"from_begin"</span><span class="o">,</span> <span class="s">"from_end"</span><span class="o">,</span> <span class="s">"from_label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setToEntity</span><span class="o">(</span><span class="s">"to_begin"</span><span class="o">,</span> <span class="s">"to_end"</span><span class="o">,</span> <span class="s">"to_label"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">finisher</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Finisher</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"relations_t"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"relations"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setValueSplitSymbol</span><span class="o">(</span><span class="s">","</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setAnnotationSplitSymbol</span><span class="o">(</span><span class="s">","</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsArray</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Define complete pipeline and start training</span>
<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embedder</span><span class="o">,</span>
    <span class="n">posTagger</span><span class="o">,</span>
    <span class="n">nerTagger</span><span class="o">,</span>
    <span class="n">nerConverter</span><span class="o">,</span>
    <span class="n">depencyParser</span><span class="o">,</span>
    <span class="n">re</span><span class="o">,</span>
    <span class="n">finisher</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">model</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">trainData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="relationextractiondl">RelationExtractionDL</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This Relation Extraction annotator extracts and classifies instances of relations between named entities. In contrast with <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code>, <code class="language-plaintext highlighter-rouge">RelationExtractionDLModel</code> is based on BERT.</p>

    <p>Parametres:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">predictionThreshold</code> <em>(Float)</em>: Sets minimal activation of the target unit to encode a new relation instance.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">customLabels</code> <em>(dict[str, str])</em>: Custom relation labels.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">DoExceptionHandling</code>: If it is set as True, the annotator tries to process as usual and ff exception-causing data (e.g. corrupted record/ document) is passed to the annotator, an exception warning is emitted which has the exception message.</p>
      </li>
    </ul>

    <p>Available models can be found at the <a href="https://nlp.johnsnowlabs.com/models?task=Relation+Extraction">Models Hub</a>.</p>

    <p>For more extended examples on document pre-processing see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop">Spark NLP Workshop</a></p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/relation_extraction_dl/index.html#sparknlp_jsl.annotator.re.relation_extraction_dl.RelationExtractionDLModel">RelationExtractionDLModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/re/RelationExtractionDLModel.html">RelationExtractionDLModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/RelationExtractionDLModel.ipynb">RelationExtractionDLModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">ner_tagger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_ade_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_tags"</span><span class="p">)</span>

<span class="n">ner_chunker</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner_tags"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunks"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">ade_re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"drug-ade, ade-drug"</span><span class="p">])</span>

<span class="n">ade_re_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'redl_ade_biobert'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunks"</span><span class="p">,</span> <span class="s">"sentences"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documenter</span><span class="p">,</span>
    <span class="n">sentencer</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">words_embedder</span><span class="p">,</span>
    <span class="n">pos_tagger</span><span class="p">,</span>
    <span class="n">ner_tagger</span><span class="p">,</span>
    <span class="n">ner_chunker</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">ade_re_ner_chunk_filter</span><span class="p">,</span>
    <span class="n">ade_re_model</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">results</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">results</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>   <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>                                                   <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">25</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span> <span class="n">naproxen</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>          <span class="mi">137</span><span class="o">|</span>        <span class="mi">148</span><span class="o">|</span>                                             <span class="n">tense</span> <span class="n">bullae</span><span class="o">|</span>    <span class="n">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span> <span class="mf">0.9989047</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">25</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span> <span class="n">naproxen</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>          <span class="mi">154</span><span class="o">|</span>        <span class="mi">210</span><span class="o">|</span><span class="n">cutaneous</span> <span class="n">fragility</span> <span class="n">on</span> <span class="n">the</span> <span class="n">face</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">back</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hands</span><span class="o">|</span>    <span class="n">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span> <span class="mf">0.9989704</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">87</span><span class="o">|</span>         <span class="mi">95</span><span class="o">|</span><span class="n">oxaprozin</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>          <span class="mi">137</span><span class="o">|</span>        <span class="mi">148</span><span class="o">|</span>                                             <span class="n">tense</span> <span class="n">bullae</span><span class="o">|</span>    <span class="n">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span><span class="mf">0.99895453</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">87</span><span class="o">|</span>         <span class="mi">95</span><span class="o">|</span><span class="n">oxaprozin</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>          <span class="mi">154</span><span class="o">|</span>        <span class="mi">210</span><span class="o">|</span><span class="n">cutaneous</span> <span class="n">fragility</span> <span class="n">on</span> <span class="n">the</span> <span class="n">face</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">back</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hands</span><span class="o">|</span>    <span class="n">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span><span class="mf">0.99900633</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>
<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">TextSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model_date</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_sec_dates"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_dates"</span><span class="p">)</span>

<span class="n">ner_converter_date</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_dates"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_date"</span><span class="p">)</span>

<span class="n">ner_model_org</span><span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_orgs"</span><span class="p">)</span>

<span class="n">ner_converter_org</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner_orgs"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_org"</span><span class="p">)</span>\

<span class="n">chunk_merger</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">'ner_chunk_org'</span><span class="p">,</span> <span class="s">"ner_chunk_date"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'ner_chunk'</span><span class="p">)</span>

<span class="n">pos</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"pos"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">re_filter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"ORG-ORG"</span><span class="p">,</span> <span class="s">"ORG-DATE"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">reDL</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finre_acquisitions_subsidiaries_md'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span> <span class="s">'finance/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relation"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">document_assembler</span><span class="p">,</span>
    <span class="n">text_splitter</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">embeddings</span><span class="p">,</span>
    <span class="n">ner_model_date</span><span class="p">,</span>
    <span class="n">ner_converter_date</span><span class="p">,</span>
    <span class="n">ner_model_org</span><span class="p">,</span>
    <span class="n">ner_converter_org</span><span class="p">,</span>
    <span class="n">chunk_merger</span><span class="p">,</span>
    <span class="n">pos</span><span class="p">,</span>
    <span class="n">dependency_parser</span><span class="p">,</span>
    <span class="n">re_filter</span><span class="p">,</span>
    <span class="n">reDL</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""In fiscal 2020, Cadence acquired all of the outstanding equity of AWR Corporation (“AWR”) and Integrand Software, Inc. (“Integrand”)."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">relation</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">relation</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="nb">filter</span><span class="p">(</span><span class="s">"relation != 'no_rel'"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                 <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>         <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>            <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>                <span class="n">Cadence</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="n">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span><span class="mf">0.99687237</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span>        <span class="n">AWR</span> <span class="n">Corporation</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="n">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span>  <span class="mf">0.993112</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="n">Integrand</span> <span class="n">Software</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="n">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span> <span class="mf">0.9741451</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span>        <span class="n">AWR</span> <span class="n">Corporation</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>        <span class="n">Cadence</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span>  <span class="mf">0.997124</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="n">Integrand</span> <span class="n">Software</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>        <span class="n">Cadence</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span><span class="mf">0.99910504</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="n">Integrand</span> <span class="n">Software</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span><span class="n">AWR</span> <span class="n">Corporation</span><span class="o">|</span>    <span class="n">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span><span class="mf">0.93245244</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">TextSplitter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">RoBertaEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">RelationExtractionDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legre_contract_doc_parties"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relation"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">text_splitter</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">re_model</span>
        <span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""This INTELLECTUAL PROPERTY AGREEMENT (this "Agreement"), dated as of December 31, 2018 (the "Effective Date") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ("Seller") and AFI Licensing LLC, a Delaware limited liability company ("Licensing" and together with Seller, "Arizona") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand, a "Party" and collectively, the "Parties")."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">relation</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">relation</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="nb">filter</span><span class="p">(</span><span class="s">"relation != 'no_rel'"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+-----------------------------------+-------+-------------+-----------+-----------------------+-------+--------------------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                             <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>                 <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>            <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------------------+-------+-------------+-----------+-----------------------+-------+--------------------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">5</span><span class="o">|</span>         <span class="mi">35</span><span class="o">|</span>    <span class="n">INTELLECTUAL</span> <span class="n">PROPERTY</span> <span class="n">AGREEMENT</span><span class="o">|</span>    <span class="n">DOC</span><span class="o">|</span>           <span class="mi">69</span><span class="o">|</span>         <span class="mi">85</span><span class="o">|</span>      <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2018</span><span class="o">|</span><span class="n">EFFDATE</span><span class="o">|</span>            <span class="n">dated_as</span><span class="o">|</span> <span class="mf">0.9856822</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">5</span><span class="o">|</span>         <span class="mi">35</span><span class="o">|</span>    <span class="n">INTELLECTUAL</span> <span class="n">PROPERTY</span> <span class="n">AGREEMENT</span><span class="o">|</span>    <span class="n">DOC</span><span class="o">|</span>          <span class="mi">141</span><span class="o">|</span>        <span class="mi">163</span><span class="o">|</span><span class="n">Armstrong</span> <span class="n">Flooring</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>  <span class="n">PARTY</span><span class="o">|</span>           <span class="n">signed_by</span><span class="o">|</span> <span class="mf">0.7816506</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">5</span><span class="o">|</span>         <span class="mi">35</span><span class="o">|</span>    <span class="n">INTELLECTUAL</span> <span class="n">PROPERTY</span> <span class="n">AGREEMENT</span><span class="o">|</span>    <span class="n">DOC</span><span class="o">|</span>          <span class="mi">205</span><span class="o">|</span>        <span class="mi">221</span><span class="o">|</span>      <span class="n">AFI</span> <span class="n">Licensing</span> <span class="n">LLC</span><span class="o">|</span>  <span class="n">PARTY</span><span class="o">|</span>           <span class="n">signed_by</span><span class="o">|</span><span class="mf">0.53521496</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>          <span class="mi">141</span><span class="o">|</span>        <span class="mi">163</span><span class="o">|</span>            <span class="n">Armstrong</span> <span class="n">Flooring</span><span class="p">,</span> <span class="n">Inc</span><span class="o">|</span>  <span class="n">PARTY</span><span class="o">|</span>          <span class="mi">192</span><span class="o">|</span>        <span class="mi">197</span><span class="o">|</span>                 <span class="n">Seller</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span>           <span class="n">has_alias</span><span class="o">|</span> <span class="mf">0.8962001</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>          <span class="mi">205</span><span class="o">|</span>        <span class="mi">221</span><span class="o">|</span>                  <span class="n">AFI</span> <span class="n">Licensing</span> <span class="n">LLC</span><span class="o">|</span>  <span class="n">PARTY</span><span class="o">|</span>          <span class="mi">263</span><span class="o">|</span>        <span class="mi">271</span><span class="o">|</span>              <span class="n">Licensing</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span>           <span class="n">has_alias</span><span class="o">|</span><span class="mf">0.95189077</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>          <span class="mi">292</span><span class="o">|</span>        <span class="mi">297</span><span class="o">|</span>                             <span class="n">Seller</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span>          <span class="mi">301</span><span class="o">|</span>        <span class="mi">307</span><span class="o">|</span>                <span class="n">Arizona</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span><span class="n">has_collective_alias</span><span class="o">|</span> <span class="mf">0.8934925</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">411</span><span class="o">|</span>        <span class="mi">445</span><span class="o">|</span><span class="n">Armstrong</span> <span class="n">Hardwood</span> <span class="n">Flooring</span> <span class="n">Company</span><span class="o">|</span>  <span class="n">PARTY</span><span class="o">|</span>          <span class="mi">478</span><span class="o">|</span>        <span class="mi">484</span><span class="o">|</span>                <span class="n">Company</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span>           <span class="n">has_alias</span><span class="o">|</span><span class="mf">0.98353034</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">505</span><span class="o">|</span>        <span class="mi">509</span><span class="o">|</span>                              <span class="n">Buyer</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span>          <span class="mi">516</span><span class="o">|</span>        <span class="mi">529</span><span class="o">|</span>         <span class="n">Buyer</span> <span class="n">Entities</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span><span class="n">has_collective_alias</span><span class="o">|</span> <span class="mf">0.7217146</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">611</span><span class="o">|</span>        <span class="mi">615</span><span class="o">|</span>                              <span class="n">Party</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span>          <span class="mi">641</span><span class="o">|</span>        <span class="mi">647</span><span class="o">|</span>                <span class="n">Parties</span><span class="o">|</span>  <span class="n">ALIAS</span><span class="o">|</span><span class="n">has_collective_alias</span><span class="o">|</span> <span class="mf">0.5040909</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------------------+-------+-------------+-----------+-----------------------+-------+--------------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordsEmbedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerTagger</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_ade_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerChunker</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_tags"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependencyParser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">adeReNerChunkFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"drug-ade"</span><span class="o">,</span> <span class="s">"ade-drug"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">adeReModel</span> <span class="k">=</span> <span class="nv">RelationExtractionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"redl_ade_biobert"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">,</span> <span class="s">"sentences"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.5</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documenter</span><span class="o">,</span>
    <span class="n">sentencer</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">wordsEmbedder</span><span class="o">,</span>
    <span class="n">posTagger</span><span class="o">,</span>
    <span class="n">nerTagger</span><span class="o">,</span>
    <span class="n">nerChunker</span><span class="o">,</span>
    <span class="n">dependencyParser</span><span class="o">,</span>
    <span class="n">adeReNerChunkFilter</span><span class="o">,</span>
    <span class="n">adeReModel</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>   <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>                                                   <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">25</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span> <span class="n">naproxen</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>          <span class="mi">137</span><span class="o">|</span>        <span class="mi">148</span><span class="o">|</span>                                             <span class="n">tense</span> <span class="n">bullae</span><span class="o">|</span>    <span class="nc">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span> <span class="mf">0.9989047</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">25</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span> <span class="n">naproxen</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>          <span class="mi">154</span><span class="o">|</span>        <span class="mi">210</span><span class="o">|</span><span class="n">cutaneous</span> <span class="n">fragility</span> <span class="n">on</span> <span class="n">the</span> <span class="n">face</span> <span class="n">and</span> <span class="n">the</span> <span class="n">back</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hands</span><span class="o">|</span>    <span class="nc">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span> <span class="mf">0.9989704</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">87</span><span class="o">|</span>         <span class="mi">95</span><span class="o">|</span><span class="n">oxaprozin</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>          <span class="mi">137</span><span class="o">|</span>        <span class="mi">148</span><span class="o">|</span>                                             <span class="n">tense</span> <span class="n">bullae</span><span class="o">|</span>    <span class="nc">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span><span class="mf">0.99895453</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">87</span><span class="o">|</span>         <span class="mi">95</span><span class="o">|</span><span class="n">oxaprozin</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>          <span class="mi">154</span><span class="o">|</span>        <span class="mi">210</span><span class="o">|</span><span class="n">cutaneous</span> <span class="n">fragility</span> <span class="n">on</span> <span class="n">the</span> <span class="n">face</span> <span class="n">and</span> <span class="n">the</span> <span class="n">back</span> <span class="n">of</span> <span class="n">the</span> <span class="n">hands</span><span class="o">|</span>    <span class="nc">ADE</span><span class="o">|</span>       <span class="mi">1</span><span class="o">|</span><span class="mf">0.99900633</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+---------+-------+-------------+-----------+---------------------------------------------------------+-------+--------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">text_splitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextSplitter</span><span class="o">()</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model_date</span> <span class="k">=</span> <span class="nv">NerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_sec_dates"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_dates"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_date</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_dates"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_date"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model_org</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_orgs_prods_alias"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_orgs"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_org</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner_orgs"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_org"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk_org"</span><span class="o">,</span> <span class="s">"ner_chunk_date"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pos</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependency_parser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"pos"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_filter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ORG-ORG"</span><span class="o">,</span> <span class="s">"ORG-DATE"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reDL</span> <span class="k">=</span> <span class="nv">RelationExtractionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finre_acquisitions_subsidiaries_md"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relation"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">text_splitter</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">ner_model_date</span><span class="o">,</span>
    <span class="n">ner_converter_date</span><span class="o">,</span>
    <span class="n">ner_model_org</span><span class="o">,</span>
    <span class="n">ner_converter_org</span><span class="o">,</span>
    <span class="n">chunk_merger</span><span class="o">,</span>
    <span class="n">pos</span><span class="o">,</span>
    <span class="n">dependency_parser</span><span class="o">,</span>
    <span class="n">re_filter</span><span class="o">,</span>
    <span class="n">reDL</span>
  <span class="o">))</span>

<span class="n">text</span> <span class="k">=</span> <span class="s">"""In fiscal 2020, Cadence acquired all of the outstanding equity of AWR Corporation (“AWR”) and Integrand Software, Inc. (“Integrand”)."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                 <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>         <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>            <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>                <span class="nc">Cadence</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="nc">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span><span class="mf">0.99687237</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span>        <span class="nc">AWR</span> <span class="nc">Corporation</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="nc">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span>  <span class="mf">0.993112</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="nc">Integrand</span> <span class="nc">Software</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>            <span class="mi">3</span><span class="o">|</span>         <span class="mi">13</span><span class="o">|</span>    <span class="n">fiscal</span> <span class="mi">2020</span><span class="o">|</span>   <span class="nc">DATE</span><span class="o">|</span><span class="n">has_acquisition_date</span><span class="o">|</span> <span class="mf">0.9741451</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span>        <span class="nc">AWR</span> <span class="nc">Corporation</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>        <span class="nc">Cadence</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span>  <span class="mf">0.997124</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="nc">Integrand</span> <span class="nc">Software</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>           <span class="mi">16</span><span class="o">|</span>         <span class="mi">22</span><span class="o">|</span>        <span class="nc">Cadence</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span><span class="mf">0.99910504</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">94</span><span class="o">|</span>        <span class="mi">116</span><span class="o">|</span><span class="nc">Integrand</span> <span class="nc">Software</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>           <span class="mi">66</span><span class="o">|</span>         <span class="mi">80</span><span class="o">|</span><span class="nc">AWR</span> <span class="nc">Corporation</span><span class="o">|</span>    <span class="nc">ORG</span><span class="o">|</span>     <span class="n">was_acquired_by</span><span class="o">|</span><span class="mf">0.93245244</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------+-------+-------------+-----------+---------------+-------+--------------------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">text_splitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextSplitter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">RoBertaEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"roberta_embeddings_legal_roberta_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxSentenceLength</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">LegalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">re_model</span> <span class="k">=</span> <span class="nv">RelationExtractionDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legre_contract_doc_parties"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relation"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span>
    <span class="n">text_splitter</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">ner_model</span><span class="o">,</span>
    <span class="n">ner_converter</span><span class="o">,</span>
    <span class="n">re_model</span>
  <span class="o">))</span>

<span class="n">text</span> <span class="k">=</span> <span class="s">"""This INTELLECTUAL PROPERTY AGREEMENT (this "Agreement"), dated as of December 31, 2018 (the "Effective Date") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ("Seller") and AFI Licensing LLC, a Delaware limited liability company ("Licensing" and together with Seller, "Arizona") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation ("Buyer") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the "Company" and together with Buyer the "Buyer Entities") (each of Arizona on the one hand and the Buyer Entities on the other hand, a "Party" and collectively, the "Parties")."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------+-----------+-----------------------------------+-------+-------------+-----------+-----------------------+-------+--------------------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                             <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>                 <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>            <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------------------+-------+-------------+-----------+-----------------------+-------+--------------------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">5</span><span class="o">|</span>         <span class="mi">35</span><span class="o">|</span>    <span class="nc">INTELLECTUAL</span> <span class="nc">PROPERTY</span> <span class="nc">AGREEMENT</span><span class="o">|</span>    <span class="nc">DOC</span><span class="o">|</span>           <span class="mi">69</span><span class="o">|</span>         <span class="mi">85</span><span class="o">|</span>      <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2018</span><span class="o">|</span><span class="nc">EFFDATE</span><span class="o">|</span>            <span class="n">dated_as</span><span class="o">|</span> <span class="mf">0.9856822</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">5</span><span class="o">|</span>         <span class="mi">35</span><span class="o">|</span>    <span class="nc">INTELLECTUAL</span> <span class="nc">PROPERTY</span> <span class="nc">AGREEMENT</span><span class="o">|</span>    <span class="nc">DOC</span><span class="o">|</span>          <span class="mi">141</span><span class="o">|</span>        <span class="mi">163</span><span class="o">|</span><span class="nc">Armstrong</span> <span class="nc">Flooring</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>  <span class="nc">PARTY</span><span class="o">|</span>           <span class="n">signed_by</span><span class="o">|</span> <span class="mf">0.7816506</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">5</span><span class="o">|</span>         <span class="mi">35</span><span class="o">|</span>    <span class="nc">INTELLECTUAL</span> <span class="nc">PROPERTY</span> <span class="nc">AGREEMENT</span><span class="o">|</span>    <span class="nc">DOC</span><span class="o">|</span>          <span class="mi">205</span><span class="o">|</span>        <span class="mi">221</span><span class="o">|</span>      <span class="nc">AFI</span> <span class="nc">Licensing</span> <span class="nc">LLC</span><span class="o">|</span>  <span class="nc">PARTY</span><span class="o">|</span>           <span class="n">signed_by</span><span class="o">|</span><span class="mf">0.53521496</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>          <span class="mi">141</span><span class="o">|</span>        <span class="mi">163</span><span class="o">|</span>            <span class="nc">Armstrong</span> <span class="nc">Flooring</span><span class="o">,</span> <span class="nc">Inc</span><span class="o">|</span>  <span class="nc">PARTY</span><span class="o">|</span>          <span class="mi">192</span><span class="o">|</span>        <span class="mi">197</span><span class="o">|</span>                 <span class="nc">Seller</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span>           <span class="n">has_alias</span><span class="o">|</span> <span class="mf">0.8962001</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>          <span class="mi">205</span><span class="o">|</span>        <span class="mi">221</span><span class="o">|</span>                  <span class="nc">AFI</span> <span class="nc">Licensing</span> <span class="nc">LLC</span><span class="o">|</span>  <span class="nc">PARTY</span><span class="o">|</span>          <span class="mi">263</span><span class="o">|</span>        <span class="mi">271</span><span class="o">|</span>              <span class="nc">Licensing</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span>           <span class="n">has_alias</span><span class="o">|</span><span class="mf">0.95189077</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>          <span class="mi">292</span><span class="o">|</span>        <span class="mi">297</span><span class="o">|</span>                             <span class="nc">Seller</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span>          <span class="mi">301</span><span class="o">|</span>        <span class="mi">307</span><span class="o">|</span>                <span class="nc">Arizona</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span><span class="n">has_collective_alias</span><span class="o">|</span> <span class="mf">0.8934925</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">411</span><span class="o">|</span>        <span class="mi">445</span><span class="o">|</span><span class="nc">Armstrong</span> <span class="nc">Hardwood</span> <span class="nc">Flooring</span> <span class="nc">Company</span><span class="o">|</span>  <span class="nc">PARTY</span><span class="o">|</span>          <span class="mi">478</span><span class="o">|</span>        <span class="mi">484</span><span class="o">|</span>                <span class="nc">Company</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span>           <span class="n">has_alias</span><span class="o">|</span><span class="mf">0.98353034</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">505</span><span class="o">|</span>        <span class="mi">509</span><span class="o">|</span>                              <span class="nc">Buyer</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span>          <span class="mi">516</span><span class="o">|</span>        <span class="mi">529</span><span class="o">|</span>         <span class="nc">Buyer</span> <span class="nc">Entities</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span><span class="n">has_collective_alias</span><span class="o">|</span> <span class="mf">0.7217146</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">611</span><span class="o">|</span>        <span class="mi">615</span><span class="o">|</span>                              <span class="nc">Party</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span>          <span class="mi">641</span><span class="o">|</span>        <span class="mi">647</span><span class="o">|</span>                <span class="nc">Parties</span><span class="o">|</span>  <span class="nc">ALIAS</span><span class="o">|</span><span class="n">has_collective_alias</span><span class="o">|</span> <span class="mf">0.5040909</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------------------------------+-------+-------------+-----------+-----------------------+-------+--------------------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="replacer">Replacer</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">Replacer</code> allows to replace entities in the original text with the ones extracted by the annotators <code class="language-plaintext highlighter-rouge">NameChunkObfuscatorApproach</code> or <code class="language-plaintext highlighter-rouge">DateNormalizer</code>.</p>

    <p><code class="language-plaintext highlighter-rouge">Replacer</code> is most often used in conjunction with the <code class="language-plaintext highlighter-rouge">DateNormalizer</code> annotator or in deidentification pipelines.</p>

    <p>With the dates, the <code class="language-plaintext highlighter-rouge">Replacer</code> annotator is used to replace specific tokens in a text with another token or string. The <code class="language-plaintext highlighter-rouge">DateNormalizer</code> annotator, on the other hand, is used to normalize dates and times to a standardized format.</p>

    <p>Obfuscation in healthcare is the act of making healthcare data difficult to understand or use without authorization. This can be done by replacing or removing identifying information, such as names, dates of birth, and Social Security numbers. Obfuscation can also be used to hide the contents of healthcare records, such as diagnoses, medications, and treatment plans.</p>

    <p>In the <strong>deidentification</strong> process, the <code class="language-plaintext highlighter-rouge">Replacer</code> annotator is used to replace certain tokens or patterns in the text with specified values. For example, it can be used to replace all instances of a person’s name with a placeholder like “PERSON”.</p>

    <p>The <code class="language-plaintext highlighter-rouge">NameChunkObfuscatorApproach</code> annotator is used to identify and obfuscate sensitive named entities in the text, such as people’s names, addresses, dates of birth, SSNs etc.</p>

    <p>Parameter:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">setUseReplacement</code>: (Boolean) Select what output format should be used. By default it will use the current day.</li>
      <li><code class="language-plaintext highlighter-rouge">setPlaceHolderDelimiters</code>: (String) Sets the placeholder string to use when noneValuesTo is set to “place_holder”. This placeholder string will be wrapped by the delimiters defined in placeHolderDelimiters.</li>
      <li><code class="language-plaintext highlighter-rouge">setPlaceHolder</code>: (String) Determines the action to take when encountering a value of ‘NONE’ in the annotation. This parameter can take one of the following three string values:
        <ul>
          <li>“entity”: Replaces ‘NONE’ values with the entity field extracted from the annotation, if available. If the entity field is not available, it uses the string “NONE” wrapped by the specified delimiters.</li>
          <li>“place_holder”: Replaces ‘NONE’ values with a placeholder string wrapped by the specified delimiters.</li>
          <li>“skip”: Retains the original target_text from the annotation’s metadata if available. If not available, it retains the original annotation result.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">mappingsColumn</code>: (String) Column name for mapping. This column maps the annotations to their corresponding chunks before the entities are replaced.</li>
      <li><code class="language-plaintext highlighter-rouge">returnEntityMappings</code>: (Boolean) With this property you select if you want to return mapping column.</li>
      <li><code class="language-plaintext highlighter-rouge">staticEntityMappingsFallback</code>: (String) Fallback option for static entity mappings. Allowed values: ‘entity’, ‘place_holder’, ‘skip’, ‘error’.</li>
      <li><code class="language-plaintext highlighter-rouge">staticEntityMappings</code>: (dict)  Static entity mappings. A dictionary with entity types as keys and replacement values as values.</li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, CHUNK</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/replacer/index.html#sparknlp_jsl.annotator.deid.replacer.Replacer">Replacer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/Replacer.html">Replacer</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Replacer.ipynb">ReplacerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">names</span> <span class="o">=</span> <span class="s">"""Mitchell#NAME
Clifford#NAME
Jeremiah#NAME
Lawrence#NAME
Brittany#NAME
Patricia#NAME
Samantha#NAME
Jennifer#NAME
Jackson#NAME
Leonard#NAME
Randall#NAME
Camacho#NAME
Ferrell#NAME
Mueller#NAME
Bowman#NAME
Hansen#NAME
Acosta#NAME
Gillespie#NAME
Zimmerman#NAME
Gillespie#NAME
Chandler#NAME
Bradshaw#NAME
Ferguson#NAME
Jacobson#NAME
Figueroa#NAME
Chandler#NAME
Schaefer#NAME
Matthews#NAME
Ferguson#NAME
Bradshaw#NAME
Figueroa#NAME
Delacruz#NAME
Gallegos#NAME
Villarreal#NAME
Williamson#NAME
Montgomery#NAME
Mclaughlin#NAME
Blankenship#NAME
Fitzpatrick#NAME
"""</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'names_test.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="nb">file</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>


<span class="c1"># Annotator that transforms a text column from dataframe into an Annotation ready for NLP
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\

<span class="c1"># Tokenizer splits words in a relevant format for NLP
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>\

<span class="c1"># Clinical word embeddings trained on PubMED dataset
</span><span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="c1"># NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)
</span><span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter_name</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">nameChunkObfuscator</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NameChunkObfuscatorApproach</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"replacement"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setRefFileFormat</span><span class="p">(</span><span class="s">"csv"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setObfuscateRefFile</span><span class="p">(</span><span class="s">"names_test.txt"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setRefSep</span><span class="p">(</span><span class="s">"#"</span><span class="p">)</span>\

<span class="n">replacer_name</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Replacer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"replacement"</span><span class="p">,</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"obfuscated_document_name"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setUseReplacement</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setNoneValuesTo</span><span class="p">(</span><span class="s">"entity"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setPlaceHolder</span><span class="p">(</span><span class="s">"******"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setPlaceHolderDelimiters</span><span class="p">([</span><span class="s">"&lt;"</span><span class="p">,</span> <span class="s">"&gt;"</span><span class="p">])</span>

<span class="n">nlpPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span> 
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter_name</span><span class="p">,</span>
    <span class="n">nameChunkObfuscator</span><span class="p">,</span>
    <span class="n">replacer_name</span>
    <span class="p">])</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment."</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">nlpPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="n">Original</span> <span class="n">text</span><span class="p">.</span>  <span class="p">:</span>  <span class="n">John</span> <span class="n">Davies</span> <span class="ow">is</span> <span class="n">a</span> <span class="mi">62</span> <span class="n">y</span><span class="p">.</span><span class="n">o</span><span class="p">.</span> <span class="n">patient</span> <span class="n">admitted</span><span class="p">.</span> <span class="n">Mr</span><span class="p">.</span> <span class="n">Davies</span> <span class="n">was</span> <span class="n">seen</span> <span class="n">by</span> <span class="n">attending</span> <span class="n">physician</span> <span class="n">Dr</span><span class="p">.</span> <span class="n">Lorand</span> <span class="ow">and</span> <span class="n">was</span> <span class="n">scheduled</span> <span class="k">for</span> <span class="n">emergency</span> <span class="n">assessment</span><span class="p">.</span>

<span class="n">Obfuscated</span> <span class="n">text</span> <span class="p">:</span>  <span class="n">Joseeduardo</span> <span class="ow">is</span> <span class="n">a</span> <span class="mi">62</span> <span class="n">y</span><span class="p">.</span><span class="n">o</span><span class="p">.</span> <span class="n">patient</span> <span class="n">admitted</span><span class="p">.</span> <span class="n">Mr</span><span class="p">.</span> <span class="n">Teigan</span> <span class="n">was</span> <span class="n">seen</span> <span class="n">by</span> <span class="n">attending</span> <span class="n">physician</span> <span class="n">Dr</span><span class="p">.</span> <span class="n">Mayson</span> <span class="ow">and</span> <span class="n">was</span> <span class="n">scheduled</span> <span class="k">for</span> <span class="n">emergency</span> <span class="n">assessment</span><span class="p">.</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="cm">/* names.txt file

names = """Mitchell#NAME
Clifford#NAME
Jeremiah#NAME
Lawrence#NAME
Brittany#NAME
Patricia#NAME
Samantha#NAME
Jennifer#NAME
Jackson#NAME
Leonard#NAME
Randall#NAME
Camacho#NAME
Ferrell#NAME
Mueller#NAME
Bowman#NAME
Hansen#NAME
Acosta#NAME
Gillespie#NAME
Zimmerman#NAME
Gillespie#NAME
Chandler#NAME
Bradshaw#NAME
Ferguson#NAME
Jacobson#NAME
Figueroa#NAME
Chandler#NAME
Schaefer#NAME
Matthews#NAME
Ferguson#NAME
Bradshaw#NAME
Figueroa#NAME
Delacruz#NAME
Gallegos#NAME
Villarreal#NAME
Williamson#NAME
Montgomery#NAME
Mclaughlin#NAME
Blankenship#NAME
Fitzpatrick#NAME
"""
*/</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_deid_generic_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter_name</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nameChunkObfuscator</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NameChunkObfuscatorApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"replacement"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRefFileFormat</span><span class="o">(</span><span class="s">"csv"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setObfuscateRefFile</span><span class="o">(</span><span class="s">"names_test.txt"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRefSep</span><span class="o">(</span><span class="s">"//"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">replacer_name</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Replacer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"replacement"</span><span class="o">,</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"obfuscated_document_name"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setUseReplacement</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setNoneValuesTo</span><span class="o">(</span><span class="s">"entity"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPlaceHolder</span><span class="o">(</span><span class="s">"******"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setPlaceHolderDelimiters</span><span class="o">([</span><span class="err">"</span><span class="kt">&lt;</span><span class="err">"</span>, <span class="err">"</span><span class="kt">&gt;</span><span class="err">"</span><span class="o">])</span>

<span class="k">val</span> <span class="nv">nlpPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">word_embeddings</span><span class="o">,</span> 
    <span class="n">clinical_ner</span><span class="o">,</span> 
    <span class="n">ner_converter_name</span><span class="o">,</span> 
    <span class="n">nameChunkObfuscator</span><span class="o">,</span> 
    <span class="n">replacer_name</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">test_data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"""John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment."""</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">mapperPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">test_data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">test_data</span><span class="o">)</span>

<span class="k">#</span> <span class="nc">Result</span>

<span class="nc">Original</span> <span class="n">text</span><span class="o">.</span>  <span class="k">:</span>  <span class="kt">John</span> <span class="kt">Davies</span> <span class="kt">is</span> <span class="kt">a</span> <span class="err">62</span> <span class="kt">y.o.</span> <span class="kt">patient</span> <span class="kt">admitted.</span> <span class="kt">Mr.</span> <span class="kt">Davies</span> <span class="kt">was</span> <span class="kt">seen</span> <span class="kt">by</span> <span class="kt">attending</span> <span class="kt">physician</span> <span class="kt">Dr.</span> <span class="kt">Lorand</span> <span class="kt">and</span> <span class="kt">was</span> <span class="kt">scheduled</span> <span class="kt">for</span> <span class="kt">emergency</span> <span class="kt">assessment.</span>

<span class="kt">Obfuscated</span> <span class="kt">text</span> <span class="kt">:</span>  <span class="kt">Joseeduardo</span> <span class="kt">is</span> <span class="kt">a</span> <span class="err">62</span> <span class="kt">y.o.</span> <span class="kt">patient</span> <span class="kt">admitted.</span> <span class="kt">Mr.</span> <span class="kt">Teigan</span> <span class="kt">was</span> <span class="kt">seen</span> <span class="kt">by</span> <span class="kt">attending</span> <span class="kt">physician</span> <span class="kt">Dr.</span> <span class="kt">Mayson</span> <span class="kt">and</span> <span class="kt">was</span> <span class="kt">scheduled</span> <span class="kt">for</span> <span class="kt">emergency</span> <span class="kt">assessment.</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="resolution2chunk">Resolution2Chunk</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator is responsible for converting the annotations generated by entity resolver models (typically labeled as ENTITY) into a format compatible with subsequent stages of the pipeline, such as the ChunkMapperModel. It transforms these annotations into CHUNK annotations, allowing for seamless integration and processing of clinical terminologies and entities in the pipeline.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">Resolution</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/resolution2_chunk/index.html#sparknlp_jsl.annotator.resolution2_chunk.Resolution2Chunk">Resolution2Chunk</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/Resolution2Chunk.html">Resolution2Chunk</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Resolution2Chunk.ipynb">Resolution2ChunkNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">medical</span><span class="p">,</span> <span class="n">nlp</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">rxnorm_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">resolver2chunk</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Resolution2Chunk</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"rxnorm_code"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"resolver2chunk"</span><span class="p">)</span>

<span class="n">chunkerMapper_action</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"rxnorm_action_treatment_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"resolver2chunk"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"action_mapping"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setRels</span><span class="p">([</span><span class="s">"action"</span><span class="p">])</span> <span class="c1">#for treatment
</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span><span class="n">document_assembler</span><span class="p">,</span>
                                 <span class="n">sbert_embedder</span><span class="p">,</span>
                                 <span class="n">rxnorm_resolver</span><span class="p">,</span>
                                 <span class="n">resolver2chunk</span><span class="p">,</span>
                                 <span class="n">chunkerMapper_action</span>
                                 <span class="p">])</span>

<span class="n">data</span><span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">'Zonalon 50 mg'</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>

<span class="n">res</span><span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Example results
</span>
<span class="n">res</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                  <span class="n">res</span><span class="p">.</span><span class="n">rxnorm_code</span><span class="p">.</span><span class="n">result</span><span class="p">,</span>
                                  <span class="n">res</span><span class="p">.</span><span class="n">action_mapping</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"col"</span><span class="p">))</span>\
    <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"document"</span><span class="p">),</span>
            <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">),</span>
            <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"col['2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"Action Mapping"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-------------+-----------+--------------+</span>
<span class="o">|</span><span class="n">document</span>     <span class="o">|</span><span class="n">rxnorm_code</span><span class="o">|</span><span class="n">Action</span> <span class="n">Mapping</span><span class="o">|</span>
<span class="o">+-------------+-----------+--------------+</span>
<span class="o">|</span><span class="n">Zonalon</span> <span class="mi">50</span> <span class="n">mg</span><span class="o">|</span><span class="mi">103971</span>     <span class="o">|</span><span class="n">Analgesic</span>     <span class="o">|</span>
<span class="o">+-------------+-----------+--------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sbert_embedder</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="nc">False</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">rxnorm_resolver</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"rxnorm_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">resolver2chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Resolution2Chunk</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"rxnorm_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"resolver2chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkerMapper_action</span> <span class="k">=</span> <span class="nv">ChunkMapperModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"rxnorm_action_treatment_mapper"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"resolver2chunk"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"action_mapping"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRels</span><span class="o">(</span><span class="s">"action"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">sbert_embedder</span><span class="o">,</span> 
    <span class="n">rxnorm_resolver</span><span class="o">,</span> 
    <span class="n">resolver2chunk</span><span class="o">,</span> 
    <span class="n">chunkerMapper_action</span> <span class="o">))</span> 

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Zonalon 50 mg"</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Example results</span>

<span class="o">+-------------+-----------+--------------+</span>
<span class="o">|</span><span class="n">document</span>     <span class="o">|</span><span class="n">rxnorm_code</span><span class="o">|</span><span class="nc">Action</span> <span class="nc">Mapping</span><span class="o">|</span>
<span class="o">+-------------+-----------+--------------+</span>
<span class="o">|</span><span class="nc">Zonalon</span> <span class="mi">50</span> <span class="n">mg</span><span class="o">|</span><span class="mi">103971</span>     <span class="o">|</span><span class="nc">Analgesic</span>     <span class="o">|</span>
<span class="o">+-------------+-----------+--------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="resolvermerger">ResolverMerger</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">ResolverMerger</code> provides the ability to merge sentence enitity resolver and chunk mapper model output columns.</p>

    <p>To convert a sentence or document into a vector for tasks like semantic search or recommendation systems, a common approach is to utilize transformer models like BERT. These models provide embeddings for each token in the text. One option is to extract the embedding vector of the CLS token, which represents the overall meaning of the text. Another option is to average the embeddings of all tokens.</p>

    <p>Alternatively, we can use fine-tuned Siamese network variants like SBERT, which are specifically designed to generate embeddings that bring similar sentences or documents closer together in the embedding space while separating dissimilar ones. These embeddings can be applied in “Sentence Entity Resolver Models” to perform entity mapping.</p>

    <p>However, for a more straightforward approach, we can use a chunk mapper method to extract entities from the text. In addition, by combining resolver models and mapper models using the <code class="language-plaintext highlighter-rouge">ResolverMerger</code> annotator, we can further enhance the performance and accuracy of the resolver system.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read an Array of strings.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in Document type that is generated. We can specify only one column here.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">ENTITY, LABEL_DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/resolution/resolver_merger/index.html#module-sparknlp_jsl.annotator.resolution.resolver_merger">ResolverMerger</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/ResolverMerger.html">ResolverMerger</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ResolverMerger.ipynb">ResolverMergerNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology_greedy"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">)</span>

<span class="n">chunkerMapper</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMapperModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"rxnorm_mapper"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"RxNorm_Mapper"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRel</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>

<span class="n">cfModel</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMapperFilterer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"chunk"</span><span class="p">,</span> <span class="s">"RxNorm_Mapper"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"chunks_fail"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setReturnCriteria</span><span class="p">(</span><span class="s">"fail"</span><span class="p">)</span>

<span class="n">chunk2doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunk2Doc</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"chunks_fail"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"doc_chunk"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'sbiobert_base_cased_mli'</span><span class="p">,</span> <span class="s">'en'</span><span class="p">,</span><span class="s">'clinical/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"doc_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"resolver_code"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">resolverMerger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ResolverMerger</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"resolver_code"</span><span class="p">,</span><span class="s">"RxNorm_Mapper"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"RxNorm"</span><span class="p">)</span>

<span class="n">mapper_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">word_embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">chunkerMapper</span><span class="p">,</span>
        <span class="n">chunkerMapper</span><span class="p">,</span>
        <span class="n">cfModel</span><span class="p">,</span>
        <span class="n">chunk2doc</span><span class="p">,</span>
        <span class="n">sbert_embedder</span><span class="p">,</span>
        <span class="n">resolver</span><span class="p">,</span>
        <span class="n">resolverMerger</span>
    <span class="p">])</span>

<span class="n">sample_text</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s">"The patient was given Adapin 10 MG, coumadn 5 mg"</span><span class="p">],</span>
    <span class="p">[</span><span class="s">"The patient was given Avandia 4 mg, Tegretol, zitiga"</span><span class="p">],</span>
<span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">sample_text</span><span class="p">).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">mapper_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"chunk.result as chunk"</span><span class="p">,</span>
    <span class="s">"RxNorm_Mapper.result as RxNorm_Mapper"</span><span class="p">,</span>
    <span class="s">"chunks_fail.result as chunks_fail"</span><span class="p">,</span>
    <span class="s">"resolver_code.result as resolver_code"</span><span class="p">,</span>
    <span class="s">"RxNorm.result as RxNorm"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>


<span class="c1">## Result
</span>
<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>                           <span class="o">|</span><span class="n">RxNorm_Mapper</span>         <span class="o">|</span><span class="n">chunks_fail</span>   <span class="o">|</span><span class="n">resolver_code</span><span class="o">|</span><span class="n">RxNorm</span>                  <span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Adapin</span> <span class="mi">10</span> <span class="n">MG</span><span class="p">,</span> <span class="n">coumadn</span> <span class="mi">5</span> <span class="n">mg</span><span class="p">]</span>    <span class="o">|</span><span class="p">[</span><span class="mi">1000049</span><span class="p">,</span> <span class="n">NONE</span><span class="p">]</span>       <span class="o">|</span><span class="p">[</span><span class="n">coumadn</span> <span class="mi">5</span> <span class="n">mg</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="mi">200883</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="mi">1000049</span><span class="p">,</span> <span class="mi">200883</span><span class="p">]</span>       <span class="o">|</span>
<span class="o">|</span><span class="p">[</span><span class="n">Avandia</span> <span class="mi">4</span> <span class="n">mg</span><span class="p">,</span> <span class="n">Tegretol</span><span class="p">,</span> <span class="n">zitiga</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="mi">261242</span><span class="p">,</span> <span class="mi">203029</span><span class="p">,</span> <span class="n">NONE</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">zitiga</span><span class="p">]</span>      <span class="o">|</span><span class="p">[</span><span class="mi">220989</span><span class="p">]</span>     <span class="o">|</span><span class="p">[</span><span class="mi">261242</span><span class="p">,</span> <span class="mi">203029</span><span class="p">,</span> <span class="mi">220989</span><span class="p">]</span><span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">document_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_model</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology_greedy"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunkerMapper</span> <span class="k">=</span> <span class="nv">ChunkMapperModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"rxnorm_mapper"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"RxNorm_Mapper"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRel</span><span class="o">(</span><span class="s">"rxnorm_code"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">cfModel</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMapperFilterer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"chunk"</span><span class="o">,</span><span class="s">"RxNorm_Mapper"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"chunks_fail"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setReturnCriteria</span><span class="o">(</span><span class="s">"fail"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">chunk2doc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Doc</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"chunks_fail"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"doc_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sbert_embedder</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"doc_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">resolver</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"resolver_code"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">resolverMerger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ResolverMerger</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"resolver_code"</span><span class="o">,</span><span class="s">"RxNorm_Mapper"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"RxNorm"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">mapper_pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">document_assembler</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">word_embeddings</span><span class="o">,</span> 
    <span class="n">ner_model</span><span class="o">,</span> 
    <span class="n">ner_converter</span><span class="o">,</span> 
    <span class="n">chunkerMapper</span><span class="o">,</span> 
    <span class="n">chunkerMapper</span><span class="o">,</span> 
    <span class="n">cfModel</span><span class="o">,</span> 
    <span class="n">chunk2doc</span><span class="o">,</span> 
    <span class="n">sbert_embedder</span><span class="o">,</span> 
    <span class="n">resolver</span><span class="o">,</span> 
    <span class="n">resolverMerger</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">((</span><span class="s">"""The patient was given Adapin 10 MG, coumadn 5 mg"""</span><span class="o">),(</span><span class="s">"""The patient was given Avandia 4 mg, Tegretol, zitiga"""</span><span class="o">)).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">mapperPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>

<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>                           <span class="o">|</span><span class="nc">RxNorm_Mapper</span>         <span class="o">|</span><span class="n">chunks_fail</span>   <span class="o">|</span><span class="n">resolver_code</span><span class="o">|</span><span class="nc">RxNorm</span>                  <span class="o">|</span>
<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
<span class="o">|[</span><span class="kt">Adapin</span> <span class="err">10</span> <span class="kt">MG</span>, <span class="kt">coumadn</span> <span class="err">5</span> <span class="kt">mg</span><span class="o">]</span>    <span class="o">|[</span><span class="err">1000049</span>, <span class="kt">NONE</span><span class="o">]</span>       <span class="o">|[</span><span class="kt">coumadn</span> <span class="err">5</span> <span class="kt">mg</span><span class="o">]|[</span><span class="err">200883</span><span class="o">]</span>     <span class="o">|[</span><span class="err">1000049</span>, <span class="err">200883</span><span class="o">]</span>       <span class="o">|</span>
<span class="o">|[</span><span class="kt">Avandia</span> <span class="err">4</span> <span class="kt">mg</span>, <span class="kt">Tegretol</span>, <span class="kt">zitiga</span><span class="o">]|[</span><span class="err">261242</span>, <span class="err">203029</span>, <span class="kt">NONE</span><span class="o">]|[</span><span class="kt">zitiga</span><span class="o">]</span>      <span class="o">|[</span><span class="err">220989</span><span class="o">]</span>     <span class="o">|[</span><span class="err">261242</span>, <span class="err">203029</span>, <span class="err">220989</span><span class="o">]|</span>
<span class="o">+--------------------------------+----------------------+--------------+-------------+------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="router">Router</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">Router</code> provides the ability to split an output of an annotator for a selected metadata field and the value for that field.</p>

    <p>When we need to use multiple sentence entity resolver models in the same pipeline, we typically had to run the <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> annotator multiple times based on the number of resolver models. This meant that the heavy process of generating sentence embeddings using BERT was repeated multiple times.</p>

    <p>To address this issue, Spark NLP Healthcare Library has introduced a solution using the <code class="language-plaintext highlighter-rouge">Router</code> annotator. With this new approach, we can provide all the named entity recognition (NER) chunks to the <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> annotator at once. The annotator generates the sentence embeddings for all the chunks together. Then, the output of the sentence embeddings is routed to the specific resolver models that are required for further processing.</p>

    <p>This solution eliminates the need to run <code class="language-plaintext highlighter-rouge">BertSentenceEmbeddings</code> multiple times, reducing the computational overhead and improving the efficiency of the pipeline.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputCols</code>: The name of the columns containing the input annotations. It can read an Array of strings.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">outputCol</code>: The name of the column in the Document type that is generated. We can specify only one column here.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">inputType</code>: The type of entity that you want to filter (by default <code class="language-plaintext highlighter-rouge">sentence_embeddings</code>). Possible values; <code class="language-plaintext highlighter-rouge">document|token|wordpiece|word_embeddings|sentence_embeddings|category|date|sentiment|pos|chunk|named_entity|regex|dependency|labeled_dependency|language|keyword</code></p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">metadataField</code>: The key in the metadata dictionary that you want to filter (by default <code class="language-plaintext highlighter-rouge">entity</code>)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">filterFieldsElements</code>: The <code class="language-plaintext highlighter-rouge">filterfieldsElements</code> are the allowed values for the metadata field that is being used.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in the camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">ENTITY, LABEL_DEPENDENCY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/router/index.html#module-sparknlp_jsl.annotator.router">Router</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/annotator/Router.html">Router</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Router.ipynb">RouterNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"word_embeddings"</span><span class="p">)</span>

<span class="c1"># to get PROBLEM entitis
</span><span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"clinical_ner"</span><span class="p">)</span>

<span class="n">clinical_ner_chunk</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"clinical_ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"clinical_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PROBLEM"</span><span class="p">])</span>

<span class="c1"># to get DRUG entities
</span><span class="n">posology_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"word_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"posology_ner"</span><span class="p">)</span>

<span class="n">posology_ner_chunk</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">,</span><span class="s">"token"</span><span class="p">,</span><span class="s">"posology_ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"posology_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DRUG"</span><span class="p">])</span>

<span class="c1"># merge the chunks into a single ner_chunk
</span><span class="n">chunk_merger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"clinical_ner_chunk"</span><span class="p">,</span><span class="s">"posology_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"final_ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMergeOverlapping</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># convert chunks to doc to get sentence embeddings of them
</span><span class="n">chunk2doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunk2Doc</span><span class="p">().</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"final_ner_chunk"</span><span class="p">).</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"doc_final_chunk"</span><span class="p">)</span>

<span class="n">sbiobert_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"doc_final_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># filter PROBLEM entity embeddings
</span><span class="n">router_sentence_icd10</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Router</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFilterFieldsElements</span><span class="p">([</span><span class="s">"PROBLEM"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"problem_embeddings"</span><span class="p">)</span>

<span class="c1"># filter DRUG entity embeddings
</span><span class="n">router_sentence_rxnorm</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Router</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setFilterFieldsElements</span><span class="p">([</span><span class="s">"DRUG"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"drug_embeddings"</span><span class="p">)</span>

<span class="c1"># use problem_embeddings only
</span><span class="n">icd_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_icd10cm_slim_billable_hcc"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"problem_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"icd10cm_code"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="c1"># use drug_embeddings only
</span><span class="n">rxnorm_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"drug_embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"rxnorm_code"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>


<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">clinical_ner_chunk</span><span class="p">,</span>
    <span class="n">posology_ner</span><span class="p">,</span>
    <span class="n">posology_ner_chunk</span><span class="p">,</span>
    <span class="n">chunk_merger</span><span class="p">,</span>
    <span class="n">chunk2doc</span><span class="p">,</span>
    <span class="n">sbiobert_embeddings</span><span class="p">,</span>
    <span class="n">router_sentence_icd10</span><span class="p">,</span>
    <span class="n">router_sentence_rxnorm</span><span class="p">,</span>
    <span class="n">icd_resolver</span><span class="p">,</span>
    <span class="n">rxnorm_resolver</span>
<span class="p">])</span>

<span class="n">clinical_note</span> <span class="o">=</span> <span class="s">"""The patient is a 41-year-old Vietnamese female with a cough that started last week.
She has had right-sided chest pain radiating to her back with fever starting yesterday.
She has a history of pericarditis in May 2006 and developed cough with right-sided chest pain.
MEDICATIONS
1. Coumadin 1 mg daily. Last INR was on Tuesday, August 14, 2007, and her INR was 2.3.
2. Amiodarone 100 mg p.o. daily.
"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">clinical_note</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="n">result</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s">"final_ner_chunk.result as chunk"</span><span class="p">,</span>
    <span class="s">"posology_ner_chunk.result as posology_chunk"</span><span class="p">,</span>
    <span class="s">"rxnorm_code.result as rxnorm_code"</span><span class="p">,</span>
    <span class="s">"clinical_ner_chunk.result as clinical_chunk"</span><span class="p">,</span>
    <span class="s">"icd10cm_code.result as icd10cm_code"</span><span class="p">,</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-----------------------------------------------------------------------------------------------------------+----------------------+-------------+-------------------------------------------------------------------------------------+--------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>                                                                                                      <span class="o">|</span><span class="n">posology_chunk</span>        <span class="o">|</span><span class="n">rxnorm_code</span>  <span class="o">|</span><span class="n">clinical_chunk</span>                                                                       <span class="o">|</span><span class="n">icd10cm_code</span>                          <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------+----------------------+-------------+-------------------------------------------------------------------------------------+--------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">cough</span><span class="p">,</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">chest</span> <span class="n">pain</span><span class="p">,</span> <span class="n">fever</span><span class="p">,</span> <span class="n">pericarditis</span><span class="p">,</span> <span class="n">cough</span><span class="p">,</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">chest</span> <span class="n">pain</span><span class="p">,</span> <span class="n">Coumadin</span><span class="p">,</span> <span class="n">Amiodarone</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">Coumadin</span><span class="p">,</span> <span class="n">Amiodarone</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="mi">202421</span><span class="p">,</span> <span class="mi">703</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">a</span> <span class="n">cough</span><span class="p">,</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">chest</span> <span class="n">pain</span><span class="p">,</span> <span class="n">fever</span><span class="p">,</span> <span class="n">pericarditis</span><span class="p">,</span> <span class="n">cough</span><span class="p">,</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">chest</span> <span class="n">pain</span><span class="p">]</span><span class="o">|</span><span class="p">[</span><span class="n">R05</span><span class="p">,</span> <span class="n">R10</span><span class="p">.</span><span class="mi">11</span><span class="p">,</span> <span class="n">A68</span><span class="p">,</span> <span class="n">I30</span><span class="p">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">R05</span><span class="p">,</span> <span class="n">R10</span><span class="p">.</span><span class="mi">11</span><span class="p">]</span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------+----------------------+-------------+-------------------------------------------------------------------------------------+--------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"word_embeddings"</span><span class="o">)</span>
    
<span class="c1">// to get PROBLEM entitis </span>
<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"word_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"clinical_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">clinical_ner_chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"clinical_ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"clinical_ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"PROBLEM"</span><span class="o">)</span>

<span class="c1">// to get DRUG entities </span>
<span class="k">val</span> <span class="nv">posology_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"word_embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"posology_ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posology_ner_chunk</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"posology_ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"posology_ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="s">"DRUG"</span><span class="o">)</span>

<span class="c1">// merge the chunks into a single ner_chunk </span>
<span class="k">val</span> <span class="nv">chunk_merger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"clinical_ner_chunk"</span><span class="o">,</span><span class="s">"posology_ner_chunk"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"final_ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMergeOverlapping</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// convert chunks to doc to get sentence embeddings of them </span>
<span class="k">val</span> <span class="nv">chunk2doc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Doc</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"final_ner_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"doc_final_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sbiobert_embeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"doc_final_chunk"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// filter PROBLEM entity embeddings </span>
<span class="k">val</span> <span class="nv">router_sentence_icd10</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Router</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setFilterFieldsElements</span><span class="o">(</span><span class="s">"PROBLEM"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"problem_embeddings"</span><span class="o">)</span>
    
<span class="c1">// filter DRUG entity embeddings </span>
<span class="k">val</span> <span class="nv">router_sentence_rxnorm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Router</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setFilterFieldsElements</span><span class="o">(</span><span class="s">"DRUG"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"drug_embeddings"</span><span class="o">)</span>
    
<span class="c1">// use problem_embeddings only </span>
<span class="k">val</span> <span class="nv">icd_resolver</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_icd10cm_slim_billable_hcc"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"problem_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"icd10cm_code"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span>
    
<span class="c1">// use drug_embeddings only </span>
<span class="k">val</span> <span class="nv">rxnorm_resolver</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_rxnorm_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"drug_embeddings"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"rxnorm_code"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">word_embeddings</span><span class="o">,</span> 
    <span class="n">clinical_ner</span><span class="o">,</span> 
    <span class="n">clinical_ner_chunk</span><span class="o">,</span> 
    <span class="n">posology_ner</span><span class="o">,</span> 
    <span class="n">posology_ner_chunk</span><span class="o">,</span> 
    <span class="n">chunk_merger</span><span class="o">,</span> 
    <span class="n">chunk2doc</span><span class="o">,</span> 
    <span class="n">sbiobert_embeddings</span><span class="o">,</span> 
    <span class="n">router_sentence_icd10</span><span class="o">,</span> 
    <span class="n">router_sentence_rxnorm</span><span class="o">,</span> 
    <span class="n">icd_resolver</span><span class="o">,</span> 
    <span class="n">rxnorm_resolver</span><span class="o">))</span>


<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"""The patient is a 41-year-old Vietnamese female with a cough that started last week.
She has had right-sided chest pain radiating to her back with fever starting yesterday.
She has a history of pericarditis in May 2006 and developed cough with right-sided chest pain.
MEDICATIONS
1. Coumadin 1 mg daily. Last INR was on Tuesday, August 14, 2007, and her INR was 2.3.
2. Amiodarone 100 mg p.o. daily."""</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">res</span> <span class="k">=</span> <span class="nv">mapperPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="c1">// Show results</span>

<span class="o">+-----------------------------------------------------------------------------------------------------------+----------------------+-------------+-------------------------------------------------------------------------------------+--------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>                                                                                                      <span class="o">|</span><span class="n">posology_chunk</span>        <span class="o">|</span><span class="n">rxnorm_code</span>  <span class="o">|</span><span class="n">clinical_chunk</span>                                                                       <span class="o">|</span><span class="n">icd10cm_code</span>                          <span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------+----------------------+-------------+-------------------------------------------------------------------------------------+--------------------------------------+</span>
<span class="o">|[</span><span class="kt">a</span> <span class="kt">cough</span>, <span class="kt">right-sided</span> <span class="kt">chest</span> <span class="kt">pain</span>, <span class="kt">fever</span>, <span class="kt">pericarditis</span>, <span class="kt">cough</span>, <span class="kt">right-sided</span> <span class="kt">chest</span> <span class="kt">pain</span>, <span class="kt">Coumadin</span>, <span class="kt">Amiodarone</span><span class="o">]|[</span><span class="kt">Coumadin</span>, <span class="kt">Amiodarone</span><span class="o">]|[</span><span class="err">202421</span>, <span class="err">703</span><span class="o">]|[</span><span class="kt">a</span> <span class="kt">cough</span>, <span class="kt">right-sided</span> <span class="kt">chest</span> <span class="kt">pain</span>, <span class="kt">fever</span>, <span class="kt">pericarditis</span>, <span class="kt">cough</span>, <span class="kt">right-sided</span> <span class="kt">chest</span> <span class="kt">pain</span><span class="o">]|[</span><span class="kt">R05</span>, <span class="kt">R10.</span><span class="err">11</span>, <span class="kt">A68</span>, <span class="kt">I30.</span><span class="err">1</span>, <span class="kt">R05</span>, <span class="kt">R10.</span><span class="err">11</span><span class="o">]|</span>
<span class="o">+-----------------------------------------------------------------------------------------------------------+----------------------+-------------+-------------------------------------------------------------------------------------+--------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="sentenceentityresolver">SentenceEntityResolver</h2>

  <div class="tabs-model-aproach-head tac"><button class="tab-li-model-aproach">Model</button><button class="tab-li-model-aproach tabheader_active">Approach</button></div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The model transforms a dataset with Input Annotation type SENTENCE_EMBEDDINGS, coming from e.g.
<a href="/docs/en/transformers#bertsentenceembeddings">BertSentenceEmbeddings</a>
and returns the normalized entity for a particular trained ontology / curated dataset (e.g. ICD-10, RxNorm, SNOMED etc.).</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">distanceFunction</code>: Determines how the distance between different entities will be calculated. Either <code class="language-plaintext highlighter-rouge">COSINE</code> or <code class="language-plaintext highlighter-rouge">EUCLIDEAN</code>.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">neighbours</code>: The number of neighbours to consider when computing the distances.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">caseSensitive</code>: WWhether to consider text casing or not.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">threshold</code>: Threshold of the distance between nodes to consider.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">DoExceptionHandling</code>: If it is set as True, the annotator tries to process as usual and ff exception-causing data (e.g. corrupted record/ document) is passed to the annotator, an exception warning is emitted which has the exception message.</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setInputcols()</code>.</p>

    <p>For a list of pretrained models, please see the
<a href="https://nlp.johnsnowlabs.com/models?task=Entity+Resolution">Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/resolution/sentence_entity_resolver/index.html#sparknlp_jsl.annotator.resolution.sentence_entity_resolver.SentenceEntityResolverModel">SentenceEntityResolverModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/SentenceEntityResolverModel.html">SentenceEntityResolverModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/SentenceEntityResolverModel.ipynb">SentenceEntityResolverModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">word_embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">clinical_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"jsl_ner_wip_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">NerConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"Test"</span><span class="p">,</span><span class="s">"Procedure"</span><span class="p">])</span>

<span class="n">c2doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Chunk2Doc</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk_doc"</span><span class="p">)</span>

<span class="n">sbert_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span>\
    <span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk_doc"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sbert_embeddings"</span><span class="p">)</span>

<span class="c1"># Then the resolver is defined on the extracted entities and sentence embeddings
</span><span class="n">cpt_resolver</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sbiobertresolve_cpt_procedures_augmented"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sbert_embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"cpt_code"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">word_embeddings</span><span class="p">,</span>
    <span class="n">clinical_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">,</span>
    <span class="n">c2doc</span><span class="p">,</span>
    <span class="n">sbert_embedder</span><span class="p">,</span>
    <span class="n">cpt_resolver</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""She was admitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left. CT scan of the chest also revealed a large mediastinal lymph node.
We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma.
At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy, which were performed, which revealed epithelioid malignant mesothelioma."""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="o">+--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="o">|</span>               <span class="n">chunk</span><span class="o">|</span>   <span class="n">entity</span><span class="o">|</span> <span class="n">code</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>       <span class="n">all_k_results</span><span class="o">|</span>   <span class="n">all_k_resolutions</span><span class="o">|</span>
<span class="o">+--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="o">|</span><span class="n">CT</span> <span class="n">scan</span> <span class="n">of</span> <span class="n">the</span> <span class="n">chest</span><span class="o">|</span>     <span class="n">Test</span><span class="o">|</span><span class="mi">62284</span><span class="o">|</span>    <span class="mf">0.2028</span><span class="o">|</span><span class="mi">62284</span><span class="p">:::</span><span class="mi">76497</span><span class="p">:::</span><span class="mf">7.</span><span class="p">..</span><span class="o">|</span><span class="n">Computed</span> <span class="n">tomograp</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>      <span class="n">pericardectomy</span><span class="o">|</span><span class="n">Procedure</span><span class="o">|</span><span class="mi">33031</span><span class="o">|</span>    <span class="mf">0.3329</span><span class="o">|</span><span class="mi">33031</span><span class="p">:::</span><span class="mi">33025</span><span class="p">:::</span><span class="mf">3.</span><span class="p">..</span><span class="o">|</span><span class="n">Pericardectomy</span> <span class="p">[</span><span class="n">P</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="n">chest</span> <span class="n">tube</span> <span class="n">placement</span><span class="o">|</span><span class="n">Procedure</span><span class="o">|</span><span class="mi">39503</span><span class="o">|</span>    <span class="mf">0.9343</span><span class="o">|</span><span class="mi">39503</span><span class="p">:::</span><span class="mi">32036</span><span class="p">:::</span><span class="mf">3.</span><span class="p">..</span><span class="o">|</span><span class="n">Insertion</span> <span class="n">of</span> <span class="n">ches</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span><span class="n">drainage</span> <span class="n">of</span> <span class="n">the</span> <span class="n">f</span><span class="p">...</span><span class="o">|</span><span class="n">Procedure</span><span class="o">|</span><span class="mi">49405</span><span class="o">|</span>    <span class="mf">0.2476</span><span class="o">|</span><span class="mi">49405</span><span class="p">:::</span><span class="mi">49407</span><span class="p">:::</span><span class="mf">4.</span><span class="p">..</span><span class="o">|</span><span class="n">Drainage</span> <span class="n">procedur</span><span class="p">...</span><span class="o">|</span>
<span class="o">|</span>        <span class="n">thoracoscopy</span><span class="o">|</span><span class="n">Procedure</span><span class="o">|</span><span class="mi">32660</span><span class="o">|</span>    <span class="mf">0.1422</span><span class="o">|</span><span class="mi">32660</span><span class="p">:::</span><span class="mi">32667</span><span class="p">:::</span><span class="mf">1.</span><span class="p">..</span><span class="o">|</span><span class="n">Thoracoscopy</span> <span class="p">[</span><span class="n">Tho</span><span class="p">...</span><span class="o">|</span>
<span class="o">+--------------------+---------+-----+----------+--------------------+--------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"tfhub_use"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>

<span class="n">resolver</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finel_edgar_company_name"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span> \
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"normalized"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
      <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">documentAssembler</span><span class="p">,</span>
          <span class="n">embeddings</span><span class="p">,</span>
          <span class="n">resolver</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""CONTACT GOLD"""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="o">+------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>       <span class="o">|</span><span class="n">result</span>            <span class="o">|</span><span class="n">all_k_results</span>                                                                                                                                                                                                                                  <span class="o">|</span><span class="n">all_k_resolutions</span>                                                                                                                                                                                                                              <span class="o">|</span>
<span class="o">+------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">CONTACT</span> <span class="n">GOLD</span><span class="o">|</span><span class="n">Contact</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.</span><span class="o">|</span><span class="n">Contact</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.:::</span><span class="n">ISHARES</span> <span class="n">GOLD</span> <span class="n">TRUST</span><span class="p">:::</span><span class="n">Minatura</span> <span class="n">Gold</span><span class="p">:::</span><span class="n">Mexus</span> <span class="n">Gold</span> <span class="n">US</span><span class="p">:::</span><span class="n">BESRA</span> <span class="n">GOLD</span> <span class="n">INC</span><span class="p">.:::</span><span class="n">ALAMOS</span> <span class="n">GOLD</span> <span class="n">INC</span><span class="p">:::</span><span class="n">JOSHUA</span> <span class="n">GOLD</span> <span class="n">RESOURCES</span> <span class="n">INC</span><span class="p">:::</span><span class="n">MIDEX</span> <span class="n">GOLD</span> <span class="n">CORP</span><span class="p">.:::</span><span class="n">Gold</span> <span class="n">Mark</span> <span class="n">Stephen</span><span class="p">:::</span><span class="n">Guskin</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.:::</span><span class="n">CMX</span> <span class="n">GOLD</span> <span class="o">&amp;</span> <span class="n">SILVER</span> <span class="n">CORP</span><span class="p">.:::</span><span class="n">Permal</span> <span class="n">Gold</span> <span class="n">Ltd</span><span class="p">.</span><span class="o">|</span><span class="n">Contact</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.:::</span><span class="n">ISHARES</span> <span class="n">GOLD</span> <span class="n">TRUST</span><span class="p">:::</span><span class="n">Minatura</span> <span class="n">Gold</span><span class="p">:::</span><span class="n">Mexus</span> <span class="n">Gold</span> <span class="n">US</span><span class="p">:::</span><span class="n">BESRA</span> <span class="n">GOLD</span> <span class="n">INC</span><span class="p">.:::</span><span class="n">ALAMOS</span> <span class="n">GOLD</span> <span class="n">INC</span><span class="p">:::</span><span class="n">JOSHUA</span> <span class="n">GOLD</span> <span class="n">RESOURCES</span> <span class="n">INC</span><span class="p">:::</span><span class="n">MIDEX</span> <span class="n">GOLD</span> <span class="n">CORP</span><span class="p">.:::</span><span class="n">Gold</span> <span class="n">Mark</span> <span class="n">Stephen</span><span class="p">:::</span><span class="n">Guskin</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.:::</span><span class="n">CMX</span> <span class="n">GOLD</span> <span class="o">&amp;</span> <span class="n">SILVER</span> <span class="n">CORP</span><span class="p">.:::</span><span class="n">Permal</span> <span class="n">Gold</span> <span class="n">Ltd</span><span class="p">.</span><span class="o">|</span>
<span class="o">+------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span> 

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
      <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">UniversalSentenceEncoder</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"tfhub_use"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence_embeddings"</span><span class="p">)</span>
    
<span class="n">resolver</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">SentenceEntityResolverModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legel_edgar_company_name"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence_embeddings"</span><span class="p">])</span>\
      <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"irs_code"</span><span class="p">)</span>\
      <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDEAN"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
      <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
          <span class="n">documentAssembler</span><span class="p">,</span>
          <span class="n">embeddings</span><span class="p">,</span>
          <span class="n">resolver</span><span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""CONTACT GOLD"""</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="c1"># Show Results
</span><span class="o">+------------+------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>       <span class="o">|</span><span class="n">result</span>            <span class="o">|</span><span class="n">code</span>                                                                                         <span class="o">|</span><span class="n">all_k_results</span>                                                                                                                                                                                                                                  <span class="o">|</span><span class="n">all_k_resolutions</span>                                                                                                                                                                                                                              <span class="o">|</span>
<span class="o">+------------+------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">CONTACT</span> <span class="n">GOLD</span><span class="o">|</span><span class="n">Contact</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.</span><span class="o">|</span><span class="mi">981369960</span><span class="p">:::</span><span class="mi">0</span><span class="p">:::</span><span class="mi">208273426</span><span class="p">:::</span><span class="mi">204092640</span><span class="p">:::</span><span class="mi">0</span><span class="p">:::</span><span class="mi">0</span><span class="p">:::</span><span class="mi">270531073</span><span class="p">:::</span><span class="mi">261918920</span><span class="p">:::</span><span class="mi">0</span><span class="p">:::</span><span class="mi">271989147</span><span class="p">:::</span><span class="mi">0</span><span class="p">:::</span><span class="mi">0</span><span class="o">|</span><span class="n">Contact</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.:::</span><span class="n">ISHARES</span> <span class="n">GOLD</span> <span class="n">TRUST</span><span class="p">:::</span><span class="n">Minatura</span> <span class="n">Gold</span><span class="p">:::</span><span class="n">Mexus</span> <span class="n">Gold</span> <span class="n">US</span><span class="p">:::</span><span class="n">BESRA</span> <span class="n">GOLD</span> <span class="n">INC</span><span class="p">.:::</span><span class="n">ALAMOS</span> <span class="n">GOLD</span> <span class="n">INC</span><span class="p">:::</span><span class="n">JOSHUA</span> <span class="n">GOLD</span> <span class="n">RESOURCES</span> <span class="n">INC</span><span class="p">:::</span><span class="n">MIDEX</span> <span class="n">GOLD</span> <span class="n">CORP</span><span class="p">.:::</span><span class="n">Gold</span> <span class="n">Mark</span> <span class="n">Stephen</span><span class="p">:::</span><span class="n">Guskin</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.:::</span><span class="n">CMX</span> <span class="n">GOLD</span> <span class="o">&amp;</span> <span class="n">SILVER</span> <span class="n">CORP</span><span class="p">.:::</span><span class="n">Permal</span> <span class="n">Gold</span> <span class="n">Ltd</span><span class="p">.</span><span class="o">|</span><span class="n">Contact</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.:::</span><span class="n">ISHARES</span> <span class="n">GOLD</span> <span class="n">TRUST</span><span class="p">:::</span><span class="n">Minatura</span> <span class="n">Gold</span><span class="p">:::</span><span class="n">Mexus</span> <span class="n">Gold</span> <span class="n">US</span><span class="p">:::</span><span class="n">BESRA</span> <span class="n">GOLD</span> <span class="n">INC</span><span class="p">.:::</span><span class="n">ALAMOS</span> <span class="n">GOLD</span> <span class="n">INC</span><span class="p">:::</span><span class="n">JOSHUA</span> <span class="n">GOLD</span> <span class="n">RESOURCES</span> <span class="n">INC</span><span class="p">:::</span><span class="n">MIDEX</span> <span class="n">GOLD</span> <span class="n">CORP</span><span class="p">.:::</span><span class="n">Gold</span> <span class="n">Mark</span> <span class="n">Stephen</span><span class="p">:::</span><span class="n">Guskin</span> <span class="n">Gold</span> <span class="n">Corp</span><span class="p">.:::</span><span class="n">CMX</span> <span class="n">GOLD</span> <span class="o">&amp;</span> <span class="n">SILVER</span> <span class="n">CORP</span><span class="p">.:::</span><span class="n">Permal</span> <span class="n">Gold</span> <span class="n">Ltd</span><span class="p">.</span><span class="o">|</span>
<span class="o">+------------+------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">word_embeddings</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">clinical_ner</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"jsl_ner_wip_clinical"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span><span class="s">"token"</span><span class="o">,</span><span class="s">"ner"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"Test"</span><span class="o">,</span><span class="s">"Procedure"</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">c2doc</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Chunk2Doc</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">sbert_embedder</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobert_base_cased_mli"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk_doc"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">)</span> 

<span class="c1">// Then the resolver is defined on the extracted entities and sentence embeddings </span>

<span class="k">val</span> <span class="nv">cpt_resolver</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sbiobertresolve_cpt_procedures_augmented"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sbert_embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"cpt_code"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span> 
                                              <span class="n">documentAssembler</span><span class="o">,</span> 
                                              <span class="n">sentenceDetector</span><span class="o">,</span> 
                                              <span class="n">tokenizer</span><span class="o">,</span>
                                              <span class="n">word_embeddings</span><span class="o">,</span> 
                                              <span class="n">clinical_ner</span><span class="o">,</span> 
                                              <span class="n">ner_converter</span><span class="o">,</span> 
                                              <span class="n">c2doc</span><span class="o">,</span> 
                                              <span class="n">sbert_embedder</span><span class="o">,</span> 
                                              <span class="n">cpt_resolver</span><span class="o">))</span> 


<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"She was admitted to the hospital with chest pain and found to have bilateral pleural effusion,the right greater than the left. CT scan of the chest also revealed a large mediastinal lymph node. We reviewed the pathology obtained from the pericardectomy in March 2006,which was diagnostic of mesothelioma. At this time,chest tube placement for drainage of the fluid occurred and thoracoscopy,which were performed,which revealed epithelioid malignant mesothelioma."</span> 

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// Show Results</span>
<span class="o">+--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="o">|</span>               <span class="n">chunk</span><span class="o">|</span>   <span class="n">entity</span><span class="o">|</span> <span class="n">code</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>       <span class="n">all_k_results</span><span class="o">|</span>   <span class="n">all_k_resolutions</span><span class="o">|</span>
<span class="o">+--------------------+---------+-----+----------+--------------------+--------------------+</span>
<span class="o">|</span><span class="nc">CT</span> <span class="n">scan</span> <span class="n">of</span> <span class="n">the</span> <span class="n">chest</span><span class="o">|</span>     <span class="nc">Test</span><span class="o">|</span><span class="mi">62284</span><span class="o">|</span>    <span class="mf">0.2028</span><span class="o">|</span><span class="mi">62284</span><span class="o">:::</span><span class="mi">76497</span><span class="o">:::</span><span class="mf">7.</span><span class="o">..|</span><span class="nc">Computed</span> <span class="n">tomograp</span><span class="o">...|</span>
<span class="o">|</span>      <span class="n">pericardectomy</span><span class="o">|</span><span class="nc">Procedure</span><span class="o">|</span><span class="mi">33031</span><span class="o">|</span>    <span class="mf">0.3329</span><span class="o">|</span><span class="mi">33031</span><span class="o">:::</span><span class="mi">33025</span><span class="o">:::</span><span class="mf">3.</span><span class="o">..|</span><span class="nc">Pericardectomy</span> <span class="o">[</span><span class="kt">P...|</span>
<span class="kt">|chest</span> <span class="kt">tube</span> <span class="kt">placement|Procedure|</span><span class="err">39503</span><span class="kt">|</span>    <span class="err">0</span><span class="kt">.</span><span class="err">9343</span><span class="kt">|</span><span class="err">39503</span><span class="kt">:::</span><span class="err">32036</span><span class="kt">:::</span><span class="err">3</span><span class="kt">...|Insertion</span> <span class="kt">of</span> <span class="kt">ches...|</span>
<span class="kt">|drainage</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">f...|Procedure|</span><span class="err">49405</span><span class="kt">|</span>    <span class="err">0</span><span class="kt">.</span><span class="err">2476</span><span class="kt">|</span><span class="err">49405</span><span class="kt">:::</span><span class="err">49407</span><span class="kt">:::</span><span class="err">4</span><span class="kt">...|Drainage</span> <span class="kt">procedur...|</span>
<span class="kt">|</span>        <span class="kt">thoracoscopy|Procedure|</span><span class="err">32660</span><span class="kt">|</span>    <span class="err">0</span><span class="kt">.</span><span class="err">1422</span><span class="kt">|</span><span class="err">32660</span><span class="kt">:::</span><span class="err">32667</span><span class="kt">:::</span><span class="err">1</span><span class="kt">...|Thoracoscopy</span> <span class="o">[</span><span class="kt">Tho...|</span>
<span class="kt">+--------------------+---------+-----+----------+--------------------+--------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"tfhub_use"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">resolver</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finel_edgar_company_name"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"sentence_embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"normalized"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                            <span class="n">documentAssembler</span><span class="o">,</span> 
                                            <span class="n">embeddings</span><span class="o">,</span> 
                                            <span class="n">resolver</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"CONTACT GOLD"</span> 
<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span> 

<span class="c1">// Show Results</span>
<span class="o">+------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>       <span class="o">|</span><span class="n">result</span>            <span class="o">|</span><span class="n">all_k_results</span>                                                                                                                                                                                                                                  <span class="o">|</span><span class="n">all_k_resolutions</span>                                                                                                                                                                                                                              <span class="o">|</span>
<span class="o">+------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">CONTACT</span> <span class="nc">GOLD</span><span class="o">|</span><span class="nc">Contact</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.|</span><span class="nc">Contact</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.:::</span><span class="nc">ISHARES</span> <span class="nc">GOLD</span> <span class="nc">TRUST</span><span class="o">:::</span><span class="nc">Minatura</span> <span class="nc">Gold</span><span class="o">:::</span><span class="nc">Mexus</span> <span class="nc">Gold</span> <span class="nc">US</span><span class="o">:::</span><span class="nc">BESRA</span> <span class="nc">GOLD</span> <span class="nc">INC</span><span class="o">.:::</span><span class="nc">ALAMOS</span> <span class="nc">GOLD</span> <span class="nc">INC</span><span class="o">:::</span><span class="nc">JOSHUA</span> <span class="nc">GOLD</span> <span class="nc">RESOURCES</span> <span class="nc">INC</span><span class="o">:::</span><span class="nc">MIDEX</span> <span class="nc">GOLD</span> <span class="nc">CORP</span><span class="o">.:::</span><span class="nc">Gold</span> <span class="nc">Mark</span> <span class="nc">Stephen</span><span class="o">:::</span><span class="nc">Guskin</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.:::</span><span class="nc">CMX</span> <span class="nc">GOLD</span> <span class="o">&amp;</span> <span class="nc">SILVER</span> <span class="nc">CORP</span><span class="o">.:::</span><span class="nc">Permal</span> <span class="nc">Gold</span> <span class="nc">Ltd</span><span class="o">.|</span><span class="nc">Contact</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.:::</span><span class="nc">ISHARES</span> <span class="nc">GOLD</span> <span class="nc">TRUST</span><span class="o">:::</span><span class="nc">Minatura</span> <span class="nc">Gold</span><span class="o">:::</span><span class="nc">Mexus</span> <span class="nc">Gold</span> <span class="nc">US</span><span class="o">:::</span><span class="nc">BESRA</span> <span class="nc">GOLD</span> <span class="nc">INC</span><span class="o">.:::</span><span class="nc">ALAMOS</span> <span class="nc">GOLD</span> <span class="nc">INC</span><span class="o">:::</span><span class="nc">JOSHUA</span> <span class="nc">GOLD</span> <span class="nc">RESOURCES</span> <span class="nc">INC</span><span class="o">:::</span><span class="nc">MIDEX</span> <span class="nc">GOLD</span> <span class="nc">CORP</span><span class="o">.:::</span><span class="nc">Gold</span> <span class="nc">Mark</span> <span class="nc">Stephen</span><span class="o">:::</span><span class="nc">Guskin</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.:::</span><span class="nc">CMX</span> <span class="nc">GOLD</span> <span class="o">&amp;</span> <span class="nc">SILVER</span> <span class="nc">CORP</span><span class="o">.:::</span><span class="nc">Permal</span> <span class="nc">Gold</span> <span class="nc">Ltd</span><span class="o">.|</span>
<span class="o">+------------+------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">UniversalSentenceEncoder</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"tfhub_use"</span><span class="o">,</span><span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence_embeddings"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">resolver</span> <span class="k">=</span> <span class="nv">SentenceEntityResolverModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legel_edgar_company_name"</span><span class="o">,</span><span class="s">"en"</span><span class="o">,</span><span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span><span class="s">"sentence_embeddings"</span><span class="o">))</span> 
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"irs_code"</span><span class="o">)</span> <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDEAN"</span><span class="o">)</span> 

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
                                            <span class="n">documentAssembler</span><span class="o">,</span> 
                                            <span class="n">embeddings</span><span class="o">,</span> 
                                            <span class="n">resolver</span><span class="o">))</span> 

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"CONTACT GOLD"</span> 

<span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">)</span> <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span> 
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="c1">// Show Results</span>
<span class="o">+------------+------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">chunk</span>       <span class="o">|</span><span class="n">result</span>            <span class="o">|</span><span class="n">code</span>                                                                                         <span class="o">|</span><span class="n">all_k_results</span>                                                                                                                                                                                                                                  <span class="o">|</span><span class="n">all_k_resolutions</span>                                                                                                                                                                                                                              <span class="o">|</span>
<span class="o">+------------+------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">CONTACT</span> <span class="nc">GOLD</span><span class="o">|</span><span class="nc">Contact</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.|</span><span class="mi">981369960</span><span class="o">:::</span><span class="mi">0</span><span class="o">:::</span><span class="mi">208273426</span><span class="o">:::</span><span class="mi">204092640</span><span class="o">:::</span><span class="mi">0</span><span class="o">:::</span><span class="mi">0</span><span class="o">:::</span><span class="mi">270531073</span><span class="o">:::</span><span class="mi">261918920</span><span class="o">:::</span><span class="mi">0</span><span class="o">:::</span><span class="mi">271989147</span><span class="o">:::</span><span class="mi">0</span><span class="o">:::</span><span class="mi">0</span><span class="o">|</span><span class="nc">Contact</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.:::</span><span class="nc">ISHARES</span> <span class="nc">GOLD</span> <span class="nc">TRUST</span><span class="o">:::</span><span class="nc">Minatura</span> <span class="nc">Gold</span><span class="o">:::</span><span class="nc">Mexus</span> <span class="nc">Gold</span> <span class="nc">US</span><span class="o">:::</span><span class="nc">BESRA</span> <span class="nc">GOLD</span> <span class="nc">INC</span><span class="o">.:::</span><span class="nc">ALAMOS</span> <span class="nc">GOLD</span> <span class="nc">INC</span><span class="o">:::</span><span class="nc">JOSHUA</span> <span class="nc">GOLD</span> <span class="nc">RESOURCES</span> <span class="nc">INC</span><span class="o">:::</span><span class="nc">MIDEX</span> <span class="nc">GOLD</span> <span class="nc">CORP</span><span class="o">.:::</span><span class="nc">Gold</span> <span class="nc">Mark</span> <span class="nc">Stephen</span><span class="o">:::</span><span class="nc">Guskin</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.:::</span><span class="nc">CMX</span> <span class="nc">GOLD</span> <span class="o">&amp;</span> <span class="nc">SILVER</span> <span class="nc">CORP</span><span class="o">.:::</span><span class="nc">Permal</span> <span class="nc">Gold</span> <span class="nc">Ltd</span><span class="o">.|</span><span class="nc">Contact</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.:::</span><span class="nc">ISHARES</span> <span class="nc">GOLD</span> <span class="nc">TRUST</span><span class="o">:::</span><span class="nc">Minatura</span> <span class="nc">Gold</span><span class="o">:::</span><span class="nc">Mexus</span> <span class="nc">Gold</span> <span class="nc">US</span><span class="o">:::</span><span class="nc">BESRA</span> <span class="nc">GOLD</span> <span class="nc">INC</span><span class="o">.:::</span><span class="nc">ALAMOS</span> <span class="nc">GOLD</span> <span class="nc">INC</span><span class="o">:::</span><span class="nc">JOSHUA</span> <span class="nc">GOLD</span> <span class="nc">RESOURCES</span> <span class="nc">INC</span><span class="o">:::</span><span class="nc">MIDEX</span> <span class="nc">GOLD</span> <span class="nc">CORP</span><span class="o">.:::</span><span class="nc">Gold</span> <span class="nc">Mark</span> <span class="nc">Stephen</span><span class="o">:::</span><span class="nc">Guskin</span> <span class="nc">Gold</span> <span class="nc">Corp</span><span class="o">.:::</span><span class="nc">CMX</span> <span class="nc">GOLD</span> <span class="o">&amp;</span> <span class="nc">SILVER</span> <span class="nc">CORP</span><span class="o">.:::</span><span class="nc">Permal</span> <span class="nc">Gold</span> <span class="nc">Ltd</span><span class="o">.|</span>
<span class="o">+------------+------------------+---------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

  <!--Aproach-->
  <div class="h3-box tabs-python-scala-box">

    <p>Trains a SentenceEntityResolverModel that maps sentence embeddings to entities in a knowledge base.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">labelCol</code> : Column name for the value we are trying to resolve. Usually this contains the entity ID in the knowledge base (e.g., the ICD-10 code).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">normalizedCol</code>: Column name for the original, normalized description</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">aux_label_col</code>: Auxiliary label which maps resolved entities to additional labels</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">useAuxLabel</code>: Whether to use the auxiliary column or not. Default value is False.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">distanceFunction</code>: Determines how the distance between different entities will be calculated.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">confidenceFunction</code>: What function to use to calculate confidence: Either ` <code class="language-plaintext highlighter-rouge">INVERSE</code> or <code class="language-plaintext highlighter-rouge">SOFTMAX</code>.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">caseSensitive</code>: whether to ignore case in tokens for embeddings matching (Default: <code class="language-plaintext highlighter-rouge">False</code>)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">threshold</code>: Threshold value for the last distance calculated (default: 5.0)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">missAsEmpty</code>: whether or not to return an empty annotation on unmatched chunks (default: <code class="language-plaintext highlighter-rouge">True</code>)</p>
      </li>
    </ul>

    <p>When finetuning an existing model, there are additional parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">pretrainedModelPath</code>: Path to an already trained SentenceEntityResolverModel.This pretrained model will be used as a starting point for training the new one. The path can be a local file path, a distributed file path (HDFS, DBFS), or a cloud storage (S3).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">overrideExistingCodes</code>: Whether to override the existing codes with new data while continue the training from a pretrained model. Default value is <code class="language-plaintext highlighter-rouge">False</code> (keep all the codes).</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">dropCodesList</code>: A list of codes in a pretrained model that will be omitted when the training process begins with a pretrained model.</p>
      </li>
    </ul>

    <p>You can find pretrained Sentence Embeddings (using BERT or other architecgture) in the <code class="language-plaintext highlighter-rouge">NLP Models Hub &lt;https://nlp.johnsnowlabs.com/models?task=Embeddings&gt;</code>_.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">SENTENCE_EMBEDDINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/resolution/sentence_entity_resolver/index.html#sparknlp_jsl.annotator.resolution.sentence_entity_resolver.SentenceEntityResolverApproach">SentenceEntityResolverApproach</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/resolution/SentenceEntityResolverApproach.html">SentenceEntityResolverApproach</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/SentenceEntityResolverApproach.ipynb">SentenceEntityResolverApproachNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span> 

<span class="c1"># Training a SNOMED resolution model using BERT sentence embeddings
# Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">bertEmbeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">snomedTrainingPipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">bertEmbeddings</span>
<span class="p">])</span>
<span class="n">snomedTrainingModel</span> <span class="o">=</span> <span class="n">snomedTrainingPipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">snomedData</span> <span class="o">=</span> <span class="n">snomedTrainingModel</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">bertExtractor</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">SentenceEntityResolverApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"bert_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_code"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDIAN"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">snomedModel</span> <span class="o">=</span> <span class="n">bertExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">snomedData</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="c1"># Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">bertEmbeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_bert_large_cased"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">preprocessing_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">bertEmbeddings</span>
<span class="p">])</span>
<span class="n">preprocessing_model</span> <span class="o">=</span> <span class="n">preprocessing_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">processed_data</span> <span class="o">=</span> <span class="n">preprocessing_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">bertExtractor</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">SentenceEntityResolverApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"bert_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_code"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDIAN"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">bertExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">processed_data</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="c1"># Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.
</span><span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">bertEmbeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertSentenceEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sent_bert_base_uncased_legal"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"bert_embeddings"</span><span class="p">)</span>

<span class="n">preprocessing_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">sentenceDetector</span><span class="p">,</span>
  <span class="n">bertEmbeddings</span>
<span class="p">])</span>
<span class="n">data_preprocessing_model</span> <span class="o">=</span> <span class="n">preprocessing_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">processed_data</span> <span class="o">=</span> <span class="n">data_preprocessing_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">cache</span><span class="p">()</span>

<span class="c1"># Then the Resolver can be trained with
</span><span class="n">bertExtractor</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">SentenceEntityResolverApproach</span><span class="p">()</span> \
  <span class="p">.</span><span class="n">setNeighbours</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setThreshold</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"bert_embeddings"</span><span class="p">])</span> \
  <span class="p">.</span><span class="n">setNormalizedCol</span><span class="p">(</span><span class="s">"normalized_text"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setLabelCol</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"snomed_code"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setDistanceFunction</span><span class="p">(</span><span class="s">"EUCLIDIAN"</span><span class="p">)</span> \
  <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">bertExtractor</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">processed_data</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Training a SNOMED resolution model using BERT sentence embeddings</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">bertEmbeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
   <span class="n">documentAssembler</span><span class="o">,</span>
   <span class="n">sentenceDetector</span><span class="o">,</span>
   <span class="n">bertEmbeddings</span>
 <span class="o">))</span>

 <span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">bertExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDIAN"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedModel</span> <span class="k">=</span> <span class="nv">bertExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Training a SNOMED resolution model using BERT sentence embeddings</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">bertEmbeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
   
 <span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
   <span class="n">documentAssembler</span><span class="o">,</span>
   <span class="n">sentenceDetector</span><span class="o">,</span>
   <span class="n">bertEmbeddings</span>
 <span class="o">))</span>
 <span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">bertExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDIAN"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedModel</span> <span class="k">=</span> <span class="nv">bertExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">// Training a SNOMED resolution model using BERT sentence embeddings</span>
<span class="c1">// Define pre-processing pipeline for training data. It needs consists of columns for the normalized training data and their labels.</span>
<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
   <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">bertEmbeddings</span> <span class="k">=</span> <span class="nv">BertSentenceEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sent_biobert_pubmed_base_cased"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
   <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>

 <span class="k">val</span> <span class="nv">snomedTrainingPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
   <span class="n">documentAssembler</span><span class="o">,</span>
   <span class="n">sentenceDetector</span><span class="o">,</span>
   <span class="n">bertEmbeddings</span>
 <span class="o">))</span>
 <span class="k">val</span> <span class="nv">snomedTrainingModel</span> <span class="k">=</span> <span class="nv">snomedTrainingPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
 <span class="k">val</span> <span class="nv">snomedData</span> <span class="k">=</span> <span class="nv">snomedTrainingModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">cache</span><span class="o">()</span>

<span class="c1">// Then the Resolver can be trained with</span>
<span class="k">val</span> <span class="nv">bertExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceEntityResolverApproach</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setNeighbours</span><span class="o">(</span><span class="mi">25</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setThreshold</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"bert_embeddings"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNormalizedCol</span><span class="o">(</span><span class="s">"normalized_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setLabelCol</span><span class="o">(</span><span class="s">"label"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"snomed_code"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDistanceFunction</span><span class="o">(</span><span class="s">"EUCLIDIAN"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">snomedModel</span> <span class="k">=</span> <span class="nv">bertExtractor</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">snomedData</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala-->

</details>

  </div>
  <!--END Aproach-->

</div>

<div class="tabs-model-aproach">

  <h2 id="structuredjsonconverter">StructuredJsonConverter</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator integrates seamlessly with existing systems to process outputs from pretrained pipelines, delivering structured, easy-to-read results in a dictionary format. 
Optimized for API integration and user-friendly outputs, it supports streamlined data analysis workflows by converting raw annotations into a prettified, structured JSON format.
With configurable schema mappings, it accommodates diverse outputs, including entities, assertions, resolutions, relations, summaries, deidentifications, and classifications. 
It uses column_maps to define output columns and align them with pipeline requirements. It handles diverse annotation types, including entities, assertions, resolutions, relations, summaries, deidentifications, and classifications.
It produces well-structured, easy-to-read results ideal for API consumption and streamlined workflows.</p>

    <p>Parameters:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">cleanAnnotations</code>: Whether to remove annotation columns, by default False.</li>
      <li><code class="language-plaintext highlighter-rouge">returnRelationEntities</code>: Whether to return the entities in the relations or not, by default False.</li>
      <li><code class="language-plaintext highlighter-rouge">parentSource</code>: Parent source of the output.</li>
    </ul>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Available options: `chunk` and ``.
When set to `chunk`, the output will be designed as a chunk-based struct with the following schema::
|-- json_output: array (nullable = true)
|    |-- element: struct (containsNull = true)
|    |    |-- chunk_id: string (nullable = true)
|    |    |-- chunk: string (nullable = true)
|    |    |-- begin: integer (nullable = true)
|    |    |-- end: integer (nullable = true)
|    |    |-- sentence_id: integer (nullable = true)
|    |    |-- sentence: string (nullable = true)
|    |    |-- ner_label: string (nullable = true)
|    |    |-- ner_source: string (nullable = true)
|    |    |-- ner_confidence: string (nullable = true)
|    |    |-- assertion: string (nullable = true)
|    |    |-- assertion_confidence: string (nullable = true)
|    |    |-- relations: array (nullable = true)
|    |    |    |-- element: map (containsNull = true)
|    |    |    |    |-- key: string
|    |    |    |    |-- value: string (valueContainsNull = true)
  
</code></pre></div>    </div>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">sentenceColumn</code>: Sentence column name. The sentence column is used to extract sentence of the chunk.</li>
      <li><code class="language-plaintext highlighter-rouge">outputAsStr</code>:  Whether to output the result as a string or as a structured json, by default True.</li>
    </ul>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
When set to `True`, the output column will be a string:

|-- column_name: string (nullable = true)

When set to False, the output column will be a struct with the following schema:

|-- column_name: struct (nullable = true)
      |-- document_identifier: string (nullable = true)
      |-- document_text: array (nullable = true)
      |    |-- element: string (containsNull = true)
      |-- entities: array (nullable = true)
      |    |-- element: map (containsNull = true)
      |        |-- key: string
      |        |-- value: string (valueContainsNull = true)
      |-- assertions: array (nullable = true)
      |    |-- element: map (containsNull = true)
      |        |-- key: string
      |        |-- value: string (valueContainsNull = true)
      |-- resolutions: array (nullable = true)
      |    |-- element: map (containsNull = true)
      |        |-- key: string
      |        |-- value: string (valueContainsNull = true)
      |-- relations: array (nullable = true)
      |    |-- element: map (containsNull = true)
      |        |-- key: string
      |        |-- value: string (valueContainsNull = true)
      |-- summaries: array (nullable = true)
      |    |-- element: string (containsNull = true)
      |-- deidentifications: array (nullable = true)
      |    |-- element: map (containsNull = true)
      |        |-- key: string
      |        |-- value: string (valueContainsNull = true)
      |-- classifications: array (nullable = true)
      |    |-- element: map (containsNull = true)
      |        |-- key: string
      |        |-- value: string (valueContainsNull = true)


</code></pre></div>    </div>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">converterSchema</code> and <code class="language-plaintext highlighter-rouge">converterSchemaAsStr</code>: The schema for converting the output of the pipeline into a structured JSON format. Fields in the schema:
        <ul>
          <li><code class="language-plaintext highlighter-rouge">document_identifier</code>: The identifier of the document. This column must be of type <code class="language-plaintext highlighter-rouge">StringType</code>.</li>
          <li><code class="language-plaintext highlighter-rouge">document_text</code>: The text of the document, typically created by the <code class="language-plaintext highlighter-rouge">DocumentAssembler</code> annotator.</li>
          <li><code class="language-plaintext highlighter-rouge">entities</code>: Chunk columns generated by various annotators, such as the <code class="language-plaintext highlighter-rouge">ChunkMergeModel</code> annotator.</li>
          <li><code class="language-plaintext highlighter-rouge">assertions</code>: Assertion columns produced by annotators like the <code class="language-plaintext highlighter-rouge">AssertionDLModel</code> annotator.</li>
          <li><code class="language-plaintext highlighter-rouge">resolutions</code>: The schema for resolutions. See <code class="language-plaintext highlighter-rouge">ResolutionSchema</code> for details.</li>
          <li><code class="language-plaintext highlighter-rouge">relations</code>: Relation columns created by annotators such as the <code class="language-plaintext highlighter-rouge">RelationExtractionModel</code> annotator.</li>
          <li><code class="language-plaintext highlighter-rouge">summaries</code>: Summary columns generated by annotators like the <code class="language-plaintext highlighter-rouge">MedicalSummarizer</code> annotator.</li>
          <li><code class="language-plaintext highlighter-rouge">deidentifications</code>: The schema for deidentifications.</li>
          <li><code class="language-plaintext highlighter-rouge">classifications</code>: The schema for classifications.</li>
        </ul>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">ANY</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">JSON</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/parser/StructuredJsonConverter/index.html">StructuredJsonConverter</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/parser/StructuredJsonConverter.html">StructuredJsonConverter</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/StructuredJsonConverter.ipynb">StructuredJsonConverter</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>
<span class="kn">from</span> <span class="nn">sparknlp_jsl.pipeline_tracer</span> <span class="kn">import</span> <span class="n">PipelineTracer</span>

<span class="n">oncology_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PretrainedPipeline</span><span class="p">(</span><span class="s">"explain_clinical_doc_oncology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""The Patient underwent a computed tomography (CT) scan of the abdomen and pelvis, which showed a complex ovarian mass. A Pap smear performed one month later was positive for atypical glandular cells suspicious for adenocarcinoma. The pathologic specimen showed extension of the tumor throughout the fallopian tubes, appendix, omentum, and 5 out of 5 enlarged lymph nodes. The final pathologic diagnosis of the tumor was stage IIIC papillary serous ovarian adenocarcinoma. Two months later, the patient was diagnosed with lung metastases.Neoadjuvant chemotherapy with the regimens of Cyclophosphamide (500 mg/m2) is being given for 6 cycles with poor response"""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result_df</span> <span class="o">=</span> <span class="n">oncology_pipeline</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">pipeline_tracer</span> <span class="o">=</span> <span class="n">PipelineTracer</span><span class="p">(</span><span class="n">oncology_pipeline</span><span class="p">)</span>

<span class="n">column_maps</span> <span class="o">=</span> <span class="n">pipeline_tracer</span><span class="p">.</span><span class="n">createParserDictionary</span><span class="p">()</span>

<span class="n">output_converter</span> <span class="o">=</span> <span class="n">StructuredJsonConverter</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"result"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setConverterSchema</span><span class="p">(</span><span class="n">column_maps</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCleanAnnotations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setReturnRelationEntities</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputAsStr</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">json_output</span> <span class="o">=</span> <span class="n">output_converter</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">result_df</span><span class="p">).</span><span class="n">select</span><span class="p">(</span><span class="s">"result"</span><span class="p">)</span>

<span class="n">json_output</span><span class="p">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="c1"># result
</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                  <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">{</span><span class="s">"result"</span><span class="p">:{</span><span class="s">"document_identifier"</span><span class="p">:</span><span class="s">"fc43295f-cbbe-4ca9-b842-abb1c2fc017e"</span><span class="p">,</span><span class="s">"document_text"</span><span class="p">:[</span><span class="s">"The Patient underwent a computed tomography (CT) scan of the abdomen and pelvis, which showed a complex ova...|
+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
</span></code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.nlp.pretrained.PretrainedPipeline</span>
<span class="k">import</span> <span class="nn">com.johnsnowlabs.util.tracer.PipelineTracer</span>

<span class="k">val</span> <span class="nv">oncology_pipeline</span> <span class="k">=</span> <span class="nc">PretrainedPipeline</span><span class="o">(</span><span class="s">"explain_clinical_doc_oncology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""The Patient underwent a computed tomography (CT) scan of the abdomen and pelvis, which showed a complex ovarian mass. A Pap smear performed one month later was positive for atypical glandular cells suspicious for adenocarcinoma. The pathologic specimen showed extension of the tumor throughout the fallopian tubes, appendix, omentum, and 5 out of 5 enlarged lymph nodes. The final pathologic diagnosis of the tumor was stage IIIC papillary serous ovarian adenocarcinoma. Two months later, the patient was diagnosed with lung metastases.Neoadjuvant chemotherapy with the regimens of Cyclophosphamide (500 mg/m2) is being given for 6 cycles with poor response"""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result_df</span>  <span class="k">=</span> <span class="nv">oncology_pipeline</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline_tracer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PipelineTracer</span><span class="o">(</span><span class="n">oncology_pipeline</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">column_maps</span> <span class="k">=</span> <span class="nv">pipeline_tracer</span><span class="o">.</span><span class="py">createParserDictionary</span><span class="o">()</span>

<span class="k">val</span> <span class="nv">output_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">StructuredJsonConverter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"result"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setConverterSchemaAsStr</span><span class="o">(</span><span class="n">column_maps</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCleanAnnotations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setReturnRelationEntities</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputAsStr</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">json_output</span> <span class="k">=</span> <span class="nv">output_converter</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">result_df</span><span class="o">).</span><span class="py">select</span><span class="o">(</span><span class="s">"result"</span><span class="o">)</span>

<span class="nv">json_output</span><span class="o">.</span><span class="py">show</span><span class="o">()</span>

<span class="k">#</span> <span class="n">result</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                  <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|{</span><span class="s">"result"</span><span class="k">:</span><span class="o">{</span><span class="err">"</span><span class="kt">document_identifier</span><span class="err">"</span><span class="kt">:</span><span class="err">"</span><span class="kt">fc43295f-cbbe-</span><span class="err">4</span><span class="kt">ca9-b842-abb1c2fc017e</span><span class="err">"</span><span class="o">,</span><span class="err">"</span><span class="kt">document_text</span><span class="err">"</span><span class="kt">:</span><span class="err">["</span><span class="kt">The</span> <span class="kt">Patient</span> <span class="kt">underwent</span> <span class="kt">a</span> <span class="kt">computed</span> <span class="kt">tomography</span> <span class="o">(</span><span class="kt">CT</span><span class="o">)</span> <span class="kt">scan</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">abdomen</span> <span class="kt">and</span> <span class="kt">pelvis</span><span class="o">,</span> <span class="n">which</span> <span class="n">showed</span> <span class="n">a</span> <span class="n">complex</span> <span class="n">ova</span><span class="o">...|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="summarizer">Summarizer</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>Summarizer annotator that uses a generative deep learning model to create summaries of medical, finance, and legal texts. This annotator helps to quickly summarize complex medical, finance, and legal information from related documents.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">doSample</code>: Whether or not to use sampling, use greedy decoding otherwise (Default: false)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ignoreTokenIds</code>: A list of token ids which are ignored in the decoder’s output (Default: Array())</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxNewTokens</code>: Maximum number of new tokens to be generated (Default: 30)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxTextLength</code>: Maximum length of context text.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">noRepeatNgramSize</code>: If set to int &gt; 0, all ngrams of that size can only occur once (Default: 0)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">randomSeed</code>: Optional Random seed for the model.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">refineChunkSize</code>: How large should refined chunks Be.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">refineMaxAttempts</code>: How many times should chunks be re-summarized while they are above SummaryTargetLength before stopping.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">refineSummary</code>: Set true to perform refined summarization at increased computation cost.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">refineSummaryTargetLength</code>: Target length for refined summary.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">topK</code>: The number of highest probability vocabulary tokens to keep for top-k-filtering (Default: 50)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">useCache</code>: Cache internal state of the model to improve performance</p>
      </li>
    </ul>

    <p>Available models can be found at the <a href="https://nlp.johnsnowlabs.com/models?task=Summarization">Models Hub</a>.</p>

    <p>For more extended examples on document pre-processing see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop">Spark NLP Workshop</a></p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/seq2seq/medical_summarizer/index.html#sparknlp_jsl.annotator.seq2seq.medical_summarizer.MedicalSummarizer">MedicalSummarizer</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/seq2seq/MedicalSummarizer.html">MedicalSummarizer</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">'document'</span><span class="p">)</span>

<span class="n">summarizer</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">Summarizer</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"summarizer_clinical_jsl"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"summary"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxTextLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">summarizer</span>
<span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""The patient is a pleasant 17-year-old gentleman who was playing basketball today in gym. Two hours prior to presentation, he started to fall and someone stepped on his ankle and kind of twisted his right ankle and he cannot bear weight on it now. It hurts to move or bear weight. No other injuries noted. He does not think he has had injuries to his ankle in the past.
SOCIAL HISTORY: He does not drink or smoke.
MEDICAL DECISION MAKING:
He had an x-ray of his ankle that showed a small ossicle versus avulsion fracture of the talonavicular joint on the lateral view. He has had no pain over the metatarsals themselves. This may be a fracture based upon his exam. He does want to have me to put him in a splint. He was given Motrin here. He will be discharged home to follow up with Dr. X from Orthopedics.
DISPOSITION: Crutches and splint were administered here. I gave him a prescription for Motrin and some Darvocet if he needs to length his sleep and if he has continued pain to follow up with Dr. X. Return if any worsening problems."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"summary.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                 <span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">A</span> <span class="mi">17</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span> <span class="n">man</span> <span class="n">fell</span> <span class="ow">and</span> <span class="n">twisted</span> <span class="n">his</span> <span class="n">right</span> <span class="n">ankle</span><span class="p">,</span> <span class="n">causing</span> <span class="n">pain</span> <span class="n">to</span> <span class="n">move</span> <span class="ow">or</span> <span class="n">bear</span> <span class="n">weight</span><span class="p">.</span> <span class="n">An</span> <span class="n">x</span><span class="o">-</span><span class="n">ray</span> <span class="n">showed</span> <span class="n">a</span> <span class="n">small</span> <span class="n">ossicle</span> <span class="ow">or</span> <span class="n">avulsion</span> <span class="n">fracture</span> <span class="n">of</span> <span class="n">the</span> <span class="n">talonavicular</span> <span class="n">joint</span> <span class="n">on</span> <span class="n">the</span> <span class="n">lateral</span> <span class="n">view</span><span class="p">,</span> <span class="n">which</span> <span class="n">may</span> <span class="n">be</span> <span class="n">a</span> <span class="n">fracture</span> <span class="n">based</span> <span class="n">upon</span> <span class="n">his</span> <span class="n">exam</span><span class="p">.</span> <span class="n">He</span> <span class="n">was</span> <span class="n">given</span> <span class="n">Motrin</span> <span class="ow">and</span> <span class="n">discharged</span> <span class="n">home</span> <span class="k">with</span> <span class="n">crutches</span> <span class="ow">and</span> <span class="n">a</span> <span class="n">prescription</span> <span class="k">for</span> <span class="n">Motrin</span> <span class="ow">and</span> <span class="n">Darvocet</span><span class="p">.</span> <span class="n">He</span> <span class="n">was</span> <span class="n">advised</span> <span class="n">to</span> <span class="n">follow</span> <span class="n">up</span> <span class="k">with</span> <span class="n">his</span> <span class="n">doctor</span> <span class="k">if</span> <span class="n">pain</span> <span class="n">worsens</span> <span class="ow">and</span> <span class="k">return</span> <span class="k">if</span> <span class="nb">any</span> <span class="n">worsening</span> <span class="n">problems</span> <span class="n">worsen</span><span class="p">.]</span><span class="o">|</span>
<span class="o">+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">summarizer</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">Summarizer</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'finsum_flant5_base'</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'finance/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"summary"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">summarizer</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"""Lost Time Incident Rate: 
The lost time incident rate per 200,000 hours worked in 2021 was 0.14, which decreased by 17.6% compared to 2020 (0.17) and decreased by 70.8% compared to 2019 (0.48). The decrease in the lost time incident rate can be attributed to the company's efforts to improve workplace safety and implement effective risk management strategies. 
The total Scope 2 GHG emissions in 2021 were 688,228 tonnes, which remained relatively stable compared to 2020. The company's efforts to transition to renewable energy sources have helped to minimize Scope 2 GHG emissions."""</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"summary.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">summarizer</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">Summarizer</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'legsum_flant5_legal_augmented'</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span><span class="s">'legal/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"summary"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">summarizer</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([</span>
  <span class="p">[</span><span class="s">"""NOW, THEREFORE, in consideration of the Company’s disclosure of information to the Recipient
and the promises set forth below, the parties agree as follows:

     1. Confidential Information. “Confidential Information” as used in this
Agreement means all information relating to the Company disclosed to the Recipient by the Company,
including without limitation any business, technical, marketing, financial or other information,
whether in written, electronic or oral form. Any and all reproductions, copies, notes, summaries,
reports, analyses or other material derived by the Recipient or its Representatives (as defined
below) in whole or in part from the Confidential Information in whatever form maintained shall be
considered part of the Confidential Information itself and shall be treated as such. Confidential
Information does not include information that (a) is or becomes part of the public domain other
than as a result of disclosure by the Recipient or its Representatives; (b) becomes available to
the Recipient on a nonconfidential basis from a source other than the Company, provided that source
is not bound with respect to that information by a confidentiality agreement with the Company or is
otherwise prohibited from transmitting that information by a contractual, legal or other
obligation; (c) can be proven by the Recipient to have been in the Recipient’s possession prior to
disclosure of the same by the Company; or (d) is independently developed by the Recipient without
reference to or reliance on any of the Company’s Confidential Information."""</span><span class="p">]</span>
<span class="p">]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"summary.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">This</span> <span class="n">legal</span> <span class="n">agreement</span> <span class="n">states</span> <span class="n">that</span> <span class="n">the</span> <span class="n">company</span> <span class="n">has</span> <span class="n">disclosed</span> <span class="nb">all</span> <span class="n">information</span> <span class="n">relating</span> <span class="n">to</span> <span class="n">the</span> <span class="n">company</span> <span class="n">to</span> <span class="n">the</span> <span class="n">recipient</span><span class="p">,</span> <span class="n">including</span> <span class="nb">any</span> <span class="n">business</span><span class="p">,</span> <span class="n">technical</span><span class="p">,</span> <span class="n">marketing</span><span class="p">,</span> <span class="n">financial</span> <span class="ow">or</span> <span class="n">other</span> <span class="n">information</span><span class="p">.</span> <span class="n">It</span> <span class="n">also</span> <span class="n">states</span> <span class="n">that</span> <span class="nb">any</span> <span class="n">reproductions</span><span class="p">,</span> <span class="n">copies</span><span class="p">,</span> <span class="n">notes</span><span class="p">,</span> <span class="n">summaries</span><span class="p">,</span> <span class="n">reports</span><span class="p">,</span> <span class="n">analyses</span> <span class="ow">or</span> <span class="n">other</span> <span class="n">material</span> <span class="n">derived</span> <span class="k">from</span> <span class="n">the</span> <span class="n">confidential</span> <span class="n">information</span> <span class="n">must</span> <span class="n">be</span> <span class="n">treated</span> <span class="k">as</span> <span class="n">part</span> <span class="n">of</span> <span class="n">the</span> <span class="n">confidential</span> <span class="n">information</span><span class="p">.</span> <span class="n">The</span> <span class="n">confidential</span> <span class="n">information</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">include</span> <span class="n">information</span> <span class="n">that</span> <span class="ow">is</span> <span class="ow">or</span> <span class="n">becomes</span> <span class="n">part</span> <span class="n">of</span> <span class="n">the</span> <span class="n">public</span> <span class="n">domain</span> <span class="n">other</span> <span class="n">than</span> <span class="k">as</span> <span class="n">a</span> <span class="n">result</span> <span class="n">of</span> <span class="n">disclosure</span> <span class="n">by</span> <span class="n">the</span> <span class="n">recipient</span> <span class="ow">or</span> <span class="n">its</span> <span class="n">representatives</span><span class="p">,</span> <span class="n">becomes</span> <span class="n">available</span> <span class="n">to</span> <span class="n">the</span> <span class="n">recipient</span> <span class="n">on</span> <span class="n">a</span> <span class="n">nonconfidential</span> <span class="n">basis</span> <span class="k">from</span> <span class="n">a</span> <span class="n">source</span> <span class="n">other</span> <span class="n">than</span> <span class="n">the</span> <span class="n">company</span><span class="p">,</span> <span class="n">can</span> <span class="n">be</span> <span class="n">proven</span> <span class="n">by</span> <span class="n">the</span> <span class="n">recipient</span> <span class="n">to</span> <span class="n">have</span> <span class="n">been</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">recipient</span><span class="err">’</span><span class="n">s</span> <span class="n">possession</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">disclosure</span><span class="p">,</span> <span class="ow">or</span> <span class="ow">is</span> <span class="n">independently</span> <span class="n">developed</span> <span class="n">by</span> <span class="n">the</span> <span class="n">recipient</span> <span class="n">without</span> <span class="n">reference</span> <span class="n">to</span> <span class="ow">or</span> <span class="n">reliance</span> <span class="n">on</span> <span class="nb">any</span> <span class="n">of</span> <span class="n">the</span> <span class="n">company</span><span class="err">’</span><span class="n">s</span> <span class="n">confidential</span> <span class="n">information</span><span class="p">.]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">summarizer</span> <span class="k">=</span> <span class="nv">Summarizer</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"summarizer_clinical_jsl"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"summary"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxTextLength</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">summarizer</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""The patient is a pleasant 17-year-old gentleman who was playing basketball today in gym. Two hours prior to presentation, he started to fall and someone stepped on his ankle and kind of twisted his right ankle and he cannot bear weight on it now. It hurts to move or bear weight. No other injuries noted. He does not think he has had injuries to his ankle in the past.
SOCIAL HISTORY: He does not drink or smoke.
MEDICAL DECISION MAKING:
He had an x-ray of his ankle that showed a small ossicle versus avulsion fracture of the talonavicular joint on the lateral view. He has had no pain over the metatarsals themselves. This may be a fracture based upon his exam. He does want to have me to put him in a splint. He was given Motrin here. He will be discharged home to follow up with Dr. X from Orthopedics.
DISPOSITION: Crutches and splint were administered here. I gave him a prescription for Motrin and some Darvocet if he needs to length his sleep and if he has continued pain to follow up with Dr. X. Return if any worsening problems."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">summarizer</span> <span class="k">=</span> <span class="nv">Summarizer</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finsum_flant5_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"summary"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">summarizer</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""Lost Time Incident Rate: 
The lost time incident rate per 200,000 hours worked in 2021 was 0.14, which decreased by 17.6% compared to 2020 (0.17) and decreased by 70.8% compared to 2019 (0.48). The decrease in the lost time incident rate can be attributed to the company's efforts to improve workplace safety and implement effective risk management strategies. 
The total Scope 2 GHG emissions in 2021 were 688,228 tonnes, which remained relatively stable compared to 2020. The company's efforts to transition to renewable energy sources have helped to minimize Scope 2 GHG emissions."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">summarizer</span> <span class="k">=</span> <span class="nv">Summarizer</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legsum_flant5_legal_augmented"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"summary"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">1000</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">summarizer</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""NOW, THEREFORE, in consideration of the Company’s disclosure of information to the Recipient
and the promises set forth below, the parties agree as follows:

     1. Confidential Information. “Confidential Information” as used in this
Agreement means all information relating to the Company disclosed to the Recipient by the Company,
including without limitation any business, technical, marketing, financial or other information,
whether in written, electronic or oral form. Any and all reproductions, copies, notes, summaries,
reports, analyses or other material derived by the Recipient or its Representatives (as defined
below) in whole or in part from the Confidential Information in whatever form maintained shall be
considered part of the Confidential Information itself and shall be treated as such. Confidential
Information does not include information that (a) is or becomes part of the public domain other
than as a result of disclosure by the Recipient or its Representatives; (b) becomes available to
the Recipient on a nonconfidential basis from a source other than the Company, provided that source
is not bound with respect to that information by a confidentiality agreement with the Company or is
otherwise prohibited from transmitting that information by a contractual, legal or other
obligation; (c) can be proven by the Recipient to have been in the Recipient’s possession prior to
disclosure of the same by the Company; or (d) is independently developed by the Recipient without
reference to or reliance on any of the Company’s Confidential Information."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">This</span> <span class="kt">legal</span> <span class="kt">agreement</span> <span class="kt">states</span> <span class="kt">that</span> <span class="kt">the</span> <span class="kt">company</span> <span class="kt">has</span> <span class="kt">disclosed</span> <span class="kt">all</span> <span class="kt">information</span> <span class="kt">relating</span> <span class="kt">to</span> <span class="kt">the</span> <span class="kt">company</span> <span class="kt">to</span> <span class="kt">the</span> <span class="kt">recipient</span>, <span class="kt">including</span> <span class="kt">any</span> <span class="kt">business</span>, <span class="kt">technical</span>, <span class="kt">marketing</span>, <span class="kt">financial</span> <span class="kt">or</span> <span class="kt">other</span> <span class="kt">information.</span> <span class="kt">It</span> <span class="kt">also</span> <span class="kt">states</span> <span class="kt">that</span> <span class="kt">any</span> <span class="kt">reproductions</span>, <span class="kt">copies</span>, <span class="kt">notes</span>, <span class="kt">summaries</span>, <span class="kt">reports</span>, <span class="kt">analyses</span> <span class="kt">or</span> <span class="kt">other</span> <span class="kt">material</span> <span class="kt">derived</span> <span class="kt">from</span> <span class="kt">the</span> <span class="kt">confidential</span> <span class="kt">information</span> <span class="kt">must</span> <span class="kt">be</span> <span class="kt">treated</span> <span class="kt">as</span> <span class="kt">part</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">confidential</span> <span class="kt">information.</span> <span class="kt">The</span> <span class="kt">confidential</span> <span class="kt">information</span> <span class="kt">does</span> <span class="kt">not</span> <span class="kt">include</span> <span class="kt">information</span> <span class="kt">that</span> <span class="kt">is</span> <span class="kt">or</span> <span class="kt">becomes</span> <span class="kt">part</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">public</span> <span class="kt">domain</span> <span class="kt">other</span> <span class="kt">than</span> <span class="kt">as</span> <span class="kt">a</span> <span class="kt">result</span> <span class="kt">of</span> <span class="kt">disclosure</span> <span class="kt">by</span> <span class="kt">the</span> <span class="kt">recipient</span> <span class="kt">or</span> <span class="kt">its</span> <span class="kt">representatives</span>, <span class="kt">becomes</span> <span class="kt">available</span> <span class="kt">to</span> <span class="kt">the</span> <span class="kt">recipient</span> <span class="kt">on</span> <span class="kt">a</span> <span class="kt">nonconfidential</span> <span class="kt">basis</span> <span class="kt">from</span> <span class="kt">a</span> <span class="kt">source</span> <span class="kt">other</span> <span class="kt">than</span> <span class="kt">the</span> <span class="kt">company</span>, <span class="kt">can</span> <span class="kt">be</span> <span class="kt">proven</span> <span class="kt">by</span> <span class="kt">the</span> <span class="kt">recipient</span> <span class="kt">to</span> <span class="kt">have</span> <span class="kt">been</span> <span class="kt">in</span> <span class="kt">the</span> <span class="kt">recipient</span><span class="err">’</span><span class="kt">s</span> <span class="kt">possession</span> <span class="kt">prior</span> <span class="kt">to</span> <span class="kt">disclosure</span>, <span class="kt">or</span> <span class="kt">is</span> <span class="kt">independently</span> <span class="kt">developed</span> <span class="kt">by</span> <span class="kt">the</span> <span class="kt">recipient</span> <span class="kt">without</span> <span class="kt">reference</span> <span class="kt">to</span> <span class="kt">or</span> <span class="kt">reliance</span> <span class="kt">on</span> <span class="kt">any</span> <span class="kt">of</span> <span class="kt">the</span> <span class="kt">company</span><span class="err">’</span><span class="kt">s</span> <span class="kt">confidential</span> <span class="kt">information.</span><span class="o">]|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="tfgraphbuilder">TFGraphBuilder</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">TFGraphBuilder</code> annotator can be used to create graphs in the model training pipeline. <code class="language-plaintext highlighter-rouge">TFGraphBuilder</code> inspects the data and creates the proper graph if a suitable version of TensorFlow (&gt;= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach.</p>

    <p>You can use this builder with <code class="language-plaintext highlighter-rouge">MedicalNerApproach</code>, <code class="language-plaintext highlighter-rouge">FinanceNerApproach</code>, <code class="language-plaintext highlighter-rouge">LegalNerApproach</code>, <code class="language-plaintext highlighter-rouge">RelationExtractionApproach</code>, <code class="language-plaintext highlighter-rouge">AssertionDLApproach</code>, and <code class="language-plaintext highlighter-rouge">GenericClassifierApproach</code>.</p>

    <p><strong>ATTENTION:</strong> Playing with the parameters of <code class="language-plaintext highlighter-rouge">TFGraphBuilder</code> may affect the model performance that you want to train.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">The setInputCols parameter is changing based on the setModelName parameter.</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">There is no output file. The setGraphFile function creates a file with a .pb extension and saves it there.</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/tf_graph_builder/index.html#sparknlp_jsl.annotator.tf_graph_builder.TFGraphBuilder">TFGraphBuilder</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">graph_folder</span> <span class="o">=</span> <span class="s">"./medical_graphs"</span>
<span class="n">ner_graph_builder</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">TFGraphBuilder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setModelName</span><span class="p">(</span><span class="s">"ner_dl"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="s">"auto"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setHiddenUnitsNumber</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIsLicensed</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># False -&gt; for NerDLApproach
</span></code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">graph_folder</span> <span class="o">=</span> <span class="s">"./finance_graphs"</span>
<span class="n">ner_graph_builder</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">TFGraphBuilder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setModelName</span><span class="p">(</span><span class="s">"ner_dl"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="s">"auto"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setHiddenUnitsNumber</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIsLicensed</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># False -&gt; for NerDLApproach
</span></code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">graph_folder</span> <span class="o">=</span> <span class="s">"./legal_graphs"</span>
<span class="n">ner_graph_builder</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">TFGraphBuilder</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setModelName</span><span class="p">(</span><span class="s">"ner_dl"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setLabelColumn</span><span class="p">(</span><span class="s">"label"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFile</span><span class="p">(</span><span class="s">"auto"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setHiddenUnitsNumber</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setGraphFolder</span><span class="p">(</span><span class="n">graph_folder</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setIsLicensed</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># False -&gt; for NerDLApproach
</span></code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="textgenerator">TextGenerator</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>The Medical, Financial, and Legal Text Generators are specialized tools designed for text abstraction in their respective fields. The <code class="language-plaintext highlighter-rouge">MedicalTextGenerator</code>, based on the BioGPT model, excels in medical text abstraction, allowing users to provide prompts and contexts for tasks like disease explanation, paraphrasing medical context, or creating clinical notes for cancer patients. This model is adept at extracting relevant information due to its training on extensive medical data.</p>

    <p>Similarly, the Financial and Legal Text Generators utilize the Flan-T5 model, an advanced version of the T5 model, for tasks in financial and legal text abstraction. Users can input prompts and contexts to receive high-quality summaries, document abstractions, and other text-based outputs. The Flan-T5 model’s training on a diverse range of texts ensures the generation of coherent and accurate content in these domains.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxNewTokens</code>: Maximum number of of new tokens to generate, by default 30</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">maxContextLength</code>: Maximum length of context text</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">configProtoBytes</code>: ConfigProto from tensorflow, serialized into byte array.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">doSample</code>: Whether or not to use sampling; use greedy decoding otherwise, by default False</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">topK</code>: The number of highest probability vocabulary tokens to consider, by default 1</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">noRepeatNgramSize</code>: The number of tokens that can’t be repeated in the same order. Useful for preventing loops. The default is 0.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ignoreTokenIds</code>: A list of token ids which are ignored in the decoder’s output, by default []</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">randomSeed</code>: Set to positive integer to get reproducible results, by default None.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">customPrompt</code>: The only available variable is {DOCUMENT} and it is populated with the contents of the input document</p>
      </li>
    </ul>

    <p>Available models can be found at the <a href="https://nlp.johnsnowlabs.com/models?task=Text+Generation&amp;language=en&amp;type=model">Models Hub</a>.</p>

    <p>For more extended examples on document pre-processing see the <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop">Spark NLP Workshop</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/seq2seq/medical_text_generator/index.html">MedicalTextGenerator</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/seq2seq/MedicalTextGenerator.html">MedicalTextGenerator</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"prompt"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document_prompt"</span><span class="p">)</span>

<span class="n">med_text_generator</span>  <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">TextGenerator</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"text_generator_biomedical_biogpt_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document_prompt"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDoSample</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTopK</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStopAtEos</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">med_text_generator</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">'Covid 19 is'</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"prompt"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                    <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Covid</span> <span class="mi">19</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">pandemic</span> <span class="n">that</span> <span class="n">has</span> <span class="n">affected</span> <span class="n">the</span> <span class="n">world</span><span class="s">'s economy and health.]|
+--------------------------------------------------------------------------+
</span></code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span> 

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prompt"</span><span class="p">)</span>

<span class="n">flant5</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">TextGenerator</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"fingen_flant5_base"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"prompt"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">150</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStopAtEos</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
  
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">flant5</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"Explain what is Sec 10-k filing"</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">'text'</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                              <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="p">[</span><span class="n">Sec</span> <span class="mi">10</span><span class="n">k</span> <span class="n">filing</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">form</span> <span class="n">of</span> <span class="n">tax</span> <span class="n">filing</span> <span class="n">that</span> <span class="n">requires</span> <span class="n">a</span> <span class="n">party</span> <span class="n">to</span> <span class="nb">file</span> <span class="n">jointly</span> <span class="ow">or</span> <span class="n">several</span> <span class="n">entities</span> <span class="k">for</span> <span class="n">tax</span> <span class="n">purposes</span><span class="p">.]</span><span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"prompt"</span><span class="p">)</span>

<span class="n">flant5</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">TextGenerator</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"leggen_flant5_finetuned"</span><span class="p">,</span><span class="s">"en"</span><span class="p">,</span><span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"prompt"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"answer"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxNewTokens</span><span class="p">(</span><span class="mi">200</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setTopK</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRandomSeed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setNoRepeatNgramSize</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setStopAtEos</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
 
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">document_assembler</span><span class="p">,</span> <span class="n">flant5</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"This exhibit has been redacted and is the subject of a confidential treatment request. Redacted material is marked with [* * *] and has been filed separately with the securities and exchange commission."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">"answer.result"</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">result</span>                                                                                                                                                                                                                                           <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">This</span> <span class="n">exhibit</span> <span class="n">has</span> <span class="n">been</span> <span class="n">redacted</span> <span class="ow">and</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">subject</span> <span class="n">of</span> <span class="n">a</span> <span class="n">confidential</span> <span class="n">treatment</span> <span class="n">request</span><span class="p">.</span> <span class="n">Redacted</span> <span class="n">material</span> <span class="ow">is</span> <span class="n">marked</span> <span class="k">with</span> <span class="p">[</span><span class="o">*</span> <span class="o">*</span> <span class="o">*</span><span class="p">]</span> <span class="ow">and</span> <span class="n">has</span> <span class="n">been</span> <span class="n">filed</span> <span class="n">separately</span> <span class="k">with</span> <span class="n">the</span> <span class="n">securities</span> <span class="ow">and</span> <span class="n">exchange</span> <span class="n">commission</span><span class="p">.</span> <span class="n">The</span> <span class="n">redacted</span> <span class="n">material</span> <span class="ow">is</span> <span class="n">confidential</span> <span class="o">|</span>
<span class="o">|</span> <span class="ow">and</span> <span class="n">will</span> <span class="ow">not</span> <span class="n">be</span> <span class="n">disclosed</span> <span class="n">to</span> <span class="nb">any</span> <span class="n">third</span> <span class="n">party</span> <span class="n">without</span> <span class="n">the</span> <span class="n">prior</span> <span class="n">written</span> <span class="n">consent</span> <span class="n">of</span> <span class="n">the</span> <span class="n">parties</span><span class="p">.</span>                                                                                                                                                   <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"prompt"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document_prompt"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">medTextGenerator</span> <span class="k">=</span> <span class="nv">TextGenerator</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"text_generator_biomedical_biogpt_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document_prompt"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">256</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDoSample</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTopK</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">42</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStopAtEos</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">medTextGenerator</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Covid 19 is"</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"prompt"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                    <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Covid</span> <span class="err">19</span> <span class="kt">is</span> <span class="kt">a</span> <span class="kt">pandemic</span> <span class="kt">that</span> <span class="kt">has</span> <span class="kt">affected</span> <span class="kt">the</span> <span class="kt">world's</span> <span class="kt">economy</span> <span class="kt">and</span> <span class="kt">health.</span><span class="o">]|</span>
<span class="o">+--------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prompt"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">flanT5</span> <span class="k">=</span> <span class="nv">TextGenerator</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"fingen_flant5_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"prompt"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">150</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStopAtEos</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">flanT5</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Explain what is Sec 10-k filing"</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                              <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|[</span><span class="kt">Sec</span> <span class="err">10</span><span class="kt">k</span> <span class="kt">filing</span> <span class="kt">is</span> <span class="kt">a</span> <span class="kt">form</span> <span class="kt">of</span> <span class="kt">tax</span> <span class="kt">filing</span> <span class="kt">that</span> <span class="kt">requires</span> <span class="kt">a</span> <span class="kt">party</span> <span class="kt">to</span> <span class="kt">file</span> <span class="kt">jointly</span> <span class="kt">or</span> <span class="kt">several</span> <span class="kt">entities</span> <span class="kt">for</span> <span class="kt">tax</span> <span class="kt">purposes.</span><span class="o">]|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"prompt"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">flanT5</span> <span class="k">=</span> <span class="nv">TextGenerator</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"leggen_flant5_finetuned"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"prompt"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"answer"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMaxNewTokens</span><span class="o">(</span><span class="mi">200</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setTopK</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRandomSeed</span><span class="o">(</span><span class="mi">42</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setNoRepeatNgramSize</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setStopAtEos</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> <span class="n">flanT5</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"This exhibit has been redacted and is the subject of a confidential treatment request. Redacted material is marked with [* * *] and has been filed separately with the securities and exchange commission."</span><span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>


<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="n">result</span>                                                                                                                                                                                                                                           <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span> <span class="nc">This</span> <span class="n">exhibit</span> <span class="n">has</span> <span class="n">been</span> <span class="n">redacted</span> <span class="n">and</span> <span class="n">is</span> <span class="n">the</span> <span class="n">subject</span> <span class="n">of</span> <span class="n">a</span> <span class="n">confidential</span> <span class="n">treatment</span> <span class="n">request</span><span class="o">.</span> <span class="nc">Redacted</span> <span class="n">material</span> <span class="n">is</span> <span class="n">marked</span> <span class="k">with</span> <span class="o">[</span><span class="kt">*</span> <span class="kt">*</span> <span class="kt">*</span><span class="o">]</span> <span class="n">and</span> <span class="n">has</span> <span class="n">been</span> <span class="n">filed</span> <span class="n">separately</span> <span class="k">with</span> <span class="n">the</span> <span class="n">securities</span> <span class="n">and</span> <span class="n">exchange</span> <span class="n">commission</span><span class="o">.</span> <span class="nc">The</span> <span class="n">redacted</span> <span class="n">material</span> <span class="n">is</span> <span class="n">confidential</span> <span class="o">|</span>
<span class="o">|</span> <span class="n">and</span> <span class="n">will</span> <span class="n">not</span> <span class="n">be</span> <span class="n">disclosed</span> <span class="n">to</span> <span class="n">any</span> <span class="n">third</span> <span class="n">party</span> <span class="n">without</span> <span class="n">the</span> <span class="n">prior</span> <span class="n">written</span> <span class="n">consent</span> <span class="n">of</span> <span class="n">the</span> <span class="n">parties</span><span class="o">.</span>                                                                                                                                                   <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="textmatcherinternal">TextMatcherInternal</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator match exact phrases provided in a file against a Document.</p>

    <p>Parametres:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">setEntities</code> <em>(str)</em>: Sets the external resource for the entities.
      path : str
          Path to the external resource
      read_as : str, optional
          How to read the resource, by default ReadAs.TEXT
      options : dict, optional
          Options for reading the resource, by default {“format”: “text”}</li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setCaseSensitive</code> <em>(Boolean)</em>: Sets whether to match regardless of case. (Default: True)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setMergeOverlapping</code> <em>(Boolean)</em>: Sets whether to merge overlapping matched chunks. (Default: False)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setEntityValue</code> <em>(str)</em>: Sets the value for the entity metadata field. If any entity value isn’t set in the file, we need to set it for the entity value.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setBuildFromTokens</code> <em>(Boolean)</em>: Sets whether the TextMatcherInternal should take the CHUNK from TOKEN.</p>
      </li>
      <li><code class="language-plaintext highlighter-rouge">setDelimiter</code> <em>(str)</em>: Sets value for the delimiter between Phrase, Entity.</li>
    </ul>

    <p>See <a href="https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/40.Rule_Based_Entity_Matchers.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CHUNK</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/matcher/text_matcher_internal/index.html">TextMatcherInternal</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/matcher/TextMatcherInternalModel.html">TextMatcherInternal</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">matcher_drug</span> <span class="o">=</span> <span class="s">"""
Aspirin 100mg#Drug
aspirin#Drug
paracetamol#Drug
amoxicillin#Drug
ibuprofen#Drug
lansoprazole#Drug
"""</span>

<span class="k">with</span> <span class="nb">open</span> <span class="p">(</span><span class="s">'matcher_drug.csv'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">matcher_drug</span><span class="p">)</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">entityExtractor</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">TextMatcherInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setEntities</span><span class="p">(</span><span class="s">"matcher_drug.csv"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"matched_text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDelimiter</span><span class="p">(</span><span class="s">"#"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMergeOverlapping</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>

<span class="n">mathcer_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">().</span><span class="n">setStages</span><span class="p">([</span>
                  <span class="n">documentAssembler</span><span class="p">,</span>
                  <span class="n">tokenizer</span><span class="p">,</span>
                  <span class="n">entityExtractor</span><span class="p">])</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="s">"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD."</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">matcher_model</span> <span class="o">=</span> <span class="n">mathcer_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">matcher_model</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># result
</span><span class="o">+-------------+-----+---+-----+</span>
<span class="o">|</span>        <span class="n">chunk</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">label</span><span class="o">|</span>
<span class="o">+-------------+-----+---+-----+</span>
<span class="o">|</span>      <span class="n">aspirin</span><span class="o">|</span>   <span class="mi">25</span><span class="o">|</span> <span class="mi">31</span><span class="o">|</span> <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span><span class="n">aspirin</span> <span class="mi">100</span><span class="n">mg</span><span class="o">|</span>   <span class="mi">25</span><span class="o">|</span> <span class="mi">37</span><span class="o">|</span> <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span>  <span class="n">paracetamol</span><span class="o">|</span>   <span class="mi">75</span><span class="o">|</span> <span class="mi">85</span><span class="o">|</span> <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span>  <span class="n">amoxicillin</span><span class="o">|</span>  <span class="mi">102</span><span class="o">|</span><span class="mi">112</span><span class="o">|</span> <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">ibuprofen</span><span class="o">|</span>  <span class="mi">134</span><span class="o">|</span><span class="mi">142</span><span class="o">|</span> <span class="n">Drug</span><span class="o">|</span>
<span class="o">|</span> <span class="n">lansoprazole</span><span class="o">|</span>  <span class="mi">170</span><span class="o">|</span><span class="mi">181</span><span class="o">|</span> <span class="n">Drug</span><span class="o">|</span>
<span class="o">+-------------+-----+---+-----+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="c1">//matcher_drug = """</span>
<span class="c1">//Aspirin 100mg#Drug</span>
<span class="c1">//aspirin#Drug</span>
<span class="c1">//paracetamol#Drug</span>
<span class="c1">//amoxicillin#Drug</span>
<span class="c1">//ibuprofen#Drug</span>
<span class="c1">//lansoprazole#Drug</span>
<span class="c1">//"""</span>
<span class="c1">//</span>
<span class="c1">//with open ('matcher_drug.csv', 'w') as f:</span>
<span class="c1">//  f.write(matcher_drug)</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">entityExtractor</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">EntityExtractor</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"matched_text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEntities</span><span class="o">(</span><span class="s">"matcher_drug.csv"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setDelimiter</span><span class="o">(</span><span class="s">"#"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMergeOverlapping</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">matcherPipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="n">documentAssembler</span><span class="o">,</span> 
                   <span class="n">tokenizer</span><span class="o">,</span> 
                   <span class="n">entityExtractor</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD."</span><span class="o">)</span>
  <span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">matcherModel</span> <span class="k">=</span> <span class="nv">matcherPipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">matcherModel</span><span class="o">.</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>


<span class="k">#</span> <span class="n">result</span>
<span class="o">+-------------+-----+---+-----+</span>
<span class="o">|</span>        <span class="n">chunk</span><span class="o">|</span><span class="n">begin</span><span class="o">|</span><span class="n">end</span><span class="o">|</span><span class="n">label</span><span class="o">|</span>
<span class="o">+-------------+-----+---+-----+</span>
<span class="o">|</span>      <span class="n">aspirin</span><span class="o">|</span>   <span class="mi">25</span><span class="o">|</span> <span class="mi">31</span><span class="o">|</span> <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span><span class="n">aspirin</span> <span class="mi">100</span><span class="n">mg</span><span class="o">|</span>   <span class="mi">25</span><span class="o">|</span> <span class="mi">37</span><span class="o">|</span> <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span>  <span class="n">paracetamol</span><span class="o">|</span>   <span class="mi">75</span><span class="o">|</span> <span class="mi">85</span><span class="o">|</span> <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span>  <span class="n">amoxicillin</span><span class="o">|</span>  <span class="mi">102</span><span class="o">|</span><span class="mi">112</span><span class="o">|</span> <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span>    <span class="n">ibuprofen</span><span class="o">|</span>  <span class="mi">134</span><span class="o">|</span><span class="mi">142</span><span class="o">|</span> <span class="nc">Drug</span><span class="o">|</span>
<span class="o">|</span> <span class="n">lansoprazole</span><span class="o">|</span>  <span class="mi">170</span><span class="o">|</span><span class="mi">181</span><span class="o">|</span> <span class="nc">Drug</span><span class="o">|</span>
<span class="o">+-------------+-----+---+-----+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="vectordbpostprocessor">VectorDBPostProcessor</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>VectorDBPostProcessor is used to filter and sort the annotations from the :class:<code class="language-plaintext highlighter-rouge">sparknlp_jsl.annotator.resolution.VectorDBModel</code>.</p>

    <p>Parametres:</p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">filterBy</code>:The filterBy parameter is used to select and prioritize filter options.</li>
      <li><code class="language-plaintext highlighter-rouge">sortBy</code>:The sortBy parameter is used to select sorting option. Options: <code class="language-plaintext highlighter-rouge">ascending</code>, <code class="language-plaintext highlighter-rouge">descending</code>, <code class="language-plaintext highlighter-rouge">lost_in_the_middle</code>, <code class="language-plaintext highlighter-rouge">diversity</code>.<code class="language-plaintext highlighter-rouge">ascending</code>: Sort by ascending order of distance.<code class="language-plaintext highlighter-rouge">descending</code>: Sort by descending order of distance.<code class="language-plaintext highlighter-rouge">lost_in_the_middle</code>: Sort by lost in the middle ranker. Let’s say we have 5 annotations with distances [1, 2, 3, 4, 5]. The lost in the middle ranker will sort them as [1, 3, 5, 4, 2].<code class="language-plaintext highlighter-rouge">diversity</code>:  Sort by diversity ranker. The annotations are sorted by distance and the first annotation select, and then the next annotation is selected by the maximum average distance from the selected annotations. Default: <code class="language-plaintext highlighter-rouge">ascending</code></li>
      <li><code class="language-plaintext highlighter-rouge">caseSensitive</code>: Whether the criteria of the string operators are case sensitive or not. For example, if set to False, the operator “equals” will match “John” with “john”. Default: False</li>
      <li><code class="language-plaintext highlighter-rouge">diversityThreshold</code>: The diversityThreshold parameter is used to set the threshold for the diversityByThreshold filter. The diversityByThreshold filter selects the annotations by the distance between the sorted annotations. diversityThreshold must be greater than 0. Default: 0.01</li>
      <li><code class="language-plaintext highlighter-rouge">maxTopKAfterFiltering</code>:  Whether to allow zero annotation after filtering. If set to True, the output may contain zero annotation if all annotations are filtered out. If set to False, The output is tried to contain at least one annotation. Default: False</li>
      <li><code class="language-plaintext highlighter-rouge">metadataCriteria</code>: The metadataCriteria parameter is used to filter the annotations by metadata fields.</li>
    </ul>

    <p>See <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/45.VectorDB_and_PostProcessor_for_RAG_Generative_AI.ipynb">Spark NLP Workshop</a> for more examples of usage.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">VECTOR_SIMILARITY_RANKINGS</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">VECTOR_SIMILARITY_RANKINGS</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/rag/vectordb_post_processor/index.html">VectorDBPostProcessor</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/rag/VectorDBPostProcessor.html">VectorDBPostProcessor</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># result
</span></code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">#</span> <span class="n">result</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="windowedsentencemodel">WindowedSentenceModel</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This annotator that helps you to merge the previous and following sentences of a given piece of text, so that you add the context surrounding them. This is super useful for especially context-rich analyses that require a deeper understanding of the language being used.</p>

    <p>Inferring the class from sentence X may be a much harder task sometime, due to the lack of context, than to infer the class of sentence X-1 + sentence X + sentence X+1. In this example, the window is 1, that’s why we augment sentence with 1 neighbour from behind and another from ahead. Window size can be configured so that each piece of text/sentence get a number of previous and posterior sentences as context, equal to the windows size.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setWindowSize</code>: Sets size of the sliding window.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">setGlueString</code>: Sets string to use to join the neighboring elements together.</p>
      </li>
    </ul>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/windowed/windowed_sentence/index.html#sparknlp_jsl.annotator.windowed.windowed_sentence.WindowedSentenceModel">WindowedSentenceModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/windowed/WindowedSentenceModel.html">WindowedSentenceModel</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">medical</span><span class="p">,</span> <span class="n">nlp</span>

<span class="n">documentAssembler</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">windowedSentence1</span> <span class="o">=</span>  <span class="n">medical</span><span class="p">.</span><span class="n">WindowedSentenceModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setWindowSize</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"window_1"</span><span class="p">)</span>

<span class="n">windowedSentence2</span> <span class="o">=</span>  <span class="n">medical</span><span class="p">.</span><span class="n">WindowedSentenceModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setWindowSize</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"window_2"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span> 
    <span class="n">sentenceDetector</span><span class="p">,</span> 
    <span class="n">windowedSentence1</span><span class="p">,</span> 
    <span class="n">windowedSentence2</span>
    <span class="p">])</span>


<span class="n">sample_text</span> <span class="o">=</span> <span class="s">"""The patient was admitted on Monday. 
She has a right-sided pleural effusion for thoracentesis. 
Her Coumadin was placed on hold.
A repeat echocardiogram was checked. 
She was started on prophylaxis for DVT. 
Her CT scan from March 2006 prior to her pericardectomy. 
It already shows bilateral plural effusions."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">sample_text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Example results
</span>
<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="s">'window_1'</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span><span class="s">'col.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                       <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="n">Monday</span><span class="p">.</span> <span class="n">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="p">.</span>                                                <span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="n">Monday</span><span class="p">.</span> <span class="n">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="p">.</span> <span class="n">Her</span> <span class="n">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="p">.</span>               <span class="o">|</span>
<span class="o">|</span><span class="n">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="p">.</span> <span class="n">Her</span> <span class="n">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="p">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="p">.</span>              <span class="o">|</span>
<span class="o">|</span><span class="n">Her</span> <span class="n">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="p">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="p">.</span> <span class="n">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="n">DVT</span><span class="p">.</span>                                <span class="o">|</span>
<span class="o">|</span><span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="p">.</span> <span class="n">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="n">DVT</span><span class="p">.</span> <span class="n">Her</span> <span class="n">CT</span> <span class="n">scan</span> <span class="k">from</span> <span class="n">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="p">.</span>        <span class="o">|</span>
<span class="o">|</span><span class="n">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="n">DVT</span><span class="p">.</span> <span class="n">Her</span> <span class="n">CT</span> <span class="n">scan</span> <span class="k">from</span> <span class="n">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="p">.</span> <span class="n">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="p">.</span><span class="o">|</span>
<span class="o">|</span><span class="n">Her</span> <span class="n">CT</span> <span class="n">scan</span> <span class="k">from</span> <span class="n">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="p">.</span> <span class="n">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="p">.</span>                                        <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="s">'window_2'</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span><span class="s">'col.result'</span><span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                          <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="n">Monday</span><span class="p">.</span> <span class="n">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="p">.</span> <span class="n">Her</span> <span class="n">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="p">.</span>                                                                                                  <span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="n">Monday</span><span class="p">.</span> <span class="n">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="p">.</span> <span class="n">Her</span> <span class="n">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="p">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="p">.</span>                                                             <span class="o">|</span>
<span class="o">|</span><span class="n">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="n">Monday</span><span class="p">.</span> <span class="n">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="p">.</span> <span class="n">Her</span> <span class="n">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="p">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="p">.</span> <span class="n">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="n">DVT</span><span class="p">.</span>                     <span class="o">|</span>
<span class="o">|</span><span class="n">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="p">.</span> <span class="n">Her</span> <span class="n">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="p">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="p">.</span> <span class="n">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="n">DVT</span><span class="p">.</span> <span class="n">Her</span> <span class="n">CT</span> <span class="n">scan</span> <span class="k">from</span> <span class="n">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="p">.</span><span class="o">|</span>
<span class="o">|</span><span class="n">Her</span> <span class="n">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="p">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="p">.</span> <span class="n">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="n">DVT</span><span class="p">.</span> <span class="n">Her</span> <span class="n">CT</span> <span class="n">scan</span> <span class="k">from</span> <span class="n">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="p">.</span> <span class="n">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="p">.</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="p">.</span> <span class="n">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="n">DVT</span><span class="p">.</span> <span class="n">Her</span> <span class="n">CT</span> <span class="n">scan</span> <span class="k">from</span> <span class="n">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="p">.</span> <span class="n">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="p">.</span>                                              <span class="o">|</span>
<span class="o">|</span><span class="n">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="n">DVT</span><span class="p">.</span> <span class="n">Her</span> <span class="n">CT</span> <span class="n">scan</span> <span class="k">from</span> <span class="n">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="p">.</span> <span class="n">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="p">.</span>                                                                                   <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">doc_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"isolated_sentence"</span><span class="p">)</span>

<span class="n">context_window</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">WindowedSentenceModel</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"isolated_sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"window"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWindowSize</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">window_splitting_pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">doc_assembler</span><span class="p">,</span> <span class="n">sentence_detector</span><span class="p">,</span> <span class="n">context_window</span><span class="p">])</span>

<span class="n">window_splitting_model</span> <span class="o">=</span> <span class="n">window_splitting_pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

<span class="n">window_splitting_lp</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">LightPipeline</span><span class="p">(</span><span class="n">window_splitting_model</span><span class="p">)</span>

<span class="c1">## Result
</span>
<span class="p">[</span><span class="s">'1  </span><span class="se">\n</span><span class="s">MUTUAL NONDISCLOSURE AGREEMENT  </span><span class="se">\n</span><span class="s">This Mutual Nondisclosure Agreement (the “Agreement”) is made on _________ (“Effective  </span><span class="se">\n</span><span class="s">Date”) by and between:  </span><span class="se">\n</span><span class="s">(1) John Snow Labs, a Delaware corporation, registered at 16192 Coastal Highway,  </span><span class="se">\n</span><span class="s">Lewes, Delaware 19958 (“John Snow Labs”), and   </span><span class="se">\n</span><span class="s">(2) Achiles, S.L, a Spanish corporation, registered at Gran Via, 2º floor, Offices 9</span><span class="se">\n</span><span class="s">and 10.(“Company”),  </span><span class="se">\n</span><span class="s">(each a “party” and together the “parties”). Recitals:  </span><span class="se">\n</span><span class="s">John Snow Labs and Company intend to explore the possibility of a business relationship  </span><span class="se">\n</span><span class="s">between each other, whereby each party (“Discloser”) may disclose sensitive information to the  </span><span class="se">\n</span><span class="s">other party (“Recipient”).'</span><span class="p">,</span>
 <span class="s">'1  </span><span class="se">\n</span><span class="s">MUTUAL NONDISCLOSURE AGREEMENT  </span><span class="se">\n</span><span class="s">This Mutual Nondisclosure Agreement (the “Agreement”) is made on _________ (“Effective  </span><span class="se">\n</span><span class="s">Date”) by and between:  </span><span class="se">\n</span><span class="s">(1) John Snow Labs, a Delaware corporation, registered at 16192 Coastal Highway,  </span><span class="se">\n</span><span class="s">Lewes, Delaware 19958 (“John Snow Labs”), and   </span><span class="se">\n</span><span class="s">(2) Achiles, S.L, a Spanish corporation, registered at Gran Via, 2º floor, Offices 9</span><span class="se">\n</span><span class="s">and 10.(“Company”),  </span><span class="se">\n</span><span class="s">(each a “party” and together the “parties”). Recitals:  </span><span class="se">\n</span><span class="s">John Snow Labs and Company intend to explore the possibility of a business relationship  </span><span class="se">\n</span><span class="s">between each other, whereby each party (“Discloser”) may disclose sensitive information to the  </span><span class="se">\n</span><span class="s">other party (“Recipient”). The parties agree as follows:'</span><span class="p">,</span>
 <span class="s">'Recitals:  </span><span class="se">\n</span><span class="s">John Snow Labs and Company intend to explore the possibility of a business relationship  </span><span class="se">\n</span><span class="s">between each other, whereby each party (“Discloser”) may disclose sensitive information to the  </span><span class="se">\n</span><span class="s">other party (“Recipient”). The parties agree as follows: 1. Definition.'</span><span class="p">,]</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">windowedSentence1</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">WindowedSentenceModel</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setWindowSize</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"window_1"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">windowedSentence2</span> <span class="k">=</span>  <span class="k">new</span> <span class="nc">WindowedSentenceModel</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setWindowSize</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"window_2"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">windowedSentence1</span><span class="o">,</span> 
    <span class="n">windowedSentence2</span>
<span class="o">))</span>


<span class="k">val</span> <span class="nv">testDataset</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"The patient was admitted on Monday. 
She has a right-sided pleural effusion for thoracentesis. 
Her Coumadin was placed on hold.
A repeat echocardiogram was checked. 
She was started on prophylaxis for DVT. 
Her CT scan from March 2006 prior to her pericardectomy. 
It already shows bilateral plural effusions."</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">testDataset</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">testDataset</span><span class="o">)</span>

<span class="c1">// Result</span>

<span class="c1">// window 1</span>

<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                       <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="nc">Monday</span><span class="o">.</span> <span class="nc">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">.</span>                                                <span class="o">|</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="nc">Monday</span><span class="o">.</span> <span class="nc">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="o">.</span>               <span class="o">|</span>
<span class="o">|</span><span class="nc">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="o">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="o">.</span>              <span class="o">|</span>
<span class="o">|</span><span class="nc">Her</span> <span class="nc">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="o">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="o">.</span> <span class="nc">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="nc">DVT</span><span class="o">.</span>                                <span class="o">|</span>
<span class="o">|</span><span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="o">.</span> <span class="nc">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="nc">DVT</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">CT</span> <span class="n">scan</span> <span class="n">from</span> <span class="nc">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="o">.</span>        <span class="o">|</span>
<span class="o">|</span><span class="nc">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="nc">DVT</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">CT</span> <span class="n">scan</span> <span class="n">from</span> <span class="nc">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="o">.</span> <span class="nc">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="o">.|</span>
<span class="o">|</span><span class="nc">Her</span> <span class="nc">CT</span> <span class="n">scan</span> <span class="n">from</span> <span class="nc">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="o">.</span> <span class="nc">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="o">.</span>                                        <span class="o">|</span>
<span class="o">+---------------------------------------------------------------------------------------------------------------------------------------------+</span>

<span class="c1">// window 2</span>

<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="n">result</span>                                                                                                                                                                                                                          <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="nc">Monday</span><span class="o">.</span> <span class="nc">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="o">.</span>                                                                                                  <span class="o">|</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="nc">Monday</span><span class="o">.</span> <span class="nc">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="o">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="o">.</span>                                                             <span class="o">|</span>
<span class="o">|</span><span class="nc">The</span> <span class="n">patient</span> <span class="n">was</span> <span class="n">admitted</span> <span class="n">on</span> <span class="nc">Monday</span><span class="o">.</span> <span class="nc">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="o">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="o">.</span> <span class="nc">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="nc">DVT</span><span class="o">.</span>                     <span class="o">|</span>
<span class="o">|</span><span class="nc">She</span> <span class="n">has</span> <span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="o">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="o">.</span> <span class="nc">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="nc">DVT</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">CT</span> <span class="n">scan</span> <span class="n">from</span> <span class="nc">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="o">.|</span>
<span class="o">|</span><span class="nc">Her</span> <span class="nc">Coumadin</span> <span class="n">was</span> <span class="n">placed</span> <span class="n">on</span> <span class="n">hold</span><span class="o">.</span> <span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="o">.</span> <span class="nc">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="nc">DVT</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">CT</span> <span class="n">scan</span> <span class="n">from</span> <span class="nc">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="o">.</span> <span class="nc">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="o">.</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">A</span> <span class="n">repeat</span> <span class="n">echocardiogram</span> <span class="n">was</span> <span class="n">checked</span><span class="o">.</span> <span class="nc">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="nc">DVT</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">CT</span> <span class="n">scan</span> <span class="n">from</span> <span class="nc">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="o">.</span> <span class="nc">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="o">.</span>                                              <span class="o">|</span>
<span class="o">|</span><span class="nc">She</span> <span class="n">was</span> <span class="n">started</span> <span class="n">on</span> <span class="n">prophylaxis</span> <span class="k">for</span> <span class="nc">DVT</span><span class="o">.</span> <span class="nc">Her</span> <span class="nc">CT</span> <span class="n">scan</span> <span class="n">from</span> <span class="nc">March</span> <span class="mi">2006</span> <span class="n">prior</span> <span class="n">to</span> <span class="n">her</span> <span class="n">pericardectomy</span><span class="o">.</span> <span class="nc">It</span> <span class="n">already</span> <span class="n">shows</span> <span class="n">bilateral</span> <span class="n">plural</span> <span class="n">effusions</span><span class="o">.</span>                                                                                   <span class="o">|</span>
<span class="o">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">doc_assembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentence_detector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"isolated_sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">context_window</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">WindowedSentenceModel</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="s">"isolated_sentence"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"window"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWindowSize</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">doc_assembler</span><span class="o">,</span> 
    <span class="n">sentence_detector</span><span class="o">,</span> 
    <span class="n">context_window</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">window_splitting_model</span> <span class="k">=</span> <span class="nv">window_splitting_pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">window_splitting_lp</span> <span class="k">=</span> <span class="nc">LightPipeline</span><span class="o">(</span><span class="n">window_splitting_model</span><span class="o">)</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="zeroshotnermodel">ZeroShotNerModel</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p>This is a zero shot named entity recognition based on <code class="language-plaintext highlighter-rouge">RoBertaForQuestionAnswering</code>. Zero shot models excel at generalization, meaning that the model can accurately predict entities in very different data sets without the need to fine tune the model or train from scratch for each different domain.</p>

    <p>Even though a model trained to solve a specific problem can achieve better accuracy than a zero-shot model in this specific task, it probably won’t be be useful in a different task. That is where zero-shot models shows its usefulness by being able to achieve good results in many different scenarions.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">entityDefinitions</code>: A dictionary with definitions of the named entities. The keys of dictionary are the entity types and the values are lists of hypothesis templates.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">predictionThreshold</code>: Minimal confidence score to consider the entity(Default: <code class="language-plaintext highlighter-rouge">0.01</code>)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">ignoreEntitites</code>: A list of entities to be discarted from the output..</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setMultiLabel()</code>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">DOCUMENT, TOKEN</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">NAMED_ENTITY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/ner/zero_shot_ner/index.html#sparknlp_jsl.annotator.ner.zero_shot_ner.ZeroShotNerModel">ZeroShotNerModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/finance/token_classification/ner/ZeroShotNerModel.html">ZeroShotNerModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ZeroShotNerModel.ipynb">ZeroShotNerModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentenceDetector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetector</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span> \
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">zero_shot_ner</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ZeroShotNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"zero_shot_ner_roberta"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEntityDefinitions</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"PROBLEM"</span><span class="p">:</span> <span class="p">[</span><span class="s">"What is the disease?"</span><span class="p">,</span> <span class="s">"What is his symptom?"</span><span class="p">,</span> <span class="s">"What is her disease?"</span><span class="p">,</span> <span class="s">"What is his disease?"</span><span class="p">,</span>
                        <span class="s">"What is the problem?"</span> <span class="p">,</span><span class="s">"What does a patient suffer"</span><span class="p">,</span> <span class="s">'What was the reason that the patient is admitted to the clinic?'</span><span class="p">],</span>
            <span class="s">"DRUG"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which drug?"</span><span class="p">,</span> <span class="s">"Which is the drug?"</span><span class="p">,</span> <span class="s">"What is the drug?"</span><span class="p">,</span> <span class="s">"Which drug does he use?"</span><span class="p">,</span> <span class="s">"Which drug does she use?"</span><span class="p">,</span> <span class="s">"Which drug do I use?"</span><span class="p">,</span> <span class="s">"Which drug is prescribed for a symptom?"</span><span class="p">],</span>
            <span class="s">"ADMISSION_DATE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"When did patient admitted to a clinic?"</span><span class="p">],</span>
            <span class="s">"PATIENT_AGE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"How old is the patient?"</span><span class="p">,</span><span class="s">"What is the gae of the patient?"</span><span class="p">]</span>
        <span class="p">})</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"zero_shot_ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setPredictionThreshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># default 0.01
</span>
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"zero_shot_ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>\

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">documentAssembler</span><span class="p">,</span>
    <span class="n">sentenceDetector</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">zero_shot_ner</span><span class="p">,</span>
    <span class="n">ner_converter</span><span class="p">])</span>

<span class="n">text_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">"The doctor pescribed Majezik for my severe headache."</span><span class="p">,</span>
             <span class="s">"The patient was admitted to the hospital for his colon cancer."</span><span class="p">,</span>
             <span class="s">"27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis."</span>
            <span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">text_list</span><span class="p">,</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="o">+------------------------------------------------+--------------+----------+</span>
<span class="o">|</span>                                           <span class="n">chunk</span><span class="o">|</span>     <span class="n">ner_label</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+------------------------------------------------+--------------+----------+</span>
<span class="o">|</span>                                         <span class="n">Majezik</span><span class="o">|</span>          <span class="n">DRUG</span><span class="o">|</span><span class="mf">0.64671576</span><span class="o">|</span>
<span class="o">|</span>                                 <span class="n">severe</span> <span class="n">headache</span><span class="o">|</span>       <span class="n">PROBLEM</span><span class="o">|</span> <span class="mf">0.5526346</span><span class="o">|</span>
<span class="o">|</span>                                    <span class="n">colon</span> <span class="n">cancer</span><span class="o">|</span>       <span class="n">PROBLEM</span><span class="o">|</span> <span class="mf">0.8898498</span><span class="o">|</span>
<span class="o">|</span>                                    <span class="mi">27</span> <span class="n">years</span> <span class="n">old</span><span class="o">|</span>   <span class="n">PATIENT_AGE</span><span class="o">|</span> <span class="mf">0.6943085</span><span class="o">|</span>
<span class="o">|</span>                                         <span class="n">Sep</span> <span class="mi">1</span><span class="n">st</span><span class="o">|</span><span class="n">ADMISSION_DATE</span><span class="o">|</span><span class="mf">0.95646095</span><span class="o">|</span>
<span class="o">|</span><span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">|</span>       <span class="n">PROBLEM</span><span class="o">|</span><span class="mf">0.50026613</span><span class="o">|</span>
<span class="o">+------------------------------------------------+--------------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">textsplitter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">TextSplitter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">zero_shot_ner</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ZeroShotNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_roberta_zeroshot"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"zero_shot_ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setEntityDefinitions</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"DATE"</span><span class="p">:</span> <span class="p">[</span><span class="s">'When was the company acquisition?'</span><span class="p">,</span> <span class="s">'When was the company purchase agreement?'</span><span class="p">],</span>
            <span class="s">"ORG"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which company was acquired?"</span><span class="p">],</span>
            <span class="s">"PRODUCT"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which product?"</span><span class="p">],</span>
            <span class="s">"PROFIT_INCREASE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"How much has the gross profit increased?"</span><span class="p">],</span>
            <span class="s">"REVENUES_DECLINED"</span><span class="p">:</span> <span class="p">[</span><span class="s">"How much has the revenues declined?"</span><span class="p">],</span>
            <span class="s">"OPERATING_LOSS_2020"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which was the operating loss in 2020"</span><span class="p">],</span>
            <span class="s">"OPERATING_LOSS_2019"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which was the operating loss in 2019"</span><span class="p">]</span>
        <span class="p">})</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"zero_shot_ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">textsplitter</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">zero_shot_ner</span><span class="p">,</span>
  <span class="n">ner_converter</span>
  <span class="p">]</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>
<span class="n">text_list</span> <span class="o">=</span> <span class="p">[</span><span class="s">"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio."</span><span class="p">,</span>
              <span class="s">"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc."</span><span class="p">,</span>
              <span class="s">"While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019."</span><span class="p">,</span>
              <span class="s">"We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of $7,738,193 in 2019."</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">text_list</span><span class="p">,</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>


<span class="o">+------------------+-------------------+</span>
<span class="o">|</span><span class="n">chunk</span>             <span class="o">|</span><span class="n">ner_label</span>          <span class="o">|</span>
<span class="o">+------------------+-------------------+</span>
<span class="o">|</span><span class="n">March</span> <span class="mi">2012</span>        <span class="o">|</span><span class="n">DATE</span>               <span class="o">|</span>
<span class="o">|</span><span class="n">Vertro</span>            <span class="o">|</span><span class="n">ORG</span>                <span class="o">|</span>
<span class="o">|</span><span class="n">ALOT</span>              <span class="o">|</span><span class="n">PRODUCT</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">February</span> <span class="mi">2017</span>     <span class="o">|</span><span class="n">DATE</span>               <span class="o">|</span>
<span class="o">|</span><span class="n">NetSeer</span>           <span class="o">|</span><span class="n">ORG</span>                <span class="o">|</span>
<span class="o">|</span><span class="mf">81.4</span><span class="o">%</span>             <span class="o">|</span><span class="n">PROFIT_INCREASE</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">27</span><span class="o">%</span>               <span class="o">|</span><span class="n">REVENUES_DECLINED</span>  <span class="o">|</span>
<span class="o">|</span><span class="err">$</span><span class="mi">8</span><span class="p">,</span><span class="mi">048</span><span class="p">,</span><span class="mi">581</span> <span class="n">million</span><span class="o">|</span><span class="n">OPERATING_LOSS_2020</span><span class="o">|</span>
<span class="o">|</span><span class="err">$</span><span class="mi">7</span><span class="p">,</span><span class="mi">738</span><span class="p">,</span><span class="mi">193</span>        <span class="o">|</span><span class="n">OPERATING_LOSS_2019</span><span class="o">|</span>
<span class="o">|</span><span class="mi">2019</span>              <span class="o">|</span><span class="n">DATE</span>               <span class="o">|</span>
<span class="o">+------------------+-------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">textSplitter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">TextSplitter</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">zero_shot_ner</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ZeroShotNerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legner_roberta_zeroshot"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"zero_shot_ner"</span><span class="p">)</span>\
  <span class="p">.</span><span class="n">setEntityDefinitions</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"DATE"</span><span class="p">:</span> <span class="p">[</span><span class="s">'When was the company acquisition?'</span><span class="p">,</span> <span class="s">'When was the company purchase agreement?'</span><span class="p">,</span> <span class="s">"When was the agreement?"</span><span class="p">],</span>
            <span class="s">"ORG"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which company?"</span><span class="p">],</span>
            <span class="s">"STATE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"Which state?"</span><span class="p">],</span>
            <span class="s">"AGREEMENT"</span><span class="p">:</span> <span class="p">[</span><span class="s">"What kind of agreement?"</span><span class="p">],</span>
            <span class="s">"LICENSE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"What kind of license?"</span><span class="p">],</span>
            <span class="s">"LICENSE_RECIPIENT"</span><span class="p">:</span> <span class="p">[</span><span class="s">"To whom the license is granted?"</span><span class="p">]</span>
        <span class="p">})</span>
    
<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
  <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"zero_shot_ner"</span><span class="p">])</span>\
  <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span>  <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span>
  <span class="n">documentAssembler</span><span class="p">,</span>
  <span class="n">textSplitter</span><span class="p">,</span>
  <span class="n">tokenizer</span><span class="p">,</span>
  <span class="n">zero_shot_ner</span><span class="p">,</span>
  <span class="n">nerconverter</span>
  <span class="p">]</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StringType</span>

<span class="n">text_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio."</span><span class="p">,</span>
    <span class="s">"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc."</span><span class="p">,</span>
    <span class="s">"This INTELLECTUAL PROPERTY AGREEMENT, dated as of December 31, 2018 (the 'Effective Date') is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ('Seller') and AFI Licensing LLC, a Delaware company (the 'Licensee')"</span><span class="p">,</span>
    <span class="s">"The Company hereby grants to Seller a perpetual, non- exclusive, royalty-free license"</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">text_list</span><span class="p">,</span> <span class="n">nlp</span><span class="p">.</span><span class="n">StringType</span><span class="p">()).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">ner_chunk</span><span class="p">.</span><span class="n">metadata</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">))</span>\
      <span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk"</span><span class="p">),</span>
              <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']['entity']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"ner_label"</span><span class="p">)).</span><span class="n">show</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">truncate</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="o">+-------------------------------------+-----------------+</span>
<span class="o">|</span><span class="n">chunk</span>                                <span class="o">|</span><span class="n">ner_label</span>        <span class="o">|</span>
<span class="o">+-------------------------------------+-----------------+</span>
<span class="o">|</span><span class="n">March</span> <span class="mi">2012</span>                           <span class="o">|</span><span class="n">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">Vertro</span><span class="p">,</span> <span class="n">Inc</span>                          <span class="o">|</span><span class="n">ORG</span>              <span class="o">|</span>
<span class="o">|</span><span class="n">February</span> <span class="mi">2017</span>                        <span class="o">|</span><span class="n">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">asset</span> <span class="n">purchase</span> <span class="n">agreement</span>             <span class="o">|</span><span class="n">AGREEMENT</span>        <span class="o">|</span>
<span class="o">|</span><span class="n">NetSeer</span>                              <span class="o">|</span><span class="n">ORG</span>              <span class="o">|</span>
<span class="o">|</span><span class="n">INTELLECTUAL</span> <span class="n">PROPERTY</span>                <span class="o">|</span><span class="n">AGREEMENT</span>        <span class="o">|</span>
<span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2018</span>                    <span class="o">|</span><span class="n">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">Armstrong</span> <span class="n">Flooring</span>                   <span class="o">|</span><span class="n">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="n">Delaware</span>                             <span class="o">|</span><span class="n">STATE</span>            <span class="o">|</span>
<span class="o">|</span><span class="n">AFI</span> <span class="n">Licensing</span> <span class="n">LLC</span><span class="p">,</span> <span class="n">a</span> <span class="n">Delaware</span> <span class="n">company</span><span class="o">|</span><span class="n">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="n">Seller</span>                               <span class="o">|</span><span class="n">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="n">perpetual</span>                            <span class="o">|</span><span class="n">LICENSE</span>          <span class="o">|</span>
<span class="o">|</span><span class="n">non</span><span class="o">-</span> <span class="n">exclusive</span>                       <span class="o">|</span><span class="n">LICENSE</span>          <span class="o">|</span>
<span class="o">|</span><span class="n">royalty</span><span class="o">-</span><span class="n">free</span>                         <span class="o">|</span><span class="n">LICENSE</span>          <span class="o">|</span>
<span class="o">+-------------------------------------+-----------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">SentenceDetector</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">zeroShotNer</span> <span class="k">=</span> <span class="nv">ZeroShotNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"zero_shot_ner_roberta"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEntityDefinitions</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span>
    <span class="s">"PROBLEM"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What is the disease?"</span><span class="o">,</span> <span class="s">"What is his symptom?"</span><span class="o">,</span> <span class="s">"What is her disease?"</span><span class="o">,</span> <span class="s">"What is his disease?"</span><span class="o">,</span>
                     <span class="s">"What is the problem?"</span> <span class="o">,</span><span class="s">"What does a patient suffer"</span><span class="o">,</span> <span class="s">"What was the reason that the patient is admitted to the clinic?"</span><span class="o">),</span>
    <span class="s">"DRUG"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Which drug?"</span><span class="o">,</span> <span class="s">"Which is the drug?"</span><span class="o">,</span> <span class="s">"What is the drug?"</span><span class="o">,</span> <span class="s">"Which drug does he use?"</span><span class="o">,</span> <span class="s">"Which drug does she use?"</span><span class="o">,</span> <span class="s">"Which drug do I use?"</span><span class="o">,</span> <span class="s">"Which drug is prescribed for a symptom?"</span><span class="o">),</span>
    <span class="s">"ADMISSION_DATE"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"When did patient admitted to a clinic?"</span><span class="o">),</span>
    <span class="s">"PATIENT_AGE"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"How old is the patient?"</span><span class="o">,</span> <span class="s">"What is the gae of the patient?"</span><span class="o">)</span>
  <span class="o">))</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"zero_shot_ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setPredictionThreshold</span><span class="o">(</span><span class="mf">0.1</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"zero_shot_ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span> 
    <span class="n">sentenceDetector</span><span class="o">,</span> 
    <span class="n">tokenizer</span><span class="o">,</span> 
    <span class="n">zeroShotNer</span><span class="o">,</span> 
    <span class="n">nerConverter</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">textList</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"The doctor pescribed Majezik for my severe headache."</span><span class="o">,</span>
  <span class="s">"The patient was admitted to the hospital for his colon cancer."</span><span class="o">,</span>
  <span class="s">"27 years old patient was admitted to clinic on Sep 1st by Dr. X for a right-sided pleural effusion for thoracentesis."</span>
<span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">textList</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">textList</span><span class="o">)</span>

  
<span class="o">+------------------------------------------------+--------------+----------+</span>
<span class="o">|</span>                                           <span class="n">chunk</span><span class="o">|</span>     <span class="n">ner_label</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+------------------------------------------------+--------------+----------+</span>
<span class="o">|</span>                                         <span class="nc">Majezik</span><span class="o">|</span>          <span class="nc">DRUG</span><span class="o">|</span><span class="mf">0.64671576</span><span class="o">|</span>
<span class="o">|</span>                                 <span class="n">severe</span> <span class="n">headache</span><span class="o">|</span>       <span class="nc">PROBLEM</span><span class="o">|</span> <span class="mf">0.5526346</span><span class="o">|</span>
<span class="o">|</span>                                    <span class="n">colon</span> <span class="n">cancer</span><span class="o">|</span>       <span class="nc">PROBLEM</span><span class="o">|</span> <span class="mf">0.8898498</span><span class="o">|</span>
<span class="o">|</span>                                    <span class="mi">27</span> <span class="n">years</span> <span class="n">old</span><span class="o">|</span>   <span class="nc">PATIENT_AGE</span><span class="o">|</span> <span class="mf">0.6943085</span><span class="o">|</span>
<span class="o">|</span>                                         <span class="nc">Sep</span> <span class="mi">1</span><span class="n">st</span><span class="o">|</span><span class="nc">ADMISSION_DATE</span><span class="o">|</span><span class="mf">0.95646095</span><span class="o">|</span>
<span class="o">|</span><span class="n">a</span> <span class="n">right</span><span class="o">-</span><span class="n">sided</span> <span class="n">pleural</span> <span class="n">effusion</span> <span class="k">for</span> <span class="n">thoracentesis</span><span class="o">|</span>       <span class="nc">PROBLEM</span><span class="o">|</span><span class="mf">0.50026613</span><span class="o">|</span>
<span class="o">+------------------------------------------------+--------------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">textsplitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextSplitter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">zero_shot_ner</span> <span class="k">=</span> <span class="nv">ZeroShotNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_roberta_zeroshot"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"zero_shot_ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEntityDefinitions</span><span class="o">(</span>
    <span class="nc">Map</span><span class="o">(</span>
      <span class="s">"DATE"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="ss">'When</span> <span class="n">was</span> <span class="n">the</span> <span class="n">company</span> <span class="n">acquisition</span><span class="o">?',</span> <span class="ss">'When</span> <span class="n">was</span> <span class="n">the</span> <span class="n">company</span> <span class="n">purchase</span> <span class="n">agreement</span><span class="o">?'),</span>
      <span class="s">"ORG"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Which company was acquired?"</span><span class="o">),</span>
      <span class="s">"PRODUCT"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Which product?"</span><span class="o">),</span>
      <span class="s">"PROFIT_INCREASE"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"How much has the gross profit increased?"</span><span class="o">),</span>
      <span class="s">"REVENUES_DECLINED"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"How much has the revenues declined?"</span><span class="o">),</span>
      <span class="s">"OPERATING_LOSS_2020"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Which was the operating loss in 2020"</span><span class="o">),</span>
      <span class="s">"OPERATING_LOSS_2019"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Which was the operating loss in 2019"</span><span class="o">)</span>
    <span class="o">)</span>
  <span class="o">)</span>

<span class="k">val</span> <span class="nv">ner_converter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"zero_shot_ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
  <span class="n">documentAssembler</span><span class="o">,</span>
  <span class="n">textsplitter</span><span class="o">,</span>
  <span class="n">tokenizer</span><span class="o">,</span>
  <span class="n">zero_shot_ner</span><span class="o">,</span>
  <span class="n">ner_converter</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">text_list</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio."</span><span class="o">,</span>
  <span class="s">"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc."</span><span class="o">,</span>
  <span class="s">"While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019."</span><span class="o">,</span>
  <span class="s">"We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of $7,738,193 in 2019."</span>
<span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">text_list</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">text_list</span><span class="o">)</span>

<span class="o">+------------------+-------------------+</span>
<span class="o">|</span><span class="n">chunk</span>             <span class="o">|</span><span class="n">ner_label</span>          <span class="o">|</span>
<span class="o">+------------------+-------------------+</span>
<span class="o">|</span><span class="nc">March</span> <span class="mi">2012</span>        <span class="o">|</span><span class="nc">DATE</span>               <span class="o">|</span>
<span class="o">|</span><span class="nc">Vertro</span>            <span class="o">|</span><span class="nc">ORG</span>                <span class="o">|</span>
<span class="o">|</span><span class="nc">ALOT</span>              <span class="o">|</span><span class="nc">PRODUCT</span>            <span class="o">|</span>
<span class="o">|</span><span class="nc">February</span> <span class="mi">2017</span>     <span class="o">|</span><span class="nc">DATE</span>               <span class="o">|</span>
<span class="o">|</span><span class="nc">NetSeer</span>           <span class="o">|</span><span class="nc">ORG</span>                <span class="o">|</span>
<span class="o">|</span><span class="mf">81.4</span><span class="o">%</span>             <span class="o">|</span><span class="nc">PROFIT_INCREASE</span>    <span class="o">|</span>
<span class="o">|</span><span class="mi">27</span><span class="o">%</span>               <span class="o">|</span><span class="nc">REVENUES_DECLINED</span>  <span class="o">|</span>
<span class="o">|</span><span class="n">$8</span><span class="o">,</span><span class="mi">048</span><span class="o">,</span><span class="mi">581</span> <span class="n">million</span><span class="o">|</span><span class="nc">OPERATING_LOSS_2020</span><span class="o">|</span>
<span class="o">|</span><span class="n">$7</span><span class="o">,</span><span class="mi">738</span><span class="o">,</span><span class="mi">193</span>        <span class="o">|</span><span class="nc">OPERATING_LOSS_2019</span><span class="o">|</span>
<span class="o">|</span><span class="mi">2019</span>              <span class="o">|</span><span class="nc">DATE</span>               <span class="o">|</span>
<span class="o">+------------------+-------------------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">textSplitter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">TextSplitter</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">zeroShotNer</span> <span class="k">=</span> <span class="nv">ZeroShotNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_roberta_zeroshot"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"zero_shot_ner"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setEntityDefinitions</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span>
    <span class="s">"DATE"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"When was the company acquisition?"</span><span class="o">,</span> <span class="s">"When was the company purchase agreement?"</span><span class="o">,</span> <span class="s">"When was the agreement?"</span><span class="o">),</span>
    <span class="s">"ORG"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Which company?"</span><span class="o">),</span>
    <span class="s">"STATE"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"Which state?"</span><span class="o">),</span>
    <span class="s">"AGREEMENT"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What kind of agreement?"</span><span class="o">),</span>
    <span class="s">"LICENSE"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"What kind of license?"</span><span class="o">),</span>
    <span class="s">"LICENSE_RECIPIENT"</span> <span class="o">-&gt;</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">"To whom the license is granted?"</span><span class="o">)</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"zero_shot_ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>


<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">textSplitter</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">zeroShotNer</span><span class="o">,</span>
    <span class="n">nerConverter</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">textList</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span>
  <span class="s">"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio."</span><span class="o">,</span>
  <span class="s">"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc."</span><span class="o">,</span>
  <span class="s">"This INTELLECTUAL PROPERTY AGREEMENT, dated as of December 31, 2018 (the 'Effective Date') is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ('Seller') and AFI Licensing LLC, a Delaware company (the 'Licensee')"</span><span class="o">,</span>
  <span class="s">"The Company hereby grants to Seller a perpetual, non-exclusive, royalty-free license"</span>
<span class="o">).</span><span class="py">toDS</span><span class="o">.</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">textList</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">textList</span><span class="o">)</span>

<span class="o">+-------------------------------------+-----------------+</span>
<span class="o">|</span><span class="n">chunk</span>                                <span class="o">|</span><span class="n">ner_label</span>        <span class="o">|</span>
<span class="o">+-------------------------------------+-----------------+</span>
<span class="o">|</span><span class="nc">March</span> <span class="mi">2012</span>                           <span class="o">|</span><span class="nc">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="nc">Vertro</span><span class="o">,</span> <span class="nc">Inc</span>                          <span class="o">|</span><span class="nc">ORG</span>              <span class="o">|</span>
<span class="o">|</span><span class="nc">February</span> <span class="mi">2017</span>                        <span class="o">|</span><span class="nc">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="n">asset</span> <span class="n">purchase</span> <span class="n">agreement</span>             <span class="o">|</span><span class="nc">AGREEMENT</span>        <span class="o">|</span>
<span class="o">|</span><span class="nc">NetSeer</span>                              <span class="o">|</span><span class="nc">ORG</span>              <span class="o">|</span>
<span class="o">|</span><span class="nc">INTELLECTUAL</span> <span class="nc">PROPERTY</span>                <span class="o">|</span><span class="nc">AGREEMENT</span>        <span class="o">|</span>
<span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2018</span>                    <span class="o">|</span><span class="nc">DATE</span>             <span class="o">|</span>
<span class="o">|</span><span class="nc">Armstrong</span> <span class="nc">Flooring</span>                   <span class="o">|</span><span class="nc">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Delaware</span>                             <span class="o">|</span><span class="nc">STATE</span>            <span class="o">|</span>
<span class="o">|</span><span class="nc">AFI</span> <span class="nc">Licensing</span> <span class="nc">LLC</span><span class="o">,</span> <span class="n">a</span> <span class="nc">Delaware</span> <span class="n">company</span><span class="o">|</span><span class="nc">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="nc">Seller</span>                               <span class="o">|</span><span class="nc">LICENSE_RECIPIENT</span><span class="o">|</span>
<span class="o">|</span><span class="n">perpetual</span>                            <span class="o">|</span><span class="nc">LICENSE</span>          <span class="o">|</span>
<span class="o">|</span><span class="n">non</span><span class="o">-</span><span class="n">exclusive</span>                        <span class="o">|</span><span class="nc">LICENSE</span>          <span class="o">|</span>
<span class="o">|</span><span class="n">royalty</span><span class="o">-</span><span class="n">free</span>                         <span class="o">|</span><span class="nc">LICENSE</span>          <span class="o">|</span>
<span class="o">+-------------------------------------+-----------------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

<div class="tabs-model-aproach">

  <h2 id="zeroshotrelationextractionmodel">ZeroShotRelationExtractionModel</h2>

  <div class="annotator_type tac mont">Model</div>

  <!--Model-->
  <div class="h3-box tabs-python-scala-box">

    <p><code class="language-plaintext highlighter-rouge">ZeroShotRelationExtractionModel</code> implements zero-shot binary relations extraction by utilizing <code class="language-plaintext highlighter-rouge">BERT</code> transformer models trained on the NLI (Natural Language Inference) task.</p>

    <p>The model inputs consists of documents/sentences and paired NER chunks, usually obtained by <code class="language-plaintext highlighter-rouge">RENerChunksFilter</code>. The definitions of relations which are extracted is given by a dictionary structures, specifying a set of statements regarding the relationship of named entities.</p>

    <p>These statements are automatically appended to each document in the dataset and the NLI model is used to determine whether a particular relationship between entities.</p>

    <p>Parameters:</p>

    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">relationalCategories</code>: A dictionary with definitions of relational categories. The keys of dictionary are the relation labels and the values are lists of hypothesis templates.</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">predictionThreshold</code>: Minimal confidence score to encode a relation (Default: <code class="language-plaintext highlighter-rouge">0.5</code>)</p>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">multiLabel</code>: Whether or not a pair of entities can be categorized by multiple relations (Default: <code class="language-plaintext highlighter-rouge">False</code>).</p>
      </li>
    </ul>

    <p>All the parameters can be set using the corresponding set method in camel case. For example, <code class="language-plaintext highlighter-rouge">.setMultiLabel()</code>.</p>

    <p>For available pretrained models please see the <a href="https://nlp.johnsnowlabs.com/models?language=en&amp;q=zero_shot">Models Hub</a>.</p>

    <p><strong>Input Annotator Types:</strong> <code class="language-plaintext highlighter-rouge">CHUNK, DOCUMENT</code></p>

    <p><strong>Output Annotator Type:</strong> <code class="language-plaintext highlighter-rouge">CATEGORY</code></p>

    <table>
      <tbody>
        <tr>
          <td><strong>Python API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/re/zero_shot_relation_extraction/index.html#sparknlp_jsl.annotator.re.zero_shot_relation_extraction.ZeroShotRelationExtractionModel">ZeroShotRelationExtractionModel</a></td>
          <td><strong>Scala API:</strong> <a href="https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/finance/graph/relation_extraction/ZeroShotRelationExtractionModel.html">ZeroShotRelationExtractionModel</a></td>
          <td><strong>Notebook:</strong> <a href="https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ZeroShotRelationExtractionModel.ipynb">ZeroShotRelationExtractionModelNotebook</a></td>
        </tr>
      </tbody>
    </table>

    <details>

<summary class="button"><b>Show Example</b></summary>

<div class="tabs-python-scala-head"><button class="tab-python-scala-li tabheader_active">Python</button><button class="tab-python-scala-li">Scala</button></div>

<!--Python-->
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">medical</span>

<span class="n">documenter</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentencer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentences"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"tokens"</span><span class="p">)</span>

<span class="n">words_embedder</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">WordEmbeddingsModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"embeddings_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_clinical</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_clinical"</span><span class="p">)</span>

<span class="n">ner_clinical_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_clinical"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_clinical_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"PROBLEM"</span><span class="p">,</span> <span class="s">"TEST"</span><span class="p">])</span>  <span class="c1"># PROBLEM-TEST-TREATMENT
</span>
<span class="n">ner_posology</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_posology"</span><span class="p">)</span>

<span class="n">ner_posology_converter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">,</span> <span class="s">"ner_posology"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_posology_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setWhiteList</span><span class="p">([</span><span class="s">"DRUG"</span><span class="p">])</span> <span class="c1"># DRUG-FREQUENCY-DOSAGE-DURATION-FORM-ROUTE-STRENGTH
</span>
<span class="n">chunk_merger</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ChunkMergeApproach</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"ner_clinical_chunks"</span><span class="p">,</span> <span class="s">"ner_posology_chunks"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"merged_ner_chunks"</span><span class="p">)</span>

<span class="c1">## ZERO-SHOT RE Starting...
</span>
<span class="n">pos_tagger</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">PerceptronModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"pos_clinical"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentences"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"pos_tags"</span><span class="p">)</span>

<span class="n">dependency_parser</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DependencyParserModel</span><span class="p">().</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"dependency_conllu"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"pos_tags"</span><span class="p">,</span> <span class="s">"tokens"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"dependencies"</span><span class="p">)</span>

<span class="n">re_ner_chunk_filter</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">RENerChunksFilter</span><span class="p">().</span><span class="n">setRelationPairs</span><span class="p">([</span><span class="s">"problem-test"</span><span class="p">,</span> <span class="s">"problem-drug"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setMaxSyntacticDistance</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setDocLevelRelations</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"merged_ner_chunks"</span><span class="p">,</span> <span class="s">"dependencies"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"re_ner_chunks"</span><span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">medical</span><span class="p">.</span><span class="n">ZeroShotRelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"re_zeroshot_biobert"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"clinical/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"re_ner_chunks"</span><span class="p">,</span> <span class="s">"sentences"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMultiLabel</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationalCategories</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"ADE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{DRUG} causes {PROBLEM}."</span><span class="p">],</span>
            <span class="s">"IMPROVE"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{DRUG} improves {PROBLEM}."</span><span class="p">,</span> <span class="s">"{DRUG} cures {PROBLEM}."</span><span class="p">],</span>
            <span class="s">"REVEAL"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{TEST} reveals {PROBLEM}."</span><span class="p">],</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">documenter</span><span class="p">,</span>
        <span class="n">sentencer</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">words_embedder</span><span class="p">,</span>
        <span class="n">ner_clinical</span><span class="p">,</span>
        <span class="n">ner_clinical_converter</span><span class="p">,</span>
        <span class="n">ner_posology</span><span class="p">,</span>
        <span class="n">ner_posology_converter</span><span class="p">,</span>
        <span class="n">chunk_merger</span><span class="p">,</span>
        <span class="n">pos_tagger</span><span class="p">,</span>
        <span class="n">dependency_parser</span><span class="p">,</span>
        <span class="n">re_ner_chunk_filter</span><span class="p">,</span>
        <span class="n">re_model</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer."</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">results</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">results</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['hypothesis']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"hypothesis"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['nli_prediction']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"nli_prediction"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+------------------------------+--------------+--------+----------+</span>
<span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>     <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>  <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>                    <span class="n">hypothesis</span><span class="o">|</span><span class="n">nli_prediction</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+------------------------------+--------------+--------+----------+</span>
       <span class="mi">0</span><span class="o">|</span>            <span class="mi">0</span><span class="o">|</span>         <span class="mi">10</span><span class="o">|</span><span class="n">Paracetamol</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>           <span class="mi">38</span><span class="o">|</span>         <span class="mi">45</span><span class="o">|</span><span class="n">sickness</span><span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">Paracetamol</span> <span class="n">improves</span> <span class="n">sickness</span><span class="p">.</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span> <span class="n">IMPROVE</span><span class="o">|</span><span class="mf">0.98819494</span><span class="o">|</span>
       <span class="mi">0</span><span class="o">|</span>            <span class="mi">0</span><span class="o">|</span>         <span class="mi">10</span><span class="o">|</span><span class="n">Paracetamol</span><span class="o">|</span>   <span class="n">DRUG</span><span class="o">|</span>           <span class="mi">26</span><span class="o">|</span>         <span class="mi">33</span><span class="o">|</span><span class="n">headache</span><span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span><span class="n">Paracetamol</span> <span class="n">improves</span> <span class="n">headache</span><span class="p">.</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span> <span class="n">IMPROVE</span><span class="o">|</span> <span class="mf">0.9929625</span><span class="o">|</span>
       <span class="mi">1</span><span class="o">|</span>           <span class="mi">48</span><span class="o">|</span>         <span class="mi">58</span><span class="o">|</span><span class="n">An</span> <span class="n">MRI</span> <span class="n">test</span><span class="o">|</span>   <span class="n">TEST</span><span class="o">|</span>           <span class="mi">80</span><span class="o">|</span>         <span class="mi">85</span><span class="o">|</span>  <span class="n">cancer</span><span class="o">|</span><span class="n">PROBLEM</span><span class="o">|</span>   <span class="n">An</span> <span class="n">MRI</span> <span class="n">test</span> <span class="n">reveals</span> <span class="n">cancer</span><span class="p">.</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>  <span class="n">REVEAL</span><span class="o">|</span> <span class="mf">0.9760039</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+------------------------------+--------------+--------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">finance</span>

<span class="n">document_assembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">sentence_detector</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">SentenceDetectorDLModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"sentence_detector_dl"</span><span class="p">,</span> <span class="s">"xx"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">embeddings</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">BertEmbeddings</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"embeddings"</span><span class="p">)</span>

<span class="n">ner_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finner_financial_small"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"embeddings"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"sentence"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">finance</span><span class="p">.</span><span class="n">ZeroShotRelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"finre_zero_shot"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"finance/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"sentence"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMultiLabel</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setRelationalCategories</span><span class="p">(</span>
        <span class="p">{</span>
            <span class="s">"profit_decline_by"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"{PROFIT_DECLINE} decreased by {AMOUNT} from"</span><span class="p">,</span>
                <span class="s">"{PROFIT_DECLINE} decreased by {AMOUNT} to"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s">"profit_decline_by_per"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"{PROFIT_DECLINE} decreased by a {PERCENTAGE} from"</span><span class="p">,</span>
                <span class="s">"{PROFIT_DECLINE} decreased by a {PERCENTAGE} to"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s">"profit_decline_from"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"{PROFIT_DECLINE} decreased from {AMOUNT}"</span><span class="p">,</span>
                <span class="s">"{PROFIT_DECLINE} decreased from {AMOUNT} for the year"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s">"profit_decline_from_per"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"{PROFIT_DECLINE} decreased from {PERCENTAGE} to"</span><span class="p">,</span>
                <span class="s">"{PROFIT_DECLINE} decreased from {PERCENTAGE} to a total of"</span><span class="p">,</span>
            <span class="p">],</span>
            <span class="s">"profit_decline_to"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{PROFIT_DECLINE} to {AMOUNT}"</span><span class="p">],</span>
            <span class="s">"profit_increase_from"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{PROFIT_INCREASE} from {AMOUNT}"</span><span class="p">],</span>
            <span class="s">"profit_increase_to"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{PROFIT_INCREASE} to {AMOUNT}"</span><span class="p">],</span>
            <span class="s">"expense_decrease_by"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{EXPENSE_DECREASE} decreased by {AMOUNT}"</span><span class="p">],</span>
            <span class="s">"expense_decrease_by_per"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{EXPENSE_DECREASE} decreased by a {PERCENTAGE}"</span><span class="p">],</span>
            <span class="s">"expense_decrease_from"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{EXPENSE_DECREASE} decreased from {AMOUNT}"</span><span class="p">],</span>
            <span class="s">"expense_decrease_to"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"{EXPENSE_DECREASE} for a total of {AMOUNT} for the fiscal year"</span>
            <span class="p">],</span>
            <span class="s">"has_date"</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">"{AMOUNT} for the fiscal year ended {FISCAL_YEAR}"</span><span class="p">,</span>
                <span class="s">"{PERCENTAGE} for the fiscal year ended {FISCAL_YEAR}"</span><span class="p">,</span>
            <span class="p">],</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span>
    <span class="n">stages</span><span class="o">=</span><span class="p">[</span>
        <span class="n">document_assembler</span><span class="p">,</span>
        <span class="n">sentence_detector</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">embeddings</span><span class="p">,</span>
        <span class="n">ner_model</span><span class="p">,</span>
        <span class="n">ner_converter</span><span class="p">,</span>
        <span class="n">re_model</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""License fees revenue decreased 40 %, or $ 0.5 million to $ 0.7 million for the year ended December 31, 2020 compared to $ 1.2 million for the year ended December 31, 2019. Services revenue increased 4 %, or $ 1.1 million, to $ 25.6 million for the year ended December 31, 2020 from $ 24.5 million for the year ended December 31, 2019. Costs of revenue, excluding depreciation and amortization increased by $ 0.1 million, or 2 %, to $ 8.8 million for the year ended December 31, 2020 from $ 8.7 million for the year ended December 31, 2019.  Also, a decrease in travel costs of $ 0.4 million due to travel restrictions caused by the global pandemic. As a percentage of revenue, cost of revenue, excluding depreciation and amortization was 34 % for each of the years ended December 31, 2020 and 2019. Sales and marketing expenses decreased 20 %, or $ 1.5 million, to $ 6.0 million for the year ended December 31, 2020 from $ 7.5 million for the year ended December 31, 2019."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['hypothesis']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"hypothesis"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['nli_prediction']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"nli_prediction"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+----------------------------+----------------+-------------+-----------+-----------------+-----------+--------------------------------------------------------+--------------+---------------------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                      <span class="n">chunk1</span><span class="o">|</span>         <span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>           <span class="n">chunk2</span><span class="o">|</span>    <span class="n">entity2</span><span class="o">|</span>                                              <span class="n">hypothesis</span><span class="o">|</span><span class="n">nli_prediction</span><span class="o">|</span>             <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+----------------------------+----------------+-------------+-----------+-----------------+-----------+--------------------------------------------------------+--------------+---------------------+----------+</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">227</span><span class="o">|</span>        <span class="mi">238</span><span class="o">|</span>                <span class="mf">25.6</span> <span class="n">million</span><span class="o">|</span>          <span class="n">AMOUNT</span><span class="o">|</span>          <span class="mi">316</span><span class="o">|</span>        <span class="mi">332</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span><span class="mf">25.6</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.8744757</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">31</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span>                          <span class="mi">40</span><span class="o">|</span>      <span class="n">PERCENTAGE</span><span class="o">|</span>          <span class="mi">153</span><span class="o">|</span>        <span class="mi">169</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span>          <span class="mi">40</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.7889032</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">5</span><span class="o">|</span>          <span class="mi">799</span><span class="o">|</span>        <span class="mi">826</span><span class="o">|</span><span class="n">Sales</span> <span class="ow">and</span> <span class="n">marketing</span> <span class="n">expenses</span><span class="o">|</span><span class="n">EXPENSE_DECREASE</span><span class="o">|</span>          <span class="mi">923</span><span class="o">|</span>        <span class="mi">933</span><span class="o">|</span>      <span class="mf">7.5</span> <span class="n">million</span><span class="o">|</span>     <span class="n">AMOUNT</span><span class="o">|</span> <span class="n">Sales</span> <span class="ow">and</span> <span class="n">marketing</span> <span class="n">expenses</span> <span class="n">decreased</span> <span class="k">from</span> <span class="mf">7.5</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span><span class="n">expense_decrease_from</span><span class="o">|</span> <span class="mf">0.9770538</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">59</span><span class="o">|</span>         <span class="mi">69</span><span class="o">|</span>                 <span class="mf">0.7</span> <span class="n">million</span><span class="o">|</span>          <span class="n">AMOUNT</span><span class="o">|</span>           <span class="mi">90</span><span class="o">|</span>        <span class="mi">106</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.7</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.67187774</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">172</span><span class="o">|</span>        <span class="mi">187</span><span class="o">|</span>            <span class="n">Services</span> <span class="n">revenue</span><span class="o">|</span> <span class="n">PROFIT_INCREASE</span><span class="o">|</span>          <span class="mi">227</span><span class="o">|</span>        <span class="mi">238</span><span class="o">|</span>     <span class="mf">25.6</span> <span class="n">million</span><span class="o">|</span>     <span class="n">AMOUNT</span><span class="o">|</span>                        <span class="n">Services</span> <span class="n">revenue</span> <span class="n">to</span> <span class="mf">25.6</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>   <span class="n">profit_increase_to</span><span class="o">|</span> <span class="mf">0.9674029</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">31</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span>                          <span class="mi">40</span><span class="o">|</span>      <span class="n">PERCENTAGE</span><span class="o">|</span>           <span class="mi">90</span><span class="o">|</span>        <span class="mi">106</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span>          <span class="mi">40</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.77800345</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">5</span><span class="o">|</span>          <span class="mi">838</span><span class="o">|</span>        <span class="mi">839</span><span class="o">|</span>                          <span class="mi">20</span><span class="o">|</span>      <span class="n">PERCENTAGE</span><span class="o">|</span>          <span class="mi">898</span><span class="o">|</span>        <span class="mi">914</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span>          <span class="mi">20</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.85455483</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">3</span><span class="o">|</span>          <span class="mi">561</span><span class="o">|</span>        <span class="mi">572</span><span class="o">|</span>                <span class="n">travel</span> <span class="n">costs</span><span class="o">|</span><span class="n">EXPENSE_DECREASE</span><span class="o">|</span>          <span class="mi">579</span><span class="o">|</span>        <span class="mi">589</span><span class="o">|</span>      <span class="mf">0.4</span> <span class="n">million</span><span class="o">|</span>     <span class="n">AMOUNT</span><span class="o">|</span>                   <span class="n">travel</span> <span class="n">costs</span> <span class="n">decreased</span> <span class="n">by</span> <span class="mf">0.4</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>  <span class="n">expense_decrease_by</span><span class="o">|</span> <span class="mf">0.9946776</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">42</span><span class="o">|</span>         <span class="mi">52</span><span class="o">|</span>                 <span class="mf">0.5</span> <span class="n">million</span><span class="o">|</span>          <span class="n">AMOUNT</span><span class="o">|</span>          <span class="mi">153</span><span class="o">|</span>        <span class="mi">169</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.7756689</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">172</span><span class="o">|</span>        <span class="mi">187</span><span class="o">|</span>            <span class="n">Services</span> <span class="n">revenue</span><span class="o">|</span> <span class="n">PROFIT_INCREASE</span><span class="o">|</span>          <span class="mi">209</span><span class="o">|</span>        <span class="mi">219</span><span class="o">|</span>      <span class="mf">1.1</span> <span class="n">million</span><span class="o">|</span>     <span class="n">AMOUNT</span><span class="o">|</span>                       <span class="n">Services</span> <span class="n">revenue</span> <span class="k">from</span> <span class="mf">1.1</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span> <span class="n">profit_increase_from</span><span class="o">|</span><span class="mf">0.96610945</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">2</span><span class="o">|</span>          <span class="mi">408</span><span class="o">|</span>        <span class="mi">418</span><span class="o">|</span>                 <span class="mf">0.1</span> <span class="n">million</span><span class="o">|</span>          <span class="n">AMOUNT</span><span class="o">|</span>          <span class="mi">521</span><span class="o">|</span>        <span class="mi">537</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.1</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.9083247</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">5</span><span class="o">|</span>          <span class="mi">849</span><span class="o">|</span>        <span class="mi">859</span><span class="o">|</span>                 <span class="mf">1.5</span> <span class="n">million</span><span class="o">|</span>          <span class="n">AMOUNT</span><span class="o">|</span>          <span class="mi">898</span><span class="o">|</span>        <span class="mi">914</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">1.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.7528142</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">5</span><span class="o">|</span>          <span class="mi">849</span><span class="o">|</span>        <span class="mi">859</span><span class="o">|</span>                 <span class="mf">1.5</span> <span class="n">million</span><span class="o">|</span>          <span class="n">AMOUNT</span><span class="o">|</span>          <span class="mi">954</span><span class="o">|</span>        <span class="mi">970</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">1.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.80734617</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">42</span><span class="o">|</span>         <span class="mi">52</span><span class="o">|</span>                 <span class="mf">0.5</span> <span class="n">million</span><span class="o">|</span>          <span class="n">AMOUNT</span><span class="o">|</span>           <span class="mi">90</span><span class="o">|</span>        <span class="mi">106</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.7157578</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">172</span><span class="o">|</span>        <span class="mi">187</span><span class="o">|</span>            <span class="n">Services</span> <span class="n">revenue</span><span class="o">|</span> <span class="n">PROFIT_INCREASE</span><span class="o">|</span>          <span class="mi">284</span><span class="o">|</span>        <span class="mi">295</span><span class="o">|</span>     <span class="mf">24.5</span> <span class="n">million</span><span class="o">|</span>     <span class="n">AMOUNT</span><span class="o">|</span>                        <span class="n">Services</span> <span class="n">revenue</span> <span class="n">to</span> <span class="mf">24.5</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>   <span class="n">profit_increase_to</span><span class="o">|</span> <span class="mf">0.8597209</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">59</span><span class="o">|</span>         <span class="mi">69</span><span class="o">|</span>                 <span class="mf">0.7</span> <span class="n">million</span><span class="o">|</span>          <span class="n">AMOUNT</span><span class="o">|</span>          <span class="mi">153</span><span class="o">|</span>        <span class="mi">169</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.7</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.74845695</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">199</span><span class="o">|</span>        <span class="mi">199</span><span class="o">|</span>                           <span class="mi">4</span><span class="o">|</span>      <span class="n">PERCENTAGE</span><span class="o">|</span>          <span class="mi">259</span><span class="o">|</span>        <span class="mi">275</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span>           <span class="mi">4</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.84127575</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">2</span><span class="o">|</span>          <span class="mi">424</span><span class="o">|</span>        <span class="mi">424</span><span class="o">|</span>                           <span class="mi">2</span><span class="o">|</span>      <span class="n">PERCENTAGE</span><span class="o">|</span>          <span class="mi">465</span><span class="o">|</span>        <span class="mi">481</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span>           <span class="mi">2</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.8046481</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">2</span><span class="o">|</span>          <span class="mi">424</span><span class="o">|</span>        <span class="mi">424</span><span class="o">|</span>                           <span class="mi">2</span><span class="o">|</span>      <span class="n">PERCENTAGE</span><span class="o">|</span>          <span class="mi">521</span><span class="o">|</span>        <span class="mi">537</span><span class="o">|</span><span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span><span class="n">FISCAL_YEAR</span><span class="o">|</span>           <span class="mi">2</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="n">December</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.8485104</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">0</span><span class="o">|</span>         <span class="mi">19</span><span class="o">|</span>        <span class="n">License</span> <span class="n">fees</span> <span class="n">revenue</span><span class="o">|</span>  <span class="n">PROFIT_DECLINE</span><span class="o">|</span>           <span class="mi">31</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span>               <span class="mi">40</span><span class="o">|</span> <span class="n">PERCENTAGE</span><span class="o">|</span>               <span class="n">License</span> <span class="n">fees</span> <span class="n">revenue</span> <span class="n">decreased</span> <span class="n">by</span> <span class="n">a</span> <span class="mi">40</span> <span class="n">to</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span><span class="n">profit_decline_by_per</span><span class="o">|</span> <span class="mf">0.9948003</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+----------------------------+----------------+-------------+-----------+-----------------+-----------+--------------------------------------------------------+--------------+---------------------+----------+</span>
<span class="n">only</span> <span class="n">showing</span> <span class="n">top</span> <span class="mi">20</span> <span class="n">rows</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">johnsnowlabs</span> <span class="kn">import</span> <span class="n">nlp</span><span class="p">,</span> <span class="n">legal</span>

<span class="n">documentAssembler</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">DocumentAssembler</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCol</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"token"</span><span class="p">)</span>

<span class="n">tokenClassifier</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">BertForTokenClassification</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">'legner_obligations'</span><span class="p">,</span><span class="s">'en'</span><span class="p">,</span> <span class="s">'legal/models'</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">(</span><span class="s">"token"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setMaxSentenceLength</span><span class="p">(</span><span class="mi">512</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setCaseSensitive</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>

<span class="n">ner_converter</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">NerConverterInternal</span><span class="p">()</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"document"</span><span class="p">,</span> <span class="s">"token"</span><span class="p">,</span> <span class="s">"ner"</span><span class="p">])</span>\
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"ner_chunk"</span><span class="p">)</span>

<span class="n">re_model</span> <span class="o">=</span> <span class="n">legal</span><span class="p">.</span><span class="n">ZeroShotRelationExtractionModel</span><span class="p">.</span><span class="n">pretrained</span><span class="p">(</span><span class="s">"legre_zero_shot"</span><span class="p">,</span> <span class="s">"en"</span><span class="p">,</span> <span class="s">"legal/models"</span><span class="p">)</span>\
    <span class="p">.</span><span class="n">setInputCols</span><span class="p">([</span><span class="s">"ner_chunk"</span><span class="p">,</span> <span class="s">"document"</span><span class="p">])</span> \
    <span class="p">.</span><span class="n">setOutputCol</span><span class="p">(</span><span class="s">"relations"</span><span class="p">)</span>

<span class="n">re_model</span><span class="p">.</span><span class="n">setRelationalCategories</span><span class="p">({</span>
    <span class="s">"GRANTS_TO"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{OBLIGATION_SUBJECT} grants {OBLIGATION_INDIRECT_OBJECT}"</span><span class="p">],</span>
    <span class="s">"GRANTS"</span><span class="p">:</span> <span class="p">[</span><span class="s">"{OBLIGATION_SUBJECT} grants {OBLIGATION_ACTION}"</span><span class="p">]</span>
<span class="p">})</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">document_assembler</span><span class="p">,</span>  
                <span class="n">tokenizer</span><span class="p">,</span>
                <span class="n">tokenClassifier</span><span class="p">,</span> 
                <span class="n">ner_converter</span><span class="p">,</span>
                <span class="n">re_model</span>
               <span class="p">])</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"""Arizona Copyright Grant. Subject to the terms and conditions of this Agreement, Arizona hereby grants to the Company a perpetual, non-exclusive, royalty-free license in, to and under the Arizona Licensed Copyrights for use in the Company Field throughout the world."""</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">createDataFrame</span><span class="p">([[</span><span class="n">text</span><span class="p">]]).</span><span class="n">toDF</span><span class="p">(</span><span class="s">"text"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">functions</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">result</span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">explode</span><span class="p">(</span><span class="n">F</span><span class="p">.</span><span class="n">arrays_zip</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">metadata</span><span class="p">,</span> <span class="n">result</span><span class="p">.</span><span class="n">relations</span><span class="p">.</span><span class="n">result</span><span class="p">)).</span><span class="n">alias</span><span class="p">(</span><span class="s">"cols"</span><span class="p">)).</span><span class="n">select</span><span class="p">(</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['sentence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"sentence"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity1"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_begin']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_begin"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2_end']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2_end"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['chunk2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"chunk2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['entity2']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"entity2"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['hypothesis']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"hypothesis"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['nli_prediction']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"nli_prediction"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['1']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"relation"</span><span class="p">),</span>
    <span class="n">F</span><span class="p">.</span><span class="n">expr</span><span class="p">(</span><span class="s">"cols['0']['confidence']"</span><span class="p">).</span><span class="n">alias</span><span class="p">(</span><span class="s">"confidence"</span><span class="p">),</span>
<span class="p">).</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>

<span class="o">+--------+-------------+-----------+-------+------------------+-------------+-----------+-------------+--------------------------+----------------------------+--------------+---------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span> <span class="n">chunk1</span><span class="o">|</span>           <span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>       <span class="n">chunk2</span><span class="o">|</span>                   <span class="n">entity2</span><span class="o">|</span>                  <span class="n">hypothesis</span><span class="o">|</span><span class="n">nli_prediction</span><span class="o">|</span> <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-------+------------------+-------------+-----------+-------------+--------------------------+----------------------------+--------------+---------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">80</span><span class="o">|</span>         <span class="mi">86</span><span class="o">|</span><span class="n">Arizona</span><span class="o">|</span><span class="n">OBLIGATION_SUBJECT</span><span class="o">|</span>          <span class="mi">109</span><span class="o">|</span>        <span class="mi">115</span><span class="o">|</span>      <span class="n">Company</span><span class="o">|</span><span class="n">OBLIGATION_INDIRECT_OBJECT</span><span class="o">|</span>      <span class="n">Arizona</span> <span class="n">grants</span> <span class="n">Company</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span><span class="n">GRANTS_TO</span><span class="o">|</span> <span class="mf">0.9535338</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">80</span><span class="o">|</span>         <span class="mi">86</span><span class="o">|</span><span class="n">Arizona</span><span class="o">|</span><span class="n">OBLIGATION_SUBJECT</span><span class="o">|</span>           <span class="mi">88</span><span class="o">|</span>        <span class="mi">100</span><span class="o">|</span><span class="n">hereby</span> <span class="n">grants</span><span class="o">|</span>         <span class="n">OBLIGATION_ACTION</span><span class="o">|</span><span class="n">Arizona</span> <span class="n">grants</span> <span class="n">hereby</span> <span class="n">grants</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>   <span class="n">GRANTS</span><span class="o">|</span> <span class="mf">0.9873099</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-------+------------------+-------------+-----------+-------------+--------------------------+----------------------------+--------------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Python-->
<!--Scala--> 
<div class="tabs-mfl-box">

        <div class="tabs-mfl-head">
          <p><button class="tab-mfl-li">Medical</button><button class="tab-mfl-li">Finance</button><button class="tab-mfl-li">Legal</button></p>
        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documenter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentencer</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl_healthcare"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"tokens"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">wordsEmbedder</span> <span class="k">=</span> <span class="nv">WordEmbeddingsModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"embeddings_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerClinical</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_clinical"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerClinicalConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_clinical"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_clinical_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"PROBLEM"</span><span class="o">,</span> <span class="s">"TEST"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">nerPosology</span> <span class="k">=</span> <span class="nv">MedicalNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_posology"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerPosologyConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">,</span> <span class="s">"ner_posology"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_posology_chunks"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setWhiteList</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"DRUG"</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">chunkMerger</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ChunkMergeApproach</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_clinical_chunks"</span><span class="o">,</span> <span class="s">"ner_posology_chunks"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"merged_ner_chunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">posTagger</span> <span class="k">=</span> <span class="nv">PerceptronModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"pos_clinical"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentences"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"pos_tags"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">dependencyParser</span> <span class="k">=</span> <span class="nv">DependencyParserModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"dependency_conllu"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"pos_tags"</span><span class="o">,</span> <span class="s">"tokens"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"dependencies"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reNerChunkFilter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">RENerChunksFilter</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setRelationPairs</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"problem-test"</span><span class="o">,</span> <span class="s">"problem-drug"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setMaxSyntacticDistance</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setDocLevelRelations</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"merged_ner_chunks"</span><span class="o">,</span> <span class="s">"dependencies"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reModel</span> <span class="k">=</span> <span class="nv">ZeroShotRelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"re_zeroshot_biobert"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"clinical/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"re_ner_chunks"</span><span class="o">,</span> <span class="s">"sentences"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMultiLabel</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setRelationalCategories</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span>
        <span class="s">"ADE"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{DRUG} causes {PROBLEM}."</span><span class="o">),</span>
        <span class="s">"IMPROVE"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{DRUG} improves {PROBLEM}."</span><span class="o">,</span> <span class="s">"{DRUG} cures {PROBLEM}."</span><span class="o">),</span>
        <span class="s">"REVEAL"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{TEST} reveals {PROBLEM}."</span><span class="o">)</span>
    <span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documenter</span><span class="o">,</span>
    <span class="n">sentencer</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">wordsEmbedder</span><span class="o">,</span>
    <span class="n">nerClinical</span><span class="o">,</span>
    <span class="n">nerClinicalConverter</span><span class="o">,</span>
    <span class="n">nerPosology</span><span class="o">,</span>
    <span class="n">nerPosologyConverter</span><span class="o">,</span>
    <span class="n">chunkMerger</span><span class="o">,</span>
    <span class="n">posTagger</span><span class="o">,</span>
    <span class="n">dependencyParser</span><span class="o">,</span>
    <span class="n">reNerChunkFilter</span><span class="o">,</span>
    <span class="n">reModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"Paracetamol can alleviate headache or sickness. An MRI test can be used to find cancer."</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>
 
<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+--------------------+--------------+--------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>     <span class="n">chunk1</span><span class="o">|</span><span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>  <span class="n">chunk2</span><span class="o">|</span><span class="n">entity2</span><span class="o">|</span>          <span class="n">hypothesis</span><span class="o">|</span><span class="n">nli_prediction</span><span class="o">|</span><span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+--------------------+--------------+--------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">0</span><span class="o">|</span>         <span class="mi">10</span><span class="o">|</span><span class="nc">Paracetamol</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>           <span class="mi">38</span><span class="o">|</span>         <span class="mi">45</span><span class="o">|</span><span class="n">sickness</span><span class="o">|</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="nc">Paracetamol</span> <span class="n">impro</span><span class="o">...|</span>        <span class="n">entail</span><span class="o">|</span> <span class="nc">IMPROVE</span><span class="o">|</span><span class="mf">0.98819494</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">0</span><span class="o">|</span>         <span class="mi">10</span><span class="o">|</span><span class="nc">Paracetamol</span><span class="o">|</span>   <span class="nc">DRUG</span><span class="o">|</span>           <span class="mi">26</span><span class="o">|</span>         <span class="mi">33</span><span class="o">|</span><span class="n">headache</span><span class="o">|</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="nc">Paracetamol</span> <span class="n">impro</span><span class="o">...|</span>        <span class="n">entail</span><span class="o">|</span> <span class="nc">IMPROVE</span><span class="o">|</span> <span class="mf">0.9929625</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>           <span class="mi">48</span><span class="o">|</span>         <span class="mi">58</span><span class="o">|</span><span class="nc">An</span> <span class="nc">MRI</span> <span class="n">test</span><span class="o">|</span>   <span class="nc">TEST</span><span class="o">|</span>           <span class="mi">80</span><span class="o">|</span>         <span class="mi">85</span><span class="o">|</span>  <span class="n">cancer</span><span class="o">|</span><span class="nc">PROBLEM</span><span class="o">|</span><span class="nc">An</span> <span class="nc">MRI</span> <span class="n">test</span> <span class="n">revea</span><span class="o">...|</span>        <span class="n">entail</span><span class="o">|</span>  <span class="nc">REVEAL</span><span class="o">|</span> <span class="mf">0.9760039</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-----------+-------+-------------+-----------+--------+-------+--------------------+--------------+--------+----------+</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">sentenceDetector</span> <span class="k">=</span> <span class="nv">SentenceDetectorDLModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"sentence_detector_dl"</span><span class="o">,</span> <span class="s">"xx"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">embeddings</span> <span class="k">=</span> <span class="nv">BertEmbeddings</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"bert_embeddings_sec_bert_base"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"embeddings"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerModel</span> <span class="k">=</span> <span class="nv">FinanceNerModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finner_financial_small"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"embeddings"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"sentence"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reModel</span> <span class="k">=</span> <span class="nv">ZeroShotRelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"finre_zero_shot"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"finance/models"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"sentence"</span><span class="o">))</span>
  <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setMultiLabel</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
  <span class="o">.</span><span class="py">setRelationalCategories</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span>
  <span class="s">"profit_decline_by"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span>
    <span class="s">"{PROFIT_DECLINE} decreased by {AMOUNT} from"</span><span class="o">,</span>
    <span class="s">"{PROFIT_DECLINE} decreased by {AMOUNT} to"</span>
  <span class="o">),</span>
  <span class="s">"profit_decline_by_per"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span>
    <span class="s">"{PROFIT_DECLINE} decreased by a {PERCENTAGE} from"</span><span class="o">,</span>
    <span class="s">"{PROFIT_DECLINE} decreased by a {PERCENTAGE} to"</span>
  <span class="o">),</span>
  <span class="s">"profit_decline_from"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span>
    <span class="s">"{PROFIT_DECLINE} decreased from {AMOUNT}"</span><span class="o">,</span>
    <span class="s">"{PROFIT_DECLINE} decreased from {AMOUNT} for the year"</span>
  <span class="o">),</span>
  <span class="s">"profit_decline_from_per"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span>
    <span class="s">"{PROFIT_DECLINE} decreased from {PERCENTAGE} to"</span><span class="o">,</span>
    <span class="s">"{PROFIT_DECLINE} decreased from {PERCENTAGE} to a total of"</span>
  <span class="o">),</span>
  <span class="s">"profit_decline_to"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{PROFIT_DECLINE} to {AMOUNT}"</span><span class="o">),</span>
  <span class="s">"profit_increase_from"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{PROFIT_INCREASE} from {AMOUNT}"</span><span class="o">),</span>
  <span class="s">"profit_increase_to"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{PROFIT_INCREASE} to {AMOUNT}"</span><span class="o">),</span>
  <span class="s">"expense_decrease_by"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{EXPENSE_DECREASE} decreased by {AMOUNT}"</span><span class="o">),</span>
  <span class="s">"expense_decrease_by_per"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{EXPENSE_DECREASE} decreased by a {PERCENTAGE}"</span><span class="o">),</span>
  <span class="s">"expense_decrease_from"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{EXPENSE_DECREASE} decreased from {AMOUNT}"</span><span class="o">),</span>
  <span class="s">"expense_decrease_to"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{EXPENSE_DECREASE} for a total of {AMOUNT} for the fiscal year"</span><span class="o">),</span>
  <span class="s">"has_date"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span>
    <span class="s">"{AMOUNT} for the fiscal year ended {FISCAL_YEAR}"</span><span class="o">,</span>
    <span class="s">"{PERCENTAGE} for the fiscal year ended {FISCAL_YEAR}"</span>
  <span class="o">)</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">sentenceDetector</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">embeddings</span><span class="o">,</span>
    <span class="n">nerModel</span><span class="o">,</span>
    <span class="n">nerConverter</span><span class="o">,</span>
    <span class="n">reModel</span>
  <span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""License fees revenue decreased 40 %, or $ 0.5 million to $ 0.7 million for the year ended December 31, 2020 compared to $ 1.2 million for the year ended December 31, 2019. Services revenue increased 4 %, or $ 1.1 million, to $ 25.6 million for the year ended December 31, 2020 from $ 24.5 million for the year ended December 31, 2019. Costs of revenue, excluding depreciation and amortization increased by $ 0.1 million, or 2 %, to $ 8.8 million for the year ended December 31, 2020 from $ 8.7 million for the year ended December 31, 2019.  Also, a decrease in travel costs of $ 0.4 million due to travel restrictions caused by the global pandemic. As a percentage of revenue, cost of revenue, excluding depreciation and amortization was 34 % for each of the years ended December 31, 2020 and 2019. Sales and marketing expenses decreased 20 %, or $ 1.5 million, to $ 6.0 million for the year ended December 31, 2020 from $ 7.5 million for the year ended December 31, 2019."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>

<span class="o">+--------+-------------+-----------+----------------------------+----------------+-------------+-----------+-----------------+-----------+--------------------------------------------------------+--------------+---------------------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span>                      <span class="n">chunk1</span><span class="o">|</span>         <span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>           <span class="n">chunk2</span><span class="o">|</span>    <span class="n">entity2</span><span class="o">|</span>                                              <span class="n">hypothesis</span><span class="o">|</span><span class="n">nli_prediction</span><span class="o">|</span>             <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+----------------------------+----------------+-------------+-----------+-----------------+-----------+--------------------------------------------------------+--------------+---------------------+----------+</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">227</span><span class="o">|</span>        <span class="mi">238</span><span class="o">|</span>                <span class="mf">25.6</span> <span class="n">million</span><span class="o">|</span>          <span class="nc">AMOUNT</span><span class="o">|</span>          <span class="mi">316</span><span class="o">|</span>        <span class="mi">332</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span><span class="mf">25.6</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.8744757</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">31</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span>                          <span class="mi">40</span><span class="o">|</span>      <span class="nc">PERCENTAGE</span><span class="o">|</span>          <span class="mi">153</span><span class="o">|</span>        <span class="mi">169</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span>          <span class="mi">40</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.7889032</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">5</span><span class="o">|</span>          <span class="mi">799</span><span class="o">|</span>        <span class="mi">826</span><span class="o">|</span><span class="nc">Sales</span> <span class="n">and</span> <span class="n">marketing</span> <span class="n">expenses</span><span class="o">|</span><span class="nc">EXPENSE_DECREASE</span><span class="o">|</span>          <span class="mi">923</span><span class="o">|</span>        <span class="mi">933</span><span class="o">|</span>      <span class="mf">7.5</span> <span class="n">million</span><span class="o">|</span>     <span class="nc">AMOUNT</span><span class="o">|</span> <span class="nc">Sales</span> <span class="n">and</span> <span class="n">marketing</span> <span class="n">expenses</span> <span class="n">decreased</span> <span class="n">from</span> <span class="mf">7.5</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span><span class="n">expense_decrease_from</span><span class="o">|</span> <span class="mf">0.9770538</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">59</span><span class="o">|</span>         <span class="mi">69</span><span class="o">|</span>                 <span class="mf">0.7</span> <span class="n">million</span><span class="o">|</span>          <span class="nc">AMOUNT</span><span class="o">|</span>           <span class="mi">90</span><span class="o">|</span>        <span class="mi">106</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.7</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.67187774</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">172</span><span class="o">|</span>        <span class="mi">187</span><span class="o">|</span>            <span class="nc">Services</span> <span class="n">revenue</span><span class="o">|</span> <span class="nc">PROFIT_INCREASE</span><span class="o">|</span>          <span class="mi">227</span><span class="o">|</span>        <span class="mi">238</span><span class="o">|</span>     <span class="mf">25.6</span> <span class="n">million</span><span class="o">|</span>     <span class="nc">AMOUNT</span><span class="o">|</span>                        <span class="nc">Services</span> <span class="n">revenue</span> <span class="n">to</span> <span class="mf">25.6</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>   <span class="n">profit_increase_to</span><span class="o">|</span> <span class="mf">0.9674029</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">31</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span>                          <span class="mi">40</span><span class="o">|</span>      <span class="nc">PERCENTAGE</span><span class="o">|</span>           <span class="mi">90</span><span class="o">|</span>        <span class="mi">106</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span>          <span class="mi">40</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.77800345</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">5</span><span class="o">|</span>          <span class="mi">838</span><span class="o">|</span>        <span class="mi">839</span><span class="o">|</span>                          <span class="mi">20</span><span class="o">|</span>      <span class="nc">PERCENTAGE</span><span class="o">|</span>          <span class="mi">898</span><span class="o">|</span>        <span class="mi">914</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span>          <span class="mi">20</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.85455483</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">3</span><span class="o">|</span>          <span class="mi">561</span><span class="o">|</span>        <span class="mi">572</span><span class="o">|</span>                <span class="n">travel</span> <span class="n">costs</span><span class="o">|</span><span class="nc">EXPENSE_DECREASE</span><span class="o">|</span>          <span class="mi">579</span><span class="o">|</span>        <span class="mi">589</span><span class="o">|</span>      <span class="mf">0.4</span> <span class="n">million</span><span class="o">|</span>     <span class="nc">AMOUNT</span><span class="o">|</span>                   <span class="n">travel</span> <span class="n">costs</span> <span class="n">decreased</span> <span class="n">by</span> <span class="mf">0.4</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>  <span class="n">expense_decrease_by</span><span class="o">|</span> <span class="mf">0.9946776</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">42</span><span class="o">|</span>         <span class="mi">52</span><span class="o">|</span>                 <span class="mf">0.5</span> <span class="n">million</span><span class="o">|</span>          <span class="nc">AMOUNT</span><span class="o">|</span>          <span class="mi">153</span><span class="o">|</span>        <span class="mi">169</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.7756689</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">172</span><span class="o">|</span>        <span class="mi">187</span><span class="o">|</span>            <span class="nc">Services</span> <span class="n">revenue</span><span class="o">|</span> <span class="nc">PROFIT_INCREASE</span><span class="o">|</span>          <span class="mi">209</span><span class="o">|</span>        <span class="mi">219</span><span class="o">|</span>      <span class="mf">1.1</span> <span class="n">million</span><span class="o">|</span>     <span class="nc">AMOUNT</span><span class="o">|</span>                       <span class="nc">Services</span> <span class="n">revenue</span> <span class="n">from</span> <span class="mf">1.1</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span> <span class="n">profit_increase_from</span><span class="o">|</span><span class="mf">0.96610945</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">2</span><span class="o">|</span>          <span class="mi">408</span><span class="o">|</span>        <span class="mi">418</span><span class="o">|</span>                 <span class="mf">0.1</span> <span class="n">million</span><span class="o">|</span>          <span class="nc">AMOUNT</span><span class="o">|</span>          <span class="mi">521</span><span class="o">|</span>        <span class="mi">537</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.1</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.9083247</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">5</span><span class="o">|</span>          <span class="mi">849</span><span class="o">|</span>        <span class="mi">859</span><span class="o">|</span>                 <span class="mf">1.5</span> <span class="n">million</span><span class="o">|</span>          <span class="nc">AMOUNT</span><span class="o">|</span>          <span class="mi">898</span><span class="o">|</span>        <span class="mi">914</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">1.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.7528142</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">5</span><span class="o">|</span>          <span class="mi">849</span><span class="o">|</span>        <span class="mi">859</span><span class="o">|</span>                 <span class="mf">1.5</span> <span class="n">million</span><span class="o">|</span>          <span class="nc">AMOUNT</span><span class="o">|</span>          <span class="mi">954</span><span class="o">|</span>        <span class="mi">970</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">1.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.80734617</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">42</span><span class="o">|</span>         <span class="mi">52</span><span class="o">|</span>                 <span class="mf">0.5</span> <span class="n">million</span><span class="o">|</span>          <span class="nc">AMOUNT</span><span class="o">|</span>           <span class="mi">90</span><span class="o">|</span>        <span class="mi">106</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.5</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.7157578</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">172</span><span class="o">|</span>        <span class="mi">187</span><span class="o">|</span>            <span class="nc">Services</span> <span class="n">revenue</span><span class="o">|</span> <span class="nc">PROFIT_INCREASE</span><span class="o">|</span>          <span class="mi">284</span><span class="o">|</span>        <span class="mi">295</span><span class="o">|</span>     <span class="mf">24.5</span> <span class="n">million</span><span class="o">|</span>     <span class="nc">AMOUNT</span><span class="o">|</span>                        <span class="nc">Services</span> <span class="n">revenue</span> <span class="n">to</span> <span class="mf">24.5</span> <span class="n">million</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>   <span class="n">profit_increase_to</span><span class="o">|</span> <span class="mf">0.8597209</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">59</span><span class="o">|</span>         <span class="mi">69</span><span class="o">|</span>                 <span class="mf">0.7</span> <span class="n">million</span><span class="o">|</span>          <span class="nc">AMOUNT</span><span class="o">|</span>          <span class="mi">153</span><span class="o">|</span>        <span class="mi">169</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span> <span class="mf">0.7</span> <span class="n">million</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.74845695</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">1</span><span class="o">|</span>          <span class="mi">199</span><span class="o">|</span>        <span class="mi">199</span><span class="o">|</span>                           <span class="mi">4</span><span class="o">|</span>      <span class="nc">PERCENTAGE</span><span class="o">|</span>          <span class="mi">259</span><span class="o">|</span>        <span class="mi">275</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span>           <span class="mi">4</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span><span class="mf">0.84127575</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">2</span><span class="o">|</span>          <span class="mi">424</span><span class="o">|</span>        <span class="mi">424</span><span class="o">|</span>                           <span class="mi">2</span><span class="o">|</span>      <span class="nc">PERCENTAGE</span><span class="o">|</span>          <span class="mi">465</span><span class="o">|</span>        <span class="mi">481</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span>           <span class="mi">2</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2020</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.8046481</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">2</span><span class="o">|</span>          <span class="mi">424</span><span class="o">|</span>        <span class="mi">424</span><span class="o">|</span>                           <span class="mi">2</span><span class="o">|</span>      <span class="nc">PERCENTAGE</span><span class="o">|</span>          <span class="mi">521</span><span class="o">|</span>        <span class="mi">537</span><span class="o">|</span><span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span><span class="nc">FISCAL_YEAR</span><span class="o">|</span>           <span class="mi">2</span> <span class="k">for</span> <span class="n">the</span> <span class="n">fiscal</span> <span class="n">year</span> <span class="n">ended</span> <span class="nc">December</span> <span class="mi">31</span><span class="o">,</span> <span class="mi">2019</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>             <span class="n">has_date</span><span class="o">|</span> <span class="mf">0.8485104</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>            <span class="mi">0</span><span class="o">|</span>         <span class="mi">19</span><span class="o">|</span>        <span class="nc">License</span> <span class="n">fees</span> <span class="n">revenue</span><span class="o">|</span>  <span class="nc">PROFIT_DECLINE</span><span class="o">|</span>           <span class="mi">31</span><span class="o">|</span>         <span class="mi">32</span><span class="o">|</span>               <span class="mi">40</span><span class="o">|</span> <span class="nc">PERCENTAGE</span><span class="o">|</span>               <span class="nc">License</span> <span class="n">fees</span> <span class="n">revenue</span> <span class="n">decreased</span> <span class="n">by</span> <span class="n">a</span> <span class="mi">40</span> <span class="n">to</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span><span class="n">profit_decline_by_per</span><span class="o">|</span> <span class="mf">0.9948003</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+----------------------------+----------------+-------------+-----------+-----------------+-----------+--------------------------------------------------------+--------------+---------------------+----------+</span>
<span class="n">only</span> <span class="n">showing</span> <span class="n">top</span> <span class="mi">20</span> <span class="n">rows</span>
</code></pre></div>          </div>

        </div>

        <div class="tab-mfl-content">

          <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">val</span> <span class="nv">documentAssembler</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">DocumentAssembler</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCol</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"document"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenizer</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Tokenizer</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"token"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">tokenClassifier</span> <span class="k">=</span> <span class="nv">LegalBertForTokenClassification</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legner_obligations"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"token"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setMaxSentenceLength</span><span class="o">(</span><span class="mi">512</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setCaseSensitive</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">nerConverter</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">NerConverterInternal</span><span class="o">()</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"document"</span><span class="o">,</span> <span class="s">"token"</span><span class="o">,</span> <span class="s">"ner"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">reModel</span> <span class="k">=</span> <span class="nv">ZeroShotRelationExtractionModel</span><span class="o">.</span><span class="py">pretrained</span><span class="o">(</span><span class="s">"legre_zero_shot"</span><span class="o">,</span> <span class="s">"en"</span><span class="o">,</span> <span class="s">"legal/models"</span><span class="o">)</span>
    <span class="o">.</span><span class="py">setInputCols</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="s">"ner_chunk"</span><span class="o">,</span> <span class="s">"document"</span><span class="o">))</span>
    <span class="o">.</span><span class="py">setOutputCol</span><span class="o">(</span><span class="s">"relations"</span><span class="o">)</span>

<span class="nv">reModel</span><span class="o">.</span><span class="py">setRelationalCategories</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span>
    <span class="s">"GRANTS_TO"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{OBLIGATION_SUBJECT} grants {OBLIGATION_INDIRECT_OBJECT}"</span><span class="o">),</span>
    <span class="s">"GRANTS"</span> <span class="o">-&gt;</span> <span class="nc">Array</span><span class="o">(</span><span class="s">"{OBLIGATION_SUBJECT} grants {OBLIGATION_ACTION}"</span><span class="o">)</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">pipeline</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">Pipeline</span><span class="o">().</span><span class="py">setStages</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span>
    <span class="n">documentAssembler</span><span class="o">,</span>
    <span class="n">tokenizer</span><span class="o">,</span>
    <span class="n">tokenClassifier</span><span class="o">,</span>
    <span class="n">nerConverter</span><span class="o">,</span>
    <span class="n">reModel</span>
<span class="o">))</span>

<span class="k">val</span> <span class="nv">text</span> <span class="k">=</span> <span class="s">"""Arizona Copyright Grant. Subject to the terms and conditions of this Agreement, Arizona hereby grants to the Company a perpetual, non-exclusive, royalty-free license in, to and under the Arizona Licensed Copyrights for use in the Company Field throughout the world."""</span>

<span class="k">val</span> <span class="nv">data</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="n">text</span><span class="o">).</span><span class="py">toDF</span><span class="o">(</span><span class="s">"text"</span><span class="o">)</span>

<span class="k">val</span> <span class="nv">result</span> <span class="k">=</span> <span class="nv">pipeline</span><span class="o">.</span><span class="py">fit</span><span class="o">(</span><span class="n">data</span><span class="o">).</span><span class="py">transform</span><span class="o">(</span><span class="n">data</span><span class="o">)</span>


<span class="o">+--------+-------------+-----------+-------+------------------+-------------+-----------+-------------+--------------------------+----------------------------+--------------+---------+----------+</span>
<span class="o">|</span><span class="n">sentence</span><span class="o">|</span><span class="n">entity1_begin</span><span class="o">|</span><span class="n">entity1_end</span><span class="o">|</span> <span class="n">chunk1</span><span class="o">|</span>           <span class="n">entity1</span><span class="o">|</span><span class="n">entity2_begin</span><span class="o">|</span><span class="n">entity2_end</span><span class="o">|</span>       <span class="n">chunk2</span><span class="o">|</span>                   <span class="n">entity2</span><span class="o">|</span>                  <span class="n">hypothesis</span><span class="o">|</span><span class="n">nli_prediction</span><span class="o">|</span> <span class="n">relation</span><span class="o">|</span><span class="n">confidence</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-------+------------------+-------------+-----------+-------------+--------------------------+----------------------------+--------------+---------+----------+</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">80</span><span class="o">|</span>         <span class="mi">86</span><span class="o">|</span><span class="nc">Arizona</span><span class="o">|</span><span class="nc">OBLIGATION_SUBJECT</span><span class="o">|</span>          <span class="mi">109</span><span class="o">|</span>        <span class="mi">115</span><span class="o">|</span>      <span class="nc">Company</span><span class="o">|</span><span class="nc">OBLIGATION_INDIRECT_OBJECT</span><span class="o">|</span>      <span class="nc">Arizona</span> <span class="n">grants</span> <span class="nc">Company</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span><span class="nc">GRANTS_TO</span><span class="o">|</span> <span class="mf">0.9535338</span><span class="o">|</span>
<span class="o">|</span>       <span class="mi">0</span><span class="o">|</span>           <span class="mi">80</span><span class="o">|</span>         <span class="mi">86</span><span class="o">|</span><span class="nc">Arizona</span><span class="o">|</span><span class="nc">OBLIGATION_SUBJECT</span><span class="o">|</span>           <span class="mi">88</span><span class="o">|</span>        <span class="mi">100</span><span class="o">|</span><span class="n">hereby</span> <span class="n">grants</span><span class="o">|</span>         <span class="nc">OBLIGATION_ACTION</span><span class="o">|</span><span class="nc">Arizona</span> <span class="n">grants</span> <span class="n">hereby</span> <span class="n">grants</span><span class="o">|</span>        <span class="n">entail</span><span class="o">|</span>   <span class="nc">GRANTS</span><span class="o">|</span> <span class="mf">0.9873099</span><span class="o">|</span>
<span class="o">+--------+-------------+-----------+-------+------------------+-------------+-----------+-------------+--------------------------+----------------------------+--------------+---------+----------+</span>
</code></pre></div>          </div>

        </div>

      </div>
<!--END Scala--> 

</details>

  </div>
  <!--END Model-->

</div>

</div><div class="d-print-none"><footer class="article__footer"><span class="footer_date">Last updated
      <time itemprop="dateModified" datetime="2020-08-10T00:00:00+00:00">Aug 10, 2020</time>
    </span><!-- start custom article footer snippet -->

<!-- end custom article footer snippet --></footer>

<script>

'use strict';

function tabs({tabsWrapperSelector, tabsParentSelector, tabsSelector, tabsContentSelector, activeClass}) {
    //Tabs

    const tabsWrapper = document.querySelectorAll(tabsWrapperSelector);

   

    
    //Detecting all tabs
    tabsWrapper.forEach(tab => {
        const tabsParent = tab.querySelector(tabsParentSelector),
                tabsLi = tab.querySelectorAll(tabsSelector),
                tabsContent = tab.querySelectorAll(tabsContentSelector);

        let jslFlag = false;


        tabsContent.forEach(item => {
            if(item.classList.contains('jsl-block')) {
                jslFlag = true;
                return;
            }
        })
        

        if(!jslFlag) {
            tabsLi.forEach(item => {
                if(item.classList.contains('tab-li-jsl')) {
                    item.remove();
                    return;
                }
            })
        }

        const   tabsLiAfter = tab.querySelectorAll(tabsSelector),
                tabsContentAfter = tab.querySelectorAll(tabsContentSelector);
                

        //Hiding all tabs
        function hideTabsContent() {
            if(Array.from(tabsLiAfter).length != 0) {
                tabsContentAfter.forEach(item => {
                    item.style.display = 'none';                    
                }); 
            }
            
            if(Array.from(tabsLiAfter).length != 0) {
                tabsLiAfter.forEach(item => {
                    item.classList.remove(activeClass);
                }); 
            }
        }

        //Show active tabs
        function showTabContent(i = 0) {
            if(Array.from(tabsContentAfter).length != 0) {
                tabsContentAfter[i].style.display = "block";
            }
            if(Array.from(tabsLiAfter).length != 0) {
                tabsLiAfter[i].classList.add(activeClass);            
            }
        }

        //Changing the tabs
        if(tabsParent != null) {
            tabsParent.addEventListener('click', (event) => {
                const target = event.target;
    
                if(target && target.classList.contains(tabsSelector.slice(1))) {
                    tabsLiAfter.forEach((item, i) => {
                        if(target == item) {
                            hideTabsContent();
                            try{showTabContent(i);}catch(e){}
                        }
                    });
                }
            });
        }        
        
        hideTabsContent();
        showTabContent();
    });
}

tabs({
    tabsWrapperSelector: '.tabs-model-aproach', 
    tabsParentSelector: '.tabs-model-aproach-head', 
    tabsSelector: '.tab-li-model-aproach', 
    tabsContentSelector: '.tabs-python-scala-box', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-python-scala-box', 
    tabsParentSelector: '.tabs-python-scala-head', 
    tabsSelector: '.tab-python-scala-li', 
    tabsContentSelector: '.tabs-mfl-box', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-mfl-box', 
    tabsParentSelector: '.tabs-mfl-head', 
    tabsSelector: '.tab-mfl-li', 
    tabsContentSelector: '.tab-mfl-content', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-wrapper', 
    tabsParentSelector: '.tabs-python-scala-head', 
    tabsSelector: '.tab-python-scala-li', 
    tabsContentSelector: '.tabs-item', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-box', 
    tabsParentSelector: '.tabs-model-aproach-head', 
    tabsSelector: '.tab-li-model-aproach', 
    tabsContentSelector: '.tabs-box .highlighter-rouge', 
    activeClass: 'tabheader_active'
});
tabs({
    tabsWrapperSelector: '.tabs-new', 
    tabsParentSelector: '.tabs-python-scala-head', 
    tabsSelector: '.tab-python-scala-li', 
    tabsContentSelector: '.tabs-new .highlighter-rouge', 
    activeClass: 'tabheader_active'
});

</script>


<style>
  /* Remove Scrollbar from Code Segments */
.article__content .highlighter-rouge > .highlight > pre > code, .article__content figure.highlight > pre > code  {
    overflow: auto;
}



button.code-selector-active {
 background-color: white;
 color: #08c;
 font-weight: bold;
 border-width: 1px;
 padding-left: 12px;
 padding-right: 12px;
 width: 90px;
 padding-top: 6px;
 margin-right: 2px;

 border-bottom: none;

 position: relative;
 z-index: 2;
}

button.code-selector-un-active {
    background-color: white;
    padding-left: 12px;
    padding-right: 12px;
    width: 90px;
    margin-right: 2px;
    padding-top: 8px;
    position: relative;
    border-bottom: none;

   }

hr.code-selector-underlie {
    border-top: 1px solid;
    background-color: black;
    width: 100%;
    height: 1px;
    margin-top: -3px;
    position: relative;

}

</style><div class="article__section-navigator clearfix"><div class="previous nav_link"><span>PREVIOUS</span><a href="/docs/en/licensed_install">Installation</a></div><div class="next nav_link"><span>NEXT</span><a href="/docs/en/licensed_training">Training</a></div></div></div>

</div>
</div>

<script>/*! jQuery v1.12.3 | (c) jQuery Foundation | jquery.org/license */
!function(a,b){"object"==typeof module&&"object"==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error("jQuery requires a window with a document");return b(a)}:b(a)}("undefined"!=typeof window?window:this,function(a,b){var c=[],d=a.document,e=c.slice,f=c.concat,g=c.push,h=c.indexOf,i={},j=i.toString,k=i.hasOwnProperty,l={},m="1.12.3",n=function(a,b){return new n.fn.init(a,b)},o=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,p=/^-ms-/,q=/-([\da-z])/gi,r=function(a,b){return b.toUpperCase()};n.fn=n.prototype={jquery:m,constructor:n,selector:"",length:0,toArray:function(){return e.call(this)},get:function(a){return null!=a?0>a?this[a+this.length]:this[a]:e.call(this)},pushStack:function(a){var b=n.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a){return n.each(this,a)},map:function(a){return this.pushStack(n.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(e.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0>a?b:0);return this.pushStack(c>=0&&b>c?[this[c]]:[])},end:function(){return this.prevObject||this.constructor()},push:g,sort:c.sort,splice:c.splice},n.extend=n.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for("boolean"==typeof g&&(j=g,g=arguments[h]||{},h++),"object"==typeof g||n.isFunction(g)||(g={}),h===i&&(g=this,h--);i>h;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&&(j&&c&&(n.isPlainObject(c)||(b=n.isArray(c)))?(b?(b=!1,f=a&&n.isArray(a)?a:[]):f=a&&n.isPlainObject(a)?a:{},g[d]=n.extend(j,f,c)):void 0!==c&&(g[d]=c));return g},n.extend({expando:"jQuery"+(m+Math.random()).replace(/\D/g,""),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return"function"===n.type(a)},isArray:Array.isArray||function(a){return"array"===n.type(a)},isWindow:function(a){return null!=a&&a==a.window},isNumeric:function(a){var b=a&&a.toString();return!n.isArray(a)&&b-parseFloat(b)+1>=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||"object"!==n.type(a)||a.nodeType||n.isWindow(a))return!1;try{if(a.constructor&&!k.call(a,"constructor")&&!k.call(a.constructor.prototype,"isPrototypeOf"))return!1}catch(c){return!1}if(!l.ownFirst)for(b in a)return k.call(a,b);for(b in a);return void 0===b||k.call(a,b)},type:function(a){return null==a?a+"":"object"==typeof a||"function"==typeof a?i[j.call(a)]||"object":typeof a},globalEval:function(b){b&&n.trim(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(p,"ms-").replace(q,r)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toLowerCase()===b.toLowerCase()},each:function(a,b){var c,d=0;if(s(a)){for(c=a.length;c>d;d++)if(b.call(a[d],d,a[d])===!1)break}else for(d in a)if(b.call(a[d],d,a[d])===!1)break;return a},trim:function(a){return null==a?"":(a+"").replace(o,"")},makeArray:function(a,b){var c=b||[];return null!=a&&(s(Object(a))?n.merge(c,"string"==typeof a?[a]:a):g.call(c,a)),c},inArray:function(a,b,c){var d;if(b){if(h)return h.call(b,a,c);for(d=b.length,c=c?0>c?Math.max(0,d+c):c:0;d>c;c++)if(c in b&&b[c]===a)return c}return-1},merge:function(a,b){var c=+b.length,d=0,e=a.length;while(c>d)a[e++]=b[d++];if(c!==c)while(void 0!==b[d])a[e++]=b[d++];return a.length=e,a},grep:function(a,b,c){for(var d,e=[],f=0,g=a.length,h=!c;g>f;f++)d=!b(a[f],f),d!==h&&e.push(a[f]);return e},map:function(a,b,c){var d,e,g=0,h=[];if(s(a))for(d=a.length;d>g;g++)e=b(a[g],g,c),null!=e&&h.push(e);else for(g in a)e=b(a[g],g,c),null!=e&&h.push(e);return f.apply([],h)},guid:1,proxy:function(a,b){var c,d,f;return"string"==typeof b&&(f=a[b],b=a,a=f),n.isFunction(a)?(c=e.call(arguments,2),d=function(){return a.apply(b||this,c.concat(e.call(arguments)))},d.guid=a.guid=a.guid||n.guid++,d):void 0},now:function(){return+new Date},support:l}),"function"==typeof Symbol&&(n.fn[Symbol.iterator]=c[Symbol.iterator]),n.each("Boolean Number String Function Array Date RegExp Object Error Symbol".split(" "),function(a,b){i["[object "+b+"]"]=b.toLowerCase()});function s(a){var b=!!a&&"length"in a&&a.length,c=n.type(a);return"function"===c||n.isWindow(a)?!1:"array"===c||0===b||"number"==typeof b&&b>0&&b-1 in a}var t=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u="sizzle"+1*new Date,v=a.document,w=0,x=0,y=ga(),z=ga(),A=ga(),B=function(a,b){return a===b&&(l=!0),0},C=1<<31,D={}.hasOwnProperty,E=[],F=E.pop,G=E.push,H=E.push,I=E.slice,J=function(a,b){for(var c=0,d=a.length;d>c;c++)if(a[c]===b)return c;return-1},K="checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped",L="[\\x20\\t\\r\\n\\f]",M="(?:\\\\.|[\\w-]|[^\\x00-\\xa0])+",N="\\["+L+"*("+M+")(?:"+L+"*([*^$|!~]?=)"+L+"*(?:'((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\"|("+M+"))|)"+L+"*\\]",O=":("+M+")(?:\\((('((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\")|((?:\\\\.|[^\\\\()[\\]]|"+N+")*)|.*)\\)|)",P=new RegExp(L+"+","g"),Q=new RegExp("^"+L+"+|((?:^|[^\\\\])(?:\\\\.)*)"+L+"+$","g"),R=new RegExp("^"+L+"*,"+L+"*"),S=new RegExp("^"+L+"*([>+~]|"+L+")"+L+"*"),T=new RegExp("="+L+"*([^\\]'\"]*?)"+L+"*\\]","g"),U=new RegExp(O),V=new RegExp("^"+M+"$"),W={ID:new RegExp("^#("+M+")"),CLASS:new RegExp("^\\.("+M+")"),TAG:new RegExp("^("+M+"|[*])"),ATTR:new RegExp("^"+N),PSEUDO:new RegExp("^"+O),CHILD:new RegExp("^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\("+L+"*(even|odd|(([+-]|)(\\d*)n|)"+L+"*(?:([+-]|)"+L+"*(\\d+)|))"+L+"*\\)|)","i"),bool:new RegExp("^(?:"+K+")$","i"),needsContext:new RegExp("^"+L+"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\("+L+"*((?:-\\d)?\\d*)"+L+"*\\)|)(?=[^-]|$)","i")},X=/^(?:input|select|textarea|button)$/i,Y=/^h\d$/i,Z=/^[^{]+\{\s*\[native \w/,$=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,_=/[+~]/,aa=/'|\\/g,ba=new RegExp("\\\\([\\da-f]{1,6}"+L+"?|("+L+")|.)","ig"),ca=function(a,b,c){var d="0x"+b-65536;return d!==d||c?b:0>d?String.fromCharCode(d+65536):String.fromCharCode(d>>10|55296,1023&d|56320)},da=function(){m()};try{H.apply(E=I.call(v.childNodes),v.childNodes),E[v.childNodes.length].nodeType}catch(ea){H={apply:E.length?function(a,b){G.apply(a,I.call(b))}:function(a,b){var c=a.length,d=0;while(a[c++]=b[d++]);a.length=c-1}}}function fa(a,b,d,e){var f,h,j,k,l,o,r,s,w=b&&b.ownerDocument,x=b?b.nodeType:9;if(d=d||[],"string"!=typeof a||!a||1!==x&&9!==x&&11!==x)return d;if(!e&&((b?b.ownerDocument||b:v)!==n&&m(b),b=b||n,p)){if(11!==x&&(o=$.exec(a)))if(f=o[1]){if(9===x){if(!(j=b.getElementById(f)))return d;if(j.id===f)return d.push(j),d}else if(w&&(j=w.getElementById(f))&&t(b,j)&&j.id===f)return d.push(j),d}else{if(o[2])return H.apply(d,b.getElementsByTagName(a)),d;if((f=o[3])&&c.getElementsByClassName&&b.getElementsByClassName)return H.apply(d,b.getElementsByClassName(f)),d}if(c.qsa&&!A[a+" "]&&(!q||!q.test(a))){if(1!==x)w=b,s=a;else if("object"!==b.nodeName.toLowerCase()){(k=b.getAttribute("id"))?k=k.replace(aa,"\\$&"):b.setAttribute("id",k=u),r=g(a),h=r.length,l=V.test(k)?"#"+k:"[id='"+k+"']";while(h--)r[h]=l+" "+qa(r[h]);s=r.join(","),w=_.test(a)&&oa(b.parentNode)||b}if(s)try{return H.apply(d,w.querySelectorAll(s)),d}catch(y){}finally{k===u&&b.removeAttribute("id")}}}return i(a.replace(Q,"$1"),b,d,e)}function ga(){var a=[];function b(c,e){return a.push(c+" ")>d.cacheLength&&delete b[a.shift()],b[c+" "]=e}return b}function ha(a){return a[u]=!0,a}function ia(a){var b=n.createElement("div");try{return!!a(b)}catch(c){return!1}finally{b.parentNode&&b.parentNode.removeChild(b),b=null}}function ja(a,b){var c=a.split("|"),e=c.length;while(e--)d.attrHandle[c[e]]=b}function ka(a,b){var c=b&&a,d=c&&1===a.nodeType&&1===b.nodeType&&(~b.sourceIndex||C)-(~a.sourceIndex||C);if(d)return d;if(c)while(c=c.nextSibling)if(c===b)return-1;return a?1:-1}function la(a){return function(b){var c=b.nodeName.toLowerCase();return"input"===c&&b.type===a}}function ma(a){return function(b){var c=b.nodeName.toLowerCase();return("input"===c||"button"===c)&&b.type===a}}function na(a){return ha(function(b){return b=+b,ha(function(c,d){var e,f=a([],c.length,b),g=f.length;while(g--)c[e=f[g]]&&(c[e]=!(d[e]=c[e]))})})}function oa(a){return a&&"undefined"!=typeof a.getElementsByTagName&&a}c=fa.support={},f=fa.isXML=function(a){var b=a&&(a.ownerDocument||a).documentElement;return b?"HTML"!==b.nodeName:!1},m=fa.setDocument=function(a){var b,e,g=a?a.ownerDocument||a:v;return g!==n&&9===g.nodeType&&g.documentElement?(n=g,o=n.documentElement,p=!f(n),(e=n.defaultView)&&e.top!==e&&(e.addEventListener?e.addEventListener("unload",da,!1):e.attachEvent&&e.attachEvent("onunload",da)),c.attributes=ia(function(a){return a.className="i",!a.getAttribute("className")}),c.getElementsByTagName=ia(function(a){return a.appendChild(n.createComment("")),!a.getElementsByTagName("*").length}),c.getElementsByClassName=Z.test(n.getElementsByClassName),c.getById=ia(function(a){return o.appendChild(a).id=u,!n.getElementsByName||!n.getElementsByName(u).length}),c.getById?(d.find.ID=function(a,b){if("undefined"!=typeof b.getElementById&&p){var c=b.getElementById(a);return c?[c]:[]}},d.filter.ID=function(a){var b=a.replace(ba,ca);return function(a){return a.getAttribute("id")===b}}):(delete d.find.ID,d.filter.ID=function(a){var b=a.replace(ba,ca);return function(a){var c="undefined"!=typeof a.getAttributeNode&&a.getAttributeNode("id");return c&&c.value===b}}),d.find.TAG=c.getElementsByTagName?function(a,b){return"undefined"!=typeof b.getElementsByTagName?b.getElementsByTagName(a):c.qsa?b.querySelectorAll(a):void 0}:function(a,b){var c,d=[],e=0,f=b.getElementsByTagName(a);if("*"===a){while(c=f[e++])1===c.nodeType&&d.push(c);return d}return f},d.find.CLASS=c.getElementsByClassName&&function(a,b){return"undefined"!=typeof b.getElementsByClassName&&p?b.getElementsByClassName(a):void 0},r=[],q=[],(c.qsa=Z.test(n.querySelectorAll))&&(ia(function(a){o.appendChild(a).innerHTML="<a id='"+u+"'></a><select id='"+u+"-\r\\' msallowcapture=''><option selected=''></option></select>",a.querySelectorAll("[msallowcapture^='']").length&&q.push("[*^$]="+L+"*(?:''|\"\")"),a.querySelectorAll("[selected]").length||q.push("\\["+L+"*(?:value|"+K+")"),a.querySelectorAll("[id~="+u+"-]").length||q.push("~="),a.querySelectorAll(":checked").length||q.push(":checked"),a.querySelectorAll("a#"+u+"+*").length||q.push(".#.+[+~]")}),ia(function(a){var b=n.createElement("input");b.setAttribute("type","hidden"),a.appendChild(b).setAttribute("name","D"),a.querySelectorAll("[name=d]").length&&q.push("name"+L+"*[*^$|!~]?="),a.querySelectorAll(":enabled").length||q.push(":enabled",":disabled"),a.querySelectorAll("*,:x"),q.push(",.*:")})),(c.matchesSelector=Z.test(s=o.matches||o.webkitMatchesSelector||o.mozMatchesSelector||o.oMatchesSelector||o.msMatchesSelector))&&ia(function(a){c.disconnectedMatch=s.call(a,"div"),s.call(a,"[s!='']:x"),r.push("!=",O)}),q=q.length&&new RegExp(q.join("|")),r=r.length&&new RegExp(r.join("|")),b=Z.test(o.compareDocumentPosition),t=b||Z.test(o.contains)?function(a,b){var c=9===a.nodeType?a.documentElement:a,d=b&&b.parentNode;return a===d||!(!d||1!==d.nodeType||!(c.contains?c.contains(d):a.compareDocumentPosition&&16&a.compareDocumentPosition(d)))}:function(a,b){if(b)while(b=b.parentNode)if(b===a)return!0;return!1},B=b?function(a,b){if(a===b)return l=!0,0;var d=!a.compareDocumentPosition-!b.compareDocumentPosition;return d?d:(d=(a.ownerDocument||a)===(b.ownerDocument||b)?a.compareDocumentPosition(b):1,1&d||!c.sortDetached&&b.compareDocumentPosition(a)===d?a===n||a.ownerDocument===v&&t(v,a)?-1:b===n||b.ownerDocument===v&&t(v,b)?1:k?J(k,a)-J(k,b):0:4&d?-1:1)}:function(a,b){if(a===b)return l=!0,0;var c,d=0,e=a.parentNode,f=b.parentNode,g=[a],h=[b];if(!e||!f)return a===n?-1:b===n?1:e?-1:f?1:k?J(k,a)-J(k,b):0;if(e===f)return ka(a,b);c=a;while(c=c.parentNode)g.unshift(c);c=b;while(c=c.parentNode)h.unshift(c);while(g[d]===h[d])d++;return d?ka(g[d],h[d]):g[d]===v?-1:h[d]===v?1:0},n):n},fa.matches=function(a,b){return fa(a,null,null,b)},fa.matchesSelector=function(a,b){if((a.ownerDocument||a)!==n&&m(a),b=b.replace(T,"='$1']"),c.matchesSelector&&p&&!A[b+" "]&&(!r||!r.test(b))&&(!q||!q.test(b)))try{var d=s.call(a,b);if(d||c.disconnectedMatch||a.document&&11!==a.document.nodeType)return d}catch(e){}return fa(b,n,null,[a]).length>0},fa.contains=function(a,b){return(a.ownerDocument||a)!==n&&m(a),t(a,b)},fa.attr=function(a,b){(a.ownerDocument||a)!==n&&m(a);var e=d.attrHandle[b.toLowerCase()],f=e&&D.call(d.attrHandle,b.toLowerCase())?e(a,b,!p):void 0;return void 0!==f?f:c.attributes||!p?a.getAttribute(b):(f=a.getAttributeNode(b))&&f.specified?f.value:null},fa.error=function(a){throw new Error("Syntax error, unrecognized expression: "+a)},fa.uniqueSort=function(a){var b,d=[],e=0,f=0;if(l=!c.detectDuplicates,k=!c.sortStable&&a.slice(0),a.sort(B),l){while(b=a[f++])b===a[f]&&(e=d.push(f));while(e--)a.splice(d[e],1)}return k=null,a},e=fa.getText=function(a){var b,c="",d=0,f=a.nodeType;if(f){if(1===f||9===f||11===f){if("string"==typeof a.textContent)return a.textContent;for(a=a.firstChild;a;a=a.nextSibling)c+=e(a)}else if(3===f||4===f)return a.nodeValue}else while(b=a[d++])c+=e(b);return c},d=fa.selectors={cacheLength:50,createPseudo:ha,match:W,attrHandle:{},find:{},relative:{">":{dir:"parentNode",first:!0}," ":{dir:"parentNode"},"+":{dir:"previousSibling",first:!0},"~":{dir:"previousSibling"}},preFilter:{ATTR:function(a){return a[1]=a[1].replace(ba,ca),a[3]=(a[3]||a[4]||a[5]||"").replace(ba,ca),"~="===a[2]&&(a[3]=" "+a[3]+" "),a.slice(0,4)},CHILD:function(a){return a[1]=a[1].toLowerCase(),"nth"===a[1].slice(0,3)?(a[3]||fa.error(a[0]),a[4]=+(a[4]?a[5]+(a[6]||1):2*("even"===a[3]||"odd"===a[3])),a[5]=+(a[7]+a[8]||"odd"===a[3])):a[3]&&fa.error(a[0]),a},PSEUDO:function(a){var b,c=!a[6]&&a[2];return W.CHILD.test(a[0])?null:(a[3]?a[2]=a[4]||a[5]||"":c&&U.test(c)&&(b=g(c,!0))&&(b=c.indexOf(")",c.length-b)-c.length)&&(a[0]=a[0].slice(0,b),a[2]=c.slice(0,b)),a.slice(0,3))}},filter:{TAG:function(a){var b=a.replace(ba,ca).toLowerCase();return"*"===a?function(){return!0}:function(a){return a.nodeName&&a.nodeName.toLowerCase()===b}},CLASS:function(a){var b=y[a+" "];return b||(b=new RegExp("(^|"+L+")"+a+"("+L+"|$)"))&&y(a,function(a){return b.test("string"==typeof a.className&&a.className||"undefined"!=typeof a.getAttribute&&a.getAttribute("class")||"")})},ATTR:function(a,b,c){return function(d){var e=fa.attr(d,a);return null==e?"!="===b:b?(e+="","="===b?e===c:"!="===b?e!==c:"^="===b?c&&0===e.indexOf(c):"*="===b?c&&e.indexOf(c)>-1:"$="===b?c&&e.slice(-c.length)===c:"~="===b?(" "+e.replace(P," ")+" ").indexOf(c)>-1:"|="===b?e===c||e.slice(0,c.length+1)===c+"-":!1):!0}},CHILD:function(a,b,c,d,e){var f="nth"!==a.slice(0,3),g="last"!==a.slice(-4),h="of-type"===b;return 1===d&&0===e?function(a){return!!a.parentNode}:function(b,c,i){var j,k,l,m,n,o,p=f!==g?"nextSibling":"previousSibling",q=b.parentNode,r=h&&b.nodeName.toLowerCase(),s=!i&&!h,t=!1;if(q){if(f){while(p){m=b;while(m=m[p])if(h?m.nodeName.toLowerCase()===r:1===m.nodeType)return!1;o=p="only"===a&&!o&&"nextSibling"}return!0}if(o=[g?q.firstChild:q.lastChild],g&&s){m=q,l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),j=k[a]||[],n=j[0]===w&&j[1],t=n&&j[2],m=n&&q.childNodes[n];while(m=++n&&m&&m[p]||(t=n=0)||o.pop())if(1===m.nodeType&&++t&&m===b){k[a]=[w,n,t];break}}else if(s&&(m=b,l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),j=k[a]||[],n=j[0]===w&&j[1],t=n),t===!1)while(m=++n&&m&&m[p]||(t=n=0)||o.pop())if((h?m.nodeName.toLowerCase()===r:1===m.nodeType)&&++t&&(s&&(l=m[u]||(m[u]={}),k=l[m.uniqueID]||(l[m.uniqueID]={}),k[a]=[w,t]),m===b))break;return t-=e,t===d||t%d===0&&t/d>=0}}},PSEUDO:function(a,b){var c,e=d.pseudos[a]||d.setFilters[a.toLowerCase()]||fa.error("unsupported pseudo: "+a);return e[u]?e(b):e.length>1?(c=[a,a,"",b],d.setFilters.hasOwnProperty(a.toLowerCase())?ha(function(a,c){var d,f=e(a,b),g=f.length;while(g--)d=J(a,f[g]),a[d]=!(c[d]=f[g])}):function(a){return e(a,0,c)}):e}},pseudos:{not:ha(function(a){var b=[],c=[],d=h(a.replace(Q,"$1"));return d[u]?ha(function(a,b,c,e){var f,g=d(a,null,e,[]),h=a.length;while(h--)(f=g[h])&&(a[h]=!(b[h]=f))}):function(a,e,f){return b[0]=a,d(b,null,f,c),b[0]=null,!c.pop()}}),has:ha(function(a){return function(b){return fa(a,b).length>0}}),contains:ha(function(a){return a=a.replace(ba,ca),function(b){return(b.textContent||b.innerText||e(b)).indexOf(a)>-1}}),lang:ha(function(a){return V.test(a||"")||fa.error("unsupported lang: "+a),a=a.replace(ba,ca).toLowerCase(),function(b){var c;do if(c=p?b.lang:b.getAttribute("xml:lang")||b.getAttribute("lang"))return c=c.toLowerCase(),c===a||0===c.indexOf(a+"-");while((b=b.parentNode)&&1===b.nodeType);return!1}}),target:function(b){var c=a.location&&a.location.hash;return c&&c.slice(1)===b.id},root:function(a){return a===o},focus:function(a){return a===n.activeElement&&(!n.hasFocus||n.hasFocus())&&!!(a.type||a.href||~a.tabIndex)},enabled:function(a){return a.disabled===!1},disabled:function(a){return a.disabled===!0},checked:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&!!a.checked||"option"===b&&!!a.selected},selected:function(a){return a.parentNode&&a.parentNode.selectedIndex,a.selected===!0},empty:function(a){for(a=a.firstChild;a;a=a.nextSibling)if(a.nodeType<6)return!1;return!0},parent:function(a){return!d.pseudos.empty(a)},header:function(a){return Y.test(a.nodeName)},input:function(a){return X.test(a.nodeName)},button:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&"button"===a.type||"button"===b},text:function(a){var b;return"input"===a.nodeName.toLowerCase()&&"text"===a.type&&(null==(b=a.getAttribute("type"))||"text"===b.toLowerCase())},first:na(function(){return[0]}),last:na(function(a,b){return[b-1]}),eq:na(function(a,b,c){return[0>c?c+b:c]}),even:na(function(a,b){for(var c=0;b>c;c+=2)a.push(c);return a}),odd:na(function(a,b){for(var c=1;b>c;c+=2)a.push(c);return a}),lt:na(function(a,b,c){for(var d=0>c?c+b:c;--d>=0;)a.push(d);return a}),gt:na(function(a,b,c){for(var d=0>c?c+b:c;++d<b;)a.push(d);return a})}},d.pseudos.nth=d.pseudos.eq;for(b in{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})d.pseudos[b]=la(b);for(b in{submit:!0,reset:!0})d.pseudos[b]=ma(b);function pa(){}pa.prototype=d.filters=d.pseudos,d.setFilters=new pa,g=fa.tokenize=function(a,b){var c,e,f,g,h,i,j,k=z[a+" "];if(k)return b?0:k.slice(0);h=a,i=[],j=d.preFilter;while(h){c&&!(e=R.exec(h))||(e&&(h=h.slice(e[0].length)||h),i.push(f=[])),c=!1,(e=S.exec(h))&&(c=e.shift(),f.push({value:c,type:e[0].replace(Q," ")}),h=h.slice(c.length));for(g in d.filter)!(e=W[g].exec(h))||j[g]&&!(e=j[g](e))||(c=e.shift(),f.push({value:c,type:g,matches:e}),h=h.slice(c.length));if(!c)break}return b?h.length:h?fa.error(a):z(a,i).slice(0)};function qa(a){for(var b=0,c=a.length,d="";c>b;b++)d+=a[b].value;return d}function ra(a,b,c){var d=b.dir,e=c&&"parentNode"===d,f=x++;return b.first?function(b,c,f){while(b=b[d])if(1===b.nodeType||e)return a(b,c,f)}:function(b,c,g){var h,i,j,k=[w,f];if(g){while(b=b[d])if((1===b.nodeType||e)&&a(b,c,g))return!0}else while(b=b[d])if(1===b.nodeType||e){if(j=b[u]||(b[u]={}),i=j[b.uniqueID]||(j[b.uniqueID]={}),(h=i[d])&&h[0]===w&&h[1]===f)return k[2]=h[2];if(i[d]=k,k[2]=a(b,c,g))return!0}}}function sa(a){return a.length>1?function(b,c,d){var e=a.length;while(e--)if(!a[e](b,c,d))return!1;return!0}:a[0]}function ta(a,b,c){for(var d=0,e=b.length;e>d;d++)fa(a,b[d],c);return c}function ua(a,b,c,d,e){for(var f,g=[],h=0,i=a.length,j=null!=b;i>h;h++)(f=a[h])&&(c&&!c(f,d,e)||(g.push(f),j&&b.push(h)));return g}function va(a,b,c,d,e,f){return d&&!d[u]&&(d=va(d)),e&&!e[u]&&(e=va(e,f)),ha(function(f,g,h,i){var j,k,l,m=[],n=[],o=g.length,p=f||ta(b||"*",h.nodeType?[h]:h,[]),q=!a||!f&&b?p:ua(p,m,a,h,i),r=c?e||(f?a:o||d)?[]:g:q;if(c&&c(q,r,h,i),d){j=ua(r,n),d(j,[],h,i),k=j.length;while(k--)(l=j[k])&&(r[n[k]]=!(q[n[k]]=l))}if(f){if(e||a){if(e){j=[],k=r.length;while(k--)(l=r[k])&&j.push(q[k]=l);e(null,r=[],j,i)}k=r.length;while(k--)(l=r[k])&&(j=e?J(f,l):m[k])>-1&&(f[j]=!(g[j]=l))}}else r=ua(r===g?r.splice(o,r.length):r),e?e(null,g,r,i):H.apply(g,r)})}function wa(a){for(var b,c,e,f=a.length,g=d.relative[a[0].type],h=g||d.relative[" "],i=g?1:0,k=ra(function(a){return a===b},h,!0),l=ra(function(a){return J(b,a)>-1},h,!0),m=[function(a,c,d){var e=!g&&(d||c!==j)||((b=c).nodeType?k(a,c,d):l(a,c,d));return b=null,e}];f>i;i++)if(c=d.relative[a[i].type])m=[ra(sa(m),c)];else{if(c=d.filter[a[i].type].apply(null,a[i].matches),c[u]){for(e=++i;f>e;e++)if(d.relative[a[e].type])break;return va(i>1&&sa(m),i>1&&qa(a.slice(0,i-1).concat({value:" "===a[i-2].type?"*":""})).replace(Q,"$1"),c,e>i&&wa(a.slice(i,e)),f>e&&wa(a=a.slice(e)),f>e&&qa(a))}m.push(c)}return sa(m)}function xa(a,b){var c=b.length>0,e=a.length>0,f=function(f,g,h,i,k){var l,o,q,r=0,s="0",t=f&&[],u=[],v=j,x=f||e&&d.find.TAG("*",k),y=w+=null==v?1:Math.random()||.1,z=x.length;for(k&&(j=g===n||g||k);s!==z&&null!=(l=x[s]);s++){if(e&&l){o=0,g||l.ownerDocument===n||(m(l),h=!p);while(q=a[o++])if(q(l,g||n,h)){i.push(l);break}k&&(w=y)}c&&((l=!q&&l)&&r--,f&&t.push(l))}if(r+=s,c&&s!==r){o=0;while(q=b[o++])q(t,u,g,h);if(f){if(r>0)while(s--)t[s]||u[s]||(u[s]=F.call(i));u=ua(u)}H.apply(i,u),k&&!f&&u.length>0&&r+b.length>1&&fa.uniqueSort(i)}return k&&(w=y,j=v),t};return c?ha(f):f}return h=fa.compile=function(a,b){var c,d=[],e=[],f=A[a+" "];if(!f){b||(b=g(a)),c=b.length;while(c--)f=wa(b[c]),f[u]?d.push(f):e.push(f);f=A(a,xa(e,d)),f.selector=a}return f},i=fa.select=function(a,b,e,f){var i,j,k,l,m,n="function"==typeof a&&a,o=!f&&g(a=n.selector||a);if(e=e||[],1===o.length){if(j=o[0]=o[0].slice(0),j.length>2&&"ID"===(k=j[0]).type&&c.getById&&9===b.nodeType&&p&&d.relative[j[1].type]){if(b=(d.find.ID(k.matches[0].replace(ba,ca),b)||[])[0],!b)return e;n&&(b=b.parentNode),a=a.slice(j.shift().value.length)}i=W.needsContext.test(a)?0:j.length;while(i--){if(k=j[i],d.relative[l=k.type])break;if((m=d.find[l])&&(f=m(k.matches[0].replace(ba,ca),_.test(j[0].type)&&oa(b.parentNode)||b))){if(j.splice(i,1),a=f.length&&qa(j),!a)return H.apply(e,f),e;break}}}return(n||h(a,o))(f,b,!p,e,!b||_.test(a)&&oa(b.parentNode)||b),e},c.sortStable=u.split("").sort(B).join("")===u,c.detectDuplicates=!!l,m(),c.sortDetached=ia(function(a){return 1&a.compareDocumentPosition(n.createElement("div"))}),ia(function(a){return a.innerHTML="<a href='#'></a>","#"===a.firstChild.getAttribute("href")})||ja("type|href|height|width",function(a,b,c){return c?void 0:a.getAttribute(b,"type"===b.toLowerCase()?1:2)}),c.attributes&&ia(function(a){return a.innerHTML="<input/>",a.firstChild.setAttribute("value",""),""===a.firstChild.getAttribute("value")})||ja("value",function(a,b,c){return c||"input"!==a.nodeName.toLowerCase()?void 0:a.defaultValue}),ia(function(a){return null==a.getAttribute("disabled")})||ja(K,function(a,b,c){var d;return c?void 0:a[b]===!0?b.toLowerCase():(d=a.getAttributeNode(b))&&d.specified?d.value:null}),fa}(a);n.find=t,n.expr=t.selectors,n.expr[":"]=n.expr.pseudos,n.uniqueSort=n.unique=t.uniqueSort,n.text=t.getText,n.isXMLDoc=t.isXML,n.contains=t.contains;var u=function(a,b,c){var d=[],e=void 0!==c;while((a=a[b])&&9!==a.nodeType)if(1===a.nodeType){if(e&&n(a).is(c))break;d.push(a)}return d},v=function(a,b){for(var c=[];a;a=a.nextSibling)1===a.nodeType&&a!==b&&c.push(a);return c},w=n.expr.match.needsContext,x=/^<([\w-]+)\s*\/?>(?:<\/\1>|)$/,y=/^.[^:#\[\.,]*$/;function z(a,b,c){if(n.isFunction(b))return n.grep(a,function(a,d){return!!b.call(a,d,a)!==c});if(b.nodeType)return n.grep(a,function(a){return a===b!==c});if("string"==typeof b){if(y.test(b))return n.filter(b,a,c);b=n.filter(b,a)}return n.grep(a,function(a){return n.inArray(a,b)>-1!==c})}n.filter=function(a,b,c){var d=b[0];return c&&(a=":not("+a+")"),1===b.length&&1===d.nodeType?n.find.matchesSelector(d,a)?[d]:[]:n.find.matches(a,n.grep(b,function(a){return 1===a.nodeType}))},n.fn.extend({find:function(a){var b,c=[],d=this,e=d.length;if("string"!=typeof a)return this.pushStack(n(a).filter(function(){for(b=0;e>b;b++)if(n.contains(d[b],this))return!0}));for(b=0;e>b;b++)n.find(a,d[b],c);return c=this.pushStack(e>1?n.unique(c):c),c.selector=this.selector?this.selector+" "+a:a,c},filter:function(a){return this.pushStack(z(this,a||[],!1))},not:function(a){return this.pushStack(z(this,a||[],!0))},is:function(a){return!!z(this,"string"==typeof a&&w.test(a)?n(a):a||[],!1).length}});var A,B=/^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]*))$/,C=n.fn.init=function(a,b,c){var e,f;if(!a)return this;if(c=c||A,"string"==typeof a){if(e="<"===a.charAt(0)&&">"===a.charAt(a.length-1)&&a.length>=3?[null,a,null]:B.exec(a),!e||!e[1]&&b)return!b||b.jquery?(b||c).find(a):this.constructor(b).find(a);if(e[1]){if(b=b instanceof n?b[0]:b,n.merge(this,n.parseHTML(e[1],b&&b.nodeType?b.ownerDocument||b:d,!0)),x.test(e[1])&&n.isPlainObject(b))for(e in b)n.isFunction(this[e])?this[e](b[e]):this.attr(e,b[e]);return this}if(f=d.getElementById(e[2]),f&&f.parentNode){if(f.id!==e[2])return A.find(a);this.length=1,this[0]=f}return this.context=d,this.selector=a,this}return a.nodeType?(this.context=this[0]=a,this.length=1,this):n.isFunction(a)?"undefined"!=typeof c.ready?c.ready(a):a(n):(void 0!==a.selector&&(this.selector=a.selector,this.context=a.context),n.makeArray(a,this))};C.prototype=n.fn,A=n(d);var D=/^(?:parents|prev(?:Until|All))/,E={children:!0,contents:!0,next:!0,prev:!0};n.fn.extend({has:function(a){var b,c=n(a,this),d=c.length;return this.filter(function(){for(b=0;d>b;b++)if(n.contains(this,c[b]))return!0})},closest:function(a,b){for(var c,d=0,e=this.length,f=[],g=w.test(a)||"string"!=typeof a?n(a,b||this.context):0;e>d;d++)for(c=this[d];c&&c!==b;c=c.parentNode)if(c.nodeType<11&&(g?g.index(c)>-1:1===c.nodeType&&n.find.matchesSelector(c,a))){f.push(c);break}return this.pushStack(f.length>1?n.uniqueSort(f):f)},index:function(a){return a?"string"==typeof a?n.inArray(this[0],n(a)):n.inArray(a.jquery?a[0]:a,this):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(a,b){return this.pushStack(n.uniqueSort(n.merge(this.get(),n(a,b))))},addBack:function(a){return this.add(null==a?this.prevObject:this.prevObject.filter(a))}});function F(a,b){do a=a[b];while(a&&1!==a.nodeType);return a}n.each({parent:function(a){var b=a.parentNode;return b&&11!==b.nodeType?b:null},parents:function(a){return u(a,"parentNode")},parentsUntil:function(a,b,c){return u(a,"parentNode",c)},next:function(a){return F(a,"nextSibling")},prev:function(a){return F(a,"previousSibling")},nextAll:function(a){return u(a,"nextSibling")},prevAll:function(a){return u(a,"previousSibling")},nextUntil:function(a,b,c){return u(a,"nextSibling",c)},prevUntil:function(a,b,c){return u(a,"previousSibling",c)},siblings:function(a){return v((a.parentNode||{}).firstChild,a)},children:function(a){return v(a.firstChild)},contents:function(a){return n.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:n.merge([],a.childNodes)}},function(a,b){n.fn[a]=function(c,d){var e=n.map(this,b,c);return"Until"!==a.slice(-5)&&(d=c),d&&"string"==typeof d&&(e=n.filter(d,e)),this.length>1&&(E[a]||(e=n.uniqueSort(e)),D.test(a)&&(e=e.reverse())),this.pushStack(e)}});var G=/\S+/g;function H(a){var b={};return n.each(a.match(G)||[],function(a,c){b[c]=!0}),b}n.Callbacks=function(a){a="string"==typeof a?H(a):n.extend({},a);var b,c,d,e,f=[],g=[],h=-1,i=function(){for(e=a.once,d=b=!0;g.length;h=-1){c=g.shift();while(++h<f.length)f[h].apply(c[0],c[1])===!1&&a.stopOnFalse&&(h=f.length,c=!1)}a.memory||(c=!1),b=!1,e&&(f=c?[]:"")},j={add:function(){return f&&(c&&!b&&(h=f.length-1,g.push(c)),function d(b){n.each(b,function(b,c){n.isFunction(c)?a.unique&&j.has(c)||f.push(c):c&&c.length&&"string"!==n.type(c)&&d(c)})}(arguments),c&&!b&&i()),this},remove:function(){return n.each(arguments,function(a,b){var c;while((c=n.inArray(b,f,c))>-1)f.splice(c,1),h>=c&&h--}),this},has:function(a){return a?n.inArray(a,f)>-1:f.length>0},empty:function(){return f&&(f=[]),this},disable:function(){return e=g=[],f=c="",this},disabled:function(){return!f},lock:function(){return e=!0,c||j.disable(),this},locked:function(){return!!e},fireWith:function(a,c){return e||(c=c||[],c=[a,c.slice?c.slice():c],g.push(c),b||i()),this},fire:function(){return j.fireWith(this,arguments),this},fired:function(){return!!d}};return j},n.extend({Deferred:function(a){var b=[["resolve","done",n.Callbacks("once memory"),"resolved"],["reject","fail",n.Callbacks("once memory"),"rejected"],["notify","progress",n.Callbacks("memory")]],c="pending",d={state:function(){return c},always:function(){return e.done(arguments).fail(arguments),this},then:function(){var a=arguments;return n.Deferred(function(c){n.each(b,function(b,f){var g=n.isFunction(a[b])&&a[b];e[f[1]](function(){var a=g&&g.apply(this,arguments);a&&n.isFunction(a.promise)?a.promise().progress(c.notify).done(c.resolve).fail(c.reject):c[f[0]+"With"](this===d?c.promise():this,g?[a]:arguments)})}),a=null}).promise()},promise:function(a){return null!=a?n.extend(a,d):d}},e={};return d.pipe=d.then,n.each(b,function(a,f){var g=f[2],h=f[3];d[f[1]]=g.add,h&&g.add(function(){c=h},b[1^a][2].disable,b[2][2].lock),e[f[0]]=function(){return e[f[0]+"With"](this===e?d:this,arguments),this},e[f[0]+"With"]=g.fireWith}),d.promise(e),a&&a.call(e,e),e},when:function(a){var b=0,c=e.call(arguments),d=c.length,f=1!==d||a&&n.isFunction(a.promise)?d:0,g=1===f?a:n.Deferred(),h=function(a,b,c){return function(d){b[a]=this,c[a]=arguments.length>1?e.call(arguments):d,c===i?g.notifyWith(b,c):--f||g.resolveWith(b,c)}},i,j,k;if(d>1)for(i=new Array(d),j=new Array(d),k=new Array(d);d>b;b++)c[b]&&n.isFunction(c[b].promise)?c[b].promise().progress(h(b,j,i)).done(h(b,k,c)).fail(g.reject):--f;return f||g.resolveWith(k,c),g.promise()}});var I;n.fn.ready=function(a){return n.ready.promise().done(a),this},n.extend({isReady:!1,readyWait:1,holdReady:function(a){a?n.readyWait++:n.ready(!0)},ready:function(a){(a===!0?--n.readyWait:n.isReady)||(n.isReady=!0,a!==!0&&--n.readyWait>0||(I.resolveWith(d,[n]),n.fn.triggerHandler&&(n(d).triggerHandler("ready"),n(d).off("ready"))))}});function J(){d.addEventListener?(d.removeEventListener("DOMContentLoaded",K),a.removeEventListener("load",K)):(d.detachEvent("onreadystatechange",K),a.detachEvent("onload",K))}function K(){(d.addEventListener||"load"===a.event.type||"complete"===d.readyState)&&(J(),n.ready())}n.ready.promise=function(b){if(!I)if(I=n.Deferred(),"complete"===d.readyState||"loading"!==d.readyState&&!d.documentElement.doScroll)a.setTimeout(n.ready);else if(d.addEventListener)d.addEventListener("DOMContentLoaded",K),a.addEventListener("load",K);else{d.attachEvent("onreadystatechange",K),a.attachEvent("onload",K);var c=!1;try{c=null==a.frameElement&&d.documentElement}catch(e){}c&&c.doScroll&&!function f(){if(!n.isReady){try{c.doScroll("left")}catch(b){return a.setTimeout(f,50)}J(),n.ready()}}()}return I.promise(b)},n.ready.promise();var L;for(L in n(l))break;l.ownFirst="0"===L,l.inlineBlockNeedsLayout=!1,n(function(){var a,b,c,e;c=d.getElementsByTagName("body")[0],c&&c.style&&(b=d.createElement("div"),e=d.createElement("div"),e.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(e).appendChild(b),"undefined"!=typeof b.style.zoom&&(b.style.cssText="display:inline;margin:0;border:0;padding:1px;width:1px;zoom:1",l.inlineBlockNeedsLayout=a=3===b.offsetWidth,a&&(c.style.zoom=1)),c.removeChild(e))}),function(){var a=d.createElement("div");l.deleteExpando=!0;try{delete a.test}catch(b){l.deleteExpando=!1}a=null}();var M=function(a){var b=n.noData[(a.nodeName+" ").toLowerCase()],c=+a.nodeType||1;return 1!==c&&9!==c?!1:!b||b!==!0&&a.getAttribute("classid")===b},N=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,O=/([A-Z])/g;function P(a,b,c){if(void 0===c&&1===a.nodeType){var d="data-"+b.replace(O,"-$1").toLowerCase();if(c=a.getAttribute(d),"string"==typeof c){try{c="true"===c?!0:"false"===c?!1:"null"===c?null:+c+""===c?+c:N.test(c)?n.parseJSON(c):c}catch(e){}n.data(a,b,c)}else c=void 0;
}return c}function Q(a){var b;for(b in a)if(("data"!==b||!n.isEmptyObject(a[b]))&&"toJSON"!==b)return!1;return!0}function R(a,b,d,e){if(M(a)){var f,g,h=n.expando,i=a.nodeType,j=i?n.cache:a,k=i?a[h]:a[h]&&h;if(k&&j[k]&&(e||j[k].data)||void 0!==d||"string"!=typeof b)return k||(k=i?a[h]=c.pop()||n.guid++:h),j[k]||(j[k]=i?{}:{toJSON:n.noop}),"object"!=typeof b&&"function"!=typeof b||(e?j[k]=n.extend(j[k],b):j[k].data=n.extend(j[k].data,b)),g=j[k],e||(g.data||(g.data={}),g=g.data),void 0!==d&&(g[n.camelCase(b)]=d),"string"==typeof b?(f=g[b],null==f&&(f=g[n.camelCase(b)])):f=g,f}}function S(a,b,c){if(M(a)){var d,e,f=a.nodeType,g=f?n.cache:a,h=f?a[n.expando]:n.expando;if(g[h]){if(b&&(d=c?g[h]:g[h].data)){n.isArray(b)?b=b.concat(n.map(b,n.camelCase)):b in d?b=[b]:(b=n.camelCase(b),b=b in d?[b]:b.split(" ")),e=b.length;while(e--)delete d[b[e]];if(c?!Q(d):!n.isEmptyObject(d))return}(c||(delete g[h].data,Q(g[h])))&&(f?n.cleanData([a],!0):l.deleteExpando||g!=g.window?delete g[h]:g[h]=void 0)}}}n.extend({cache:{},noData:{"applet ":!0,"embed ":!0,"object ":"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"},hasData:function(a){return a=a.nodeType?n.cache[a[n.expando]]:a[n.expando],!!a&&!Q(a)},data:function(a,b,c){return R(a,b,c)},removeData:function(a,b){return S(a,b)},_data:function(a,b,c){return R(a,b,c,!0)},_removeData:function(a,b){return S(a,b,!0)}}),n.fn.extend({data:function(a,b){var c,d,e,f=this[0],g=f&&f.attributes;if(void 0===a){if(this.length&&(e=n.data(f),1===f.nodeType&&!n._data(f,"parsedAttrs"))){c=g.length;while(c--)g[c]&&(d=g[c].name,0===d.indexOf("data-")&&(d=n.camelCase(d.slice(5)),P(f,d,e[d])));n._data(f,"parsedAttrs",!0)}return e}return"object"==typeof a?this.each(function(){n.data(this,a)}):arguments.length>1?this.each(function(){n.data(this,a,b)}):f?P(f,a,n.data(f,a)):void 0},removeData:function(a){return this.each(function(){n.removeData(this,a)})}}),n.extend({queue:function(a,b,c){var d;return a?(b=(b||"fx")+"queue",d=n._data(a,b),c&&(!d||n.isArray(c)?d=n._data(a,b,n.makeArray(c)):d.push(c)),d||[]):void 0},dequeue:function(a,b){b=b||"fx";var c=n.queue(a,b),d=c.length,e=c.shift(),f=n._queueHooks(a,b),g=function(){n.dequeue(a,b)};"inprogress"===e&&(e=c.shift(),d--),e&&("fx"===b&&c.unshift("inprogress"),delete f.stop,e.call(a,g,f)),!d&&f&&f.empty.fire()},_queueHooks:function(a,b){var c=b+"queueHooks";return n._data(a,c)||n._data(a,c,{empty:n.Callbacks("once memory").add(function(){n._removeData(a,b+"queue"),n._removeData(a,c)})})}}),n.fn.extend({queue:function(a,b){var c=2;return"string"!=typeof a&&(b=a,a="fx",c--),arguments.length<c?n.queue(this[0],a):void 0===b?this:this.each(function(){var c=n.queue(this,a,b);n._queueHooks(this,a),"fx"===a&&"inprogress"!==c[0]&&n.dequeue(this,a)})},dequeue:function(a){return this.each(function(){n.dequeue(this,a)})},clearQueue:function(a){return this.queue(a||"fx",[])},promise:function(a,b){var c,d=1,e=n.Deferred(),f=this,g=this.length,h=function(){--d||e.resolveWith(f,[f])};"string"!=typeof a&&(b=a,a=void 0),a=a||"fx";while(g--)c=n._data(f[g],a+"queueHooks"),c&&c.empty&&(d++,c.empty.add(h));return h(),e.promise(b)}}),function(){var a;l.shrinkWrapBlocks=function(){if(null!=a)return a;a=!1;var b,c,e;return c=d.getElementsByTagName("body")[0],c&&c.style?(b=d.createElement("div"),e=d.createElement("div"),e.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(e).appendChild(b),"undefined"!=typeof b.style.zoom&&(b.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:1px;width:1px;zoom:1",b.appendChild(d.createElement("div")).style.width="5px",a=3!==b.offsetWidth),c.removeChild(e),a):void 0}}();var T=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,U=new RegExp("^(?:([+-])=|)("+T+")([a-z%]*)$","i"),V=["Top","Right","Bottom","Left"],W=function(a,b){return a=b||a,"none"===n.css(a,"display")||!n.contains(a.ownerDocument,a)};function X(a,b,c,d){var e,f=1,g=20,h=d?function(){return d.cur()}:function(){return n.css(a,b,"")},i=h(),j=c&&c[3]||(n.cssNumber[b]?"":"px"),k=(n.cssNumber[b]||"px"!==j&&+i)&&U.exec(n.css(a,b));if(k&&k[3]!==j){j=j||k[3],c=c||[],k=+i||1;do f=f||".5",k/=f,n.style(a,b,k+j);while(f!==(f=h()/i)&&1!==f&&--g)}return c&&(k=+k||+i||0,e=c[1]?k+(c[1]+1)*c[2]:+c[2],d&&(d.unit=j,d.start=k,d.end=e)),e}var Y=function(a,b,c,d,e,f,g){var h=0,i=a.length,j=null==c;if("object"===n.type(c)){e=!0;for(h in c)Y(a,b,h,c[h],!0,f,g)}else if(void 0!==d&&(e=!0,n.isFunction(d)||(g=!0),j&&(g?(b.call(a,d),b=null):(j=b,b=function(a,b,c){return j.call(n(a),c)})),b))for(;i>h;h++)b(a[h],c,g?d:d.call(a[h],h,b(a[h],c)));return e?a:j?b.call(a):i?b(a[0],c):f},Z=/^(?:checkbox|radio)$/i,$=/<([\w:-]+)/,_=/^$|\/(?:java|ecma)script/i,aa=/^\s+/,ba="abbr|article|aside|audio|bdi|canvas|data|datalist|details|dialog|figcaption|figure|footer|header|hgroup|main|mark|meter|nav|output|picture|progress|section|summary|template|time|video";function ca(a){var b=ba.split("|"),c=a.createDocumentFragment();if(c.createElement)while(b.length)c.createElement(b.pop());return c}!function(){var a=d.createElement("div"),b=d.createDocumentFragment(),c=d.createElement("input");a.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",l.leadingWhitespace=3===a.firstChild.nodeType,l.tbody=!a.getElementsByTagName("tbody").length,l.htmlSerialize=!!a.getElementsByTagName("link").length,l.html5Clone="<:nav></:nav>"!==d.createElement("nav").cloneNode(!0).outerHTML,c.type="checkbox",c.checked=!0,b.appendChild(c),l.appendChecked=c.checked,a.innerHTML="<textarea>x</textarea>",l.noCloneChecked=!!a.cloneNode(!0).lastChild.defaultValue,b.appendChild(a),c=d.createElement("input"),c.setAttribute("type","radio"),c.setAttribute("checked","checked"),c.setAttribute("name","t"),a.appendChild(c),l.checkClone=a.cloneNode(!0).cloneNode(!0).lastChild.checked,l.noCloneEvent=!!a.addEventListener,a[n.expando]=1,l.attributes=!a.getAttribute(n.expando)}();var da={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],area:[1,"<map>","</map>"],param:[1,"<object>","</object>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],_default:l.htmlSerialize?[0,"",""]:[1,"X<div>","</div>"]};da.optgroup=da.option,da.tbody=da.tfoot=da.colgroup=da.caption=da.thead,da.th=da.td;function ea(a,b){var c,d,e=0,f="undefined"!=typeof a.getElementsByTagName?a.getElementsByTagName(b||"*"):"undefined"!=typeof a.querySelectorAll?a.querySelectorAll(b||"*"):void 0;if(!f)for(f=[],c=a.childNodes||a;null!=(d=c[e]);e++)!b||n.nodeName(d,b)?f.push(d):n.merge(f,ea(d,b));return void 0===b||b&&n.nodeName(a,b)?n.merge([a],f):f}function fa(a,b){for(var c,d=0;null!=(c=a[d]);d++)n._data(c,"globalEval",!b||n._data(b[d],"globalEval"))}var ga=/<|&#?\w+;/,ha=/<tbody/i;function ia(a){Z.test(a.type)&&(a.defaultChecked=a.checked)}function ja(a,b,c,d,e){for(var f,g,h,i,j,k,m,o=a.length,p=ca(b),q=[],r=0;o>r;r++)if(g=a[r],g||0===g)if("object"===n.type(g))n.merge(q,g.nodeType?[g]:g);else if(ga.test(g)){i=i||p.appendChild(b.createElement("div")),j=($.exec(g)||["",""])[1].toLowerCase(),m=da[j]||da._default,i.innerHTML=m[1]+n.htmlPrefilter(g)+m[2],f=m[0];while(f--)i=i.lastChild;if(!l.leadingWhitespace&&aa.test(g)&&q.push(b.createTextNode(aa.exec(g)[0])),!l.tbody){g="table"!==j||ha.test(g)?"<table>"!==m[1]||ha.test(g)?0:i:i.firstChild,f=g&&g.childNodes.length;while(f--)n.nodeName(k=g.childNodes[f],"tbody")&&!k.childNodes.length&&g.removeChild(k)}n.merge(q,i.childNodes),i.textContent="";while(i.firstChild)i.removeChild(i.firstChild);i=p.lastChild}else q.push(b.createTextNode(g));i&&p.removeChild(i),l.appendChecked||n.grep(ea(q,"input"),ia),r=0;while(g=q[r++])if(d&&n.inArray(g,d)>-1)e&&e.push(g);else if(h=n.contains(g.ownerDocument,g),i=ea(p.appendChild(g),"script"),h&&fa(i),c){f=0;while(g=i[f++])_.test(g.type||"")&&c.push(g)}return i=null,p}!function(){var b,c,e=d.createElement("div");for(b in{submit:!0,change:!0,focusin:!0})c="on"+b,(l[b]=c in a)||(e.setAttribute(c,"t"),l[b]=e.attributes[c].expando===!1);e=null}();var ka=/^(?:input|select|textarea)$/i,la=/^key/,ma=/^(?:mouse|pointer|contextmenu|drag|drop)|click/,na=/^(?:focusinfocus|focusoutblur)$/,oa=/^([^.]*)(?:\.(.+)|)/;function pa(){return!0}function qa(){return!1}function ra(){try{return d.activeElement}catch(a){}}function sa(a,b,c,d,e,f){var g,h;if("object"==typeof b){"string"!=typeof c&&(d=d||c,c=void 0);for(h in b)sa(a,h,c,d,b[h],f);return a}if(null==d&&null==e?(e=c,d=c=void 0):null==e&&("string"==typeof c?(e=d,d=void 0):(e=d,d=c,c=void 0)),e===!1)e=qa;else if(!e)return a;return 1===f&&(g=e,e=function(a){return n().off(a),g.apply(this,arguments)},e.guid=g.guid||(g.guid=n.guid++)),a.each(function(){n.event.add(this,b,e,d,c)})}n.event={global:{},add:function(a,b,c,d,e){var f,g,h,i,j,k,l,m,o,p,q,r=n._data(a);if(r){c.handler&&(i=c,c=i.handler,e=i.selector),c.guid||(c.guid=n.guid++),(g=r.events)||(g=r.events={}),(k=r.handle)||(k=r.handle=function(a){return"undefined"==typeof n||a&&n.event.triggered===a.type?void 0:n.event.dispatch.apply(k.elem,arguments)},k.elem=a),b=(b||"").match(G)||[""],h=b.length;while(h--)f=oa.exec(b[h])||[],o=q=f[1],p=(f[2]||"").split(".").sort(),o&&(j=n.event.special[o]||{},o=(e?j.delegateType:j.bindType)||o,j=n.event.special[o]||{},l=n.extend({type:o,origType:q,data:d,handler:c,guid:c.guid,selector:e,needsContext:e&&n.expr.match.needsContext.test(e),namespace:p.join(".")},i),(m=g[o])||(m=g[o]=[],m.delegateCount=0,j.setup&&j.setup.call(a,d,p,k)!==!1||(a.addEventListener?a.addEventListener(o,k,!1):a.attachEvent&&a.attachEvent("on"+o,k))),j.add&&(j.add.call(a,l),l.handler.guid||(l.handler.guid=c.guid)),e?m.splice(m.delegateCount++,0,l):m.push(l),n.event.global[o]=!0);a=null}},remove:function(a,b,c,d,e){var f,g,h,i,j,k,l,m,o,p,q,r=n.hasData(a)&&n._data(a);if(r&&(k=r.events)){b=(b||"").match(G)||[""],j=b.length;while(j--)if(h=oa.exec(b[j])||[],o=q=h[1],p=(h[2]||"").split(".").sort(),o){l=n.event.special[o]||{},o=(d?l.delegateType:l.bindType)||o,m=k[o]||[],h=h[2]&&new RegExp("(^|\\.)"+p.join("\\.(?:.*\\.|)")+"(\\.|$)"),i=f=m.length;while(f--)g=m[f],!e&&q!==g.origType||c&&c.guid!==g.guid||h&&!h.test(g.namespace)||d&&d!==g.selector&&("**"!==d||!g.selector)||(m.splice(f,1),g.selector&&m.delegateCount--,l.remove&&l.remove.call(a,g));i&&!m.length&&(l.teardown&&l.teardown.call(a,p,r.handle)!==!1||n.removeEvent(a,o,r.handle),delete k[o])}else for(o in k)n.event.remove(a,o+b[j],c,d,!0);n.isEmptyObject(k)&&(delete r.handle,n._removeData(a,"events"))}},trigger:function(b,c,e,f){var g,h,i,j,l,m,o,p=[e||d],q=k.call(b,"type")?b.type:b,r=k.call(b,"namespace")?b.namespace.split("."):[];if(i=m=e=e||d,3!==e.nodeType&&8!==e.nodeType&&!na.test(q+n.event.triggered)&&(q.indexOf(".")>-1&&(r=q.split("."),q=r.shift(),r.sort()),h=q.indexOf(":")<0&&"on"+q,b=b[n.expando]?b:new n.Event(q,"object"==typeof b&&b),b.isTrigger=f?2:3,b.namespace=r.join("."),b.rnamespace=b.namespace?new RegExp("(^|\\.)"+r.join("\\.(?:.*\\.|)")+"(\\.|$)"):null,b.result=void 0,b.target||(b.target=e),c=null==c?[b]:n.makeArray(c,[b]),l=n.event.special[q]||{},f||!l.trigger||l.trigger.apply(e,c)!==!1)){if(!f&&!l.noBubble&&!n.isWindow(e)){for(j=l.delegateType||q,na.test(j+q)||(i=i.parentNode);i;i=i.parentNode)p.push(i),m=i;m===(e.ownerDocument||d)&&p.push(m.defaultView||m.parentWindow||a)}o=0;while((i=p[o++])&&!b.isPropagationStopped())b.type=o>1?j:l.bindType||q,g=(n._data(i,"events")||{})[b.type]&&n._data(i,"handle"),g&&g.apply(i,c),g=h&&i[h],g&&g.apply&&M(i)&&(b.result=g.apply(i,c),b.result===!1&&b.preventDefault());if(b.type=q,!f&&!b.isDefaultPrevented()&&(!l._default||l._default.apply(p.pop(),c)===!1)&&M(e)&&h&&e[q]&&!n.isWindow(e)){m=e[h],m&&(e[h]=null),n.event.triggered=q;try{e[q]()}catch(s){}n.event.triggered=void 0,m&&(e[h]=m)}return b.result}},dispatch:function(a){a=n.event.fix(a);var b,c,d,f,g,h=[],i=e.call(arguments),j=(n._data(this,"events")||{})[a.type]||[],k=n.event.special[a.type]||{};if(i[0]=a,a.delegateTarget=this,!k.preDispatch||k.preDispatch.call(this,a)!==!1){h=n.event.handlers.call(this,a,j),b=0;while((f=h[b++])&&!a.isPropagationStopped()){a.currentTarget=f.elem,c=0;while((g=f.handlers[c++])&&!a.isImmediatePropagationStopped())a.rnamespace&&!a.rnamespace.test(g.namespace)||(a.handleObj=g,a.data=g.data,d=((n.event.special[g.origType]||{}).handle||g.handler).apply(f.elem,i),void 0!==d&&(a.result=d)===!1&&(a.preventDefault(),a.stopPropagation()))}return k.postDispatch&&k.postDispatch.call(this,a),a.result}},handlers:function(a,b){var c,d,e,f,g=[],h=b.delegateCount,i=a.target;if(h&&i.nodeType&&("click"!==a.type||isNaN(a.button)||a.button<1))for(;i!=this;i=i.parentNode||this)if(1===i.nodeType&&(i.disabled!==!0||"click"!==a.type)){for(d=[],c=0;h>c;c++)f=b[c],e=f.selector+" ",void 0===d[e]&&(d[e]=f.needsContext?n(e,this).index(i)>-1:n.find(e,this,null,[i]).length),d[e]&&d.push(f);d.length&&g.push({elem:i,handlers:d})}return h<b.length&&g.push({elem:this,handlers:b.slice(h)}),g},fix:function(a){if(a[n.expando])return a;var b,c,e,f=a.type,g=a,h=this.fixHooks[f];h||(this.fixHooks[f]=h=ma.test(f)?this.mouseHooks:la.test(f)?this.keyHooks:{}),e=h.props?this.props.concat(h.props):this.props,a=new n.Event(g),b=e.length;while(b--)c=e[b],a[c]=g[c];return a.target||(a.target=g.srcElement||d),3===a.target.nodeType&&(a.target=a.target.parentNode),a.metaKey=!!a.metaKey,h.filter?h.filter(a,g):a},props:"altKey bubbles cancelable ctrlKey currentTarget detail eventPhase metaKey relatedTarget shiftKey target timeStamp view which".split(" "),fixHooks:{},keyHooks:{props:"char charCode key keyCode".split(" "),filter:function(a,b){return null==a.which&&(a.which=null!=b.charCode?b.charCode:b.keyCode),a}},mouseHooks:{props:"button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement".split(" "),filter:function(a,b){var c,e,f,g=b.button,h=b.fromElement;return null==a.pageX&&null!=b.clientX&&(e=a.target.ownerDocument||d,f=e.documentElement,c=e.body,a.pageX=b.clientX+(f&&f.scrollLeft||c&&c.scrollLeft||0)-(f&&f.clientLeft||c&&c.clientLeft||0),a.pageY=b.clientY+(f&&f.scrollTop||c&&c.scrollTop||0)-(f&&f.clientTop||c&&c.clientTop||0)),!a.relatedTarget&&h&&(a.relatedTarget=h===a.target?b.toElement:h),a.which||void 0===g||(a.which=1&g?1:2&g?3:4&g?2:0),a}},special:{load:{noBubble:!0},focus:{trigger:function(){if(this!==ra()&&this.focus)try{return this.focus(),!1}catch(a){}},delegateType:"focusin"},blur:{trigger:function(){return this===ra()&&this.blur?(this.blur(),!1):void 0},delegateType:"focusout"},click:{trigger:function(){return n.nodeName(this,"input")&&"checkbox"===this.type&&this.click?(this.click(),!1):void 0},_default:function(a){return n.nodeName(a.target,"a")}},beforeunload:{postDispatch:function(a){void 0!==a.result&&a.originalEvent&&(a.originalEvent.returnValue=a.result)}}},simulate:function(a,b,c){var d=n.extend(new n.Event,c,{type:a,isSimulated:!0});n.event.trigger(d,null,b),d.isDefaultPrevented()&&c.preventDefault()}},n.removeEvent=d.removeEventListener?function(a,b,c){a.removeEventListener&&a.removeEventListener(b,c)}:function(a,b,c){var d="on"+b;a.detachEvent&&("undefined"==typeof a[d]&&(a[d]=null),a.detachEvent(d,c))},n.Event=function(a,b){return this instanceof n.Event?(a&&a.type?(this.originalEvent=a,this.type=a.type,this.isDefaultPrevented=a.defaultPrevented||void 0===a.defaultPrevented&&a.returnValue===!1?pa:qa):this.type=a,b&&n.extend(this,b),this.timeStamp=a&&a.timeStamp||n.now(),void(this[n.expando]=!0)):new n.Event(a,b)},n.Event.prototype={constructor:n.Event,isDefaultPrevented:qa,isPropagationStopped:qa,isImmediatePropagationStopped:qa,preventDefault:function(){var a=this.originalEvent;this.isDefaultPrevented=pa,a&&(a.preventDefault?a.preventDefault():a.returnValue=!1)},stopPropagation:function(){var a=this.originalEvent;this.isPropagationStopped=pa,a&&!this.isSimulated&&(a.stopPropagation&&a.stopPropagation(),a.cancelBubble=!0)},stopImmediatePropagation:function(){var a=this.originalEvent;this.isImmediatePropagationStopped=pa,a&&a.stopImmediatePropagation&&a.stopImmediatePropagation(),this.stopPropagation()}},n.each({mouseenter:"mouseover",mouseleave:"mouseout",pointerenter:"pointerover",pointerleave:"pointerout"},function(a,b){n.event.special[a]={delegateType:b,bindType:b,handle:function(a){var c,d=this,e=a.relatedTarget,f=a.handleObj;return e&&(e===d||n.contains(d,e))||(a.type=f.origType,c=f.handler.apply(this,arguments),a.type=b),c}}}),l.submit||(n.event.special.submit={setup:function(){return n.nodeName(this,"form")?!1:void n.event.add(this,"click._submit keypress._submit",function(a){var b=a.target,c=n.nodeName(b,"input")||n.nodeName(b,"button")?n.prop(b,"form"):void 0;c&&!n._data(c,"submit")&&(n.event.add(c,"submit._submit",function(a){a._submitBubble=!0}),n._data(c,"submit",!0))})},postDispatch:function(a){a._submitBubble&&(delete a._submitBubble,this.parentNode&&!a.isTrigger&&n.event.simulate("submit",this.parentNode,a))},teardown:function(){return n.nodeName(this,"form")?!1:void n.event.remove(this,"._submit")}}),l.change||(n.event.special.change={setup:function(){return ka.test(this.nodeName)?("checkbox"!==this.type&&"radio"!==this.type||(n.event.add(this,"propertychange._change",function(a){"checked"===a.originalEvent.propertyName&&(this._justChanged=!0)}),n.event.add(this,"click._change",function(a){this._justChanged&&!a.isTrigger&&(this._justChanged=!1),n.event.simulate("change",this,a)})),!1):void n.event.add(this,"beforeactivate._change",function(a){var b=a.target;ka.test(b.nodeName)&&!n._data(b,"change")&&(n.event.add(b,"change._change",function(a){!this.parentNode||a.isSimulated||a.isTrigger||n.event.simulate("change",this.parentNode,a)}),n._data(b,"change",!0))})},handle:function(a){var b=a.target;return this!==b||a.isSimulated||a.isTrigger||"radio"!==b.type&&"checkbox"!==b.type?a.handleObj.handler.apply(this,arguments):void 0},teardown:function(){return n.event.remove(this,"._change"),!ka.test(this.nodeName)}}),l.focusin||n.each({focus:"focusin",blur:"focusout"},function(a,b){var c=function(a){n.event.simulate(b,a.target,n.event.fix(a))};n.event.special[b]={setup:function(){var d=this.ownerDocument||this,e=n._data(d,b);e||d.addEventListener(a,c,!0),n._data(d,b,(e||0)+1)},teardown:function(){var d=this.ownerDocument||this,e=n._data(d,b)-1;e?n._data(d,b,e):(d.removeEventListener(a,c,!0),n._removeData(d,b))}}}),n.fn.extend({on:function(a,b,c,d){return sa(this,a,b,c,d)},one:function(a,b,c,d){return sa(this,a,b,c,d,1)},off:function(a,b,c){var d,e;if(a&&a.preventDefault&&a.handleObj)return d=a.handleObj,n(a.delegateTarget).off(d.namespace?d.origType+"."+d.namespace:d.origType,d.selector,d.handler),this;if("object"==typeof a){for(e in a)this.off(e,b,a[e]);return this}return b!==!1&&"function"!=typeof b||(c=b,b=void 0),c===!1&&(c=qa),this.each(function(){n.event.remove(this,a,c,b)})},trigger:function(a,b){return this.each(function(){n.event.trigger(a,b,this)})},triggerHandler:function(a,b){var c=this[0];return c?n.event.trigger(a,b,c,!0):void 0}});var ta=/ jQuery\d+="(?:null|\d+)"/g,ua=new RegExp("<(?:"+ba+")[\\s/>]","i"),va=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:-]+)[^>]*)\/>/gi,wa=/<script|<style|<link/i,xa=/checked\s*(?:[^=]|=\s*.checked.)/i,ya=/^true\/(.*)/,za=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g,Aa=ca(d),Ba=Aa.appendChild(d.createElement("div"));function Ca(a,b){return n.nodeName(a,"table")&&n.nodeName(11!==b.nodeType?b:b.firstChild,"tr")?a.getElementsByTagName("tbody")[0]||a.appendChild(a.ownerDocument.createElement("tbody")):a}function Da(a){return a.type=(null!==n.find.attr(a,"type"))+"/"+a.type,a}function Ea(a){var b=ya.exec(a.type);return b?a.type=b[1]:a.removeAttribute("type"),a}function Fa(a,b){if(1===b.nodeType&&n.hasData(a)){var c,d,e,f=n._data(a),g=n._data(b,f),h=f.events;if(h){delete g.handle,g.events={};for(c in h)for(d=0,e=h[c].length;e>d;d++)n.event.add(b,c,h[c][d])}g.data&&(g.data=n.extend({},g.data))}}function Ga(a,b){var c,d,e;if(1===b.nodeType){if(c=b.nodeName.toLowerCase(),!l.noCloneEvent&&b[n.expando]){e=n._data(b);for(d in e.events)n.removeEvent(b,d,e.handle);b.removeAttribute(n.expando)}"script"===c&&b.text!==a.text?(Da(b).text=a.text,Ea(b)):"object"===c?(b.parentNode&&(b.outerHTML=a.outerHTML),l.html5Clone&&a.innerHTML&&!n.trim(b.innerHTML)&&(b.innerHTML=a.innerHTML)):"input"===c&&Z.test(a.type)?(b.defaultChecked=b.checked=a.checked,b.value!==a.value&&(b.value=a.value)):"option"===c?b.defaultSelected=b.selected=a.defaultSelected:"input"!==c&&"textarea"!==c||(b.defaultValue=a.defaultValue)}}function Ha(a,b,c,d){b=f.apply([],b);var e,g,h,i,j,k,m=0,o=a.length,p=o-1,q=b[0],r=n.isFunction(q);if(r||o>1&&"string"==typeof q&&!l.checkClone&&xa.test(q))return a.each(function(e){var f=a.eq(e);r&&(b[0]=q.call(this,e,f.html())),Ha(f,b,c,d)});if(o&&(k=ja(b,a[0].ownerDocument,!1,a,d),e=k.firstChild,1===k.childNodes.length&&(k=e),e||d)){for(i=n.map(ea(k,"script"),Da),h=i.length;o>m;m++)g=k,m!==p&&(g=n.clone(g,!0,!0),h&&n.merge(i,ea(g,"script"))),c.call(a[m],g,m);if(h)for(j=i[i.length-1].ownerDocument,n.map(i,Ea),m=0;h>m;m++)g=i[m],_.test(g.type||"")&&!n._data(g,"globalEval")&&n.contains(j,g)&&(g.src?n._evalUrl&&n._evalUrl(g.src):n.globalEval((g.text||g.textContent||g.innerHTML||"").replace(za,"")));k=e=null}return a}function Ia(a,b,c){for(var d,e=b?n.filter(b,a):a,f=0;null!=(d=e[f]);f++)c||1!==d.nodeType||n.cleanData(ea(d)),d.parentNode&&(c&&n.contains(d.ownerDocument,d)&&fa(ea(d,"script")),d.parentNode.removeChild(d));return a}n.extend({htmlPrefilter:function(a){return a.replace(va,"<$1></$2>")},clone:function(a,b,c){var d,e,f,g,h,i=n.contains(a.ownerDocument,a);if(l.html5Clone||n.isXMLDoc(a)||!ua.test("<"+a.nodeName+">")?f=a.cloneNode(!0):(Ba.innerHTML=a.outerHTML,Ba.removeChild(f=Ba.firstChild)),!(l.noCloneEvent&&l.noCloneChecked||1!==a.nodeType&&11!==a.nodeType||n.isXMLDoc(a)))for(d=ea(f),h=ea(a),g=0;null!=(e=h[g]);++g)d[g]&&Ga(e,d[g]);if(b)if(c)for(h=h||ea(a),d=d||ea(f),g=0;null!=(e=h[g]);g++)Fa(e,d[g]);else Fa(a,f);return d=ea(f,"script"),d.length>0&&fa(d,!i&&ea(a,"script")),d=h=e=null,f},cleanData:function(a,b){for(var d,e,f,g,h=0,i=n.expando,j=n.cache,k=l.attributes,m=n.event.special;null!=(d=a[h]);h++)if((b||M(d))&&(f=d[i],g=f&&j[f])){if(g.events)for(e in g.events)m[e]?n.event.remove(d,e):n.removeEvent(d,e,g.handle);j[f]&&(delete j[f],k||"undefined"==typeof d.removeAttribute?d[i]=void 0:d.removeAttribute(i),c.push(f))}}}),n.fn.extend({domManip:Ha,detach:function(a){return Ia(this,a,!0)},remove:function(a){return Ia(this,a)},text:function(a){return Y(this,function(a){return void 0===a?n.text(this):this.empty().append((this[0]&&this[0].ownerDocument||d).createTextNode(a))},null,a,arguments.length)},append:function(){return Ha(this,arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=Ca(this,a);b.appendChild(a)}})},prepend:function(){return Ha(this,arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=Ca(this,a);b.insertBefore(a,b.firstChild)}})},before:function(){return Ha(this,arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this)})},after:function(){return Ha(this,arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this.nextSibling)})},empty:function(){for(var a,b=0;null!=(a=this[b]);b++){1===a.nodeType&&n.cleanData(ea(a,!1));while(a.firstChild)a.removeChild(a.firstChild);a.options&&n.nodeName(a,"select")&&(a.options.length=0)}return this},clone:function(a,b){return a=null==a?!1:a,b=null==b?a:b,this.map(function(){return n.clone(this,a,b)})},html:function(a){return Y(this,function(a){var b=this[0]||{},c=0,d=this.length;if(void 0===a)return 1===b.nodeType?b.innerHTML.replace(ta,""):void 0;if("string"==typeof a&&!wa.test(a)&&(l.htmlSerialize||!ua.test(a))&&(l.leadingWhitespace||!aa.test(a))&&!da[($.exec(a)||["",""])[1].toLowerCase()]){a=n.htmlPrefilter(a);try{for(;d>c;c++)b=this[c]||{},1===b.nodeType&&(n.cleanData(ea(b,!1)),b.innerHTML=a);b=0}catch(e){}}b&&this.empty().append(a)},null,a,arguments.length)},replaceWith:function(){var a=[];return Ha(this,arguments,function(b){var c=this.parentNode;n.inArray(this,a)<0&&(n.cleanData(ea(this)),c&&c.replaceChild(b,this))},a)}}),n.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){n.fn[a]=function(a){for(var c,d=0,e=[],f=n(a),h=f.length-1;h>=d;d++)c=d===h?this:this.clone(!0),n(f[d])[b](c),g.apply(e,c.get());return this.pushStack(e)}});var Ja,Ka={HTML:"block",BODY:"block"};function La(a,b){var c=n(b.createElement(a)).appendTo(b.body),d=n.css(c[0],"display");return c.detach(),d}function Ma(a){var b=d,c=Ka[a];return c||(c=La(a,b),"none"!==c&&c||(Ja=(Ja||n("<iframe frameborder='0' width='0' height='0'/>")).appendTo(b.documentElement),b=(Ja[0].contentWindow||Ja[0].contentDocument).document,b.write(),b.close(),c=La(a,b),Ja.detach()),Ka[a]=c),c}var Na=/^margin/,Oa=new RegExp("^("+T+")(?!px)[a-z%]+$","i"),Pa=function(a,b,c,d){var e,f,g={};for(f in b)g[f]=a.style[f],a.style[f]=b[f];e=c.apply(a,d||[]);for(f in b)a.style[f]=g[f];return e},Qa=d.documentElement;!function(){var b,c,e,f,g,h,i=d.createElement("div"),j=d.createElement("div");if(j.style){j.style.cssText="float:left;opacity:.5",l.opacity="0.5"===j.style.opacity,l.cssFloat=!!j.style.cssFloat,j.style.backgroundClip="content-box",j.cloneNode(!0).style.backgroundClip="",l.clearCloneStyle="content-box"===j.style.backgroundClip,i=d.createElement("div"),i.style.cssText="border:0;width:8px;height:0;top:0;left:-9999px;padding:0;margin-top:1px;position:absolute",j.innerHTML="",i.appendChild(j),l.boxSizing=""===j.style.boxSizing||""===j.style.MozBoxSizing||""===j.style.WebkitBoxSizing,n.extend(l,{reliableHiddenOffsets:function(){return null==b&&k(),f},boxSizingReliable:function(){return null==b&&k(),e},pixelMarginRight:function(){return null==b&&k(),c},pixelPosition:function(){return null==b&&k(),b},reliableMarginRight:function(){return null==b&&k(),g},reliableMarginLeft:function(){return null==b&&k(),h}});function k(){var k,l,m=d.documentElement;m.appendChild(i),j.style.cssText="-webkit-box-sizing:border-box;box-sizing:border-box;position:relative;display:block;margin:auto;border:1px;padding:1px;top:1%;width:50%",b=e=h=!1,c=g=!0,a.getComputedStyle&&(l=a.getComputedStyle(j),b="1%"!==(l||{}).top,h="2px"===(l||{}).marginLeft,e="4px"===(l||{width:"4px"}).width,j.style.marginRight="50%",c="4px"===(l||{marginRight:"4px"}).marginRight,k=j.appendChild(d.createElement("div")),k.style.cssText=j.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:0",k.style.marginRight=k.style.width="0",j.style.width="1px",g=!parseFloat((a.getComputedStyle(k)||{}).marginRight),j.removeChild(k)),j.style.display="none",f=0===j.getClientRects().length,f&&(j.style.display="",j.innerHTML="<table><tr><td></td><td>t</td></tr></table>",k=j.getElementsByTagName("td"),k[0].style.cssText="margin:0;border:0;padding:0;display:none",f=0===k[0].offsetHeight,f&&(k[0].style.display="",k[1].style.display="none",f=0===k[0].offsetHeight)),m.removeChild(i)}}}();var Ra,Sa,Ta=/^(top|right|bottom|left)$/;a.getComputedStyle?(Ra=function(b){var c=b.ownerDocument.defaultView;return c&&c.opener||(c=a),c.getComputedStyle(b)},Sa=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ra(a),g=c?c.getPropertyValue(b)||c[b]:void 0,""!==g&&void 0!==g||n.contains(a.ownerDocument,a)||(g=n.style(a,b)),c&&!l.pixelMarginRight()&&Oa.test(g)&&Na.test(b)&&(d=h.width,e=h.minWidth,f=h.maxWidth,h.minWidth=h.maxWidth=h.width=g,g=c.width,h.width=d,h.minWidth=e,h.maxWidth=f),void 0===g?g:g+""}):Qa.currentStyle&&(Ra=function(a){return a.currentStyle},Sa=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ra(a),g=c?c[b]:void 0,null==g&&h&&h[b]&&(g=h[b]),Oa.test(g)&&!Ta.test(b)&&(d=h.left,e=a.runtimeStyle,f=e&&e.left,f&&(e.left=a.currentStyle.left),h.left="fontSize"===b?"1em":g,g=h.pixelLeft+"px",h.left=d,f&&(e.left=f)),void 0===g?g:g+""||"auto"});function Ua(a,b){return{get:function(){return a()?void delete this.get:(this.get=b).apply(this,arguments)}}}var Va=/alpha\([^)]*\)/i,Wa=/opacity\s*=\s*([^)]*)/i,Xa=/^(none|table(?!-c[ea]).+)/,Ya=new RegExp("^("+T+")(.*)$","i"),Za={position:"absolute",visibility:"hidden",display:"block"},$a={letterSpacing:"0",fontWeight:"400"},_a=["Webkit","O","Moz","ms"],ab=d.createElement("div").style;function bb(a){if(a in ab)return a;var b=a.charAt(0).toUpperCase()+a.slice(1),c=_a.length;while(c--)if(a=_a[c]+b,a in ab)return a}function cb(a,b){for(var c,d,e,f=[],g=0,h=a.length;h>g;g++)d=a[g],d.style&&(f[g]=n._data(d,"olddisplay"),c=d.style.display,b?(f[g]||"none"!==c||(d.style.display=""),""===d.style.display&&W(d)&&(f[g]=n._data(d,"olddisplay",Ma(d.nodeName)))):(e=W(d),(c&&"none"!==c||!e)&&n._data(d,"olddisplay",e?c:n.css(d,"display"))));for(g=0;h>g;g++)d=a[g],d.style&&(b&&"none"!==d.style.display&&""!==d.style.display||(d.style.display=b?f[g]||"":"none"));return a}function db(a,b,c){var d=Ya.exec(b);return d?Math.max(0,d[1]-(c||0))+(d[2]||"px"):b}function eb(a,b,c,d,e){for(var f=c===(d?"border":"content")?4:"width"===b?1:0,g=0;4>f;f+=2)"margin"===c&&(g+=n.css(a,c+V[f],!0,e)),d?("content"===c&&(g-=n.css(a,"padding"+V[f],!0,e)),"margin"!==c&&(g-=n.css(a,"border"+V[f]+"Width",!0,e))):(g+=n.css(a,"padding"+V[f],!0,e),"padding"!==c&&(g+=n.css(a,"border"+V[f]+"Width",!0,e)));return g}function fb(b,c,e){var f=!0,g="width"===c?b.offsetWidth:b.offsetHeight,h=Ra(b),i=l.boxSizing&&"border-box"===n.css(b,"boxSizing",!1,h);if(d.msFullscreenElement&&a.top!==a&&b.getClientRects().length&&(g=Math.round(100*b.getBoundingClientRect()[c])),0>=g||null==g){if(g=Sa(b,c,h),(0>g||null==g)&&(g=b.style[c]),Oa.test(g))return g;f=i&&(l.boxSizingReliable()||g===b.style[c]),g=parseFloat(g)||0}return g+eb(b,c,e||(i?"border":"content"),f,h)+"px"}n.extend({cssHooks:{opacity:{get:function(a,b){if(b){var c=Sa(a,"opacity");return""===c?"1":c}}}},cssNumber:{animationIterationCount:!0,columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{"float":l.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,c,d){if(a&&3!==a.nodeType&&8!==a.nodeType&&a.style){var e,f,g,h=n.camelCase(b),i=a.style;if(b=n.cssProps[h]||(n.cssProps[h]=bb(h)||h),g=n.cssHooks[b]||n.cssHooks[h],void 0===c)return g&&"get"in g&&void 0!==(e=g.get(a,!1,d))?e:i[b];if(f=typeof c,"string"===f&&(e=U.exec(c))&&e[1]&&(c=X(a,b,e),f="number"),null!=c&&c===c&&("number"===f&&(c+=e&&e[3]||(n.cssNumber[h]?"":"px")),l.clearCloneStyle||""!==c||0!==b.indexOf("background")||(i[b]="inherit"),!(g&&"set"in g&&void 0===(c=g.set(a,c,d)))))try{i[b]=c}catch(j){}}},css:function(a,b,c,d){var e,f,g,h=n.camelCase(b);return b=n.cssProps[h]||(n.cssProps[h]=bb(h)||h),g=n.cssHooks[b]||n.cssHooks[h],g&&"get"in g&&(f=g.get(a,!0,c)),void 0===f&&(f=Sa(a,b,d)),"normal"===f&&b in $a&&(f=$a[b]),""===c||c?(e=parseFloat(f),c===!0||isFinite(e)?e||0:f):f}}),n.each(["height","width"],function(a,b){n.cssHooks[b]={get:function(a,c,d){return c?Xa.test(n.css(a,"display"))&&0===a.offsetWidth?Pa(a,Za,function(){return fb(a,b,d)}):fb(a,b,d):void 0},set:function(a,c,d){var e=d&&Ra(a);return db(a,c,d?eb(a,b,d,l.boxSizing&&"border-box"===n.css(a,"boxSizing",!1,e),e):0)}}}),l.opacity||(n.cssHooks.opacity={get:function(a,b){return Wa.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?.01*parseFloat(RegExp.$1)+"":b?"1":""},set:function(a,b){var c=a.style,d=a.currentStyle,e=n.isNumeric(b)?"alpha(opacity="+100*b+")":"",f=d&&d.filter||c.filter||"";c.zoom=1,(b>=1||""===b)&&""===n.trim(f.replace(Va,""))&&c.removeAttribute&&(c.removeAttribute("filter"),""===b||d&&!d.filter)||(c.filter=Va.test(f)?f.replace(Va,e):f+" "+e)}}),n.cssHooks.marginRight=Ua(l.reliableMarginRight,function(a,b){return b?Pa(a,{display:"inline-block"},Sa,[a,"marginRight"]):void 0}),n.cssHooks.marginLeft=Ua(l.reliableMarginLeft,function(a,b){
return b?(parseFloat(Sa(a,"marginLeft"))||(n.contains(a.ownerDocument,a)?a.getBoundingClientRect().left-Pa(a,{marginLeft:0},function(){return a.getBoundingClientRect().left}):0))+"px":void 0}),n.each({margin:"",padding:"",border:"Width"},function(a,b){n.cssHooks[a+b]={expand:function(c){for(var d=0,e={},f="string"==typeof c?c.split(" "):[c];4>d;d++)e[a+V[d]+b]=f[d]||f[d-2]||f[0];return e}},Na.test(a)||(n.cssHooks[a+b].set=db)}),n.fn.extend({css:function(a,b){return Y(this,function(a,b,c){var d,e,f={},g=0;if(n.isArray(b)){for(d=Ra(a),e=b.length;e>g;g++)f[b[g]]=n.css(a,b[g],!1,d);return f}return void 0!==c?n.style(a,b,c):n.css(a,b)},a,b,arguments.length>1)},show:function(){return cb(this,!0)},hide:function(){return cb(this)},toggle:function(a){return"boolean"==typeof a?a?this.show():this.hide():this.each(function(){W(this)?n(this).show():n(this).hide()})}});function gb(a,b,c,d,e){return new gb.prototype.init(a,b,c,d,e)}n.Tween=gb,gb.prototype={constructor:gb,init:function(a,b,c,d,e,f){this.elem=a,this.prop=c,this.easing=e||n.easing._default,this.options=b,this.start=this.now=this.cur(),this.end=d,this.unit=f||(n.cssNumber[c]?"":"px")},cur:function(){var a=gb.propHooks[this.prop];return a&&a.get?a.get(this):gb.propHooks._default.get(this)},run:function(a){var b,c=gb.propHooks[this.prop];return this.options.duration?this.pos=b=n.easing[this.easing](a,this.options.duration*a,0,1,this.options.duration):this.pos=b=a,this.now=(this.end-this.start)*b+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),c&&c.set?c.set(this):gb.propHooks._default.set(this),this}},gb.prototype.init.prototype=gb.prototype,gb.propHooks={_default:{get:function(a){var b;return 1!==a.elem.nodeType||null!=a.elem[a.prop]&&null==a.elem.style[a.prop]?a.elem[a.prop]:(b=n.css(a.elem,a.prop,""),b&&"auto"!==b?b:0)},set:function(a){n.fx.step[a.prop]?n.fx.step[a.prop](a):1!==a.elem.nodeType||null==a.elem.style[n.cssProps[a.prop]]&&!n.cssHooks[a.prop]?a.elem[a.prop]=a.now:n.style(a.elem,a.prop,a.now+a.unit)}}},gb.propHooks.scrollTop=gb.propHooks.scrollLeft={set:function(a){a.elem.nodeType&&a.elem.parentNode&&(a.elem[a.prop]=a.now)}},n.easing={linear:function(a){return a},swing:function(a){return.5-Math.cos(a*Math.PI)/2},_default:"swing"},n.fx=gb.prototype.init,n.fx.step={};var hb,ib,jb=/^(?:toggle|show|hide)$/,kb=/queueHooks$/;function lb(){return a.setTimeout(function(){hb=void 0}),hb=n.now()}function mb(a,b){var c,d={height:a},e=0;for(b=b?1:0;4>e;e+=2-b)c=V[e],d["margin"+c]=d["padding"+c]=a;return b&&(d.opacity=d.width=a),d}function nb(a,b,c){for(var d,e=(qb.tweeners[b]||[]).concat(qb.tweeners["*"]),f=0,g=e.length;g>f;f++)if(d=e[f].call(c,b,a))return d}function ob(a,b,c){var d,e,f,g,h,i,j,k,m=this,o={},p=a.style,q=a.nodeType&&W(a),r=n._data(a,"fxshow");c.queue||(h=n._queueHooks(a,"fx"),null==h.unqueued&&(h.unqueued=0,i=h.empty.fire,h.empty.fire=function(){h.unqueued||i()}),h.unqueued++,m.always(function(){m.always(function(){h.unqueued--,n.queue(a,"fx").length||h.empty.fire()})})),1===a.nodeType&&("height"in b||"width"in b)&&(c.overflow=[p.overflow,p.overflowX,p.overflowY],j=n.css(a,"display"),k="none"===j?n._data(a,"olddisplay")||Ma(a.nodeName):j,"inline"===k&&"none"===n.css(a,"float")&&(l.inlineBlockNeedsLayout&&"inline"!==Ma(a.nodeName)?p.zoom=1:p.display="inline-block")),c.overflow&&(p.overflow="hidden",l.shrinkWrapBlocks()||m.always(function(){p.overflow=c.overflow[0],p.overflowX=c.overflow[1],p.overflowY=c.overflow[2]}));for(d in b)if(e=b[d],jb.exec(e)){if(delete b[d],f=f||"toggle"===e,e===(q?"hide":"show")){if("show"!==e||!r||void 0===r[d])continue;q=!0}o[d]=r&&r[d]||n.style(a,d)}else j=void 0;if(n.isEmptyObject(o))"inline"===("none"===j?Ma(a.nodeName):j)&&(p.display=j);else{r?"hidden"in r&&(q=r.hidden):r=n._data(a,"fxshow",{}),f&&(r.hidden=!q),q?n(a).show():m.done(function(){n(a).hide()}),m.done(function(){var b;n._removeData(a,"fxshow");for(b in o)n.style(a,b,o[b])});for(d in o)g=nb(q?r[d]:0,d,m),d in r||(r[d]=g.start,q&&(g.end=g.start,g.start="width"===d||"height"===d?1:0))}}function pb(a,b){var c,d,e,f,g;for(c in a)if(d=n.camelCase(c),e=b[d],f=a[c],n.isArray(f)&&(e=f[1],f=a[c]=f[0]),c!==d&&(a[d]=f,delete a[c]),g=n.cssHooks[d],g&&"expand"in g){f=g.expand(f),delete a[d];for(c in f)c in a||(a[c]=f[c],b[c]=e)}else b[d]=e}function qb(a,b,c){var d,e,f=0,g=qb.prefilters.length,h=n.Deferred().always(function(){delete i.elem}),i=function(){if(e)return!1;for(var b=hb||lb(),c=Math.max(0,j.startTime+j.duration-b),d=c/j.duration||0,f=1-d,g=0,i=j.tweens.length;i>g;g++)j.tweens[g].run(f);return h.notifyWith(a,[j,f,c]),1>f&&i?c:(h.resolveWith(a,[j]),!1)},j=h.promise({elem:a,props:n.extend({},b),opts:n.extend(!0,{specialEasing:{},easing:n.easing._default},c),originalProperties:b,originalOptions:c,startTime:hb||lb(),duration:c.duration,tweens:[],createTween:function(b,c){var d=n.Tween(a,j.opts,b,c,j.opts.specialEasing[b]||j.opts.easing);return j.tweens.push(d),d},stop:function(b){var c=0,d=b?j.tweens.length:0;if(e)return this;for(e=!0;d>c;c++)j.tweens[c].run(1);return b?(h.notifyWith(a,[j,1,0]),h.resolveWith(a,[j,b])):h.rejectWith(a,[j,b]),this}}),k=j.props;for(pb(k,j.opts.specialEasing);g>f;f++)if(d=qb.prefilters[f].call(j,a,k,j.opts))return n.isFunction(d.stop)&&(n._queueHooks(j.elem,j.opts.queue).stop=n.proxy(d.stop,d)),d;return n.map(k,nb,j),n.isFunction(j.opts.start)&&j.opts.start.call(a,j),n.fx.timer(n.extend(i,{elem:a,anim:j,queue:j.opts.queue})),j.progress(j.opts.progress).done(j.opts.done,j.opts.complete).fail(j.opts.fail).always(j.opts.always)}n.Animation=n.extend(qb,{tweeners:{"*":[function(a,b){var c=this.createTween(a,b);return X(c.elem,a,U.exec(b),c),c}]},tweener:function(a,b){n.isFunction(a)?(b=a,a=["*"]):a=a.match(G);for(var c,d=0,e=a.length;e>d;d++)c=a[d],qb.tweeners[c]=qb.tweeners[c]||[],qb.tweeners[c].unshift(b)},prefilters:[ob],prefilter:function(a,b){b?qb.prefilters.unshift(a):qb.prefilters.push(a)}}),n.speed=function(a,b,c){var d=a&&"object"==typeof a?n.extend({},a):{complete:c||!c&&b||n.isFunction(a)&&a,duration:a,easing:c&&b||b&&!n.isFunction(b)&&b};return d.duration=n.fx.off?0:"number"==typeof d.duration?d.duration:d.duration in n.fx.speeds?n.fx.speeds[d.duration]:n.fx.speeds._default,null!=d.queue&&d.queue!==!0||(d.queue="fx"),d.old=d.complete,d.complete=function(){n.isFunction(d.old)&&d.old.call(this),d.queue&&n.dequeue(this,d.queue)},d},n.fn.extend({fadeTo:function(a,b,c,d){return this.filter(W).css("opacity",0).show().end().animate({opacity:b},a,c,d)},animate:function(a,b,c,d){var e=n.isEmptyObject(a),f=n.speed(b,c,d),g=function(){var b=qb(this,n.extend({},a),f);(e||n._data(this,"finish"))&&b.stop(!0)};return g.finish=g,e||f.queue===!1?this.each(g):this.queue(f.queue,g)},stop:function(a,b,c){var d=function(a){var b=a.stop;delete a.stop,b(c)};return"string"!=typeof a&&(c=b,b=a,a=void 0),b&&a!==!1&&this.queue(a||"fx",[]),this.each(function(){var b=!0,e=null!=a&&a+"queueHooks",f=n.timers,g=n._data(this);if(e)g[e]&&g[e].stop&&d(g[e]);else for(e in g)g[e]&&g[e].stop&&kb.test(e)&&d(g[e]);for(e=f.length;e--;)f[e].elem!==this||null!=a&&f[e].queue!==a||(f[e].anim.stop(c),b=!1,f.splice(e,1));!b&&c||n.dequeue(this,a)})},finish:function(a){return a!==!1&&(a=a||"fx"),this.each(function(){var b,c=n._data(this),d=c[a+"queue"],e=c[a+"queueHooks"],f=n.timers,g=d?d.length:0;for(c.finish=!0,n.queue(this,a,[]),e&&e.stop&&e.stop.call(this,!0),b=f.length;b--;)f[b].elem===this&&f[b].queue===a&&(f[b].anim.stop(!0),f.splice(b,1));for(b=0;g>b;b++)d[b]&&d[b].finish&&d[b].finish.call(this);delete c.finish})}}),n.each(["toggle","show","hide"],function(a,b){var c=n.fn[b];n.fn[b]=function(a,d,e){return null==a||"boolean"==typeof a?c.apply(this,arguments):this.animate(mb(b,!0),a,d,e)}}),n.each({slideDown:mb("show"),slideUp:mb("hide"),slideToggle:mb("toggle"),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){n.fn[a]=function(a,c,d){return this.animate(b,a,c,d)}}),n.timers=[],n.fx.tick=function(){var a,b=n.timers,c=0;for(hb=n.now();c<b.length;c++)a=b[c],a()||b[c]!==a||b.splice(c--,1);b.length||n.fx.stop(),hb=void 0},n.fx.timer=function(a){n.timers.push(a),a()?n.fx.start():n.timers.pop()},n.fx.interval=13,n.fx.start=function(){ib||(ib=a.setInterval(n.fx.tick,n.fx.interval))},n.fx.stop=function(){a.clearInterval(ib),ib=null},n.fx.speeds={slow:600,fast:200,_default:400},n.fn.delay=function(b,c){return b=n.fx?n.fx.speeds[b]||b:b,c=c||"fx",this.queue(c,function(c,d){var e=a.setTimeout(c,b);d.stop=function(){a.clearTimeout(e)}})},function(){var a,b=d.createElement("input"),c=d.createElement("div"),e=d.createElement("select"),f=e.appendChild(d.createElement("option"));c=d.createElement("div"),c.setAttribute("className","t"),c.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",a=c.getElementsByTagName("a")[0],b.setAttribute("type","checkbox"),c.appendChild(b),a=c.getElementsByTagName("a")[0],a.style.cssText="top:1px",l.getSetAttribute="t"!==c.className,l.style=/top/.test(a.getAttribute("style")),l.hrefNormalized="/a"===a.getAttribute("href"),l.checkOn=!!b.value,l.optSelected=f.selected,l.enctype=!!d.createElement("form").enctype,e.disabled=!0,l.optDisabled=!f.disabled,b=d.createElement("input"),b.setAttribute("value",""),l.input=""===b.getAttribute("value"),b.value="t",b.setAttribute("type","radio"),l.radioValue="t"===b.value}();var rb=/\r/g,sb=/[\x20\t\r\n\f]+/g;n.fn.extend({val:function(a){var b,c,d,e=this[0];{if(arguments.length)return d=n.isFunction(a),this.each(function(c){var e;1===this.nodeType&&(e=d?a.call(this,c,n(this).val()):a,null==e?e="":"number"==typeof e?e+="":n.isArray(e)&&(e=n.map(e,function(a){return null==a?"":a+""})),b=n.valHooks[this.type]||n.valHooks[this.nodeName.toLowerCase()],b&&"set"in b&&void 0!==b.set(this,e,"value")||(this.value=e))});if(e)return b=n.valHooks[e.type]||n.valHooks[e.nodeName.toLowerCase()],b&&"get"in b&&void 0!==(c=b.get(e,"value"))?c:(c=e.value,"string"==typeof c?c.replace(rb,""):null==c?"":c)}}}),n.extend({valHooks:{option:{get:function(a){var b=n.find.attr(a,"value");return null!=b?b:n.trim(n.text(a)).replace(sb," ")}},select:{get:function(a){for(var b,c,d=a.options,e=a.selectedIndex,f="select-one"===a.type||0>e,g=f?null:[],h=f?e+1:d.length,i=0>e?h:f?e:0;h>i;i++)if(c=d[i],(c.selected||i===e)&&(l.optDisabled?!c.disabled:null===c.getAttribute("disabled"))&&(!c.parentNode.disabled||!n.nodeName(c.parentNode,"optgroup"))){if(b=n(c).val(),f)return b;g.push(b)}return g},set:function(a,b){var c,d,e=a.options,f=n.makeArray(b),g=e.length;while(g--)if(d=e[g],n.inArray(n.valHooks.option.get(d),f)>-1)try{d.selected=c=!0}catch(h){d.scrollHeight}else d.selected=!1;return c||(a.selectedIndex=-1),e}}}}),n.each(["radio","checkbox"],function(){n.valHooks[this]={set:function(a,b){return n.isArray(b)?a.checked=n.inArray(n(a).val(),b)>-1:void 0}},l.checkOn||(n.valHooks[this].get=function(a){return null===a.getAttribute("value")?"on":a.value})});var tb,ub,vb=n.expr.attrHandle,wb=/^(?:checked|selected)$/i,xb=l.getSetAttribute,yb=l.input;n.fn.extend({attr:function(a,b){return Y(this,n.attr,a,b,arguments.length>1)},removeAttr:function(a){return this.each(function(){n.removeAttr(this,a)})}}),n.extend({attr:function(a,b,c){var d,e,f=a.nodeType;if(3!==f&&8!==f&&2!==f)return"undefined"==typeof a.getAttribute?n.prop(a,b,c):(1===f&&n.isXMLDoc(a)||(b=b.toLowerCase(),e=n.attrHooks[b]||(n.expr.match.bool.test(b)?ub:tb)),void 0!==c?null===c?void n.removeAttr(a,b):e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:(a.setAttribute(b,c+""),c):e&&"get"in e&&null!==(d=e.get(a,b))?d:(d=n.find.attr(a,b),null==d?void 0:d))},attrHooks:{type:{set:function(a,b){if(!l.radioValue&&"radio"===b&&n.nodeName(a,"input")){var c=a.value;return a.setAttribute("type",b),c&&(a.value=c),b}}}},removeAttr:function(a,b){var c,d,e=0,f=b&&b.match(G);if(f&&1===a.nodeType)while(c=f[e++])d=n.propFix[c]||c,n.expr.match.bool.test(c)?yb&&xb||!wb.test(c)?a[d]=!1:a[n.camelCase("default-"+c)]=a[d]=!1:n.attr(a,c,""),a.removeAttribute(xb?c:d)}}),ub={set:function(a,b,c){return b===!1?n.removeAttr(a,c):yb&&xb||!wb.test(c)?a.setAttribute(!xb&&n.propFix[c]||c,c):a[n.camelCase("default-"+c)]=a[c]=!0,c}},n.each(n.expr.match.bool.source.match(/\w+/g),function(a,b){var c=vb[b]||n.find.attr;yb&&xb||!wb.test(b)?vb[b]=function(a,b,d){var e,f;return d||(f=vb[b],vb[b]=e,e=null!=c(a,b,d)?b.toLowerCase():null,vb[b]=f),e}:vb[b]=function(a,b,c){return c?void 0:a[n.camelCase("default-"+b)]?b.toLowerCase():null}}),yb&&xb||(n.attrHooks.value={set:function(a,b,c){return n.nodeName(a,"input")?void(a.defaultValue=b):tb&&tb.set(a,b,c)}}),xb||(tb={set:function(a,b,c){var d=a.getAttributeNode(c);return d||a.setAttributeNode(d=a.ownerDocument.createAttribute(c)),d.value=b+="","value"===c||b===a.getAttribute(c)?b:void 0}},vb.id=vb.name=vb.coords=function(a,b,c){var d;return c?void 0:(d=a.getAttributeNode(b))&&""!==d.value?d.value:null},n.valHooks.button={get:function(a,b){var c=a.getAttributeNode(b);return c&&c.specified?c.value:void 0},set:tb.set},n.attrHooks.contenteditable={set:function(a,b,c){tb.set(a,""===b?!1:b,c)}},n.each(["width","height"],function(a,b){n.attrHooks[b]={set:function(a,c){return""===c?(a.setAttribute(b,"auto"),c):void 0}}})),l.style||(n.attrHooks.style={get:function(a){return a.style.cssText||void 0},set:function(a,b){return a.style.cssText=b+""}});var zb=/^(?:input|select|textarea|button|object)$/i,Ab=/^(?:a|area)$/i;n.fn.extend({prop:function(a,b){return Y(this,n.prop,a,b,arguments.length>1)},removeProp:function(a){return a=n.propFix[a]||a,this.each(function(){try{this[a]=void 0,delete this[a]}catch(b){}})}}),n.extend({prop:function(a,b,c){var d,e,f=a.nodeType;if(3!==f&&8!==f&&2!==f)return 1===f&&n.isXMLDoc(a)||(b=n.propFix[b]||b,e=n.propHooks[b]),void 0!==c?e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:a[b]=c:e&&"get"in e&&null!==(d=e.get(a,b))?d:a[b]},propHooks:{tabIndex:{get:function(a){var b=n.find.attr(a,"tabindex");return b?parseInt(b,10):zb.test(a.nodeName)||Ab.test(a.nodeName)&&a.href?0:-1}}},propFix:{"for":"htmlFor","class":"className"}}),l.hrefNormalized||n.each(["href","src"],function(a,b){n.propHooks[b]={get:function(a){return a.getAttribute(b,4)}}}),l.optSelected||(n.propHooks.selected={get:function(a){var b=a.parentNode;return b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex),null},set:function(a){var b=a.parentNode;b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex)}}),n.each(["tabIndex","readOnly","maxLength","cellSpacing","cellPadding","rowSpan","colSpan","useMap","frameBorder","contentEditable"],function(){n.propFix[this.toLowerCase()]=this}),l.enctype||(n.propFix.enctype="encoding");var Bb=/[\t\r\n\f]/g;function Cb(a){return n.attr(a,"class")||""}n.fn.extend({addClass:function(a){var b,c,d,e,f,g,h,i=0;if(n.isFunction(a))return this.each(function(b){n(this).addClass(a.call(this,b,Cb(this)))});if("string"==typeof a&&a){b=a.match(G)||[];while(c=this[i++])if(e=Cb(c),d=1===c.nodeType&&(" "+e+" ").replace(Bb," ")){g=0;while(f=b[g++])d.indexOf(" "+f+" ")<0&&(d+=f+" ");h=n.trim(d),e!==h&&n.attr(c,"class",h)}}return this},removeClass:function(a){var b,c,d,e,f,g,h,i=0;if(n.isFunction(a))return this.each(function(b){n(this).removeClass(a.call(this,b,Cb(this)))});if(!arguments.length)return this.attr("class","");if("string"==typeof a&&a){b=a.match(G)||[];while(c=this[i++])if(e=Cb(c),d=1===c.nodeType&&(" "+e+" ").replace(Bb," ")){g=0;while(f=b[g++])while(d.indexOf(" "+f+" ")>-1)d=d.replace(" "+f+" "," ");h=n.trim(d),e!==h&&n.attr(c,"class",h)}}return this},toggleClass:function(a,b){var c=typeof a;return"boolean"==typeof b&&"string"===c?b?this.addClass(a):this.removeClass(a):n.isFunction(a)?this.each(function(c){n(this).toggleClass(a.call(this,c,Cb(this),b),b)}):this.each(function(){var b,d,e,f;if("string"===c){d=0,e=n(this),f=a.match(G)||[];while(b=f[d++])e.hasClass(b)?e.removeClass(b):e.addClass(b)}else void 0!==a&&"boolean"!==c||(b=Cb(this),b&&n._data(this,"__className__",b),n.attr(this,"class",b||a===!1?"":n._data(this,"__className__")||""))})},hasClass:function(a){var b,c,d=0;b=" "+a+" ";while(c=this[d++])if(1===c.nodeType&&(" "+Cb(c)+" ").replace(Bb," ").indexOf(b)>-1)return!0;return!1}}),n.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu".split(" "),function(a,b){n.fn[b]=function(a,c){return arguments.length>0?this.on(b,null,a,c):this.trigger(b)}}),n.fn.extend({hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var Db=a.location,Eb=n.now(),Fb=/\?/,Gb=/(,)|(\[|{)|(}|])|"(?:[^"\\\r\n]|\\["\\\/bfnrt]|\\u[\da-fA-F]{4})*"\s*:?|true|false|null|-?(?!0\d)\d+(?:\.\d+|)(?:[eE][+-]?\d+|)/g;n.parseJSON=function(b){if(a.JSON&&a.JSON.parse)return a.JSON.parse(b+"");var c,d=null,e=n.trim(b+"");return e&&!n.trim(e.replace(Gb,function(a,b,e,f){return c&&b&&(d=0),0===d?a:(c=e||b,d+=!f-!e,"")}))?Function("return "+e)():n.error("Invalid JSON: "+b)},n.parseXML=function(b){var c,d;if(!b||"string"!=typeof b)return null;try{a.DOMParser?(d=new a.DOMParser,c=d.parseFromString(b,"text/xml")):(c=new a.ActiveXObject("Microsoft.XMLDOM"),c.async="false",c.loadXML(b))}catch(e){c=void 0}return c&&c.documentElement&&!c.getElementsByTagName("parsererror").length||n.error("Invalid XML: "+b),c};var Hb=/#.*$/,Ib=/([?&])_=[^&]*/,Jb=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,Kb=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,Lb=/^(?:GET|HEAD)$/,Mb=/^\/\//,Nb=/^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/,Ob={},Pb={},Qb="*/".concat("*"),Rb=Db.href,Sb=Nb.exec(Rb.toLowerCase())||[];function Tb(a){return function(b,c){"string"!=typeof b&&(c=b,b="*");var d,e=0,f=b.toLowerCase().match(G)||[];if(n.isFunction(c))while(d=f[e++])"+"===d.charAt(0)?(d=d.slice(1)||"*",(a[d]=a[d]||[]).unshift(c)):(a[d]=a[d]||[]).push(c)}}function Ub(a,b,c,d){var e={},f=a===Pb;function g(h){var i;return e[h]=!0,n.each(a[h]||[],function(a,h){var j=h(b,c,d);return"string"!=typeof j||f||e[j]?f?!(i=j):void 0:(b.dataTypes.unshift(j),g(j),!1)}),i}return g(b.dataTypes[0])||!e["*"]&&g("*")}function Vb(a,b){var c,d,e=n.ajaxSettings.flatOptions||{};for(d in b)void 0!==b[d]&&((e[d]?a:c||(c={}))[d]=b[d]);return c&&n.extend(!0,a,c),a}function Wb(a,b,c){var d,e,f,g,h=a.contents,i=a.dataTypes;while("*"===i[0])i.shift(),void 0===e&&(e=a.mimeType||b.getResponseHeader("Content-Type"));if(e)for(g in h)if(h[g]&&h[g].test(e)){i.unshift(g);break}if(i[0]in c)f=i[0];else{for(g in c){if(!i[0]||a.converters[g+" "+i[0]]){f=g;break}d||(d=g)}f=f||d}return f?(f!==i[0]&&i.unshift(f),c[f]):void 0}function Xb(a,b,c,d){var e,f,g,h,i,j={},k=a.dataTypes.slice();if(k[1])for(g in a.converters)j[g.toLowerCase()]=a.converters[g];f=k.shift();while(f)if(a.responseFields[f]&&(c[a.responseFields[f]]=b),!i&&d&&a.dataFilter&&(b=a.dataFilter(b,a.dataType)),i=f,f=k.shift())if("*"===f)f=i;else if("*"!==i&&i!==f){if(g=j[i+" "+f]||j["* "+f],!g)for(e in j)if(h=e.split(" "),h[1]===f&&(g=j[i+" "+h[0]]||j["* "+h[0]])){g===!0?g=j[e]:j[e]!==!0&&(f=h[0],k.unshift(h[1]));break}if(g!==!0)if(g&&a["throws"])b=g(b);else try{b=g(b)}catch(l){return{state:"parsererror",error:g?l:"No conversion from "+i+" to "+f}}}return{state:"success",data:b}}n.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:Rb,type:"GET",isLocal:Kb.test(Sb[1]),global:!0,processData:!0,async:!0,contentType:"application/x-www-form-urlencoded; charset=UTF-8",accepts:{"*":Qb,text:"text/plain",html:"text/html",xml:"application/xml, text/xml",json:"application/json, text/javascript"},contents:{xml:/\bxml\b/,html:/\bhtml/,json:/\bjson\b/},responseFields:{xml:"responseXML",text:"responseText",json:"responseJSON"},converters:{"* text":String,"text html":!0,"text json":n.parseJSON,"text xml":n.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(a,b){return b?Vb(Vb(a,n.ajaxSettings),b):Vb(n.ajaxSettings,a)},ajaxPrefilter:Tb(Ob),ajaxTransport:Tb(Pb),ajax:function(b,c){"object"==typeof b&&(c=b,b=void 0),c=c||{};var d,e,f,g,h,i,j,k,l=n.ajaxSetup({},c),m=l.context||l,o=l.context&&(m.nodeType||m.jquery)?n(m):n.event,p=n.Deferred(),q=n.Callbacks("once memory"),r=l.statusCode||{},s={},t={},u=0,v="canceled",w={readyState:0,getResponseHeader:function(a){var b;if(2===u){if(!k){k={};while(b=Jb.exec(g))k[b[1].toLowerCase()]=b[2]}b=k[a.toLowerCase()]}return null==b?null:b},getAllResponseHeaders:function(){return 2===u?g:null},setRequestHeader:function(a,b){var c=a.toLowerCase();return u||(a=t[c]=t[c]||a,s[a]=b),this},overrideMimeType:function(a){return u||(l.mimeType=a),this},statusCode:function(a){var b;if(a)if(2>u)for(b in a)r[b]=[r[b],a[b]];else w.always(a[w.status]);return this},abort:function(a){var b=a||v;return j&&j.abort(b),y(0,b),this}};if(p.promise(w).complete=q.add,w.success=w.done,w.error=w.fail,l.url=((b||l.url||Rb)+"").replace(Hb,"").replace(Mb,Sb[1]+"//"),l.type=c.method||c.type||l.method||l.type,l.dataTypes=n.trim(l.dataType||"*").toLowerCase().match(G)||[""],null==l.crossDomain&&(d=Nb.exec(l.url.toLowerCase()),l.crossDomain=!(!d||d[1]===Sb[1]&&d[2]===Sb[2]&&(d[3]||("http:"===d[1]?"80":"443"))===(Sb[3]||("http:"===Sb[1]?"80":"443")))),l.data&&l.processData&&"string"!=typeof l.data&&(l.data=n.param(l.data,l.traditional)),Ub(Ob,l,c,w),2===u)return w;i=n.event&&l.global,i&&0===n.active++&&n.event.trigger("ajaxStart"),l.type=l.type.toUpperCase(),l.hasContent=!Lb.test(l.type),f=l.url,l.hasContent||(l.data&&(f=l.url+=(Fb.test(f)?"&":"?")+l.data,delete l.data),l.cache===!1&&(l.url=Ib.test(f)?f.replace(Ib,"$1_="+Eb++):f+(Fb.test(f)?"&":"?")+"_="+Eb++)),l.ifModified&&(n.lastModified[f]&&w.setRequestHeader("If-Modified-Since",n.lastModified[f]),n.etag[f]&&w.setRequestHeader("If-None-Match",n.etag[f])),(l.data&&l.hasContent&&l.contentType!==!1||c.contentType)&&w.setRequestHeader("Content-Type",l.contentType),w.setRequestHeader("Accept",l.dataTypes[0]&&l.accepts[l.dataTypes[0]]?l.accepts[l.dataTypes[0]]+("*"!==l.dataTypes[0]?", "+Qb+"; q=0.01":""):l.accepts["*"]);for(e in l.headers)w.setRequestHeader(e,l.headers[e]);if(l.beforeSend&&(l.beforeSend.call(m,w,l)===!1||2===u))return w.abort();v="abort";for(e in{success:1,error:1,complete:1})w[e](l[e]);if(j=Ub(Pb,l,c,w)){if(w.readyState=1,i&&o.trigger("ajaxSend",[w,l]),2===u)return w;l.async&&l.timeout>0&&(h=a.setTimeout(function(){w.abort("timeout")},l.timeout));try{u=1,j.send(s,y)}catch(x){if(!(2>u))throw x;y(-1,x)}}else y(-1,"No Transport");function y(b,c,d,e){var k,s,t,v,x,y=c;2!==u&&(u=2,h&&a.clearTimeout(h),j=void 0,g=e||"",w.readyState=b>0?4:0,k=b>=200&&300>b||304===b,d&&(v=Wb(l,w,d)),v=Xb(l,v,w,k),k?(l.ifModified&&(x=w.getResponseHeader("Last-Modified"),x&&(n.lastModified[f]=x),x=w.getResponseHeader("etag"),x&&(n.etag[f]=x)),204===b||"HEAD"===l.type?y="nocontent":304===b?y="notmodified":(y=v.state,s=v.data,t=v.error,k=!t)):(t=y,!b&&y||(y="error",0>b&&(b=0))),w.status=b,w.statusText=(c||y)+"",k?p.resolveWith(m,[s,y,w]):p.rejectWith(m,[w,y,t]),w.statusCode(r),r=void 0,i&&o.trigger(k?"ajaxSuccess":"ajaxError",[w,l,k?s:t]),q.fireWith(m,[w,y]),i&&(o.trigger("ajaxComplete",[w,l]),--n.active||n.event.trigger("ajaxStop")))}return w},getJSON:function(a,b,c){return n.get(a,b,c,"json")},getScript:function(a,b){return n.get(a,void 0,b,"script")}}),n.each(["get","post"],function(a,b){n[b]=function(a,c,d,e){return n.isFunction(c)&&(e=e||d,d=c,c=void 0),n.ajax(n.extend({url:a,type:b,dataType:e,data:c,success:d},n.isPlainObject(a)&&a))}}),n._evalUrl=function(a){return n.ajax({url:a,type:"GET",dataType:"script",cache:!0,async:!1,global:!1,"throws":!0})},n.fn.extend({wrapAll:function(a){if(n.isFunction(a))return this.each(function(b){n(this).wrapAll(a.call(this,b))});if(this[0]){var b=n(a,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&b.insertBefore(this[0]),b.map(function(){var a=this;while(a.firstChild&&1===a.firstChild.nodeType)a=a.firstChild;return a}).append(this)}return this},wrapInner:function(a){return n.isFunction(a)?this.each(function(b){n(this).wrapInner(a.call(this,b))}):this.each(function(){var b=n(this),c=b.contents();c.length?c.wrapAll(a):b.append(a)})},wrap:function(a){var b=n.isFunction(a);return this.each(function(c){n(this).wrapAll(b?a.call(this,c):a)})},unwrap:function(){return this.parent().each(function(){n.nodeName(this,"body")||n(this).replaceWith(this.childNodes)}).end()}});function Yb(a){return a.style&&a.style.display||n.css(a,"display")}function Zb(a){while(a&&1===a.nodeType){if("none"===Yb(a)||"hidden"===a.type)return!0;a=a.parentNode}return!1}n.expr.filters.hidden=function(a){return l.reliableHiddenOffsets()?a.offsetWidth<=0&&a.offsetHeight<=0&&!a.getClientRects().length:Zb(a)},n.expr.filters.visible=function(a){return!n.expr.filters.hidden(a)};var $b=/%20/g,_b=/\[\]$/,ac=/\r?\n/g,bc=/^(?:submit|button|image|reset|file)$/i,cc=/^(?:input|select|textarea|keygen)/i;function dc(a,b,c,d){var e;if(n.isArray(b))n.each(b,function(b,e){c||_b.test(a)?d(a,e):dc(a+"["+("object"==typeof e&&null!=e?b:"")+"]",e,c,d)});else if(c||"object"!==n.type(b))d(a,b);else for(e in b)dc(a+"["+e+"]",b[e],c,d)}n.param=function(a,b){var c,d=[],e=function(a,b){b=n.isFunction(b)?b():null==b?"":b,d[d.length]=encodeURIComponent(a)+"="+encodeURIComponent(b)};if(void 0===b&&(b=n.ajaxSettings&&n.ajaxSettings.traditional),n.isArray(a)||a.jquery&&!n.isPlainObject(a))n.each(a,function(){e(this.name,this.value)});else for(c in a)dc(c,a[c],b,e);return d.join("&").replace($b,"+")},n.fn.extend({serialize:function(){return n.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var a=n.prop(this,"elements");return a?n.makeArray(a):this}).filter(function(){var a=this.type;return this.name&&!n(this).is(":disabled")&&cc.test(this.nodeName)&&!bc.test(a)&&(this.checked||!Z.test(a))}).map(function(a,b){var c=n(this).val();return null==c?null:n.isArray(c)?n.map(c,function(a){return{name:b.name,value:a.replace(ac,"\r\n")}}):{name:b.name,value:c.replace(ac,"\r\n")}}).get()}}),n.ajaxSettings.xhr=void 0!==a.ActiveXObject?function(){return this.isLocal?ic():d.documentMode>8?hc():/^(get|post|head|put|delete|options)$/i.test(this.type)&&hc()||ic()}:hc;var ec=0,fc={},gc=n.ajaxSettings.xhr();a.attachEvent&&a.attachEvent("onunload",function(){for(var a in fc)fc[a](void 0,!0)}),l.cors=!!gc&&"withCredentials"in gc,gc=l.ajax=!!gc,gc&&n.ajaxTransport(function(b){if(!b.crossDomain||l.cors){var c;return{send:function(d,e){var f,g=b.xhr(),h=++ec;if(g.open(b.type,b.url,b.async,b.username,b.password),b.xhrFields)for(f in b.xhrFields)g[f]=b.xhrFields[f];b.mimeType&&g.overrideMimeType&&g.overrideMimeType(b.mimeType),b.crossDomain||d["X-Requested-With"]||(d["X-Requested-With"]="XMLHttpRequest");for(f in d)void 0!==d[f]&&g.setRequestHeader(f,d[f]+"");g.send(b.hasContent&&b.data||null),c=function(a,d){var f,i,j;if(c&&(d||4===g.readyState))if(delete fc[h],c=void 0,g.onreadystatechange=n.noop,d)4!==g.readyState&&g.abort();else{j={},f=g.status,"string"==typeof g.responseText&&(j.text=g.responseText);try{i=g.statusText}catch(k){i=""}f||!b.isLocal||b.crossDomain?1223===f&&(f=204):f=j.text?200:404}j&&e(f,i,j,g.getAllResponseHeaders())},b.async?4===g.readyState?a.setTimeout(c):g.onreadystatechange=fc[h]=c:c()},abort:function(){c&&c(void 0,!0)}}}});function hc(){try{return new a.XMLHttpRequest}catch(b){}}function ic(){try{return new a.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}}n.ajaxSetup({accepts:{script:"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"},contents:{script:/\b(?:java|ecma)script\b/},converters:{"text script":function(a){return n.globalEval(a),a}}}),n.ajaxPrefilter("script",function(a){void 0===a.cache&&(a.cache=!1),a.crossDomain&&(a.type="GET",a.global=!1)}),n.ajaxTransport("script",function(a){if(a.crossDomain){var b,c=d.head||n("head")[0]||d.documentElement;return{send:function(e,f){b=d.createElement("script"),b.async=!0,a.scriptCharset&&(b.charset=a.scriptCharset),b.src=a.url,b.onload=b.onreadystatechange=function(a,c){(c||!b.readyState||/loaded|complete/.test(b.readyState))&&(b.onload=b.onreadystatechange=null,b.parentNode&&b.parentNode.removeChild(b),b=null,c||f(200,"success"))},c.insertBefore(b,c.firstChild)},abort:function(){b&&b.onload(void 0,!0)}}}});var jc=[],kc=/(=)\?(?=&|$)|\?\?/;n.ajaxSetup({jsonp:"callback",jsonpCallback:function(){var a=jc.pop()||n.expando+"_"+Eb++;return this[a]=!0,a}}),n.ajaxPrefilter("json jsonp",function(b,c,d){var e,f,g,h=b.jsonp!==!1&&(kc.test(b.url)?"url":"string"==typeof b.data&&0===(b.contentType||"").indexOf("application/x-www-form-urlencoded")&&kc.test(b.data)&&"data");return h||"jsonp"===b.dataTypes[0]?(e=b.jsonpCallback=n.isFunction(b.jsonpCallback)?b.jsonpCallback():b.jsonpCallback,h?b[h]=b[h].replace(kc,"$1"+e):b.jsonp!==!1&&(b.url+=(Fb.test(b.url)?"&":"?")+b.jsonp+"="+e),b.converters["script json"]=function(){return g||n.error(e+" was not called"),g[0]},b.dataTypes[0]="json",f=a[e],a[e]=function(){g=arguments},d.always(function(){void 0===f?n(a).removeProp(e):a[e]=f,b[e]&&(b.jsonpCallback=c.jsonpCallback,jc.push(e)),g&&n.isFunction(f)&&f(g[0]),g=f=void 0}),"script"):void 0}),n.parseHTML=function(a,b,c){if(!a||"string"!=typeof a)return null;"boolean"==typeof b&&(c=b,b=!1),b=b||d;var e=x.exec(a),f=!c&&[];return e?[b.createElement(e[1])]:(e=ja([a],b,f),f&&f.length&&n(f).remove(),n.merge([],e.childNodes))};var lc=n.fn.load;n.fn.load=function(a,b,c){if("string"!=typeof a&&lc)return lc.apply(this,arguments);var d,e,f,g=this,h=a.indexOf(" ");return h>-1&&(d=n.trim(a.slice(h,a.length)),a=a.slice(0,h)),n.isFunction(b)?(c=b,b=void 0):b&&"object"==typeof b&&(e="POST"),g.length>0&&n.ajax({url:a,type:e||"GET",dataType:"html",data:b}).done(function(a){f=arguments,g.html(d?n("<div>").append(n.parseHTML(a)).find(d):a)}).always(c&&function(a,b){g.each(function(){c.apply(this,f||[a.responseText,b,a])})}),this},n.each(["ajaxStart","ajaxStop","ajaxComplete","ajaxError","ajaxSuccess","ajaxSend"],function(a,b){n.fn[b]=function(a){return this.on(b,a)}}),n.expr.filters.animated=function(a){return n.grep(n.timers,function(b){return a===b.elem}).length};function mc(a){return n.isWindow(a)?a:9===a.nodeType?a.defaultView||a.parentWindow:!1}n.offset={setOffset:function(a,b,c){var d,e,f,g,h,i,j,k=n.css(a,"position"),l=n(a),m={};"static"===k&&(a.style.position="relative"),h=l.offset(),f=n.css(a,"top"),i=n.css(a,"left"),j=("absolute"===k||"fixed"===k)&&n.inArray("auto",[f,i])>-1,j?(d=l.position(),g=d.top,e=d.left):(g=parseFloat(f)||0,e=parseFloat(i)||0),n.isFunction(b)&&(b=b.call(a,c,n.extend({},h))),null!=b.top&&(m.top=b.top-h.top+g),null!=b.left&&(m.left=b.left-h.left+e),"using"in b?b.using.call(a,m):l.css(m)}},n.fn.extend({offset:function(a){if(arguments.length)return void 0===a?this:this.each(function(b){n.offset.setOffset(this,a,b)});var b,c,d={top:0,left:0},e=this[0],f=e&&e.ownerDocument;if(f)return b=f.documentElement,n.contains(b,e)?("undefined"!=typeof e.getBoundingClientRect&&(d=e.getBoundingClientRect()),c=mc(f),{top:d.top+(c.pageYOffset||b.scrollTop)-(b.clientTop||0),left:d.left+(c.pageXOffset||b.scrollLeft)-(b.clientLeft||0)}):d},position:function(){if(this[0]){var a,b,c={top:0,left:0},d=this[0];return"fixed"===n.css(d,"position")?b=d.getBoundingClientRect():(a=this.offsetParent(),b=this.offset(),n.nodeName(a[0],"html")||(c=a.offset()),c.top+=n.css(a[0],"borderTopWidth",!0),c.left+=n.css(a[0],"borderLeftWidth",!0)),{top:b.top-c.top-n.css(d,"marginTop",!0),left:b.left-c.left-n.css(d,"marginLeft",!0)}}},offsetParent:function(){return this.map(function(){var a=this.offsetParent;while(a&&!n.nodeName(a,"html")&&"static"===n.css(a,"position"))a=a.offsetParent;return a||Qa})}}),n.each({scrollLeft:"pageXOffset",scrollTop:"pageYOffset"},function(a,b){var c=/Y/.test(b);n.fn[a]=function(d){return Y(this,function(a,d,e){var f=mc(a);return void 0===e?f?b in f?f[b]:f.document.documentElement[d]:a[d]:void(f?f.scrollTo(c?n(f).scrollLeft():e,c?e:n(f).scrollTop()):a[d]=e)},a,d,arguments.length,null)}}),n.each(["top","left"],function(a,b){n.cssHooks[b]=Ua(l.pixelPosition,function(a,c){return c?(c=Sa(a,b),Oa.test(c)?n(a).position()[b]+"px":c):void 0;
})}),n.each({Height:"height",Width:"width"},function(a,b){n.each({padding:"inner"+a,content:b,"":"outer"+a},function(c,d){n.fn[d]=function(d,e){var f=arguments.length&&(c||"boolean"!=typeof d),g=c||(d===!0||e===!0?"margin":"border");return Y(this,function(b,c,d){var e;return n.isWindow(b)?b.document.documentElement["client"+a]:9===b.nodeType?(e=b.documentElement,Math.max(b.body["scroll"+a],e["scroll"+a],b.body["offset"+a],e["offset"+a],e["client"+a])):void 0===d?n.css(b,c,g):n.style(b,c,d,g)},b,f?d:void 0,f,null)}})}),n.fn.extend({bind:function(a,b,c){return this.on(a,null,b,c)},unbind:function(a,b){return this.off(a,null,b)},delegate:function(a,b,c,d){return this.on(b,a,c,d)},undelegate:function(a,b,c){return 1===arguments.length?this.off(a,"**"):this.off(b,a||"**",c)}}),n.fn.size=function(){return this.length},n.fn.andSelf=n.fn.addBack,"function"==typeof define&&define.amd&&define("jquery",[],function(){return n});var nc=a.jQuery,oc=a.$;return n.noConflict=function(b){return a.$===n&&(a.$=oc),b&&a.jQuery===n&&(a.jQuery=nc),n},b||(a.jQuery=a.$=n),n});
/**
 * Owl Carousel v2.3.4
 * Copyright 2013-2018 David Deutsch
 * Licensed under: SEE LICENSE IN https://github.com/OwlCarousel2/OwlCarousel2/blob/master/LICENSE
 */
!function(a,b,c,d){function e(b,c){this.settings=null,this.options=a.extend({},e.Defaults,c),this.$element=a(b),this._handlers={},this._plugins={},this._supress={},this._current=null,this._speed=null,this._coordinates=[],this._breakpoint=null,this._width=null,this._items=[],this._clones=[],this._mergers=[],this._widths=[],this._invalidated={},this._pipe=[],this._drag={time:null,target:null,pointer:null,stage:{start:null,current:null},direction:null},this._states={current:{},tags:{initializing:["busy"],animating:["busy"],dragging:["interacting"]}},a.each(["onResize","onThrottledResize"],a.proxy(function(b,c){this._handlers[c]=a.proxy(this[c],this)},this)),a.each(e.Plugins,a.proxy(function(a,b){this._plugins[a.charAt(0).toLowerCase()+a.slice(1)]=new b(this)},this)),a.each(e.Workers,a.proxy(function(b,c){this._pipe.push({filter:c.filter,run:a.proxy(c.run,this)})},this)),this.setup(),this.initialize()}e.Defaults={items:3,loop:!1,center:!1,rewind:!1,checkVisibility:!0,mouseDrag:!0,touchDrag:!0,pullDrag:!0,freeDrag:!1,margin:0,stagePadding:0,merge:!1,mergeFit:!0,autoWidth:!1,startPosition:0,rtl:!1,smartSpeed:250,fluidSpeed:!1,dragEndSpeed:!1,responsive:{},responsiveRefreshRate:200,responsiveBaseElement:b,fallbackEasing:"swing",slideTransition:"",info:!1,nestedItemSelector:!1,itemElement:"div",stageElement:"div",refreshClass:"owl-refresh",loadedClass:"owl-loaded",loadingClass:"owl-loading",rtlClass:"owl-rtl",responsiveClass:"owl-responsive",dragClass:"owl-drag",itemClass:"owl-item",stageClass:"owl-stage",stageOuterClass:"owl-stage-outer",grabClass:"owl-grab"},e.Width={Default:"default",Inner:"inner",Outer:"outer"},e.Type={Event:"event",State:"state"},e.Plugins={},e.Workers=[{filter:["width","settings"],run:function(){this._width=this.$element.width()}},{filter:["width","items","settings"],run:function(a){a.current=this._items&&this._items[this.relative(this._current)]}},{filter:["items","settings"],run:function(){this.$stage.children(".cloned").remove()}},{filter:["width","items","settings"],run:function(a){var b=this.settings.margin||"",c=!this.settings.autoWidth,d=this.settings.rtl,e={width:"auto","margin-left":d?b:"","margin-right":d?"":b};!c&&this.$stage.children().css(e),a.css=e}},{filter:["width","items","settings"],run:function(a){var b=(this.width()/this.settings.items).toFixed(3)-this.settings.margin,c=null,d=this._items.length,e=!this.settings.autoWidth,f=[];for(a.items={merge:!1,width:b};d--;)c=this._mergers[d],c=this.settings.mergeFit&&Math.min(c,this.settings.items)||c,a.items.merge=c>1||a.items.merge,f[d]=e?b*c:this._items[d].width();this._widths=f}},{filter:["items","settings"],run:function(){var b=[],c=this._items,d=this.settings,e=Math.max(2*d.items,4),f=2*Math.ceil(c.length/2),g=d.loop&&c.length?d.rewind?e:Math.max(e,f):0,h="",i="";for(g/=2;g>0;)b.push(this.normalize(b.length/2,!0)),h+=c[b[b.length-1]][0].outerHTML,b.push(this.normalize(c.length-1-(b.length-1)/2,!0)),i=c[b[b.length-1]][0].outerHTML+i,g-=1;this._clones=b,a(h).addClass("cloned").appendTo(this.$stage),a(i).addClass("cloned").prependTo(this.$stage)}},{filter:["width","items","settings"],run:function(){for(var a=this.settings.rtl?1:-1,b=this._clones.length+this._items.length,c=-1,d=0,e=0,f=[];++c<b;)d=f[c-1]||0,e=this._widths[this.relative(c)]+this.settings.margin,f.push(d+e*a);this._coordinates=f}},{filter:["width","items","settings"],run:function(){var a=this.settings.stagePadding,b=this._coordinates,c={width:Math.ceil(Math.abs(b[b.length-1]))+2*a,"padding-left":a||"","padding-right":a||""};this.$stage.css(c)}},{filter:["width","items","settings"],run:function(a){var b=this._coordinates.length,c=!this.settings.autoWidth,d=this.$stage.children();if(c&&a.items.merge)for(;b--;)a.css.width=this._widths[this.relative(b)],d.eq(b).css(a.css);else c&&(a.css.width=a.items.width,d.css(a.css))}},{filter:["items"],run:function(){this._coordinates.length<1&&this.$stage.removeAttr("style")}},{filter:["width","items","settings"],run:function(a){a.current=a.current?this.$stage.children().index(a.current):0,a.current=Math.max(this.minimum(),Math.min(this.maximum(),a.current)),this.reset(a.current)}},{filter:["position"],run:function(){this.animate(this.coordinates(this._current))}},{filter:["width","position","items","settings"],run:function(){var a,b,c,d,e=this.settings.rtl?1:-1,f=2*this.settings.stagePadding,g=this.coordinates(this.current())+f,h=g+this.width()*e,i=[];for(c=0,d=this._coordinates.length;c<d;c++)a=this._coordinates[c-1]||0,b=Math.abs(this._coordinates[c])+f*e,(this.op(a,"<=",g)&&this.op(a,">",h)||this.op(b,"<",g)&&this.op(b,">",h))&&i.push(c);this.$stage.children(".active").removeClass("active"),this.$stage.children(":eq("+i.join("), :eq(")+")").addClass("active"),this.$stage.children(".center").removeClass("center"),this.settings.center&&this.$stage.children().eq(this.current()).addClass("center")}}],e.prototype.initializeStage=function(){this.$stage=this.$element.find("."+this.settings.stageClass),this.$stage.length||(this.$element.addClass(this.options.loadingClass),this.$stage=a("<"+this.settings.stageElement+">",{class:this.settings.stageClass}).wrap(a("<div/>",{class:this.settings.stageOuterClass})),this.$element.append(this.$stage.parent()))},e.prototype.initializeItems=function(){var b=this.$element.find(".owl-item");if(b.length)return this._items=b.get().map(function(b){return a(b)}),this._mergers=this._items.map(function(){return 1}),void this.refresh();this.replace(this.$element.children().not(this.$stage.parent())),this.isVisible()?this.refresh():this.invalidate("width"),this.$element.removeClass(this.options.loadingClass).addClass(this.options.loadedClass)},e.prototype.initialize=function(){if(this.enter("initializing"),this.trigger("initialize"),this.$element.toggleClass(this.settings.rtlClass,this.settings.rtl),this.settings.autoWidth&&!this.is("pre-loading")){var a,b,c;a=this.$element.find("img"),b=this.settings.nestedItemSelector?"."+this.settings.nestedItemSelector:d,c=this.$element.children(b).width(),a.length&&c<=0&&this.preloadAutoWidthImages(a)}this.initializeStage(),this.initializeItems(),this.registerEventHandlers(),this.leave("initializing"),this.trigger("initialized")},e.prototype.isVisible=function(){return!this.settings.checkVisibility||this.$element.is(":visible")},e.prototype.setup=function(){var b=this.viewport(),c=this.options.responsive,d=-1,e=null;c?(a.each(c,function(a){a<=b&&a>d&&(d=Number(a))}),e=a.extend({},this.options,c[d]),"function"==typeof e.stagePadding&&(e.stagePadding=e.stagePadding()),delete e.responsive,e.responsiveClass&&this.$element.attr("class",this.$element.attr("class").replace(new RegExp("("+this.options.responsiveClass+"-)\\S+\\s","g"),"$1"+d))):e=a.extend({},this.options),this.trigger("change",{property:{name:"settings",value:e}}),this._breakpoint=d,this.settings=e,this.invalidate("settings"),this.trigger("changed",{property:{name:"settings",value:this.settings}})},e.prototype.optionsLogic=function(){this.settings.autoWidth&&(this.settings.stagePadding=!1,this.settings.merge=!1)},e.prototype.prepare=function(b){var c=this.trigger("prepare",{content:b});return c.data||(c.data=a("<"+this.settings.itemElement+"/>").addClass(this.options.itemClass).append(b)),this.trigger("prepared",{content:c.data}),c.data},e.prototype.update=function(){for(var b=0,c=this._pipe.length,d=a.proxy(function(a){return this[a]},this._invalidated),e={};b<c;)(this._invalidated.all||a.grep(this._pipe[b].filter,d).length>0)&&this._pipe[b].run(e),b++;this._invalidated={},!this.is("valid")&&this.enter("valid")},e.prototype.width=function(a){switch(a=a||e.Width.Default){case e.Width.Inner:case e.Width.Outer:return this._width;default:return this._width-2*this.settings.stagePadding+this.settings.margin}},e.prototype.refresh=function(){this.enter("refreshing"),this.trigger("refresh"),this.setup(),this.optionsLogic(),this.$element.addClass(this.options.refreshClass),this.update(),this.$element.removeClass(this.options.refreshClass),this.leave("refreshing"),this.trigger("refreshed")},e.prototype.onThrottledResize=function(){b.clearTimeout(this.resizeTimer),this.resizeTimer=b.setTimeout(this._handlers.onResize,this.settings.responsiveRefreshRate)},e.prototype.onResize=function(){return!!this._items.length&&(this._width!==this.$element.width()&&(!!this.isVisible()&&(this.enter("resizing"),this.trigger("resize").isDefaultPrevented()?(this.leave("resizing"),!1):(this.invalidate("width"),this.refresh(),this.leave("resizing"),void this.trigger("resized")))))},e.prototype.registerEventHandlers=function(){a.support.transition&&this.$stage.on(a.support.transition.end+".owl.core",a.proxy(this.onTransitionEnd,this)),!1!==this.settings.responsive&&this.on(b,"resize",this._handlers.onThrottledResize),this.settings.mouseDrag&&(this.$element.addClass(this.options.dragClass),this.$stage.on("mousedown.owl.core",a.proxy(this.onDragStart,this)),this.$stage.on("dragstart.owl.core selectstart.owl.core",function(){return!1})),this.settings.touchDrag&&(this.$stage.on("touchstart.owl.core",a.proxy(this.onDragStart,this)),this.$stage.on("touchcancel.owl.core",a.proxy(this.onDragEnd,this)))},e.prototype.onDragStart=function(b){var d=null;3!==b.which&&(a.support.transform?(d=this.$stage.css("transform").replace(/.*\(|\)| /g,"").split(","),d={x:d[16===d.length?12:4],y:d[16===d.length?13:5]}):(d=this.$stage.position(),d={x:this.settings.rtl?d.left+this.$stage.width()-this.width()+this.settings.margin:d.left,y:d.top}),this.is("animating")&&(a.support.transform?this.animate(d.x):this.$stage.stop(),this.invalidate("position")),this.$element.toggleClass(this.options.grabClass,"mousedown"===b.type),this.speed(0),this._drag.time=(new Date).getTime(),this._drag.target=a(b.target),this._drag.stage.start=d,this._drag.stage.current=d,this._drag.pointer=this.pointer(b),a(c).on("mouseup.owl.core touchend.owl.core",a.proxy(this.onDragEnd,this)),a(c).one("mousemove.owl.core touchmove.owl.core",a.proxy(function(b){var d=this.difference(this._drag.pointer,this.pointer(b));a(c).on("mousemove.owl.core touchmove.owl.core",a.proxy(this.onDragMove,this)),Math.abs(d.x)<Math.abs(d.y)&&this.is("valid")||(b.preventDefault(),this.enter("dragging"),this.trigger("drag"))},this)))},e.prototype.onDragMove=function(a){var b=null,c=null,d=null,e=this.difference(this._drag.pointer,this.pointer(a)),f=this.difference(this._drag.stage.start,e);this.is("dragging")&&(a.preventDefault(),this.settings.loop?(b=this.coordinates(this.minimum()),c=this.coordinates(this.maximum()+1)-b,f.x=((f.x-b)%c+c)%c+b):(b=this.settings.rtl?this.coordinates(this.maximum()):this.coordinates(this.minimum()),c=this.settings.rtl?this.coordinates(this.minimum()):this.coordinates(this.maximum()),d=this.settings.pullDrag?-1*e.x/5:0,f.x=Math.max(Math.min(f.x,b+d),c+d)),this._drag.stage.current=f,this.animate(f.x))},e.prototype.onDragEnd=function(b){var d=this.difference(this._drag.pointer,this.pointer(b)),e=this._drag.stage.current,f=d.x>0^this.settings.rtl?"left":"right";a(c).off(".owl.core"),this.$element.removeClass(this.options.grabClass),(0!==d.x&&this.is("dragging")||!this.is("valid"))&&(this.speed(this.settings.dragEndSpeed||this.settings.smartSpeed),this.current(this.closest(e.x,0!==d.x?f:this._drag.direction)),this.invalidate("position"),this.update(),this._drag.direction=f,(Math.abs(d.x)>3||(new Date).getTime()-this._drag.time>300)&&this._drag.target.one("click.owl.core",function(){return!1})),this.is("dragging")&&(this.leave("dragging"),this.trigger("dragged"))},e.prototype.closest=function(b,c){var e=-1,f=30,g=this.width(),h=this.coordinates();return this.settings.freeDrag||a.each(h,a.proxy(function(a,i){return"left"===c&&b>i-f&&b<i+f?e=a:"right"===c&&b>i-g-f&&b<i-g+f?e=a+1:this.op(b,"<",i)&&this.op(b,">",h[a+1]!==d?h[a+1]:i-g)&&(e="left"===c?a+1:a),-1===e},this)),this.settings.loop||(this.op(b,">",h[this.minimum()])?e=b=this.minimum():this.op(b,"<",h[this.maximum()])&&(e=b=this.maximum())),e},e.prototype.animate=function(b){var c=this.speed()>0;this.is("animating")&&this.onTransitionEnd(),c&&(this.enter("animating"),this.trigger("translate")),a.support.transform3d&&a.support.transition?this.$stage.css({transform:"translate3d("+b+"px,0px,0px)",transition:this.speed()/1e3+"s"+(this.settings.slideTransition?" "+this.settings.slideTransition:"")}):c?this.$stage.animate({left:b+"px"},this.speed(),this.settings.fallbackEasing,a.proxy(this.onTransitionEnd,this)):this.$stage.css({left:b+"px"})},e.prototype.is=function(a){return this._states.current[a]&&this._states.current[a]>0},e.prototype.current=function(a){if(a===d)return this._current;if(0===this._items.length)return d;if(a=this.normalize(a),this._current!==a){var b=this.trigger("change",{property:{name:"position",value:a}});b.data!==d&&(a=this.normalize(b.data)),this._current=a,this.invalidate("position"),this.trigger("changed",{property:{name:"position",value:this._current}})}return this._current},e.prototype.invalidate=function(b){return"string"===a.type(b)&&(this._invalidated[b]=!0,this.is("valid")&&this.leave("valid")),a.map(this._invalidated,function(a,b){return b})},e.prototype.reset=function(a){(a=this.normalize(a))!==d&&(this._speed=0,this._current=a,this.suppress(["translate","translated"]),this.animate(this.coordinates(a)),this.release(["translate","translated"]))},e.prototype.normalize=function(a,b){var c=this._items.length,e=b?0:this._clones.length;return!this.isNumeric(a)||c<1?a=d:(a<0||a>=c+e)&&(a=((a-e/2)%c+c)%c+e/2),a},e.prototype.relative=function(a){return a-=this._clones.length/2,this.normalize(a,!0)},e.prototype.maximum=function(a){var b,c,d,e=this.settings,f=this._coordinates.length;if(e.loop)f=this._clones.length/2+this._items.length-1;else if(e.autoWidth||e.merge){if(b=this._items.length)for(c=this._items[--b].width(),d=this.$element.width();b--&&!((c+=this._items[b].width()+this.settings.margin)>d););f=b+1}else f=e.center?this._items.length-1:this._items.length-e.items;return a&&(f-=this._clones.length/2),Math.max(f,0)},e.prototype.minimum=function(a){return a?0:this._clones.length/2},e.prototype.items=function(a){return a===d?this._items.slice():(a=this.normalize(a,!0),this._items[a])},e.prototype.mergers=function(a){return a===d?this._mergers.slice():(a=this.normalize(a,!0),this._mergers[a])},e.prototype.clones=function(b){var c=this._clones.length/2,e=c+this._items.length,f=function(a){return a%2==0?e+a/2:c-(a+1)/2};return b===d?a.map(this._clones,function(a,b){return f(b)}):a.map(this._clones,function(a,c){return a===b?f(c):null})},e.prototype.speed=function(a){return a!==d&&(this._speed=a),this._speed},e.prototype.coordinates=function(b){var c,e=1,f=b-1;return b===d?a.map(this._coordinates,a.proxy(function(a,b){return this.coordinates(b)},this)):(this.settings.center?(this.settings.rtl&&(e=-1,f=b+1),c=this._coordinates[b],c+=(this.width()-c+(this._coordinates[f]||0))/2*e):c=this._coordinates[f]||0,c=Math.ceil(c))},e.prototype.duration=function(a,b,c){return 0===c?0:Math.min(Math.max(Math.abs(b-a),1),6)*Math.abs(c||this.settings.smartSpeed)},e.prototype.to=function(a,b){var c=this.current(),d=null,e=a-this.relative(c),f=(e>0)-(e<0),g=this._items.length,h=this.minimum(),i=this.maximum();this.settings.loop?(!this.settings.rewind&&Math.abs(e)>g/2&&(e+=-1*f*g),a=c+e,(d=((a-h)%g+g)%g+h)!==a&&d-e<=i&&d-e>0&&(c=d-e,a=d,this.reset(c))):this.settings.rewind?(i+=1,a=(a%i+i)%i):a=Math.max(h,Math.min(i,a)),this.speed(this.duration(c,a,b)),this.current(a),this.isVisible()&&this.update()},e.prototype.next=function(a){a=a||!1,this.to(this.relative(this.current())+1,a)},e.prototype.prev=function(a){a=a||!1,this.to(this.relative(this.current())-1,a)},e.prototype.onTransitionEnd=function(a){if(a!==d&&(a.stopPropagation(),(a.target||a.srcElement||a.originalTarget)!==this.$stage.get(0)))return!1;this.leave("animating"),this.trigger("translated")},e.prototype.viewport=function(){var d;return this.options.responsiveBaseElement!==b?d=a(this.options.responsiveBaseElement).width():b.innerWidth?d=b.innerWidth:c.documentElement&&c.documentElement.clientWidth?d=c.documentElement.clientWidth:console.warn("Can not detect viewport width."),d},e.prototype.replace=function(b){this.$stage.empty(),this._items=[],b&&(b=b instanceof jQuery?b:a(b)),this.settings.nestedItemSelector&&(b=b.find("."+this.settings.nestedItemSelector)),b.filter(function(){return 1===this.nodeType}).each(a.proxy(function(a,b){b=this.prepare(b),this.$stage.append(b),this._items.push(b),this._mergers.push(1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)},this)),this.reset(this.isNumeric(this.settings.startPosition)?this.settings.startPosition:0),this.invalidate("items")},e.prototype.add=function(b,c){var e=this.relative(this._current);c=c===d?this._items.length:this.normalize(c,!0),b=b instanceof jQuery?b:a(b),this.trigger("add",{content:b,position:c}),b=this.prepare(b),0===this._items.length||c===this._items.length?(0===this._items.length&&this.$stage.append(b),0!==this._items.length&&this._items[c-1].after(b),this._items.push(b),this._mergers.push(1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)):(this._items[c].before(b),this._items.splice(c,0,b),this._mergers.splice(c,0,1*b.find("[data-merge]").addBack("[data-merge]").attr("data-merge")||1)),this._items[e]&&this.reset(this._items[e].index()),this.invalidate("items"),this.trigger("added",{content:b,position:c})},e.prototype.remove=function(a){(a=this.normalize(a,!0))!==d&&(this.trigger("remove",{content:this._items[a],position:a}),this._items[a].remove(),this._items.splice(a,1),this._mergers.splice(a,1),this.invalidate("items"),this.trigger("removed",{content:null,position:a}))},e.prototype.preloadAutoWidthImages=function(b){b.each(a.proxy(function(b,c){this.enter("pre-loading"),c=a(c),a(new Image).one("load",a.proxy(function(a){c.attr("src",a.target.src),c.css("opacity",1),this.leave("pre-loading"),!this.is("pre-loading")&&!this.is("initializing")&&this.refresh()},this)).attr("src",c.attr("src")||c.attr("data-src")||c.attr("data-src-retina"))},this))},e.prototype.destroy=function(){this.$element.off(".owl.core"),this.$stage.off(".owl.core"),a(c).off(".owl.core"),!1!==this.settings.responsive&&(b.clearTimeout(this.resizeTimer),this.off(b,"resize",this._handlers.onThrottledResize));for(var d in this._plugins)this._plugins[d].destroy();this.$stage.children(".cloned").remove(),this.$stage.unwrap(),this.$stage.children().contents().unwrap(),this.$stage.children().unwrap(),this.$stage.remove(),this.$element.removeClass(this.options.refreshClass).removeClass(this.options.loadingClass).removeClass(this.options.loadedClass).removeClass(this.options.rtlClass).removeClass(this.options.dragClass).removeClass(this.options.grabClass).attr("class",this.$element.attr("class").replace(new RegExp(this.options.responsiveClass+"-\\S+\\s","g"),"")).removeData("owl.carousel")},e.prototype.op=function(a,b,c){var d=this.settings.rtl;switch(b){case"<":return d?a>c:a<c;case">":return d?a<c:a>c;case">=":return d?a<=c:a>=c;case"<=":return d?a>=c:a<=c}},e.prototype.on=function(a,b,c,d){a.addEventListener?a.addEventListener(b,c,d):a.attachEvent&&a.attachEvent("on"+b,c)},e.prototype.off=function(a,b,c,d){a.removeEventListener?a.removeEventListener(b,c,d):a.detachEvent&&a.detachEvent("on"+b,c)},e.prototype.trigger=function(b,c,d,f,g){var h={item:{count:this._items.length,index:this.current()}},i=a.camelCase(a.grep(["on",b,d],function(a){return a}).join("-").toLowerCase()),j=a.Event([b,"owl",d||"carousel"].join(".").toLowerCase(),a.extend({relatedTarget:this},h,c));return this._supress[b]||(a.each(this._plugins,function(a,b){b.onTrigger&&b.onTrigger(j)}),this.register({type:e.Type.Event,name:b}),this.$element.trigger(j),this.settings&&"function"==typeof this.settings[i]&&this.settings[i].call(this,j)),j},e.prototype.enter=function(b){a.each([b].concat(this._states.tags[b]||[]),a.proxy(function(a,b){this._states.current[b]===d&&(this._states.current[b]=0),this._states.current[b]++},this))},e.prototype.leave=function(b){a.each([b].concat(this._states.tags[b]||[]),a.proxy(function(a,b){this._states.current[b]--},this))},e.prototype.register=function(b){if(b.type===e.Type.Event){if(a.event.special[b.name]||(a.event.special[b.name]={}),!a.event.special[b.name].owl){var c=a.event.special[b.name]._default;a.event.special[b.name]._default=function(a){return!c||!c.apply||a.namespace&&-1!==a.namespace.indexOf("owl")?a.namespace&&a.namespace.indexOf("owl")>-1:c.apply(this,arguments)},a.event.special[b.name].owl=!0}}else b.type===e.Type.State&&(this._states.tags[b.name]?this._states.tags[b.name]=this._states.tags[b.name].concat(b.tags):this._states.tags[b.name]=b.tags,this._states.tags[b.name]=a.grep(this._states.tags[b.name],a.proxy(function(c,d){return a.inArray(c,this._states.tags[b.name])===d},this)))},e.prototype.suppress=function(b){a.each(b,a.proxy(function(a,b){this._supress[b]=!0},this))},e.prototype.release=function(b){a.each(b,a.proxy(function(a,b){delete this._supress[b]},this))},e.prototype.pointer=function(a){var c={x:null,y:null};return a=a.originalEvent||a||b.event,a=a.touches&&a.touches.length?a.touches[0]:a.changedTouches&&a.changedTouches.length?a.changedTouches[0]:a,a.pageX?(c.x=a.pageX,c.y=a.pageY):(c.x=a.clientX,c.y=a.clientY),c},e.prototype.isNumeric=function(a){return!isNaN(parseFloat(a))},e.prototype.difference=function(a,b){return{x:a.x-b.x,y:a.y-b.y}},a.fn.owlCarousel=function(b){var c=Array.prototype.slice.call(arguments,1);return this.each(function(){var d=a(this),f=d.data("owl.carousel");f||(f=new e(this,"object"==typeof b&&b),d.data("owl.carousel",f),a.each(["next","prev","to","destroy","refresh","replace","add","remove"],function(b,c){f.register({type:e.Type.Event,name:c}),f.$element.on(c+".owl.carousel.core",a.proxy(function(a){a.namespace&&a.relatedTarget!==this&&(this.suppress([c]),f[c].apply(this,[].slice.call(arguments,1)),this.release([c]))},f))})),"string"==typeof b&&"_"!==b.charAt(0)&&f[b].apply(f,c)})},a.fn.owlCarousel.Constructor=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._interval=null,this._visible=null,this._handlers={"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoRefresh&&this.watch()},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers)};e.Defaults={autoRefresh:!0,autoRefreshInterval:500},e.prototype.watch=function(){this._interval||(this._visible=this._core.isVisible(),this._interval=b.setInterval(a.proxy(this.refresh,this),this._core.settings.autoRefreshInterval))},e.prototype.refresh=function(){this._core.isVisible()!==this._visible&&(this._visible=!this._visible,this._core.$element.toggleClass("owl-hidden",!this._visible),this._visible&&this._core.invalidate("width")&&this._core.refresh())},e.prototype.destroy=function(){var a,c;b.clearInterval(this._interval);for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(c in Object.getOwnPropertyNames(this))"function"!=typeof this[c]&&(this[c]=null)},a.fn.owlCarousel.Constructor.Plugins.AutoRefresh=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._loaded=[],this._handlers={"initialized.owl.carousel change.owl.carousel resized.owl.carousel":a.proxy(function(b){if(b.namespace&&this._core.settings&&this._core.settings.lazyLoad&&(b.property&&"position"==b.property.name||"initialized"==b.type)){var c=this._core.settings,e=c.center&&Math.ceil(c.items/2)||c.items,f=c.center&&-1*e||0,g=(b.property&&b.property.value!==d?b.property.value:this._core.current())+f,h=this._core.clones().length,i=a.proxy(function(a,b){this.load(b)},this);for(c.lazyLoadEager>0&&(e+=c.lazyLoadEager,c.loop&&(g-=c.lazyLoadEager,e++));f++<e;)this.load(h/2+this._core.relative(g)),h&&a.each(this._core.clones(this._core.relative(g)),i),g++}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers)};e.Defaults={lazyLoad:!1,lazyLoadEager:0},e.prototype.load=function(c){var d=this._core.$stage.children().eq(c),e=d&&d.find(".owl-lazy");!e||a.inArray(d.get(0),this._loaded)>-1||(e.each(a.proxy(function(c,d){var e,f=a(d),g=b.devicePixelRatio>1&&f.attr("data-src-retina")||f.attr("data-src")||f.attr("data-srcset");this._core.trigger("load",{element:f,url:g},"lazy"),f.is("img")?f.one("load.owl.lazy",a.proxy(function(){f.css("opacity",1),this._core.trigger("loaded",{element:f,url:g},"lazy")},this)).attr("src",g):f.is("source")?f.one("load.owl.lazy",a.proxy(function(){this._core.trigger("loaded",{element:f,url:g},"lazy")},this)).attr("srcset",g):(e=new Image,e.onload=a.proxy(function(){f.css({"background-image":'url("'+g+'")',opacity:"1"}),this._core.trigger("loaded",{element:f,url:g},"lazy")},this),e.src=g)},this)),this._loaded.push(d.get(0)))},e.prototype.destroy=function(){var a,b;for(a in this.handlers)this._core.$element.off(a,this.handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Lazy=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(c){this._core=c,this._previousHeight=null,this._handlers={"initialized.owl.carousel refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&this.update()},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&"position"===a.property.name&&this.update()},this),"loaded.owl.lazy":a.proxy(function(a){a.namespace&&this._core.settings.autoHeight&&a.element.closest("."+this._core.settings.itemClass).index()===this._core.current()&&this.update()},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers),this._intervalId=null;var d=this;a(b).on("load",function(){d._core.settings.autoHeight&&d.update()}),a(b).resize(function(){d._core.settings.autoHeight&&(null!=d._intervalId&&clearTimeout(d._intervalId),d._intervalId=setTimeout(function(){d.update()},250))})};e.Defaults={autoHeight:!1,autoHeightClass:"owl-height"},e.prototype.update=function(){var b=this._core._current,c=b+this._core.settings.items,d=this._core.settings.lazyLoad,e=this._core.$stage.children().toArray().slice(b,c),f=[],g=0;a.each(e,function(b,c){f.push(a(c).height())}),g=Math.max.apply(null,f),g<=1&&d&&this._previousHeight&&(g=this._previousHeight),this._previousHeight=g,this._core.$stage.parent().height(g).addClass(this._core.settings.autoHeightClass)},e.prototype.destroy=function(){var a,b;for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.AutoHeight=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._videos={},this._playing=null,this._handlers={"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.register({type:"state",name:"playing",tags:["interacting"]})},this),"resize.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.video&&this.isInFullScreen()&&a.preventDefault()},this),"refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._core.is("resizing")&&this._core.$stage.find(".cloned .owl-video-frame").remove()},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&"position"===a.property.name&&this._playing&&this.stop()},this),"prepared.owl.carousel":a.proxy(function(b){if(b.namespace){var c=a(b.content).find(".owl-video");c.length&&(c.css("display","none"),this.fetch(c,a(b.content)))}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this._core.$element.on(this._handlers),this._core.$element.on("click.owl.video",".owl-video-play-icon",a.proxy(function(a){this.play(a)},this))};e.Defaults={video:!1,videoHeight:!1,videoWidth:!1},e.prototype.fetch=function(a,b){var c=function(){return a.attr("data-vimeo-id")?"vimeo":a.attr("data-vzaar-id")?"vzaar":"youtube"}(),d=a.attr("data-vimeo-id")||a.attr("data-youtube-id")||a.attr("data-vzaar-id"),e=a.attr("data-width")||this._core.settings.videoWidth,f=a.attr("data-height")||this._core.settings.videoHeight,g=a.attr("href");if(!g)throw new Error("Missing video URL.");if(d=g.match(/(http:|https:|)\/\/(player.|www.|app.)?(vimeo\.com|youtu(be\.com|\.be|be\.googleapis\.com|be\-nocookie\.com)|vzaar\.com)\/(video\/|videos\/|embed\/|channels\/.+\/|groups\/.+\/|watch\?v=|v\/)?([A-Za-z0-9._%-]*)(\&\S+)?/),d[3].indexOf("youtu")>-1)c="youtube";else if(d[3].indexOf("vimeo")>-1)c="vimeo";else{if(!(d[3].indexOf("vzaar")>-1))throw new Error("Video URL not supported.");c="vzaar"}d=d[6],this._videos[g]={type:c,id:d,width:e,height:f},b.attr("data-video",g),this.thumbnail(a,this._videos[g])},e.prototype.thumbnail=function(b,c){var d,e,f,g=c.width&&c.height?"width:"+c.width+"px;height:"+c.height+"px;":"",h=b.find("img"),i="src",j="",k=this._core.settings,l=function(c){e='<div class="owl-video-play-icon"></div>',d=k.lazyLoad?a("<div/>",{class:"owl-video-tn "+j,srcType:c}):a("<div/>",{class:"owl-video-tn",style:"opacity:1;background-image:url("+c+")"}),b.after(d),b.after(e)};if(b.wrap(a("<div/>",{class:"owl-video-wrapper",style:g})),this._core.settings.lazyLoad&&(i="data-src",j="owl-lazy"),h.length)return l(h.attr(i)),h.remove(),!1;"youtube"===c.type?(f="//img.youtube.com/vi/"+c.id+"/hqdefault.jpg",l(f)):"vimeo"===c.type?a.ajax({type:"GET",url:"//vimeo.com/api/v2/video/"+c.id+".json",jsonp:"callback",dataType:"jsonp",success:function(a){f=a[0].thumbnail_large,l(f)}}):"vzaar"===c.type&&a.ajax({type:"GET",url:"//vzaar.com/api/videos/"+c.id+".json",jsonp:"callback",dataType:"jsonp",success:function(a){f=a.framegrab_url,l(f)}})},e.prototype.stop=function(){this._core.trigger("stop",null,"video"),this._playing.find(".owl-video-frame").remove(),this._playing.removeClass("owl-video-playing"),this._playing=null,this._core.leave("playing"),this._core.trigger("stopped",null,"video")},e.prototype.play=function(b){var c,d=a(b.target),e=d.closest("."+this._core.settings.itemClass),f=this._videos[e.attr("data-video")],g=f.width||"100%",h=f.height||this._core.$stage.height();this._playing||(this._core.enter("playing"),this._core.trigger("play",null,"video"),e=this._core.items(this._core.relative(e.index())),this._core.reset(e.index()),c=a('<iframe frameborder="0" allowfullscreen mozallowfullscreen webkitAllowFullScreen ></iframe>'),c.attr("height",h),c.attr("width",g),"youtube"===f.type?c.attr("src","//www.youtube.com/embed/"+f.id+"?autoplay=1&rel=0&v="+f.id):"vimeo"===f.type?c.attr("src","//player.vimeo.com/video/"+f.id+"?autoplay=1"):"vzaar"===f.type&&c.attr("src","//view.vzaar.com/"+f.id+"/player?autoplay=true"),a(c).wrap('<div class="owl-video-frame" />').insertAfter(e.find(".owl-video")),this._playing=e.addClass("owl-video-playing"))},e.prototype.isInFullScreen=function(){var b=c.fullscreenElement||c.mozFullScreenElement||c.webkitFullscreenElement;return b&&a(b).parent().hasClass("owl-video-frame")},e.prototype.destroy=function(){var a,b;this._core.$element.off("click.owl.video");for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Video=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this.core=b,this.core.options=a.extend({},e.Defaults,this.core.options),this.swapping=!0,this.previous=d,this.next=d,this.handlers={"change.owl.carousel":a.proxy(function(a){a.namespace&&"position"==a.property.name&&(this.previous=this.core.current(),this.next=a.property.value)},this),"drag.owl.carousel dragged.owl.carousel translated.owl.carousel":a.proxy(function(a){a.namespace&&(this.swapping="translated"==a.type)},this),"translate.owl.carousel":a.proxy(function(a){a.namespace&&this.swapping&&(this.core.options.animateOut||this.core.options.animateIn)&&this.swap()},this)},this.core.$element.on(this.handlers)};e.Defaults={animateOut:!1,
animateIn:!1},e.prototype.swap=function(){if(1===this.core.settings.items&&a.support.animation&&a.support.transition){this.core.speed(0);var b,c=a.proxy(this.clear,this),d=this.core.$stage.children().eq(this.previous),e=this.core.$stage.children().eq(this.next),f=this.core.settings.animateIn,g=this.core.settings.animateOut;this.core.current()!==this.previous&&(g&&(b=this.core.coordinates(this.previous)-this.core.coordinates(this.next),d.one(a.support.animation.end,c).css({left:b+"px"}).addClass("animated owl-animated-out").addClass(g)),f&&e.one(a.support.animation.end,c).addClass("animated owl-animated-in").addClass(f))}},e.prototype.clear=function(b){a(b.target).css({left:""}).removeClass("animated owl-animated-out owl-animated-in").removeClass(this.core.settings.animateIn).removeClass(this.core.settings.animateOut),this.core.onTransitionEnd()},e.prototype.destroy=function(){var a,b;for(a in this.handlers)this.core.$element.off(a,this.handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.Animate=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){var e=function(b){this._core=b,this._call=null,this._time=0,this._timeout=0,this._paused=!0,this._handlers={"changed.owl.carousel":a.proxy(function(a){a.namespace&&"settings"===a.property.name?this._core.settings.autoplay?this.play():this.stop():a.namespace&&"position"===a.property.name&&this._paused&&(this._time=0)},this),"initialized.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.autoplay&&this.play()},this),"play.owl.autoplay":a.proxy(function(a,b,c){a.namespace&&this.play(b,c)},this),"stop.owl.autoplay":a.proxy(function(a){a.namespace&&this.stop()},this),"mouseover.owl.autoplay":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.pause()},this),"mouseleave.owl.autoplay":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.play()},this),"touchstart.owl.core":a.proxy(function(){this._core.settings.autoplayHoverPause&&this._core.is("rotating")&&this.pause()},this),"touchend.owl.core":a.proxy(function(){this._core.settings.autoplayHoverPause&&this.play()},this)},this._core.$element.on(this._handlers),this._core.options=a.extend({},e.Defaults,this._core.options)};e.Defaults={autoplay:!1,autoplayTimeout:5e3,autoplayHoverPause:!1,autoplaySpeed:!1},e.prototype._next=function(d){this._call=b.setTimeout(a.proxy(this._next,this,d),this._timeout*(Math.round(this.read()/this._timeout)+1)-this.read()),this._core.is("interacting")||c.hidden||this._core.next(d||this._core.settings.autoplaySpeed)},e.prototype.read=function(){return(new Date).getTime()-this._time},e.prototype.play=function(c,d){var e;this._core.is("rotating")||this._core.enter("rotating"),c=c||this._core.settings.autoplayTimeout,e=Math.min(this._time%(this._timeout||c),c),this._paused?(this._time=this.read(),this._paused=!1):b.clearTimeout(this._call),this._time+=this.read()%c-e,this._timeout=c,this._call=b.setTimeout(a.proxy(this._next,this,d),c-e)},e.prototype.stop=function(){this._core.is("rotating")&&(this._time=0,this._paused=!0,b.clearTimeout(this._call),this._core.leave("rotating"))},e.prototype.pause=function(){this._core.is("rotating")&&!this._paused&&(this._time=this.read(),this._paused=!0,b.clearTimeout(this._call))},e.prototype.destroy=function(){var a,b;this.stop();for(a in this._handlers)this._core.$element.off(a,this._handlers[a]);for(b in Object.getOwnPropertyNames(this))"function"!=typeof this[b]&&(this[b]=null)},a.fn.owlCarousel.Constructor.Plugins.autoplay=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){"use strict";var e=function(b){this._core=b,this._initialized=!1,this._pages=[],this._controls={},this._templates=[],this.$element=this._core.$element,this._overrides={next:this._core.next,prev:this._core.prev,to:this._core.to},this._handlers={"prepared.owl.carousel":a.proxy(function(b){b.namespace&&this._core.settings.dotsData&&this._templates.push('<div class="'+this._core.settings.dotClass+'">'+a(b.content).find("[data-dot]").addBack("[data-dot]").attr("data-dot")+"</div>")},this),"added.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.dotsData&&this._templates.splice(a.position,0,this._templates.pop())},this),"remove.owl.carousel":a.proxy(function(a){a.namespace&&this._core.settings.dotsData&&this._templates.splice(a.position,1)},this),"changed.owl.carousel":a.proxy(function(a){a.namespace&&"position"==a.property.name&&this.draw()},this),"initialized.owl.carousel":a.proxy(function(a){a.namespace&&!this._initialized&&(this._core.trigger("initialize",null,"navigation"),this.initialize(),this.update(),this.draw(),this._initialized=!0,this._core.trigger("initialized",null,"navigation"))},this),"refreshed.owl.carousel":a.proxy(function(a){a.namespace&&this._initialized&&(this._core.trigger("refresh",null,"navigation"),this.update(),this.draw(),this._core.trigger("refreshed",null,"navigation"))},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this.$element.on(this._handlers)};e.Defaults={nav:!1,navText:['<span aria-label="Previous">&#x2039;</span>','<span aria-label="Next">&#x203a;</span>'],navSpeed:!1,navElement:'button type="button" role="presentation"',navContainer:!1,navContainerClass:"owl-nav",navClass:["owl-prev","owl-next"],slideBy:1,dotClass:"owl-dot",dotsClass:"owl-dots",dots:!0,dotsEach:!1,dotsData:!1,dotsSpeed:!1,dotsContainer:!1},e.prototype.initialize=function(){var b,c=this._core.settings;this._controls.$relative=(c.navContainer?a(c.navContainer):a("<div>").addClass(c.navContainerClass).appendTo(this.$element)).addClass("disabled"),this._controls.$previous=a("<"+c.navElement+">").addClass(c.navClass[0]).html(c.navText[0]).prependTo(this._controls.$relative).on("click",a.proxy(function(a){this.prev(c.navSpeed)},this)),this._controls.$next=a("<"+c.navElement+">").addClass(c.navClass[1]).html(c.navText[1]).appendTo(this._controls.$relative).on("click",a.proxy(function(a){this.next(c.navSpeed)},this)),c.dotsData||(this._templates=[a('<button role="button">').addClass(c.dotClass).append(a("<span>")).prop("outerHTML")]),this._controls.$absolute=(c.dotsContainer?a(c.dotsContainer):a("<div>").addClass(c.dotsClass).appendTo(this.$element)).addClass("disabled"),this._controls.$absolute.on("click","button",a.proxy(function(b){var d=a(b.target).parent().is(this._controls.$absolute)?a(b.target).index():a(b.target).parent().index();b.preventDefault(),this.to(d,c.dotsSpeed)},this));for(b in this._overrides)this._core[b]=a.proxy(this[b],this)},e.prototype.destroy=function(){var a,b,c,d,e;e=this._core.settings;for(a in this._handlers)this.$element.off(a,this._handlers[a]);for(b in this._controls)"$relative"===b&&e.navContainer?this._controls[b].html(""):this._controls[b].remove();for(d in this.overides)this._core[d]=this._overrides[d];for(c in Object.getOwnPropertyNames(this))"function"!=typeof this[c]&&(this[c]=null)},e.prototype.update=function(){var a,b,c,d=this._core.clones().length/2,e=d+this._core.items().length,f=this._core.maximum(!0),g=this._core.settings,h=g.center||g.autoWidth||g.dotsData?1:g.dotsEach||g.items;if("page"!==g.slideBy&&(g.slideBy=Math.min(g.slideBy,g.items)),g.dots||"page"==g.slideBy)for(this._pages=[],a=d,b=0,c=0;a<e;a++){if(b>=h||0===b){if(this._pages.push({start:Math.min(f,a-d),end:a-d+h-1}),Math.min(f,a-d)===f)break;b=0,++c}b+=this._core.mergers(this._core.relative(a))}},e.prototype.draw=function(){var b,c=this._core.settings,d=this._core.items().length<=c.items,e=this._core.relative(this._core.current()),f=c.loop||c.rewind;this._controls.$relative.toggleClass("disabled",!c.nav||d),c.nav&&(this._controls.$previous.toggleClass("disabled",!f&&e<=this._core.minimum(!0)),this._controls.$next.toggleClass("disabled",!f&&e>=this._core.maximum(!0))),this._controls.$absolute.toggleClass("disabled",!c.dots||d),c.dots&&(b=this._pages.length-this._controls.$absolute.children().length,c.dotsData&&0!==b?this._controls.$absolute.html(this._templates.join("")):b>0?this._controls.$absolute.append(new Array(b+1).join(this._templates[0])):b<0&&this._controls.$absolute.children().slice(b).remove(),this._controls.$absolute.find(".active").removeClass("active"),this._controls.$absolute.children().eq(a.inArray(this.current(),this._pages)).addClass("active"))},e.prototype.onTrigger=function(b){var c=this._core.settings;b.page={index:a.inArray(this.current(),this._pages),count:this._pages.length,size:c&&(c.center||c.autoWidth||c.dotsData?1:c.dotsEach||c.items)}},e.prototype.current=function(){var b=this._core.relative(this._core.current());return a.grep(this._pages,a.proxy(function(a,c){return a.start<=b&&a.end>=b},this)).pop()},e.prototype.getPosition=function(b){var c,d,e=this._core.settings;return"page"==e.slideBy?(c=a.inArray(this.current(),this._pages),d=this._pages.length,b?++c:--c,c=this._pages[(c%d+d)%d].start):(c=this._core.relative(this._core.current()),d=this._core.items().length,b?c+=e.slideBy:c-=e.slideBy),c},e.prototype.next=function(b){a.proxy(this._overrides.to,this._core)(this.getPosition(!0),b)},e.prototype.prev=function(b){a.proxy(this._overrides.to,this._core)(this.getPosition(!1),b)},e.prototype.to=function(b,c,d){var e;!d&&this._pages.length?(e=this._pages.length,a.proxy(this._overrides.to,this._core)(this._pages[(b%e+e)%e].start,c)):a.proxy(this._overrides.to,this._core)(b,c)},a.fn.owlCarousel.Constructor.Plugins.Navigation=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){"use strict";var e=function(c){this._core=c,this._hashes={},this.$element=this._core.$element,this._handlers={"initialized.owl.carousel":a.proxy(function(c){c.namespace&&"URLHash"===this._core.settings.startPosition&&a(b).trigger("hashchange.owl.navigation")},this),"prepared.owl.carousel":a.proxy(function(b){if(b.namespace){var c=a(b.content).find("[data-hash]").addBack("[data-hash]").attr("data-hash");if(!c)return;this._hashes[c]=b.content}},this),"changed.owl.carousel":a.proxy(function(c){if(c.namespace&&"position"===c.property.name){var d=this._core.items(this._core.relative(this._core.current())),e=a.map(this._hashes,function(a,b){return a===d?b:null}).join();if(!e||b.location.hash.slice(1)===e)return;b.location.hash=e}},this)},this._core.options=a.extend({},e.Defaults,this._core.options),this.$element.on(this._handlers),a(b).on("hashchange.owl.navigation",a.proxy(function(a){var c=b.location.hash.substring(1),e=this._core.$stage.children(),f=this._hashes[c]&&e.index(this._hashes[c]);f!==d&&f!==this._core.current()&&this._core.to(this._core.relative(f),!1,!0)},this))};e.Defaults={URLhashListener:!1},e.prototype.destroy=function(){var c,d;a(b).off("hashchange.owl.navigation");for(c in this._handlers)this._core.$element.off(c,this._handlers[c]);for(d in Object.getOwnPropertyNames(this))"function"!=typeof this[d]&&(this[d]=null)},a.fn.owlCarousel.Constructor.Plugins.Hash=e}(window.Zepto||window.jQuery,window,document),function(a,b,c,d){function e(b,c){var e=!1,f=b.charAt(0).toUpperCase()+b.slice(1);return a.each((b+" "+h.join(f+" ")+f).split(" "),function(a,b){if(g[b]!==d)return e=!c||b,!1}),e}function f(a){return e(a,!0)}var g=a("<support>").get(0).style,h="Webkit Moz O ms".split(" "),i={transition:{end:{WebkitTransition:"webkitTransitionEnd",MozTransition:"transitionend",OTransition:"oTransitionEnd",transition:"transitionend"}},animation:{end:{WebkitAnimation:"webkitAnimationEnd",MozAnimation:"animationend",OAnimation:"oAnimationEnd",animation:"animationend"}}},j={csstransforms:function(){return!!e("transform")},csstransforms3d:function(){return!!e("perspective")},csstransitions:function(){return!!e("transition")},cssanimations:function(){return!!e("animation")}};j.csstransitions()&&(a.support.transition=new String(f("transition")),a.support.transition.end=i.transition.end[a.support.transition]),j.cssanimations()&&(a.support.animation=new String(f("animation")),a.support.animation.end=i.animation.end[a.support.animation]),j.csstransforms()&&(a.support.transform=new String(f("transform")),a.support.transform3d=j.csstransforms3d())}(window.Zepto||window.jQuery,window,document);(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    $(function() {
      var $this ,$scroll;
      var $articleContent = $('.js-article-content');
      var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
      var scroll = hasSidebar ? '.js-page-main' : 'html, body';
      $scroll = $(scroll);

      $articleContent.find('.highlight').each(function() {
        $this = $(this);
        $this.attr('data-lang', $this.find('code').attr('data-lang'));
      });
      $articleContent.find('h1[id], h2[id], h3[id], h4[id], h5[id], h6[id]').each(function() {
        $this = $(this);
        $this.append($('<a class="anchor d-print-none" aria-hidden="true"></a>').html('<i class="fas fa-anchor"></i>'));
      });
      $articleContent.on('click', '.anchor', function() {
        $scroll.scrollToAnchor('#' + $(this).parent().attr('id'), 400);
      });
    });
  });
})();

$(document).ready(function () {

  try{
        /* Versions Pagination*/
      $('.pagination_big').owlCarousel({
        margin:10,
        nav:true,
        dots:false,
        responsive:{
            0:{
                items:3
            },
            400:{
                items:4,
                margin:10
            },
            500:{
                items:6
            },
            1600:{
                items:11
            }
        }
    });
  } catch(e){}

});

</script></div><section class="page__comments d-print-none"></section></article><!-- start custom main bottom snippet -->

<!-- end custom main bottom snippet --></div>
            </div></div></div><div class="page__footer d-print-none">
<footer class="footer py-4 js-page-footer">
  <div class="main"><div itemscope itemtype="https://schema.org/Person">
      <meta itemprop="name" content=""><meta itemprop="url" content="/"></div><div class="site-info mt-2">
      <div>© <span id="year"></span> John Snow Labs Inc.
        <a target="_blank" href="https://www.johnsnowlabs.com/terms-of-service">Terms of Service</a> | <a target="_blank" href="https://www.johnsnowlabs.com/privacy-policy/">Privacy Policy</a>
      </div>
    </div>
  </div>
</footer>

<script>

/* Responsive menu
	 ========================================================*/
jQuery(document).ready(function($) {
	jQuery('#responsive_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.top_navigation').toggleClass('open');
  });
  jQuery('#aside_menu').click(function(e) {
      e.preventDefault();
      jQuery(this).toggleClass('close');
      jQuery('.js-col-aside').toggleClass('open');
      if (jQuery(window).width() <= 1023)
      {
        jQuery('.page__sidebar').toggleClass('open'); 
      jQuery('.demomenu').toggleClass('open');
      }
  });
  jQuery('.toc--ellipsis a').click(function(e) {
    if (jQuery(window).width() <= 767)
      {
        jQuery('.js-col-aside').removeClass('open');
        jQuery('.page__sidebar').removeClass('open');    
        jQuery('#aside_menu').removeClass('close');  
      }       
  });
});

/*OPen by URL*/
jQuery(document).ready(function () {  
  const tabName = (window.location.hash || '').replace('#', '');
  const tab = document.getElementById(tabName || 'opensource');
  if (tab) {
    tab.click();
  }
});


  //Accordion demos categories
  let acc = document.getElementsByClassName("acc-top"),
    isResizeble = false;

  if(!isResizeble && document.querySelector(".acc-top")) {
      let accBody = document.querySelector('.acc-body li.active');
      if(accBody != null) {
        accBody.parentElement.style.maxHeight = accBody.parentElement.scrollHeight + 20 + "px";
        accBody.parentElement.classList.add('open');
        accBody.parentElement.previousElementSibling.classList.add('active');
        isResizeble = true;
      }
  }


for (let i = 0; i < acc.length; i++) {
  acc[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var panel = this.nextElementSibling;
    if (panel.style.maxHeight) {
      panel.style.maxHeight = null;
      panel.classList.remove('open');
    } else {
      panel.style.maxHeight = panel.scrollHeight + 20 + "px";
      panel.classList.add('open');
    }
  });
}



try {
  //Show more in demos description
  let tabDescription = document.querySelectorAll('.tab-description');

  tabDescription.forEach(element => {
    let tabDescriptionInner = element.querySelector('.tab-description-inner');
    if(element.offsetHeight < tabDescriptionInner.offsetHeight) {
      element.classList.add('big-descr');
    }
  });

  let showMore = document.querySelectorAll('.show_more');

  showMore.forEach(element => {
    element.addEventListener("click", function(e) {
      e.preventDefault();
      this.parentElement.parentElement.classList.remove('big-descr');
      this.parentElement.parentElement.classList.add('big-descr-close');
    });
  });
} catch(e){}


try{
  //disable Colab link
  let btnDisable = document.querySelectorAll('.btn.disable');

  btnDisable.forEach(element => {
    element.addEventListener("click", function(e) {
      e.preventDefault();
    });
  });
} catch(e){}


try {
  // Ancor click
const anchors = [].slice.call(document.querySelectorAll('.btn-box-install a')),
animationTime = 300,
framesCount = 20;

anchors.forEach(function(item) {
item.addEventListener('click', function(e) {
  e.preventDefault();
  let coordY = document.querySelector(item.getAttribute('href')).getBoundingClientRect().top + window.pageYOffset -100;

  let scroller = setInterval(function() {
      let scrollBy = coordY / framesCount;

if(scrollBy > window.pageYOffset - coordY && window.innerHeight + window.pageYOffset < document.body.offsetHeight) {
    window.scrollBy(0, scrollBy);
} else {
          window.scrollTo(0, coordY);
  clearInterval(scroller);
}
  }, animationTime / framesCount);
});
}); 
} catch(e){}


try {
  //Pagination active
  let paginationItems = document.querySelectorAll('.pagination_big li'),
      nextVersionContainer = document.querySelector('#nextver'),
      previosVersionContainer = document.querySelector('#previosver'),
      currentVersionContainer = document.querySelector('#currversion'),
      currentPageTitle = document.querySelector('#section').innerText;

  // Set active page and update version containers
  for (let i = 0; i < paginationItems.length; i++) {
    const item = paginationItems[i],
          itemTitle = item.firstElementChild.innerHTML;
    if (itemTitle === currentPageTitle) {
      item.classList.add('active');
      currentVersionContainer.textContent = itemTitle;       
      if(item.previousElementSibling) {
        previosVersionContainer.textContent = item.previousElementSibling.innerText; 
        previosVersionContainer.parentElement.href = 'release_notes_' + item.previousElementSibling.innerText.replaceAll('.', '_');
      } else {
        previosVersionContainer.parentElement.parentElement.classList.add('hide');
      }
      if(item.nextElementSibling) {
        nextVersionContainer.textContent = item.nextElementSibling.innerText;
        nextVersionContainer.parentElement.href = 'release_notes_' + item.nextElementSibling.innerText.replaceAll('.', '_');
      } else {
        nextVersionContainer.parentElement.parentElement.classList.add('hide');
      }         
      break;
    }
  }
} catch(e){}


try{
  // copy to clipboard
  let btnCopy = document.querySelectorAll('.button-copy-s3');

  btnCopy.forEach((element) => {
    //add span Copied!
    element.insertAdjacentHTML('beforeend', '<span>Copied!</span>');

    element.addEventListener('click', function (e) {
      e.preventDefault();
      element.classList.add('copied');
      setTimeout(function () {
        element.classList.remove('copied');
      }, 3000);
      navigator.clipboard.writeText(element.href);
    });
  });
} catch(e){}

document.getElementById("year").innerHTML = new Date().getFullYear();


try {
  let links = document.links;

  for (let i = 0, linksLength = links.length; i < linksLength; i++) {
    if (links[i].hostname != window.location.hostname) {
        links[i].target = '_blank';
    }
    if ((links[i].hostname.indexOf("johnsnowlabs.com") === -1) && (links[i].hostname != window.location.hostname)) {
      links[i].rel = 'nofollow';
    }
  }  
} catch(e){}

//Show Demo Menu

const demomenu = document.querySelector('.demomenu'),
      asideButton = document.querySelector('#aside_menu');

if(demomenu === null) {
  asideButton.classList.add('hide_aside');
}


</script></div></div>
    </div></div></div><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $body = $('body'), $window = $(window);
    var $pageRoot = $('.js-page-root'), $pageMain = $('.js-page-main');
    var activeCount = 0;
    function modal(options) {
      var $root = this, visible, onChange, hideWhenWindowScroll = false;
      var scrollTop;
      function setOptions(options) {
        var _options = options || {};
        visible = _options.initialVisible === undefined ? false : show;
        onChange = _options.onChange;
        hideWhenWindowScroll = _options.hideWhenWindowScroll;
      }
      function init() {
        setState(visible);
      }
      function setState(isShow) {
        if (isShow === visible) {
          return;
        }
        visible = isShow;
        if (visible) {
          activeCount++;
          scrollTop = $(window).scrollTop() || $pageMain.scrollTop();
          $root.addClass('modal--show');
          $pageMain.scrollTop(scrollTop);
          activeCount === 1 && ($pageRoot.addClass('show-modal'), $body.addClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.on('scroll', hide);
          $window.on('keyup', handleKeyup);
        } else {
          activeCount > 0 && activeCount--;
          $root.removeClass('modal--show');
          $window.scrollTop(scrollTop);
          activeCount === 0 && ($pageRoot.removeClass('show-modal'), $body.removeClass('of-hidden'));
          hideWhenWindowScroll && window.hasEvent('touchstart') && $window.off('scroll', hide);
          $window.off('keyup', handleKeyup);
        }
        onChange && onChange(visible);
      }
      function show() {
        setState(true);
      }
      function hide() {
        setState(false);
      }
      function handleKeyup(e) {
        // Char Code: 27  ESC
        if (e.which ===  27) {
          hide();
        }
      }
      setOptions(options);
      init();
      return {
        show: show,
        hide: hide,
        $el: $root
      };
    }
    $.fn.modal = modal;
  });
})();
</script><div class="modal modal--overflow page__search-modal d-print-none js-page-search-modal"></div></div>


<script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function scrollToAnchor(anchor, duration, callback) {
      var $root = this;
      $root.animate({ scrollTop: $(anchor).position().top }, duration, function() {
        window.history.replaceState(null, '', window.location.href.split('#')[0] + anchor);
        callback && callback();
      });
    }
    $.fn.scrollToAnchor = scrollToAnchor;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function affix(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroll,
        offsetBottom = 0, scrollTarget = window, scroll = window.document, disabled = false, isOverallScroller = true,
        rootTop, rootLeft, rootHeight, scrollBottom, rootBottomTop,
        hasInit = false, curState;

      function setOptions(options) {
        var _options = options || {};
        _options.offsetBottom && (offsetBottom = _options.offsetBottom);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroll && (scroll = _options.scroll);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $scrollTarget = $(scrollTarget);
        isOverallScroller = window.isOverallScroller($scrollTarget[0]);
        $scroll = $(scroll);
      }
      function preCalc() {
        top();
        rootHeight = $root.outerHeight();
        rootTop = $root.offset().top + (isOverallScroller ? 0 :  $scrollTarget.scrollTop());
        rootLeft = $root.offset().left;
      }
      function calc(needPreCalc) {
        needPreCalc && preCalc();
        scrollBottom = $scroll.outerHeight() - offsetBottom - rootHeight;
        rootBottomTop = scrollBottom - rootTop;
      }
      function top() {
        if (curState !== 'top') {
          $root.removeClass('fixed').css({
            left: 0,
            top: 0
          });
          curState = 'top';
        }
      }
      function fixed() {
        if (curState !== 'fixed') {
          $root.addClass('fixed').css({
            left: rootLeft + 'px',
            top: 0
          });
          curState = 'fixed';
        }
      }
      function bottom() {
        if (curState !== 'bottom') {
          $root.removeClass('fixed').css({
            left: 0,
            top: rootBottomTop + 'px'
          });
          curState = 'bottom';
        }
      }
      function setState() {
        var scrollTop = $scrollTarget.scrollTop();
        if (scrollTop >= rootTop && scrollTop <= scrollBottom) {
          fixed();
        } else if (scrollTop < rootTop) {
          top();
        } else {
          bottom();
        }
      }
      function init() {
        if(!hasInit) {
          var interval, timeout;
          calc(true); setState();
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState();
          });
          $window.on('resize', function() {
            disabled || (calc(true), setState());
          });
          hasInit = true;
        }
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions,
        refresh: function() {
          calc(true, { animation: false }); setState();
        }
      };
    }
    $.fn.affix = affix;
  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    function toc(options) {
      var $root = this, $window = $(window), $scrollTarget, $scroller, $tocUl = $('<ul class="toc toc--ellipsis"></ul>'), $tocLi, $headings, $activeLast, $activeCur,
        selectors = 'h1,h2,h3',  container = 'body', scrollTarget = window, scroller = 'html, body', disabled = false,
        headingsPos, scrolling = false, hasRendered = false, hasInit = false;

        

      function setOptions(options) {
        var _options = options || {};
        _options.selectors && (selectors = _options.selectors);
        _options.container && (container = _options.container);
        _options.scrollTarget && (scrollTarget = _options.scrollTarget);
        _options.scroller && (scroller = _options.scroller);
        _options.disabled !== undefined && (disabled = _options.disabled);
        $headings = $(container).find(selectors).filter('[id]');
        $scrollTarget = $(scrollTarget);
        $scroller = $(scroller);
      }
      function calc() {
        headingsPos = [];
        $headings.each(function() {
          headingsPos.push(Math.floor($(this).position().top));
        });
      }
      function setState(element, disabled) {
        var scrollTop = $scrollTarget.scrollTop(), i;
        if (disabled || !headingsPos || headingsPos.length < 1) { return; }
        if (element) {
          $activeCur = element;
        } else {
          for (i = 0; i < headingsPos.length; i++) {
            if (scrollTop >= headingsPos[i]) {
              $activeCur = $tocLi.eq(i);
            } else {
              $activeCur || ($activeCur = $tocLi.eq(i));
              break;
            }
          }
        }
        $activeLast && $activeLast.removeClass('active');
        ($activeLast = $activeCur).addClass('active');
      }
      function render() {
        if(!hasRendered) {
          $root.append($tocUl);
          $headings.each(function() {
            var $this = $(this);
            $tocUl.append($('<li></li>').addClass('toc-' + $this.prop('tagName')
              .toLowerCase() + ' ' + $this.prop('className'))
              .append($('<a></a>').text($this.text()).attr('href', '#' + $this.prop('id'))));
          });
          $tocLi = $tocUl.children('li');
          $tocUl.on('click', 'a', function(e) {
            e.preventDefault();
            var $this = $(this);
            scrolling = true;
            setState($this.parent());
            $scroller.scrollToAnchor($this.attr('href'), 400, function() {
              scrolling = false;
            });
          });
        }
        hasRendered = true;
      }
      function init() {
        var interval, timeout;
        if(!hasInit) {
          render(); calc(); setState(null, scrolling);
          // run calc every 100 millisecond
          interval = setInterval(function() {
            calc();
          }, 100);
          timeout = setTimeout(function() {
            clearInterval(interval);
          }, 45000);
          window.pageLoad.then(function() {
            setTimeout(function() {
              clearInterval(interval);
              clearTimeout(timeout);
            }, 3000);
          });
          $scrollTarget.on('scroll', function() {
            disabled || setState(null, scrolling);
          });
          $window.on('resize', window.throttle(function() {
            if (!disabled) {
              render(); calc(); setState(null, scrolling);
            }
          }, 100));
        }
        hasInit = true;
      }

      setOptions(options);
      if (!disabled) {
        init();
      }
      $window.on('resize', window.throttle(function() {
        init();
      }, 200));
      return {
        setOptions: setOptions
      };
    }
    $.fn.toc = toc;
  });
})();
/*(function () {

})();*/
</script><script>(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;

  window.Lazyload.js(SOURCES.jquery, function() {
    var $pageMask = $('.js-page-mask');
    var $pageRoot = $('.js-page-root');
    var $sidebarShow = $('.js-sidebar-show');
    var $sidebarHide = $('.js-sidebar-hide');

    function freeze(e) {
      if (e.target === $pageMask[0]) {
        e.preventDefault();
      }
    }
    function stopBodyScrolling(bool) {
      if (bool === true) {
        window.addEventListener('touchmove', freeze, { passive: false });
      } else {
        window.removeEventListener('touchmove', freeze, { passive: false });
      }
    }

    $sidebarShow.on('click', function() {
      stopBodyScrolling(true); $pageRoot.addClass('show-sidebar');
    });
    $sidebarHide.on('click', function() {
      stopBodyScrolling(false); $pageRoot.removeClass('show-sidebar');
    });
  });
})();
</script><script>
  /* toc must before affix, since affix need to konw toc' height. */(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  var TOC_SELECTOR = window.TEXT_VARIABLES.site.toc.selectors;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window);
    var $articleContent = $('.js-article-content');
    var $tocRoot = $('.js-toc-root'), $col2 = $('.js-col-aside');
    var toc;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');
    var hasToc = $articleContent.find(TOC_SELECTOR).length > 0;

    function disabled() {
      return $col2.css('display') === 'none' || !hasToc;
    }

    tocDisabled = disabled();

    toc = $tocRoot.toc({
      selectors: TOC_SELECTOR,
      container: $articleContent,
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      tocDisabled = disabled();
      toc && toc.setOptions({
        disabled: tocDisabled
      });
    }, 100));

  });
})();
(function() {
  var SOURCES = window.TEXT_VARIABLES.sources;
  window.Lazyload.js(SOURCES.jquery, function() {
    var $window = $(window), $pageFooter = $('.js-page-footer');
    var $pageAside = $('.js-page-aside');
    var affix;
    var tocDisabled = false;
    var hasSidebar = $('.js-page-root').hasClass('layout--page--sidebar');

    affix = $pageAside.affix({
      offsetBottom: $pageFooter.outerHeight(),
      scrollTarget: hasSidebar ? '.js-page-main' : null,
      scroller: hasSidebar ? '.js-page-main' : null,
      scroll: hasSidebar ? $('.js-page-main').children() : null,
      disabled: tocDisabled
    });

    $window.on('resize', window.throttle(function() {
      affix && affix.setOptions({
        disabled: tocDisabled
      });
    }, 100));

    window.pageAsideAffix = affix;
  });
})();
</script>
    </div>
    <script>(function () {
  var $root = document.getElementsByClassName('root')[0];
  if (window.hasEvent('touchstart')) {
    $root.dataset.isTouch = true;
    document.addEventListener('touchstart', function(){}, false);
  }
})();
</script>
  </body>
</html>