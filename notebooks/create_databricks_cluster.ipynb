{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51adebf4-7aba-4a03-b50b-36c2ec974122",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "# Automatic Databricks Cluster Creation with John Snow Labs libraries pre-Iinstalled\n",
    "For more details see https://nlp.johnsnowlabs.com/docs/en/jsl/install_advanced#via-json-secrets-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78e7d809-84ba-4043-b1dc-eb81077357b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U johnsnowlabs_for_databricks\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7015f047-b770-44d5-a50f-5dd7d822078d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from johnsnowlabs.auto_install.jsl_home import get_install_suite_from_jsl_home\n",
    "from johnsnowlabs import nlp\n",
    "import json,os\n",
    " \n",
    "cluster_license_string = \"\"\"\n",
    "Your John Snow Labs Databricks JSON LIcense\n",
    "\"\"\"\n",
    "if os.path.exists('license.json'): os.remove('license.json')\n",
    "with open('license.json', 'w') as file:\n",
    "    file.write(cluster_license_string)\n",
    "\n",
    "# 2) Setup Databricks Access Token & Host\n",
    "db_token='Your db_token'\n",
    "db_host=\"Your db_host\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8219a9d-8bff-4596-85ec-6477ac599ad8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dbfs:/johnsnowlabs\nüìã Stored John Snow Labs License in /dbfs/johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\nüë∑ Setting up  John Snow Labs home in /dbfs/johnsnowlabs, this might take a few minutes.\nDownloading üêç+üöÄ Python Library spark_nlp-5.0.2-py2.py3-none-any.whl\nDownloading üêç+üíä Python Library spark_nlp_jsl-5.0.2-py3-none-any.whl\nDownloading ü´ò+üöÄ Java Library spark-nlp-assembly-5.0.2.jar\nDownloading ü´ò+üíä Java Library spark-nlp-jsl-5.0.2.jar\nüôÜ JSL Home setup in /dbfs/johnsnowlabs\nüëå Detected license file /databricks/driver/license.json\nüëå Created cluster with id=0910-220926-5ni2v4lr on host=https://dbc-3d4c44aa-a512.cloud.databricks.com/api/\nDEBUG: INSTALL TO CLUSTER True True False\nDEBUG: INSTALL TO CLUSTER /dbfs/johnsnowlabs/py_installs/spark_nlp_jsl-5.0.2-py3-none-any.whl /dbfs/johnsnowlabs/java_installs/spark-nlp-jsl-5.0.2.jar True\nDEBUG: INSTALL TO CLUSTER /dbfs/johnsnowlabs/py_installs/spark_nlp-5.0.2-py2.py3-none-any.whl /dbfs/johnsnowlabs/java_installs/spark-nlp-assembly-5.0.2.jar True\nCopying /dbfs/johnsnowlabs/py_installs/spark_nlp_jsl-5.0.2-py3-none-any.whl to remote cluster path dbfs:/johnsnowlabs/py_installs/spark_nlp_jsl-5-py2.py3-none-any.whl\nInstalled üíäSpark-Healthcare Spark NLP for Healthcare ‚úÖ\nInstalled nlu ‚úÖ\nInstalled spark-nlp-display ‚úÖ\nInstalled johnsnowlabs_for_databricks ‚úÖ\nCopying /dbfs/johnsnowlabs/py_installs/spark_nlp-5.0.2-py2.py3-none-any.whl to remote cluster path dbfs:/johnsnowlabs/py_installs/spark_nlp-5-py2.py3-none-any.whl\nüöÄSpark-NLP Installed Spark NLP! ‚úÖ\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=PENDING\nCluster-Id=0910-220926-5ni2v4lr not ready, status=RUNNING\nüëå Cluster-Id 0910-220926-5ni2v4lr is ready!\n"
     ]
    }
   ],
   "source": [
    "runtime = '9.1.x-scala2.12'\n",
    "\n",
    "instance_type_azure =  'Standard_DS3_v2' \n",
    "instance_type_aws =  'i3.xlarge'\n",
    "\n",
    "# If you are on azure, use instance_type_azure instead ! \n",
    "# You can use any valid identifier for your cloud provider\n",
    "instance_type_to_use = instance_type_aws \n",
    "\n",
    "\n",
    "test_cluster_id = nlp.install(\n",
    "    json_license_path='license.json',\n",
    "    spark_version=runtime,\n",
    "    databricks_host=db_host,\n",
    "    databricks_token=db_token,\n",
    "    visual=False, # Set True if you want visual-NLP\n",
    "    clean_cluster=True, # Toggle this to speed up cluster creation time. Reccomend True on first run. \n",
    "    # cluster_name='my-cluster' # You can optionally specify you cluster name here \n",
    "\n",
    "    node_type_id = instance_type_aws,\n",
    "    driver_node_type_id = instance_type_aws, \n",
    "\n",
    "\n",
    "    # spark_env_vars=spark_env_vars, # add extra env vars for your cluster\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9460868-f659-498b-9523-ceb9d2505234",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "license.json\r\n"
     ]
    }
   ],
   "source": [
    "! ls /dbfs/johnsnowlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c684672e-6505-4af3-813a-0241ec99a4ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "create_databricks_cluster_PUBLIC",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
