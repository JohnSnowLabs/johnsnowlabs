<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2025-05-13T19:45:30+00:00</updated><id>/feed.xml</id><title type="html">Spark NLP</title><subtitle>High Performance NLP with Apache Spark
</subtitle><author><name>{&quot;type&quot;=&gt;nil, &quot;name&quot;=&gt;nil, &quot;url&quot;=&gt;nil, &quot;avatar&quot;=&gt;nil, &quot;bio&quot;=&gt;nil, &quot;email&quot;=&gt;nil, &quot;facebook&quot;=&gt;nil, &quot;twitter&quot;=&gt;nil, &quot;weibo&quot;=&gt;nil, &quot;googleplus&quot;=&gt;nil, &quot;telegram&quot;=&gt;nil, &quot;medium&quot;=&gt;nil, &quot;zhihu&quot;=&gt;nil, &quot;douban&quot;=&gt;nil, &quot;linkedin&quot;=&gt;nil, &quot;github&quot;=&gt;nil, &quot;npm&quot;=&gt;nil}</name></author><entry><title type="html">PDF Deidentification Multi Model</title><link href="/2025/05/09/pdf_deid_multi_model_context_pipeline.html" rel="alternate" type="text/html" title="PDF Deidentification Multi Model" /><published>2025-05-09T00:00:00+00:00</published><updated>2025-05-09T00:00:00+00:00</updated><id>/2025/05/09/pdf_deid_multi_model_context_pipeline</id><content type="html" xml:base="/2025/05/09/pdf_deid_multi_model_context_pipeline.html">## Description

This pipeline can be used to mask PHI information in PDFs. Masked entities include 'AGE', 'CITY', 'COUNTRY', 'DATE', 'DOCTOR', 'EMAIL', 'HOSPITAL', 'IDNUM', 'ORGANIZATION', 'PATIENT', 'PHONE', 'PROFESSION', 'STATE', 'STREET', 'USERNAME', 'ZIP'.
The output is a PDF document, similar to the one at the input, but with black bounding boxes on top of the targeted entities.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/ocr/pdf_deid_multi_model_context_pipeline_en_6.0.0_3.0_1746569926000.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/ocr/pdf_deid_multi_model_context_pipeline_en_6.0.0_3.0_1746569926000.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use

&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.pretrained import PretrainedPipeline
deid_pipeline = PretrainedPipeline(&quot;pdf_deid_multi_model_context_pipeline&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;)
```

&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|pdf_deid_multi_model_context_pipeline|
|Type:|pipeline|
|Compatibility:|Healthcare NLP 6.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|4.4 GB|

## Included Models

- PdfToImage
- ImageToText
- DocumentAssembler
- SentenceDetectorDLModel
- Regex
- WordEmbeddingsModel
- MedicalNerModel
- NerConverter
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- EntityExtractor
- ContextualParserModel
- RegexMatcher
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- RegexMatcher
- ChunkMergeModel
- ChunkMergeModel
- XLMRobertaEmbeddings
- MedicalNerModel
- NerConverter 
- PretrainedZeroShotNER
- NerConverter
- PretrainedZeroShotNER
- NerConverter
- ChunkMergeModel
- PositionFinder
- ImageDrawRegions
- ImageToPdf</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><summary type="html">Description This pipeline can be used to mask PHI information in PDFs. Masked entities include ‘AGE’, ‘CITY’, ‘COUNTRY’, ‘DATE’, ‘DOCTOR’, ‘EMAIL’, ‘HOSPITAL’, ‘IDNUM’, ‘ORGANIZATION’, ‘PATIENT’, ‘PHONE’, ‘PROFESSION’, ‘STATE’, ‘STREET’, ‘USERNAME’, ‘ZIP’. The output is a PDF document, similar to the one at the input, but with black bounding boxes on top of the targeted entities. Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;pdf_deid_multi_model_context_pipeline&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) Model Information Model Name: pdf_deid_multi_model_context_pipeline Type: pipeline Compatibility: Healthcare NLP 6.0.0+ License: Licensed Edition: Official Language: en Size: 4.4 GB Included Models PdfToImage ImageToText DocumentAssembler SentenceDetectorDLModel Regex WordEmbeddingsModel MedicalNerModel NerConverter ContextualParserModel ContextualParserModel ContextualParserModel ContextualParserModel ContextualParserModel ContextualParserModel EntityExtractor ContextualParserModel RegexMatcher ContextualParserModel ContextualParserModel ContextualParserModel ContextualParserModel RegexMatcher ChunkMergeModel ChunkMergeModel XLMRobertaEmbeddings MedicalNerModel NerConverter PretrainedZeroShotNER NerConverter PretrainedZeroShotNER NerConverter ChunkMergeModel PositionFinder ImageDrawRegions ImageToPdf</summary></entry><entry><title type="html">PDF Obfuscation Multi Model</title><link href="/2025/05/09/pdf_obfuscation_multi_model_context_pipeline.html" rel="alternate" type="text/html" title="PDF Obfuscation Multi Model" /><published>2025-05-09T00:00:00+00:00</published><updated>2025-05-09T00:00:00+00:00</updated><id>/2025/05/09/pdf_obfuscation_multi_model_context_pipeline</id><content type="html" xml:base="/2025/05/09/pdf_obfuscation_multi_model_context_pipeline.html">## Description

This pipeline can be used to mask PHI information in PDFs. Masked entities include 'AGE', 'CITY', 'COUNTRY', 'DATE', 'DOCTOR', 'EMAIL', 'HOSPITAL', 'IDNUM', 'ORGANIZATION', 'PATIENT', 'PHONE', 'PROFESSION', 'STATE', 'STREET', 'USERNAME', 'ZIP'.
The output is a PDF document, similar to the one at the input, but with fake obfuscated text on top of the targeted entities. 

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/ocr/pdf_obfuscation_multi_model_context_pipeline_en_6.0.0_3.0_1746699526000.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/ocr/pdf_obfuscation_multi_model_context_pipeline_en_6.0.0_3.0_1746699526000.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use

&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
from sparknlp.pretrained import PretrainedPipeline
deid_pipeline = PretrainedPipeline(&quot;pdf_obfuscation_multi_model_context_pipeline&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;)
```

&lt;/div&gt;

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|pdf_obfuscation_multi_model_context_pipeline|
|Type:|pipeline|
|Compatibility:|Healthcare NLP 6.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|4.4 GB|

## Included Models

- PdfToImage
- ImageToText
- DocumentAssembler
- SentenceDetectorDLModel
- Regex
- WordEmbeddingsModel
- MedicalNerModel
- NerConverter
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- EntityExtractor
- ContextualParserModel
- RegexMatcher
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- ContextualParserModel
- RegexMatcher
- ChunkMergeModel
- ChunkMergeModel
- XLMRobertaEmbeddings
- MedicalNerModel
- NerConverter 
- PretrainedZeroShotNER
- NerConverter
- PretrainedZeroShotNER
- NerConverter
- ChunkMergeModel
- PositionFinder
- ImageDrawRegions
- ImageToPdf</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><summary type="html">Description This pipeline can be used to mask PHI information in PDFs. Masked entities include ‘AGE’, ‘CITY’, ‘COUNTRY’, ‘DATE’, ‘DOCTOR’, ‘EMAIL’, ‘HOSPITAL’, ‘IDNUM’, ‘ORGANIZATION’, ‘PATIENT’, ‘PHONE’, ‘PROFESSION’, ‘STATE’, ‘STREET’, ‘USERNAME’, ‘ZIP’. The output is a PDF document, similar to the one at the input, but with fake obfuscated text on top of the targeted entities. Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU from sparknlp.pretrained import PretrainedPipeline deid_pipeline = PretrainedPipeline(&quot;pdf_obfuscation_multi_model_context_pipeline&quot;, &quot;en&quot;, &quot;clinical/ocr&quot;) Model Information Model Name: pdf_obfuscation_multi_model_context_pipeline Type: pipeline Compatibility: Healthcare NLP 6.0.0+ License: Licensed Edition: Official Language: en Size: 4.4 GB Included Models PdfToImage ImageToText DocumentAssembler SentenceDetectorDLModel Regex WordEmbeddingsModel MedicalNerModel NerConverter ContextualParserModel ContextualParserModel ContextualParserModel ContextualParserModel ContextualParserModel ContextualParserModel EntityExtractor ContextualParserModel RegexMatcher ContextualParserModel ContextualParserModel ContextualParserModel ContextualParserModel RegexMatcher ChunkMergeModel ChunkMergeModel XLMRobertaEmbeddings MedicalNerModel NerConverter PretrainedZeroShotNER NerConverter PretrainedZeroShotNER NerConverter ChunkMergeModel PositionFinder ImageDrawRegions ImageToPdf</summary></entry><entry><title type="html">Mapping Phenotype Entities with Corresponding HPO Codes (Pretrained Pipeline)</title><link href="/2025/05/02/hpo_mapper_pipeline_en.html" rel="alternate" type="text/html" title="Mapping Phenotype Entities with Corresponding HPO Codes (Pretrained Pipeline)" /><published>2025-05-02T00:00:00+00:00</published><updated>2025-05-02T00:00:00+00:00</updated><id>/2025/05/02/hpo_mapper_pipeline_en</id><content type="html" xml:base="/2025/05/02/hpo_mapper_pipeline_en.html">## Description

This pipeline is designed to map extracted phenotype entities from clinical or biomedical text to their corresponding Human Phenotype Ontology (HPO) codes. It ensures that observed symptoms, signs, and clinical abnormalities are standardized using HPO terminology.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/hpo_mapper_pipeline_en_6.0.0_3.2_1746195935268.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/hpo_mapper_pipeline_en_6.0.0_3.2_1746195935268.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python

from sparknlp.pretrained import PretrainedPipeline

pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)

result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```

{:.jsl-block}
```python

pipeline = nlp.PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)


result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```
```scala

import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline

val pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)

val result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```
&lt;/div&gt;

## Results

```bash

+------------------+-----+---+-----+----------+
|             chunk|begin|end|label|  hpo_code|
+------------------+-----+---+-----+----------+
|             APNEA|    0|  4|  HPO|HP:0002104|
|             apnea|   16| 20|  HPO|HP:0002104|
|HYPERBILIRUBINEMIA|   66| 83|  HPO|HP:0002904|
|hyperbilirubinemia|   91|108|  HPO|HP:0002904|
|            sepsis|  167|172|  HPO|HP:0100806|
+------------------+-----+---+-----+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|hpo_mapper_pipeline|
|Type:|pipeline|
|Compatibility:|Healthcare NLP 6.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|4.0 MB|

## Included Models

- DocumentAssembler
- TokenizerModel
- StopWordsCleaner
- TokenAssembler
- SentenceDetectorDLModel
- TokenizerModel
- TextMatcherInternalModel
- ChunkMapperModel</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="en" /><category term="clinical" /><category term="hpo" /><category term="pipeline" /><category term="ner" /><category term="mapper" /><summary type="html">Description This pipeline is designed to map extracted phenotype entities from clinical or biomedical text to their corresponding Human Phenotype Ontology (HPO) codes. It ensures that observed symptoms, signs, and clinical abnormalities are standardized using HPO terminology. Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) pipeline = nlp.PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline val pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) val result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) Results +------------------+-----+---+-----+----------+ | chunk|begin|end|label| hpo_code| +------------------+-----+---+-----+----------+ | APNEA| 0| 4| HPO|HP:0002104| | apnea| 16| 20| HPO|HP:0002104| |HYPERBILIRUBINEMIA| 66| 83| HPO|HP:0002904| |hyperbilirubinemia| 91|108| HPO|HP:0002904| | sepsis| 167|172| HPO|HP:0100806| +------------------+-----+---+-----+----------+ Model Information Model Name: hpo_mapper_pipeline Type: pipeline Compatibility: Healthcare NLP 6.0.0+ License: Licensed Edition: Official Language: en Size: 4.0 MB Included Models DocumentAssembler TokenizerModel StopWordsCleaner TokenAssembler SentenceDetectorDLModel TokenizerModel TextMatcherInternalModel ChunkMapperModel</summary></entry><entry><title type="html">Mapping Phenotype Entities with Corresponding HPO Codes (Pretrained Pipeline)</title><link href="/2025/05/02/hpo_mapper_pipeline_en.html" rel="alternate" type="text/html" title="Mapping Phenotype Entities with Corresponding HPO Codes (Pretrained Pipeline)" /><published>2025-05-02T00:00:00+00:00</published><updated>2025-05-02T00:00:00+00:00</updated><id>/2025/05/02/hpo_mapper_pipeline_en</id><content type="html" xml:base="/2025/05/02/hpo_mapper_pipeline_en.html">## Description

This pipeline is designed to map extracted phenotype entities from clinical or biomedical text to their corresponding Human Phenotype Ontology (HPO) codes. It ensures that observed symptoms, signs, and clinical abnormalities are standardized using HPO terminology.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/hpo_mapper_pipeline_en_6.0.0_3.0_1746195778533.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/hpo_mapper_pipeline_en_6.0.0_3.0_1746195778533.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python

from sparknlp.pretrained import PretrainedPipeline

pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)

result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```

{:.jsl-block}
```python

pipeline = nlp.PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)


result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```
```scala

import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline

val pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)

val result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```
&lt;/div&gt;

## Results

```bash

+------------------+-----+---+-----+----------+
|             chunk|begin|end|label|  hpo_code|
+------------------+-----+---+-----+----------+
|             APNEA|    0|  4|  HPO|HP:0002104|
|             apnea|   16| 20|  HPO|HP:0002104|
|HYPERBILIRUBINEMIA|   66| 83|  HPO|HP:0002904|
|hyperbilirubinemia|   91|108|  HPO|HP:0002904|
|            sepsis|  167|172|  HPO|HP:0100806|
+------------------+-----+---+-----+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|hpo_mapper_pipeline|
|Type:|pipeline|
|Compatibility:|Healthcare NLP 6.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|4.0 MB|

## Included Models

- DocumentAssembler
- TokenizerModel
- StopWordsCleaner
- TokenAssembler
- SentenceDetectorDLModel
- TokenizerModel
- TextMatcherInternalModel
- ChunkMapperModel</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="en" /><category term="clinical" /><category term="hpo" /><category term="pipeline" /><category term="ner" /><category term="mapper" /><summary type="html">Description This pipeline is designed to map extracted phenotype entities from clinical or biomedical text to their corresponding Human Phenotype Ontology (HPO) codes. It ensures that observed symptoms, signs, and clinical abnormalities are standardized using HPO terminology. Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) pipeline = nlp.PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline val pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) val result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) Results +------------------+-----+---+-----+----------+ | chunk|begin|end|label| hpo_code| +------------------+-----+---+-----+----------+ | APNEA| 0| 4| HPO|HP:0002104| | apnea| 16| 20| HPO|HP:0002104| |HYPERBILIRUBINEMIA| 66| 83| HPO|HP:0002904| |hyperbilirubinemia| 91|108| HPO|HP:0002904| | sepsis| 167|172| HPO|HP:0100806| +------------------+-----+---+-----+----------+ Model Information Model Name: hpo_mapper_pipeline Type: pipeline Compatibility: Healthcare NLP 6.0.0+ License: Licensed Edition: Official Language: en Size: 4.0 MB Included Models DocumentAssembler TokenizerModel StopWordsCleaner TokenAssembler SentenceDetectorDLModel TokenizerModel TextMatcherInternalModel ChunkMapperModel</summary></entry><entry><title type="html">Mapping Phenotype Entities with Corresponding HPO Codes (Pretrained Pipeline)</title><link href="/2025/05/02/hpo_mapper_pipeline_en.html" rel="alternate" type="text/html" title="Mapping Phenotype Entities with Corresponding HPO Codes (Pretrained Pipeline)" /><published>2025-05-02T00:00:00+00:00</published><updated>2025-05-02T00:00:00+00:00</updated><id>/2025/05/02/hpo_mapper_pipeline_en</id><content type="html" xml:base="/2025/05/02/hpo_mapper_pipeline_en.html">## Description

This pipeline is designed to map extracted phenotype entities from clinical or biomedical text to their corresponding Human Phenotype Ontology (HPO) codes. It ensures that observed symptoms, signs, and clinical abnormalities are standardized using HPO terminology.

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/hpo_mapper_pipeline_en_6.0.0_3.4_1746194839283.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/hpo_mapper_pipeline_en_6.0.0_3.4_1746194839283.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python

from sparknlp.pretrained import PretrainedPipeline

pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)

result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```

{:.jsl-block}
```python

pipeline = nlp.PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)


result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```
```scala

import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline

val pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;)

val result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity.
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;)

```
&lt;/div&gt;

## Results

```bash

+------------------+-----+---+-----+----------+
|             chunk|begin|end|label|  hpo_code|
+------------------+-----+---+-----+----------+
|             APNEA|    0|  4|  HPO|HP:0002104|
|             apnea|   16| 20|  HPO|HP:0002104|
|HYPERBILIRUBINEMIA|   66| 83|  HPO|HP:0002904|
|hyperbilirubinemia|   91|108|  HPO|HP:0002904|
|            sepsis|  167|172|  HPO|HP:0100806|
+------------------+-----+---+-----+----------+

```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|hpo_mapper_pipeline|
|Type:|pipeline|
|Compatibility:|Healthcare NLP 6.0.0+|
|License:|Licensed|
|Edition:|Official|
|Language:|en|
|Size:|4.0 MB|

## Included Models

- DocumentAssembler
- TokenizerModel
- StopWordsCleaner
- TokenAssembler
- SentenceDetectorDLModel
- TokenizerModel
- TextMatcherInternalModel
- ChunkMapperModel</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="en" /><category term="clinical" /><category term="hpo" /><category term="pipeline" /><category term="ner" /><category term="mapper" /><summary type="html">Description This pipeline is designed to map extracted phenotype entities from clinical or biomedical text to their corresponding Human Phenotype Ontology (HPO) codes. It ensures that observed symptoms, signs, and clinical abnormalities are standardized using HPO terminology. Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU from sparknlp.pretrained import PretrainedPipeline pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) pipeline = nlp.PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) import com.johnsnowlabs.nlp.pretrained.PretrainedPipeline val pipeline = PretrainedPipeline(&quot;hpo_mapper_pipeline&quot;, &quot;en&quot;, &quot;clinical/models&quot;) val result = pipeline.fullAnnotate(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;) Results +------------------+-----+---+-----+----------+ | chunk|begin|end|label| hpo_code| +------------------+-----+---+-----+----------+ | APNEA| 0| 4| HPO|HP:0002104| | apnea| 16| 20| HPO|HP:0002104| |HYPERBILIRUBINEMIA| 66| 83| HPO|HP:0002904| |hyperbilirubinemia| 91|108| HPO|HP:0002904| | sepsis| 167|172| HPO|HP:0100806| +------------------+-----+---+-----+----------+ Model Information Model Name: hpo_mapper_pipeline Type: pipeline Compatibility: Healthcare NLP 6.0.0+ License: Licensed Edition: Official Language: en Size: 4.0 MB Included Models DocumentAssembler TokenizerModel StopWordsCleaner TokenAssembler SentenceDetectorDLModel TokenizerModel TextMatcherInternalModel ChunkMapperModel</summary></entry><entry><title type="html">Stop Words Cleaner for HPO</title><link href="/2025/05/02/stopwords_removal_hpo_en.html" rel="alternate" type="text/html" title="Stop Words Cleaner for HPO" /><published>2025-05-02T00:00:00+00:00</published><updated>2025-05-02T00:00:00+00:00</updated><id>/2025/05/02/stopwords_removal_hpo_en</id><content type="html" xml:base="/2025/05/02/stopwords_removal_hpo_en.html">## Description

This model is designed to remove stop words from clinical phenotype descriptions, particularly in the context of Human Phenotype Ontology (HPO).

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/stopwords_removal_hpo_en_5.5.3_3.0_1746187715959.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/stopwords_removal_hpo_en_5.5.3_3.0_1746187715959.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

stopwords_cleaner = StopWordsCleaner.pretrained(&quot;stopwords_removal_hpo&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
    .setInputCols(&quot;token&quot;)\
    .setOutputCol(&quot;cleanTokens&quot;)\
    .setCaseSensitive(False)
    
pipeline = Pipeline().setStages([
    document_assembler,
    tokenizer,
    stopwords_cleaner
])

text_df = spark.createDataFrame([[&quot;The patient shows no signs of muscle weakness or developmental delay&quot;]]).toDF(&quot;text&quot;)
result_df = pipeline.fit(text_df).transform(text_df)
```

{:.jsl-block}
```python
document_assembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

stopwords_cleaner = nlp.StopWordsCleaner.pretrained(&quot;stopwords_removal_hpo&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \
    .setInputCols(&quot;token&quot;)\
    .setOutputCol(&quot;cleanTokens&quot;)\
    .setCaseSensitive(False)
    
pipeline = nlp.Pipeline().setStages([
    document_assembler,
    tokenizer,
    stopwords_cleaner
])

text_df = spark.createDataFrame([[&quot;The patient shows no signs of muscle weakness or developmental delay&quot;]]).toDF(&quot;text&quot;)
result_df = pipeline.fit(text_df).transform(text_df)
```
```scala
import spark.implicits._
val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;token&quot;)

val stopWordsCleaner = StopWordsCleaner.pretrained(&quot;stopwords_removal_hpo&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(&quot;token&quot;)
  .setOutputCol(&quot;cleanTokens&quot;)
  .setCaseSensitive(false)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  tokenizer,
  stopWordsCleaner
))

val textData = Seq(
  &quot;The patient shows no signs of muscle weakness or developmental delay&quot;
).toDF(&quot;text&quot;)

val model = pipeline.fit(textData)
val resultDF = model.transform(textData)
```
&lt;/div&gt;

## Results

```bash
|   | token         | cleanTokens    |
|---|---------------|----------------|
| 0 | The           | --             |
| 1 | patient       | patient        |
| 2 | shows         | shows          |
| 3 | no            | no             |
| 4 | signs         | signs          |
| 5 | of            | --             |
| 6 | muscle        | muscle         |
| 7 | weakness      | weakness       |
| 8 | or            | --             |
| 9 | developmental | developmental  |
|10 | delay         | delay          |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|stopwords_removal_hpo|
|Compatibility:|Healthcare NLP 5.5.3+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[token]|
|Output Labels:|[cleanTokens]|
|Language:|en|
|Size:|1.4 KB|
|Case sensitive:|false|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="clinical" /><category term="hpo" /><category term="stopwords" /><summary type="html">Description This model is designed to remove stop words from clinical phenotype descriptions, particularly in the context of Human Phenotype Ontology (HPO). Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) stopwords_cleaner = StopWordsCleaner.pretrained(&quot;stopwords_removal_hpo&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols(&quot;token&quot;)\ .setOutputCol(&quot;cleanTokens&quot;)\ .setCaseSensitive(False) pipeline = Pipeline().setStages([ document_assembler, tokenizer, stopwords_cleaner ]) text_df = spark.createDataFrame([[&quot;The patient shows no signs of muscle weakness or developmental delay&quot;]]).toDF(&quot;text&quot;) result_df = pipeline.fit(text_df).transform(text_df) document_assembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) stopwords_cleaner = nlp.StopWordsCleaner.pretrained(&quot;stopwords_removal_hpo&quot;, &quot;en&quot;, &quot;clinical/models&quot;) \ .setInputCols(&quot;token&quot;)\ .setOutputCol(&quot;cleanTokens&quot;)\ .setCaseSensitive(False) pipeline = nlp.Pipeline().setStages([ document_assembler, tokenizer, stopwords_cleaner ]) text_df = spark.createDataFrame([[&quot;The patient shows no signs of muscle weakness or developmental delay&quot;]]).toDF(&quot;text&quot;) result_df = pipeline.fit(text_df).transform(text_df) import spark.implicits._ val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val stopWordsCleaner = StopWordsCleaner.pretrained(&quot;stopwords_removal_hpo&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopWordsCleaner )) val textData = Seq( &quot;The patient shows no signs of muscle weakness or developmental delay&quot; ).toDF(&quot;text&quot;) val model = pipeline.fit(textData) val resultDF = model.transform(textData) Results | | token | cleanTokens | |---|---------------|----------------| | 0 | The | -- | | 1 | patient | patient | | 2 | shows | shows | | 3 | no | no | | 4 | signs | signs | | 5 | of | -- | | 6 | muscle | muscle | | 7 | weakness | weakness | | 8 | or | -- | | 9 | developmental | developmental | |10 | delay | delay | Model Information Model Name: stopwords_removal_hpo Compatibility: Healthcare NLP 5.5.3+ License: Licensed Edition: Official Input Labels: [token] Output Labels: [cleanTokens] Language: en Size: 1.4 KB Case sensitive: false</summary></entry><entry><title type="html">Mapping Phenotype Entities with Corresponding HPO Codes</title><link href="/2025/05/01/hpo_mapper_en.html" rel="alternate" type="text/html" title="Mapping Phenotype Entities with Corresponding HPO Codes" /><published>2025-05-01T00:00:00+00:00</published><updated>2025-05-01T00:00:00+00:00</updated><id>/2025/05/01/hpo_mapper_en</id><content type="html" xml:base="/2025/05/01/hpo_mapper_en.html">## Description

This model is designed to map extracted phenotype entities from clinical or biomedical text to their corresponding Human Phenotype Ontology (HPO) codes. It ensures that observed symptoms, signs, and clinical abnormalities are standardized using HPO terminology.

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/hpo_mapper_en_6.0.0_3.0_1746106791365.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/hpo_mapper_en_6.0.0_3.0_1746106791365.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

stopwords_cleaner = StopWordsCleaner()\
    .setInputCols(&quot;token&quot;)\
    .setOutputCol(&quot;cleanTokens&quot;)\
    .setCaseSensitive(False)

token_assembler = TokenAssembler()\
    .setInputCols(['document',&quot;cleanTokens&quot;])\
    .setOutputCol(&quot;cleanTokens_newDoc&quot;)

sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) \
    .setInputCols([&quot;cleanTokens_newDoc&quot;]) \
    .setOutputCol(&quot;sentence&quot;) 

tokenizer_2 = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;clean_tokens&quot;)

entityExtractor = TextMatcherInternalModel().pretrained(&quot;hpo_matcher&quot;,&quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;clean_tokens&quot;])\
    .setOutputCol(&quot;hpo_term&quot;)\
    .setCaseSensitive(False)\
    .setMergeOverlapping(False)

mapper = ChunkMapperModel().pretrained(&quot;hpo_mapper&quot;,&quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;hpo_term&quot;])\
    .setOutputCol(&quot;hpo_code&quot;)\
    .setLowerCase(True)

mapper_pipeline = Pipeline().setStages([
                  documentAssembler,                  
                  tokenizer,
                  stopwords_cleaner,
                  token_assembler,
                  sentenceDetector,
                  tokenizer_2,
                  entityExtractor,
                  mapper])

text =  ''' APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation. '''

data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)
 
mapper_model = mapper_pipeline.fit(data).transform(data)
```

{:.jsl-block}
```python
documentAssembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

stopwords_cleaner = nlp.StopWordsCleaner()\
    .setInputCols(&quot;token&quot;)\
    .setOutputCol(&quot;cleanTokens&quot;)\
    .setCaseSensitive(False)

token_assembler = nlp.TokenAssembler()\
    .setInputCols(['document',&quot;cleanTokens&quot;])\
    .setOutputCol(&quot;cleanTokens_newDoc&quot;)

sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) \
    .setInputCols([&quot;cleanTokens_newDoc&quot;]) \
    .setOutputCol(&quot;sentence&quot;) 

tokenizer_2 = nlp.Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;clean_tokens&quot;)

entityExtractor = medical.TextMatcherInternalModel().pretrained(&quot;hpo_matcher&quot;,&quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;clean_tokens&quot;])\
    .setOutputCol(&quot;hpo_term&quot;)\
    .setCaseSensitive(False)\
    .setMergeOverlapping(False)

mapper = medical.ChunkMapperModel().pretrained(&quot;hpo_mapper&quot;,&quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;hpo_term&quot;])\
    .setOutputCol(&quot;hpo_code&quot;)\
    .setLowerCase(True)

mapper_pipeline = nlp.Pipeline().setStages([
                  documentAssembler,                  
                  tokenizer,
                  stopwords_cleaner,
                  token_assembler,
                  sentenceDetector,
                  tokenizer_2,
                  entityExtractor,
                  mapper])

text =  ''' APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation. '''

data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)
 
mapper_model = mapper_pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;token&quot;)

val stopwordsCleaner = new StopWordsCleaner()
  .setInputCols(&quot;token&quot;)
  .setOutputCol(&quot;cleanTokens&quot;)
  .setCaseSensitive(false)

val tokenAssembler = new TokenAssembler()
  .setInputCols(Array(&quot;document&quot;, &quot;cleanTokens&quot;))
  .setOutputCol(&quot;cleanTokens_newDoc&quot;)

val sentenceDetector = SentenceDetectorDLModel
  .pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(Array(&quot;cleanTokens_newDoc&quot;))
  .setOutputCol(&quot;sentence&quot;)

val tokenizer_2 = new Tokenizer()
  .setInputCols(&quot;sentence&quot;)
  .setOutputCol(&quot;clean_tokens&quot;)

val entityExtractor = TextMatcherInternalModel
  .pretrained(&quot;hpo_matcher&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(Array(&quot;sentence&quot;, &quot;clean_tokens&quot;))
  .setOutputCol(&quot;hpo_term&quot;)
  .setCaseSensitive(false)
  .setMergeOverlapping(false)

val mapper = medical.ChunkMapperModel
    .pretrained(&quot;hpo_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(&quot;hpo_term&quot;)
    .setOutputCol(&quot;hpo_code&quot;)
    .setLowerCase(True)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  tokenizer,
  stopwordsCleaner,
  tokenAssembler,
  sentenceDetector,
  tokenizer_2,
  entityExtractor,
  mapper
))

val data = Seq(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
GENETICS: Holds thumbs in palms, findings on Hemolytic Uremic Syndrome, history of meconium plugs.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;).toDF(&quot;text&quot;)

val mapper = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+------------------+-----+---+-----+----------+
|             chunk|begin|end|label|  hpo_code|
+------------------+-----+---+-----+----------+
|             APNEA|    0|  4|  HPO|HP:0002104|
|             apnea|   16| 20|  HPO|HP:0002104|
|HYPERBILIRUBINEMIA|   66| 83|  HPO|HP:0002904|
|hyperbilirubinemia|   91|108|  HPO|HP:0002904|
|            sepsis|  167|172|  HPO|HP:0100806|
+------------------+-----+---+-----+----------+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|hpo_mapper|
|Compatibility:|Healthcare NLP 6.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[ner_chunk]|
|Output Labels:|[hpo_code]|
|Language:|en|
|Size:|1.5 MB|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="clinical" /><category term="licensed" /><category term="hpo" /><summary type="html">Description This model is designed to map extracted phenotype entities from clinical or biomedical text to their corresponding Human Phenotype Ontology (HPO) codes. It ensures that observed symptoms, signs, and clinical abnormalities are standardized using HPO terminology. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU documentAssembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) stopwords_cleaner = StopWordsCleaner()\ .setInputCols(&quot;token&quot;)\ .setOutputCol(&quot;cleanTokens&quot;)\ .setCaseSensitive(False) token_assembler = TokenAssembler()\ .setInputCols(['document',&quot;cleanTokens&quot;])\ .setOutputCol(&quot;cleanTokens_newDoc&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) \ .setInputCols([&quot;cleanTokens_newDoc&quot;]) \ .setOutputCol(&quot;sentence&quot;) tokenizer_2 = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;clean_tokens&quot;) entityExtractor = TextMatcherInternalModel().pretrained(&quot;hpo_matcher&quot;,&quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;clean_tokens&quot;])\ .setOutputCol(&quot;hpo_term&quot;)\ .setCaseSensitive(False)\ .setMergeOverlapping(False) mapper = ChunkMapperModel().pretrained(&quot;hpo_mapper&quot;,&quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;hpo_term&quot;])\ .setOutputCol(&quot;hpo_code&quot;)\ .setLowerCase(True) mapper_pipeline = Pipeline().setStages([ documentAssembler, tokenizer, stopwords_cleaner, token_assembler, sentenceDetector, tokenizer_2, entityExtractor, mapper]) text = ''' APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation. ''' data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) mapper_model = mapper_pipeline.fit(data).transform(data) documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) stopwords_cleaner = nlp.StopWordsCleaner()\ .setInputCols(&quot;token&quot;)\ .setOutputCol(&quot;cleanTokens&quot;)\ .setCaseSensitive(False) token_assembler = nlp.TokenAssembler()\ .setInputCols(['document',&quot;cleanTokens&quot;])\ .setOutputCol(&quot;cleanTokens_newDoc&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) \ .setInputCols([&quot;cleanTokens_newDoc&quot;]) \ .setOutputCol(&quot;sentence&quot;) tokenizer_2 = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;clean_tokens&quot;) entityExtractor = medical.TextMatcherInternalModel().pretrained(&quot;hpo_matcher&quot;,&quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;clean_tokens&quot;])\ .setOutputCol(&quot;hpo_term&quot;)\ .setCaseSensitive(False)\ .setMergeOverlapping(False) mapper = medical.ChunkMapperModel().pretrained(&quot;hpo_mapper&quot;,&quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;hpo_term&quot;])\ .setOutputCol(&quot;hpo_code&quot;)\ .setLowerCase(True) mapper_pipeline = nlp.Pipeline().setStages([ documentAssembler, tokenizer, stopwords_cleaner, token_assembler, sentenceDetector, tokenizer_2, entityExtractor, mapper]) text = ''' APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation. ''' data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) mapper_model = mapper_pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val stopwordsCleaner = new StopWordsCleaner() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val tokenAssembler = new TokenAssembler() .setInputCols(Array(&quot;document&quot;, &quot;cleanTokens&quot;)) .setOutputCol(&quot;cleanTokens_newDoc&quot;) val sentenceDetector = SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;cleanTokens_newDoc&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer_2 = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;clean_tokens&quot;) val entityExtractor = TextMatcherInternalModel .pretrained(&quot;hpo_matcher&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;clean_tokens&quot;)) .setOutputCol(&quot;hpo_term&quot;) .setCaseSensitive(false) .setMergeOverlapping(false) val mapper = medical.ChunkMapperModel .pretrained(&quot;hpo_mapper&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(&quot;hpo_term&quot;) .setOutputCol(&quot;hpo_code&quot;) .setLowerCase(True) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopwordsCleaner, tokenAssembler, sentenceDetector, tokenizer_2, entityExtractor, mapper )) val data = Seq(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. GENETICS: Holds thumbs in palms, findings on Hemolytic Uremic Syndrome, history of meconium plugs. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;).toDF(&quot;text&quot;) val mapper = pipeline.fit(data).transform(data) Results +------------------+-----+---+-----+----------+ | chunk|begin|end|label| hpo_code| +------------------+-----+---+-----+----------+ | APNEA| 0| 4| HPO|HP:0002104| | apnea| 16| 20| HPO|HP:0002104| |HYPERBILIRUBINEMIA| 66| 83| HPO|HP:0002904| |hyperbilirubinemia| 91|108| HPO|HP:0002904| | sepsis| 167|172| HPO|HP:0100806| +------------------+-----+---+-----+----------+ Model Information Model Name: hpo_mapper Compatibility: Healthcare NLP 6.0.0+ License: Licensed Edition: Official Input Labels: [ner_chunk] Output Labels: [hpo_code] Language: en Size: 1.5 MB</summary></entry><entry><title type="html">Human Phenotypes Text Matcher</title><link href="/2025/05/01/hpo_matcher_en.html" rel="alternate" type="text/html" title="Human Phenotypes Text Matcher" /><published>2025-05-01T00:00:00+00:00</published><updated>2025-05-01T00:00:00+00:00</updated><id>/2025/05/01/hpo_matcher_en</id><content type="html" xml:base="/2025/05/01/hpo_matcher_en.html">## Description

This model is a text matcher designed to automatically extract mentions of phenotypic abnormalities associated with human diseases from clinical or biomedical text. 

## Predicted Entities



{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/hpo_matcher_en_6.0.0_3.0_1746104158338.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/hpo_matcher_en_6.0.0_3.0_1746104158338.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
```python
documentAssembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

stopwords_cleaner = StopWordsCleaner()\
    .setInputCols(&quot;token&quot;)\
    .setOutputCol(&quot;cleanTokens&quot;)\
    .setCaseSensitive(False)

token_assembler = TokenAssembler()\
    .setInputCols(['document',&quot;cleanTokens&quot;])\
    .setOutputCol(&quot;cleanTokens_newDoc&quot;)

sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) \
    .setInputCols([&quot;cleanTokens_newDoc&quot;]) \
    .setOutputCol(&quot;sentence&quot;) 

tokenizer_2 = Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;clean_tokens&quot;)

entityExtractor = TextMatcherInternalModel().pretrained(&quot;hpo_matcher&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;clean_tokens&quot;])\
    .setOutputCol(&quot;hpo_term&quot;)\
    .setCaseSensitive(False)\
    .setMergeOverlapping(False)

matcher_pipeline = Pipeline().setStages([
                  documentAssembler,                  
                  tokenizer,
                  stopwords_cleaner,
                  token_assembler,
                  sentenceDetector,
                  tokenizer_2,
                  entityExtractor])

text =  ''' APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
GENETICS: Holds thumbs in palms, findings on Hemolytic Uremic Syndrome, history of meconium plugs.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation. '''

data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)
 
matcher_model = matcher_pipeline.fit(data).transform(data)
```

{:.jsl-block}
```python
documentAssembler = nlp.DocumentAssembler()\
    .setInputCol(&quot;text&quot;)\
    .setOutputCol(&quot;document&quot;)

tokenizer = nlp.Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)

stopwords_cleaner = nlp.StopWordsCleaner()\
    .setInputCols(&quot;token&quot;)\
    .setOutputCol(&quot;cleanTokens&quot;)\
    .setCaseSensitive(False)

token_assembler = nlp.TokenAssembler()\
    .setInputCols(['document',&quot;cleanTokens&quot;])\
    .setOutputCol(&quot;cleanTokens_newDoc&quot;)

sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) \
    .setInputCols([&quot;cleanTokens_newDoc&quot;]) \
    .setOutputCol(&quot;sentence&quot;) 

tokenizer_2 = nlp.Tokenizer()\
    .setInputCols([&quot;sentence&quot;])\
    .setOutputCol(&quot;clean_tokens&quot;)

entityExtractor = medical.TextMatcherInternalModel().pretrained(&quot;hpo_matcher&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;clean_tokens&quot;])\
    .setOutputCol(&quot;hpo_term&quot;)\
    .setCaseSensitive(False)\
    .setMergeOverlapping(False)

matcher_pipeline = nlp.Pipeline().setStages([
                  documentAssembler,                  
                  tokenizer,
                  stopwords_cleaner,
                  token_assembler,
                  sentenceDetector,
                  tokenizer_2,
                  entityExtractor])

text =  ''' APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
GENETICS: Holds thumbs in palms, findings on Hemolytic Uremic Syndrome, history of meconium plugs.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation. '''

data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)
 
matcher_model = matcher_pipeline.fit(data).transform(data)
```
```scala
val documentAssembler = new DocumentAssembler()
  .setInputCol(&quot;text&quot;)
  .setOutputCol(&quot;document&quot;)

val tokenizer = new Tokenizer()
  .setInputCols(&quot;document&quot;)
  .setOutputCol(&quot;token&quot;)

val stopwordsCleaner = new StopWordsCleaner()
  .setInputCols(&quot;token&quot;)
  .setOutputCol(&quot;cleanTokens&quot;)
  .setCaseSensitive(false)

val tokenAssembler = new TokenAssembler()
  .setInputCols(Array(&quot;document&quot;, &quot;cleanTokens&quot;))
  .setOutputCol(&quot;cleanTokens_newDoc&quot;)

val sentenceDetector = SentenceDetectorDLModel
  .pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(Array(&quot;cleanTokens_newDoc&quot;))
  .setOutputCol(&quot;sentence&quot;)

val tokenizer2 = new Tokenizer()
  .setInputCols(&quot;sentence&quot;)
  .setOutputCol(&quot;clean_tokens&quot;)

val entityExtractor = TextMatcherInternalModel
  .pretrained(&quot;hpo_matcher&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
  .setInputCols(Array(&quot;sentence&quot;, &quot;clean_tokens&quot;))
  .setOutputCol(&quot;hpo_term&quot;)
  .setCaseSensitive(false)
  .setMergeOverlapping(false)

val pipeline = new Pipeline().setStages(Array(
  documentAssembler,
  tokenizer,
  stopwordsCleaner,
  tokenAssembler,
  sentenceDetector,
  tokenizer2,
  entityExtractor
))

val data = Seq(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &lt; 34 wks gestation at birth.
GENETICS: Holds thumbs in palms, findings on Hemolytic Uremic Syndrome, history of meconium plugs.
HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 
1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;).toDF(&quot;text&quot;)

val matcher = pipeline.fit(data).transform(data)
```
&lt;/div&gt;

## Results

```bash
+-------------------------+-----+---+-----+
|                    chunk|begin|end|label|
+-------------------------+-----+---+-----+
|                    APNEA|    0|  4|  HPO|
|                    apnea|   16| 20|  HPO|
|Hemolytic Uremic Syndrome|  105|129|  HPO|
|       HYPERBILIRUBINEMIA|  156|173|  HPO|
|       hyperbilirubinemia|  181|198|  HPO|
|                   sepsis|  257|262|  HPO|
+-------------------------+-----+---+-----+
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|hpo_matcher|
|Compatibility:|Healthcare NLP 6.0.0+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[hpo_term]|
|Language:|en|
|Size:|2.1 MB|
|Case sensitive:|false|</content><author><name>John Snow Labs</name></author><category term="en" /><category term="licensed" /><category term="clinical" /><category term="hpo" /><summary type="html">Description This model is a text matcher designed to automatically extract mentions of phenotypic abnormalities associated with human diseases from clinical or biomedical text. Predicted Entities Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU documentAssembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) stopwords_cleaner = StopWordsCleaner()\ .setInputCols(&quot;token&quot;)\ .setOutputCol(&quot;cleanTokens&quot;)\ .setCaseSensitive(False) token_assembler = TokenAssembler()\ .setInputCols(['document',&quot;cleanTokens&quot;])\ .setOutputCol(&quot;cleanTokens_newDoc&quot;) sentenceDetector = SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) \ .setInputCols([&quot;cleanTokens_newDoc&quot;]) \ .setOutputCol(&quot;sentence&quot;) tokenizer_2 = Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;clean_tokens&quot;) entityExtractor = TextMatcherInternalModel().pretrained(&quot;hpo_matcher&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;clean_tokens&quot;])\ .setOutputCol(&quot;hpo_term&quot;)\ .setCaseSensitive(False)\ .setMergeOverlapping(False) matcher_pipeline = Pipeline().setStages([ documentAssembler, tokenizer, stopwords_cleaner, token_assembler, sentenceDetector, tokenizer_2, entityExtractor]) text = ''' APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. GENETICS: Holds thumbs in palms, findings on Hemolytic Uremic Syndrome, history of meconium plugs. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation. ''' data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) matcher_model = matcher_pipeline.fit(data).transform(data) documentAssembler = nlp.DocumentAssembler()\ .setInputCol(&quot;text&quot;)\ .setOutputCol(&quot;document&quot;) tokenizer = nlp.Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) stopwords_cleaner = nlp.StopWordsCleaner()\ .setInputCols(&quot;token&quot;)\ .setOutputCol(&quot;cleanTokens&quot;)\ .setCaseSensitive(False) token_assembler = nlp.TokenAssembler()\ .setInputCols(['document',&quot;cleanTokens&quot;])\ .setOutputCol(&quot;cleanTokens_newDoc&quot;) sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(&quot;sentence_detector_dl_healthcare&quot;,&quot;en&quot;,&quot;clinical/models&quot;) \ .setInputCols([&quot;cleanTokens_newDoc&quot;]) \ .setOutputCol(&quot;sentence&quot;) tokenizer_2 = nlp.Tokenizer()\ .setInputCols([&quot;sentence&quot;])\ .setOutputCol(&quot;clean_tokens&quot;) entityExtractor = medical.TextMatcherInternalModel().pretrained(&quot;hpo_matcher&quot;,&quot;en&quot;,&quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;clean_tokens&quot;])\ .setOutputCol(&quot;hpo_term&quot;)\ .setCaseSensitive(False)\ .setMergeOverlapping(False) matcher_pipeline = nlp.Pipeline().setStages([ documentAssembler, tokenizer, stopwords_cleaner, token_assembler, sentenceDetector, tokenizer_2, entityExtractor]) text = ''' APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. GENETICS: Holds thumbs in palms, findings on Hemolytic Uremic Syndrome, history of meconium plugs. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation. ''' data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) matcher_model = matcher_pipeline.fit(data).transform(data) val documentAssembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;token&quot;) val stopwordsCleaner = new StopWordsCleaner() .setInputCols(&quot;token&quot;) .setOutputCol(&quot;cleanTokens&quot;) .setCaseSensitive(false) val tokenAssembler = new TokenAssembler() .setInputCols(Array(&quot;document&quot;, &quot;cleanTokens&quot;)) .setOutputCol(&quot;cleanTokens_newDoc&quot;) val sentenceDetector = SentenceDetectorDLModel .pretrained(&quot;sentence_detector_dl_healthcare&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;cleanTokens_newDoc&quot;)) .setOutputCol(&quot;sentence&quot;) val tokenizer2 = new Tokenizer() .setInputCols(&quot;sentence&quot;) .setOutputCol(&quot;clean_tokens&quot;) val entityExtractor = TextMatcherInternalModel .pretrained(&quot;hpo_matcher&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;clean_tokens&quot;)) .setOutputCol(&quot;hpo_term&quot;) .setCaseSensitive(false) .setMergeOverlapping(false) val pipeline = new Pipeline().setStages(Array( documentAssembler, tokenizer, stopwordsCleaner, tokenAssembler, sentenceDetector, tokenizer2, entityExtractor )) val data = Seq(&quot;&quot;&quot;APNEA: Presumed apnea of prematurity since &amp;lt; 34 wks gestation at birth. GENETICS: Holds thumbs in palms, findings on Hemolytic Uremic Syndrome, history of meconium plugs. HYPERBILIRUBINEMIA: At risk for hyperbilirubinemia d/t prematurity. 1/25-1/30: Received Amp/Gent while undergoing sepsis evaluation.&quot;&quot;&quot;).toDF(&quot;text&quot;) val matcher = pipeline.fit(data).transform(data) Results +-------------------------+-----+---+-----+ | chunk|begin|end|label| +-------------------------+-----+---+-----+ | APNEA| 0| 4| HPO| | apnea| 16| 20| HPO| |Hemolytic Uremic Syndrome| 105|129| HPO| | HYPERBILIRUBINEMIA| 156|173| HPO| | hyperbilirubinemia| 181|198| HPO| | sepsis| 257|262| HPO| +-------------------------+-----+---+-----+ Model Information Model Name: hpo_matcher Compatibility: Healthcare NLP 6.0.0+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [hpo_term] Language: en Size: 2.1 MB Case sensitive: false</summary></entry><entry><title type="html">Detect Assertion Status (assertion_bert_classification_jsl)</title><link href="/2025/04/28/assertion_bert_classification_jsl_en.html" rel="alternate" type="text/html" title="Detect Assertion Status (assertion_bert_classification_jsl)" /><published>2025-04-28T00:00:00+00:00</published><updated>2025-04-28T00:00:00+00:00</updated><id>/2025/04/28/assertion_bert_classification_jsl_en</id><content type="html" xml:base="/2025/04/28/assertion_bert_classification_jsl_en.html">## Description

Assign assertion status to clinical entities.

## Predicted Entities

`Present`, `Planned`, `SomeoneElse`, `Past`, `Family`, `Absent`, `Hypothetical`, `Possible`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_bert_classification_jsl_en_5.5.3_3.0_1745864492083.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/assertion_bert_classification_jsl_en_5.5.3_3.0_1745864492083.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetector()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)
    
embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)\
    .setCaseSensitive(False)

ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)\
    .setWhiteList([&quot;PROBLEM&quot;])
    
assertion_classifier = BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;])\
    .setOutputCol(&quot;assertion_class&quot;)
    
pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    embeddings,
    ner,
    ner_converter,
    assertion_classifier
])

text = &quot;&quot;&quot;Patient with severe fever and sore throat.
He shows no stomach pain and he maintained on an epidural and PCA for pain control.
He also became short of breath with climbing a flight of stairs.
After CT, lung tumor located at the right lower lobe. Father with Alzheimer.
&quot;&quot;&quot;

data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)                         
result = pipeline.fit(data).transform(data)

# show results
result.selectExpr(&quot;explode(assertion_class) as result&quot;)\
      .selectExpr(&quot;result.metadata['ner_chunk'] as ner_chunk&quot;,
                  &quot;result.begin as begin&quot;,
                  &quot;result.begin as end&quot;,
                  &quot;result.metadata['ner_label'] as ner_chunk&quot;,
                  &quot;result.result as assertion&quot;).show(truncate=False)

```

{:.jsl-block}
```python
# Test classifier in Spark NLP pipeline
document_assembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetector()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence&quot;)
    
tokenizer = nlp.Tokenizer() \
    .setInputCols([&quot;sentence&quot;]) \
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)\
    .setCaseSensitive(False)

ner = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = medical.NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)\
    .setWhiteList([&quot;PROBLEM&quot;])
    
assertion_classifier = medical.BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;])\
    .setOutputCol(&quot;assertion_class&quot;)
    
pipeline = nlp.Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    embeddings,
    ner,
    ner_converter,
    assertion_classifier
])

text = &quot;&quot;&quot;Patient with severe fever and sore throat.
He shows no stomach pain and he maintained on an epidural and PCA for pain control.
He also became short of breath with climbing a flight of stairs.
After CT, lung tumor located at the right lower lobe. Father with Alzheimer.
&quot;&quot;&quot;

data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)                         
result = pipeline.fit(data).transform(data)

# show results
result.selectExpr(&quot;explode(assertion_class) as result&quot;)\
      .selectExpr(&quot;result.metadata['ner_chunk'] as ner_chunk&quot;,
                  &quot;result.begin as begin&quot;,
                  &quot;result.begin as end&quot;,
                  &quot;result.metadata['ner_label'] as ner_chunk&quot;,
                  &quot;result.result as assertion&quot;).show(truncate=False)

```
```scala
val document_assembler = new DocumentAssembler() 
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val sentence_detector = new SentenceDetector()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentences&quot;)
    .setOutputCol(&quot;token&quot;)

val embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(False)

val ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)
    .setWhiteList(Array(&quot;PROBLEM&quot;))
        
val assertion_classifier = BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;document&quot;, &quot;ner_chunk&quot;))
    .setOutputCol(&quot;assertion_class&quot;)

val pipeline = new Pipeline().setStages(
    Array(
        document_assembler, 
        sentence_detector,
        tokenizer, 
        embeddings,
        ner,
        ner_converter,
        assertion_classifier
))

val text = &quot;&quot;&quot;Patient with severe fever and sore throat.
He shows no stomach pain and he maintained on an epidural and PCA for pain control.
He also became short of breath with climbing a flight of stairs.
After CT, lung tumor located at the right lower lobe. Father with Alzheimer.
&quot;&quot;&quot;
val data = Seq(Array(text)).toDF(&quot;text&quot;)                         
val result = pipeline.fit(data).transform(data)

```
&lt;/div&gt;

## Results

```bash
|    | ner_chunk       |   begin |   end | ner_chunk   | assertion    |
|---:|:----------------|--------:|------:|:------------|:-------------|
|  0 | severe fever    |      13 |    13 | PROBLEM     | Present      |
|  1 | sore throat     |      30 |    30 | PROBLEM     | Present      |
|  2 | stomach pain    |      55 |    55 | PROBLEM     | Absent       |
|  3 | pain control    |     113 |   113 | PROBLEM     | Hypothetical |
|  4 | short of breath |     142 |   142 | PROBLEM     | Present      |
|  5 | lung tumor      |     202 |   202 | PROBLEM     | Present      |
|  6 | Alzheimer       |     258 |   258 | PROBLEM     | SomeoneElse  |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|assertion_bert_classification_jsl|
|Compatibility:|Healthcare NLP 5.5.3+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[assertion_class]|
|Language:|en|
|Size:|406.3 MB|
|Case sensitive:|true|


## Benchmarking

```bash
       label  precision    recall  f1-score   support
      Absent      0.953     0.975     0.964      1436
      Family      0.930     0.925     0.927       615
Hypothetical      0.898     0.900     0.899       841
        Past      0.936     0.920     0.928      1490
     Planned      0.870     0.840     0.855       326
    Possible      0.887     0.887     0.887       593
     Present      0.949     0.960     0.955      2171
 SomeoneElse      0.891     0.837     0.863       313
    accuracy       -          -       0.930      7785
   macro-avg      0.914     0.906     0.910      7785
weighted-avg      0.930     0.930     0.930      7785
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="jsl" /><category term="en" /><category term="assertion" /><category term="classification" /><category term="tensorflow" /><summary type="html">Description Assign assertion status to clinical entities. Predicted Entities Present, Planned, SomeoneElse, Past, Family, Absent, Hypothetical, Possible Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setCaseSensitive(False) ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;)\ .setWhiteList([&quot;PROBLEM&quot;]) assertion_classifier = BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;])\ .setOutputCol(&quot;assertion_class&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner, ner_converter, assertion_classifier ]) text = &quot;&quot;&quot;Patient with severe fever and sore throat. He shows no stomach pain and he maintained on an epidural and PCA for pain control. He also became short of breath with climbing a flight of stairs. After CT, lung tumor located at the right lower lobe. Father with Alzheimer. &quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) # show results result.selectExpr(&quot;explode(assertion_class) as result&quot;)\ .selectExpr(&quot;result.metadata['ner_chunk'] as ner_chunk&quot;, &quot;result.begin as begin&quot;, &quot;result.begin as end&quot;, &quot;result.metadata['ner_label'] as ner_chunk&quot;, &quot;result.result as assertion&quot;).show(truncate=False) # Test classifier in Spark NLP pipeline document_assembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetector()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols([&quot;sentence&quot;]) \ .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setCaseSensitive(False) ner = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = medical.NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;)\ .setWhiteList([&quot;PROBLEM&quot;]) assertion_classifier = medical.BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;])\ .setOutputCol(&quot;assertion_class&quot;) pipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner, ner_converter, assertion_classifier ]) text = &quot;&quot;&quot;Patient with severe fever and sore throat. He shows no stomach pain and he maintained on an epidural and PCA for pain control. He also became short of breath with climbing a flight of stairs. After CT, lung tumor located at the right lower lobe. Father with Alzheimer. &quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) # show results result.selectExpr(&quot;explode(assertion_class) as result&quot;)\ .selectExpr(&quot;result.metadata['ner_chunk'] as ner_chunk&quot;, &quot;result.begin as begin&quot;, &quot;result.begin as end&quot;, &quot;result.metadata['ner_label'] as ner_chunk&quot;, &quot;result.result as assertion&quot;).show(truncate=False) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;token&quot;) val embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) val ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(Array(&quot;PROBLEM&quot;)) val assertion_classifier = BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_jsl&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;assertion_class&quot;) val pipeline = new Pipeline().setStages( Array( document_assembler, sentence_detector, tokenizer, embeddings, ner, ner_converter, assertion_classifier )) val text = &quot;&quot;&quot;Patient with severe fever and sore throat. He shows no stomach pain and he maintained on an epidural and PCA for pain control. He also became short of breath with climbing a flight of stairs. After CT, lung tumor located at the right lower lobe. Father with Alzheimer. &quot;&quot;&quot; val data = Seq(Array(text)).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results | | ner_chunk | begin | end | ner_chunk | assertion | |---:|:----------------|--------:|------:|:------------|:-------------| | 0 | severe fever | 13 | 13 | PROBLEM | Present | | 1 | sore throat | 30 | 30 | PROBLEM | Present | | 2 | stomach pain | 55 | 55 | PROBLEM | Absent | | 3 | pain control | 113 | 113 | PROBLEM | Hypothetical | | 4 | short of breath | 142 | 142 | PROBLEM | Present | | 5 | lung tumor | 202 | 202 | PROBLEM | Present | | 6 | Alzheimer | 258 | 258 | PROBLEM | SomeoneElse | Model Information Model Name: assertion_bert_classification_jsl Compatibility: Healthcare NLP 5.5.3+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [assertion_class] Language: en Size: 406.3 MB Case sensitive: true Benchmarking label precision recall f1-score support Absent 0.953 0.975 0.964 1436 Family 0.930 0.925 0.927 615 Hypothetical 0.898 0.900 0.899 841 Past 0.936 0.920 0.928 1490 Planned 0.870 0.840 0.855 326 Possible 0.887 0.887 0.887 593 Present 0.949 0.960 0.955 2171 SomeoneElse 0.891 0.837 0.863 313 accuracy - - 0.930 7785 macro-avg 0.914 0.906 0.910 7785 weighted-avg 0.930 0.930 0.930 7785</summary></entry><entry><title type="html">Detect Assertion Status (assertion_bert_classification_radiology)</title><link href="/2025/04/28/assertion_bert_classification_radiology_en.html" rel="alternate" type="text/html" title="Detect Assertion Status (assertion_bert_classification_radiology)" /><published>2025-04-28T00:00:00+00:00</published><updated>2025-04-28T00:00:00+00:00</updated><id>/2025/04/28/assertion_bert_classification_radiology_en</id><content type="html" xml:base="/2025/04/28/assertion_bert_classification_radiology_en.html">## Description

Assign assertion status to clinical entities.

## Predicted Entities

`Confirmed`, `Suspected`, `Negative`

{:.btn-box}
&lt;button class=&quot;button button-orange&quot; disabled&gt;Live Demo&lt;/button&gt;
&lt;button class=&quot;button button-orange&quot; disabled&gt;Open in Colab&lt;/button&gt;
[Download](https://s3.amazonaws.com/auxdata.johnsnowlabs.com/clinical/models/assertion_bert_classification_radiology_en_5.5.3_3.0_1745867798958.zip){:.button.button-orange.button-orange-trans.arr.button-icon.hidden}
[Copy S3 URI](s3://auxdata.johnsnowlabs.com/clinical/models/assertion_bert_classification_radiology_en_5.5.3_3.0_1745867798958.zip){:.button.button-orange.button-orange-trans.button-icon.button-copy-s3}

## How to use



&lt;div class=&quot;tabs-box&quot; markdown=&quot;1&quot;&gt;
{% include programmingLanguageSelectScalaPythonNLU.html %}
  
```python
document_assembler = DocumentAssembler()\
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

sentence_detector = SentenceDetector()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence&quot;)

tokenizer = Tokenizer()\
    .setInputCols([&quot;document&quot;])\
    .setOutputCol(&quot;token&quot;)
    
embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)\
    .setCaseSensitive(False)

ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)\
    .setWhiteList([&quot;PROBLEM&quot;])
    
assertion_classifier = BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;])\
    .setOutputCol(&quot;assertion_class&quot;)
    
pipeline = Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    embeddings,
    ner,
    ner_converter,
    assertion_classifier
])

text = &quot;&quot;&quot;Patient with severe fever and sore throat.
He shows no stomach pain and he maintained on an epidural and PCA for pain control.
He also became short of breath with climbing a flight of stairs.
After CT, lung tumor located at the right lower lobe. Father with Alzheimer.
&quot;&quot;&quot;

data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)                         
result = pipeline.fit(data).transform(data)

# show results
result.selectExpr(&quot;explode(assertion_class) as result&quot;)\
      .selectExpr(&quot;result.metadata['ner_chunk'] as ner_chunk&quot;,
                  &quot;result.begin as begin&quot;,
                  &quot;result.begin as end&quot;,
                  &quot;result.metadata['ner_label'] as ner_chunk&quot;,
                  &quot;result.result as assertion&quot;).show(truncate=False)

```

{:.jsl-block}
```python
# Test classifier in Spark NLP pipeline
document_assembler = nlp.DocumentAssembler() \
    .setInputCol(&quot;text&quot;) \
    .setOutputCol(&quot;document&quot;)

sentence_detector = nlp.SentenceDetector()\
    .setInputCols(&quot;document&quot;)\
    .setOutputCol(&quot;sentence&quot;)
    
tokenizer = nlp.Tokenizer() \
    .setInputCols([&quot;sentence&quot;]) \
    .setOutputCol(&quot;token&quot;)

embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\
    .setOutputCol(&quot;embeddings&quot;)\
    .setCaseSensitive(False)

ner = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\
    .setOutputCol(&quot;ner&quot;)

ner_converter = medical.NerConverterInternal()\
    .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\
    .setOutputCol(&quot;ner_chunk&quot;)\
    .setWhiteList([&quot;PROBLEM&quot;])
    
assertion_classifier = medical.BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\
    .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;])\
    .setOutputCol(&quot;assertion_class&quot;)
    
pipeline = nlp.Pipeline(stages=[
    document_assembler, 
    sentence_detector,
    tokenizer,
    embeddings,
    ner,
    ner_converter,
    assertion_classifier
])

text = &quot;&quot;&quot;Patient with severe fever and sore throat.
He shows no stomach pain and he maintained on an epidural and PCA for pain control.
He also became short of breath with climbing a flight of stairs.
After CT, lung tumor located at the right lower lobe. Father with Alzheimer.
&quot;&quot;&quot;

data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;)                         
result = pipeline.fit(data).transform(data)

# show results
result.selectExpr(&quot;explode(assertion_class) as result&quot;)\
      .selectExpr(&quot;result.metadata['ner_chunk'] as ner_chunk&quot;,
                  &quot;result.begin as begin&quot;,
                  &quot;result.begin as end&quot;,
                  &quot;result.metadata['ner_label'] as ner_chunk&quot;,
                  &quot;result.result as assertion&quot;).show(truncate=False)

```
```scala
val document_assembler = new DocumentAssembler() 
    .setInputCol(&quot;text&quot;) 
    .setOutputCol(&quot;document&quot;)

val sentence_detector = new SentenceDetector()
    .setInputCols(&quot;document&quot;)
    .setOutputCol(&quot;sentence&quot;)

val tokenizer = new Tokenizer()
    .setInputCols(&quot;sentences&quot;)
    .setOutputCol(&quot;token&quot;)

val embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;))
    .setOutputCol(&quot;embeddings&quot;)
    .setCaseSensitive(False)

val ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;))
    .setOutputCol(&quot;ner&quot;)

val ner_converter = new NerConverterInternal()
    .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;))
    .setOutputCol(&quot;ner_chunk&quot;)
    .setWhiteList(Array(&quot;PROBLEM&quot;))
        
val assertion_classifier = BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;)
    .setInputCols(Array(&quot;document&quot;, &quot;ner_chunk&quot;))
    .setOutputCol(&quot;assertion_class&quot;)

val pipeline = new Pipeline().setStages(
    Array(
        document_assembler, 
        sentence_detector,
        tokenizer, 
        embeddings,
        ner,
        ner_converter,
        assertion_classifier
))

val text = &quot;&quot;&quot;Patient with severe fever and sore throat.
He shows no stomach pain and he maintained on an epidural and PCA for pain control.
He also became short of breath with climbing a flight of stairs.
After CT, lung tumor located at the right lower lobe. Father with Alzheimer.
&quot;&quot;&quot;
val data = Seq(Array(text)).toDF(&quot;text&quot;)                         
val result = pipeline.fit(data).transform(data)

```
&lt;/div&gt;

## Results

```bash
|    | ner_chunk       |   begin |   end | ner_chunk   | assertion   |
|---:|:----------------|--------:|------:|:------------|:------------|
|  0 | severe fever    |      13 |    13 | PROBLEM     | Confirmed   |
|  1 | sore throat     |      30 |    30 | PROBLEM     | Confirmed   |
|  2 | stomach pain    |      55 |    55 | PROBLEM     | Negative    |
|  3 | pain control    |     113 |   113 | PROBLEM     | Confirmed   |
|  4 | short of breath |     142 |   142 | PROBLEM     | Confirmed   |
|  5 | lung tumor      |     202 |   202 | PROBLEM     | Confirmed   |
|  6 | Alzheimer       |     258 |   258 | PROBLEM     | Confirmed   |
```

{:.model-param}
## Model Information

{:.table-model}
|---|---|
|Model Name:|assertion_bert_classification_radiology|
|Compatibility:|Healthcare NLP 5.5.3+|
|License:|Licensed|
|Edition:|Official|
|Input Labels:|[document, token]|
|Output Labels:|[assertion_class]|
|Language:|en|
|Size:|406.2 MB|
|Case sensitive:|true|


## Benchmarking

```bash
       label  precision    recall  f1-score   support
   Confirmed      0.966     0.955     0.960      3519
    Negative      0.967     0.977     0.972       605
   Suspected      0.866     0.893     0.879      1089
    accuracy        -         -       0.944      5213
   macro-avg      0.933     0.941     0.937      5213
weighted-avg      0.945     0.944     0.945      5213
```</content><author><name>John Snow Labs</name></author><category term="licensed" /><category term="radiology" /><category term="en" /><category term="assertion" /><category term="classification" /><category term="tensorflow" /><summary type="html">Description Assign assertion status to clinical entities. Predicted Entities Confirmed, Suspected, Negative Live Demo Open in Colab Download Copy S3 URI How to use PythonHealthcare NLPPythonJohnSnowLabsScalaNLU document_assembler = DocumentAssembler()\ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) sentence_detector = SentenceDetector()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence&quot;) tokenizer = Tokenizer()\ .setInputCols([&quot;document&quot;])\ .setOutputCol(&quot;token&quot;) embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setCaseSensitive(False) ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;)\ .setWhiteList([&quot;PROBLEM&quot;]) assertion_classifier = BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;])\ .setOutputCol(&quot;assertion_class&quot;) pipeline = Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner, ner_converter, assertion_classifier ]) text = &quot;&quot;&quot;Patient with severe fever and sore throat. He shows no stomach pain and he maintained on an epidural and PCA for pain control. He also became short of breath with climbing a flight of stairs. After CT, lung tumor located at the right lower lobe. Father with Alzheimer. &quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) # show results result.selectExpr(&quot;explode(assertion_class) as result&quot;)\ .selectExpr(&quot;result.metadata['ner_chunk'] as ner_chunk&quot;, &quot;result.begin as begin&quot;, &quot;result.begin as end&quot;, &quot;result.metadata['ner_label'] as ner_chunk&quot;, &quot;result.result as assertion&quot;).show(truncate=False) # Test classifier in Spark NLP pipeline document_assembler = nlp.DocumentAssembler() \ .setInputCol(&quot;text&quot;) \ .setOutputCol(&quot;document&quot;) sentence_detector = nlp.SentenceDetector()\ .setInputCols(&quot;document&quot;)\ .setOutputCol(&quot;sentence&quot;) tokenizer = nlp.Tokenizer() \ .setInputCols([&quot;sentence&quot;]) \ .setOutputCol(&quot;token&quot;) embeddings = nlp.WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;])\ .setOutputCol(&quot;embeddings&quot;)\ .setCaseSensitive(False) ner = medical.NerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;])\ .setOutputCol(&quot;ner&quot;) ner_converter = medical.NerConverterInternal()\ .setInputCols([&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;])\ .setOutputCol(&quot;ner_chunk&quot;)\ .setWhiteList([&quot;PROBLEM&quot;]) assertion_classifier = medical.BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;)\ .setInputCols([&quot;sentence&quot;, &quot;ner_chunk&quot;])\ .setOutputCol(&quot;assertion_class&quot;) pipeline = nlp.Pipeline(stages=[ document_assembler, sentence_detector, tokenizer, embeddings, ner, ner_converter, assertion_classifier ]) text = &quot;&quot;&quot;Patient with severe fever and sore throat. He shows no stomach pain and he maintained on an epidural and PCA for pain control. He also became short of breath with climbing a flight of stairs. After CT, lung tumor located at the right lower lobe. Father with Alzheimer. &quot;&quot;&quot; data = spark.createDataFrame([[text]]).toDF(&quot;text&quot;) result = pipeline.fit(data).transform(data) # show results result.selectExpr(&quot;explode(assertion_class) as result&quot;)\ .selectExpr(&quot;result.metadata['ner_chunk'] as ner_chunk&quot;, &quot;result.begin as begin&quot;, &quot;result.begin as end&quot;, &quot;result.metadata['ner_label'] as ner_chunk&quot;, &quot;result.result as assertion&quot;).show(truncate=False) val document_assembler = new DocumentAssembler() .setInputCol(&quot;text&quot;) .setOutputCol(&quot;document&quot;) val sentence_detector = new SentenceDetector() .setInputCols(&quot;document&quot;) .setOutputCol(&quot;sentence&quot;) val tokenizer = new Tokenizer() .setInputCols(&quot;sentences&quot;) .setOutputCol(&quot;token&quot;) val embeddings = WordEmbeddingsModel.pretrained(&quot;embeddings_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;)) .setOutputCol(&quot;embeddings&quot;) .setCaseSensitive(False) val ner = MedicalNerModel.pretrained(&quot;ner_clinical&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;embeddings&quot;)) .setOutputCol(&quot;ner&quot;) val ner_converter = new NerConverterInternal() .setInputCols(Array(&quot;sentence&quot;, &quot;token&quot;, &quot;ner&quot;)) .setOutputCol(&quot;ner_chunk&quot;) .setWhiteList(Array(&quot;PROBLEM&quot;)) val assertion_classifier = BertForAssertionClassification.pretrained(&quot;assertion_bert_classification_radiology&quot;, &quot;en&quot;, &quot;clinical/models&quot;) .setInputCols(Array(&quot;document&quot;, &quot;ner_chunk&quot;)) .setOutputCol(&quot;assertion_class&quot;) val pipeline = new Pipeline().setStages( Array( document_assembler, sentence_detector, tokenizer, embeddings, ner, ner_converter, assertion_classifier )) val text = &quot;&quot;&quot;Patient with severe fever and sore throat. He shows no stomach pain and he maintained on an epidural and PCA for pain control. He also became short of breath with climbing a flight of stairs. After CT, lung tumor located at the right lower lobe. Father with Alzheimer. &quot;&quot;&quot; val data = Seq(Array(text)).toDF(&quot;text&quot;) val result = pipeline.fit(data).transform(data) Results | | ner_chunk | begin | end | ner_chunk | assertion | |---:|:----------------|--------:|------:|:------------|:------------| | 0 | severe fever | 13 | 13 | PROBLEM | Confirmed | | 1 | sore throat | 30 | 30 | PROBLEM | Confirmed | | 2 | stomach pain | 55 | 55 | PROBLEM | Negative | | 3 | pain control | 113 | 113 | PROBLEM | Confirmed | | 4 | short of breath | 142 | 142 | PROBLEM | Confirmed | | 5 | lung tumor | 202 | 202 | PROBLEM | Confirmed | | 6 | Alzheimer | 258 | 258 | PROBLEM | Confirmed | Model Information Model Name: assertion_bert_classification_radiology Compatibility: Healthcare NLP 5.5.3+ License: Licensed Edition: Official Input Labels: [document, token] Output Labels: [assertion_class] Language: en Size: 406.2 MB Case sensitive: true Benchmarking label precision recall f1-score support Confirmed 0.966 0.955 0.960 3519 Negative 0.967 0.977 0.972 605 Suspected 0.866 0.893 0.879 1089 accuracy - - 0.944 5213 macro-avg 0.933 0.941 0.937 5213 weighted-avg 0.945 0.944 0.945 5213</summary></entry></feed>