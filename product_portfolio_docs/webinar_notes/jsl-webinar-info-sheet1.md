# JSL - Webinar Info - Sheet1

| Col 1 | Col 2 | Col 3 | Col 4 | Col 5 | Col 6 | Col 7 |
| --- | --- | --- | --- | --- | --- | --- |
|  |  |  |  |  |  |  |
|  | Webinar Name | Speakers (Title & Affiliation) | Date (DD/MM/YYYY) | Description/Abstract (4-5 sentences) | YouTube Link | Summary |
|  | Accelerating Rare Disease Diagnosis with Automated HPO Code Extraction from Clinical Notes | Gursev Pirge - Senior Data Scientist & Machine Learning Engineer at John Snow Labs | 2025-10-09 00:00:00 | This webinar highlights the importance of extracting patient phenotypes (observable traits) from unstructured text for rare disease diagnosis. It introduces John Snow Labs' pipeline that automatically ingests multiple clinical documents per patient to extract phenotype and gene mentions, normalize them to Human Phenotype Ontology (HPO) codes, and link phenotypes with gene mentions to aid genomic diagnosis. Real-world benchmarks are presented, showing the pipeline achieves higher accuracy in mapping phenotypic descriptions to HPO codes than existing tools (ClinPhen) and frontier large language models. The solution offers researchers and clinicians a more reliable foundation for precision medicine in rare diseases, with the pipeline outperforming alternative approaches in accuracy and supporting evidence extraction. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Accelerating%20Rare%20Disease%20Diagnosis%20with%20Automated%20HPO%20Code%20Extraction%20from%20Clinical%20Notes.docx?d=wc1d993070dc84b42ba5fddf7fcd77b39&csf=1&web=1&e=bkGRfP |
|  | HIPAA-Compliant Human-in-the-Loop Workflows in the Generative AI Lab | Amit Shrestha - Lead Engineer at John Snow Labs; Pranab Rajbhandari - Project Manager at John Snow Labs | 13/08/2025 | Learn how to implement human-in-the-loop review workflows for de-identification tasks within John Snow Labs' no-code Generative AI Lab while maintaining HIPAA compliance. This webinar demonstrates how sensitive healthcare data pipelines can integrate structured human review to ensure regulatory-grade accuracy, oversight, and traceability. Key capabilities discussed include configurable workflows for human verification of Protected Health Information (PHI) anonymization, system-wide immutable audit logs for compliance audits, and real-time audit dashboards for monitoring reviewer activity and approvals. Whether you are a compliance officer or data steward, the session provides practical tools and insights for deploying secure, auditable de-identification pipelines at scale in high-compliance environments. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/HIPAA-Compliant%20Human-in-the-Loop%20Workflows%20in%20the%20Generativ.docx?d=wd77c29cdaed841a4b1c8edc91861430b&csf=1&web=1&e=rjhP6X |
|  | Consistent Linking, Tokenization, and Obfuscation for Regulatory-Grade De-Identification of Longitudinal Medical Data | Youssef Mellah - Senior Data Scientist & Machine Learning Engineer at John Snow Labs | 23/07/2025 | This webinar delves into advanced techniques for de-identifying longitudinal patient data across diverse sources while ensuring compliance with regulations. It focuses on three core capabilities: Consistent Obfuscation, where patient identifiers (names, hospitals, dates) are replaced with realistic fictitious counterparts in a referentially consistent manner across a dataset; Deterministic Tokenization, which converts patient identifiers (e.g. MRNs or composite personal info) into cryptographic hashes so that records for the same patient can be linked over time without revealing identity; and Multimodal Linking, which applies these methods across different data modalities (EHR text, imaging, PDFs) to reconstruct patient journeys without compromising privacy. The webinar shares benchmark results showing John Snow Labs' de-identification models exceed the threshold for regulatory-grade accuracy and outperform both human experts and other AI services in PHI detection, demonstrating how this cost-effective, scalable solution meets strict privacy standards (HIPAA/GDPR) while accelerating data science initiatives. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Consistent%20Linking,%20Tokenization,%20and%20Obfuscation%20for%20Regulatory-Grade%20De-Identification%20of%20Longitudinal%20Medical%20Data.docx?d=wb2ed22786b194dff804e50ffae6ba823&csf=1&web=1&e=PC3XGD |
|  | Regulatory-Grade Multimodal Medical Data De-Identification and Tokenization | Srikanth Kumar Rana - Field Engineer at Databricks; Youssef Mellah, Ph.D. - Senior Data Scientist & Machine Learning Engineer at John Snow Labs | 16/07/2025 | This webinar shows an end-to-end solution for automating the de-identification and tokenization of large-scale, multimodal medical datasets with regulatory-grade accuracy. Experts from John Snow Labs and Databricks demonstrate how to automatically de-identify structured data, unstructured clinical text, DICOM and JPEG images, whole-slide pathology images, and PDFs using John Snow Labs' software and AI models. They explain how patient tokenization techniques enable linking de-identified data across different modalities and time points (preserving longitudinal consistency without exposing identities), and how to leverage Databricks to process and scale these de-identification workflows on large real-world datasets. The session is ideal for data scientists, clinical researchers, and compliance teams, illustrating how to support HIPAA, GDPR, and other privacy regulations while enabling longitudinal, multi-modal research at scale. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Regulatory-Grade%20Multimodal%20Medical%20Data%20De-Identification%20and%20Tokenization.docx?d=wa5c0df024e2d4fb7a2d85e46d143900f&csf=1&web=1&e=QoLmw4 |
|  | Open-Source Multimodal Data Ingestion and Enrichment at Scale with Spark NLP 6 | Maziyar Panahi - Principal AI/ML Engineer & Senior Team Lead at John Snow Labs | 28/05/2025 | This webinar introduces the capabilities of Spark NLP 6.0, an open-source library for processing large volumes of multi-modal data for batch LLM inference and data preparation for RAG (Retrieval-Augmented Generation) solutions. It highlights three major new features of this release: (1) Support for ingesting and pre-processing a variety of file formats (PDF, Excel, PowerPoint, text, images) into LLM/RAG pipelines through a unified workflow, (2) Integration of multiple visual language models (VLMs) for extracting facts and answers from images and visual PDF content, and (3) The ability to extract structure, semantics, and metadata from unstructured and visual data formats at scale via batch inference. Live Python notebook scenarios are presented to demonstrate how these new features can be applied end-to-end. By attending, viewers learn how to efficiently handle multi-format data inputs and leverage visual NLP models to build scalable, privacy-compliant LLM pipelines - all with Spark NLP 6's optimized performance (which recently surpassed 150 million downloads). | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Open-Source%20Multimodal%20Data%20Ingestion%20and%20Enrichment%20at%20Scale%20with%20Spark%20NLP%206.docx?d=w732f7749692747d2bd9c15c258d9b3db&csf=1&web=1&e=TPgJXR |
|  | Comparing Frontier LLMs on Analyzing Clinical Narratives | David Talby - Chief Executive Officer at John Snow Labs; Veysel Kocaman - Chief Technology Officer at John Snow Labs | 2025-07-05 00:00:00 | This webinar compares the performance of leading large language models on common clinical note analysis tasks. Specifically, it evaluates OpenAI's GPT-4.5, Anthropic's Claude 3.7 "Sonnet," and John Snow Labs' own Medical LLM on five tasks: summarization of a patient's medical history, information extraction (identifying procedures in the past year), question answering (e.g., about biomarkers in a case), de-identification (anonymizing a note per HIPAA safe harbor), and clinical coding (finding billable ICD-10-CM codes). Practicing medical doctors performed a blind evaluation of each model's answers, judging them on factual accuracy, clinical relevance, and conciseness. The webinar presents the evaluation methodology (including measures of inter-annotator agreement and longitudinal drift) and reveals which models the physicians preferred on each task. Attendees gain insight into how frontier LLMs stack up in clinical NLP tasks and the importance of rigorous, expert-driven evaluation for medical AI models. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Comparing%20Frontier%20LLMs%20on%20Analyzing%20Clinical%20Narratives.docx?d=w241c90de95e44a48b5e64ec2a256c499&csf=1&web=1&e=dNbeCg |
|  | An LLM-enabled Medical Terminology Server | Kate Weber - Senior Data Scientist at John Snow Labs | 26/02/2025 | Medical terminology servers ensure different systems speak the same language by providing comprehensive, up-to-date repositories of medical codes and mappings. This webinar introduces a fast, flexible terminology server (deployable privately behind a firewall) that comes pre-loaded with all widely used medical terminologies and offers full APIs and a user interface for advanced concept search, mapping, and normalization. Its standout feature is LLM-powered search, which enables intelligent concept lookup: finding relevant concepts even when exact matches don't exist (handling typos or synonyms), retrieving the most context-appropriate code given a clinical scenario (e.g., suggesting specific diagnosis or treatment codes), and identifying semantically closest concepts for a given term (useful for multi-word terms with various expressions). The session demonstrates how this terminology server, with its AI-driven search, helps map clinical phrases to codes (e.g., SNOMED CT, ICD-10, RxNorm) more effectively, improving interoperability and data quality across healthcare applications. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/An%20LLM-enabled%20Medical%20Terminology%20Server.docx?d=w1d6d6a65594b4908b2e42f7df03259ed&csf=1&web=1&e=Vn7DLr |
|  | Matching Patients with Clinical Guidelines | Veysel Kocaman - Head of Data Science at John Snow Labs | 22/01/2025 | This webinar addresses the challenge of ensuring hospitalized patients receive care aligned with the latest clinical guidelines. It showcases an AI solution that automatically reads a patient's full medical history and finds the most relevant, up-to-date clinical guideline pertinent to that history, presenting it to clinicians in context. The end-to-end architecture is discussed, featuring a state-of-the-art healthcare-specific LLM that can be deployed within an organization's secure environment (maintaining privacy and compliance) to ingest patient data and retrieve applicable guideline content. The session also covers how the system handles complex guideline formats like flowcharts, decision trees, and visual decision tables that general-purpose LLMs struggle with. By the end, attendees see how such a system can assist providers by automatically matching patients to evidence-based guidelines, thus helping close gaps in consistent guideline adherence at the point of care. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Matching%20Patients%20with%20Clinical%20Guidelines.docx?d=w0c451430335d4b0eb8349407b94f31fc&csf=1&web=1&e=pSmlLc |
|  | Integrating Multi-Modal Medical Data Into Unified Patient Journeys | David Talby - Chief Technology Officer at John Snow Labs | 2024-11-12 00:00:00 | Novel applications of generative AI now enable analysis across multiple types of patient data to build a unified longitudinal patient history. In this webinar, David Talby explains how combining NLP with other AI techniques allows one to deduce insights from a patient's full multi-modal record, moving beyond isolated data points. For example, NLP can extract tumor characteristics from pathology reports while computer vision analyzes medical images, and time-series models detect anomalies in vital signs or claims data - together forming a complete patient timeline. The session covers use cases like automatic patient cohort creation, patient-specific question answering, and matching patients to clinical trials or guidelines using these integrated data views. It also discusses practical challenges (explaining AI results to clinicians, refining queries interactively, handling uncertainty) and how to deploy an enterprise-grade, compliant platform (already analyzing millions of patients and billions of documents) that leverages healthcare-specific LLMs to achieve state-of-the-art accuracy on these complex tasks. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Integrating%20Multi-Modal%20Medical%20Data%20Into%20Unified%20Patient%20Journeys.docx?d=w9dcbf637f3d74664806816221e2252fc&csf=1&web=1&e=lXuVzq |
|  | De-identification of Medical Images in DICOM Format | Alberto Andreotti - Data Scientist at John Snow Labs | 13/11/2024 | De-identifying medical images (in DICOM format) is crucial for enabling data sharing while protecting patient privacy, but it presents unique challenges. This webinar outlines several such challenges: often PHI is "burned in" to the image pixels (requiring computer vision or OCR to detect), PHI resides in many metadata fields (including free-text fields) across thousands of DICOM variants, each DICOM study can contain thousands of image slices, and different imaging modalities have specialized considerations. The session then presents a scalable, enterprise-grade solution using John Snow Labs' Visual NLP to accurately anonymize DICOM files. Attendees see how the solution addresses both image pixel data and metadata fields: detecting and removing sensitive info from images (e.g., names on scans) and scrubbing metadata. Live demos and code snippets illustrate how to compute dataset metrics, perform high-volume image de-identification, and scale these workflows to large imaging archives. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/De-Identification%20of%20Medical%20Images%20in%20DICOM%20Format.docx?d=wdef7ecf26b9242d2aab7ca37f36018eb&csf=1&web=1&e=R8QIiV |
|  | Turnkey Deployment of Medical Language Models as Private API Endpoints | Kshitiz Shakya - Software Engineer at John Snow Labs | 28/08/2024 | This webinar demonstrates how John Snow Labs' pre-trained healthcare NLP models can be quickly deployed as private API endpoints and integrated into existing clinical text processing workflows. The session walks through end-to-end examples of discovering, deploying, and utilizing these state-of-the-art models (fine-tuned for the healthcare domain) across three major platforms: AWS SageMaker, Snowflake Marketplace, and Databricks Marketplace. Key highlights include how easily the models can be invoked in your workflows (enhancing efficiency and accuracy in processing medical text), the flexibility to toggle API endpoints on or off as needed to control costs, and various scalable infrastructure options to meet different throughput requirements. Performance benchmarks (accuracy and speed) are shared to help inform decisions on the optimal setup. Overall, attendees learn how to streamline the deployment process, reduce integration hassle, and boost the performance of healthcare applications by treating NLP models as on-demand private services. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Turnkey%20Deployment%20of%20Medical%20Language%20Models%20as%20Private%20API%20Endpoints.docx?d=w50e3f9f6c4714c1abb1303784007e7b0&csf=1&web=1&e=gMzfC2 |
|  | Automated Testing of Bias, Fairness, and Robustness of Language Models in the Generative AI Lab | David Cecchini - Ph.D. at Tsinghua-Berkeley Shenzhen Institute; Data Scientist | 31/06/2024 | Testing AI models for bias, fairness, and robustness is now a legal requirement in industries like healthcare, and this webinar presents new no-code tools to achieve that in John Snow Labs' Generative AI Lab. It introduces features that allow domain experts (with no coding) to create and manage comprehensive test suites to evaluate large language models for biases and weaknesses. The session covers how to generate and reuse test cases (including automatically generating robustness and bias test scenarios), how to manually review and fine-tune tests, and how to execute LLM test suites to get both summary and detailed results. It also shows how these tools support regression testing to compare model versions or different models. By the end, attendees understand how to incorporate responsible AI testing into their LLM development workflow - ensuring that models meet fairness and reliability standards before deployment, all within a user-friendly, no-code interface. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Automated%20Testing%20of%20Bias,%20Fairness,%20and%20Robustness%20of%20Language%20Models%20in%20the%20Generative%20AI%20Lab.docx?d=w2e26511980054762bd7c7a1a1f8313be&csf=1&web=1&e=gFNuMM |
|  | Fast, Cheap, Scalable: Open-Source LLM Inference with Spark NLP | Danilo Burbano - Software and Machine Learning Engineer at John Snow Labs | 26/06/2024 | Learn how to perform high-volume large language model inference efficiently without relying on expensive proprietary APIs or massive hardware setups. In this webinar, Danilo Burbano shows how the open-source Spark NLP library enables optimized, scalable LLM inference pipelines for processing millions of text and image interactions daily. The session demonstrates advanced methods for embedding LLM inference directly into existing big-data processing workflows (thereby improving throughput and reducing latency) and shares benchmarks comparing Spark NLP's performance and cost to both commercial API services and other open-source solutions. Key takeaways include how to drastically cut costs by avoiding per-call API fees, how to integrate LLM inference into your data pipelines for speed, and real-world benchmark results showing Spark NLP's superior speed and cost-efficiency versus alternative approaches. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Fast,%20Cheap,%20Scalable%20Open-Source%20LLM%20Inference%20with%20Spark%20NLP.docx?d=weeddfb415c7d48969f0a330e50db0f77&csf=1&web=1&e=dd9SaA |
|  | New State-of-the-art Accuracy for the 3 Primary Uses of Healthcare Language Models | David Talby - Chief Technology Officer at John Snow Labs | 29/05/2024 | This talk presents record-breaking accuracy levels recently achieved on three of the most common use cases for language models in healthcare. These use cases include: (1) Understanding clinical documents - e.g. extracting information from clinical notes, identifying entities and relations, linking to medical codes, de-identifying PHI, summarizing notes; (2) Reasoning about patients - aggregating data across modalities (text, structured data, imaging, etc.) to create a longitudinal view of a patient with plausible inferences and explanations; and (3) Answering medical questions - accurately answering medical questions (like board exam or research questions) without hallucinations and with cited sources. All results are on public, reproducible benchmarks. Attendees will learn what is now possible in Healthcare AI as of 2024, as the speaker shares how these state-of-the-art models (often fine-tuned or enhanced by John Snow Labs) significantly advance the performance on key NLP tasks relevant to patient care and research. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/New%20State-of-the-art%20Accuracy%20for%20the%203%20Primary%20Uses%20of%20Healthcare%20Language%20Models.docx?d=wd0f54fc0ecfc44eb89bf6cdc5fc7840d&csf=1&web=1&e=2K3qqe |
|  | The 2024 Generative AI in Healthcare Survey | Ben Lorica - Founder, Gradient Flow; David Talby - Chief Technology Officer at John Snow Labs | 30/04/2024 | This webinar shares key findings from the 2024 Generative AI in Healthcare Survey, which gathered input from professionals and tech leaders in February-March 2024. The presenters discuss current adoption levels of generative AI in healthcare and how budgets are being allocated, the types of language models organizations are using (e.g., large proprietary models vs. open-source models), and the top use cases for LLMs in healthcare settings. They also highlight priorities and pain points - such as what criteria teams value when evaluating LLMs, major roadblocks to deployment, and strategies being used to enhance models (fine-tuning, prompt engineering, etc.). The session covers how organizations are approaching Responsible AI, including testing LLMs for bias and robustness to meet new regulations. Attendees come away with a data-driven overview of the state of generative AI in healthcare and insights into industry trends, opportunities, and concerns for the coming year. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/The%202024%20Generative%20AI%20in%20Healthcare%20Survey.docx?d=we6a995238f154850855a7c66bf6d8d70&csf=1&web=1&e=lNu5Tn |
|  | John Snow Labs' Native Integrations with LangChain and HayStack | Muhammet Santas - Senior Data Scientist at John Snow Labs | 28/02/2024 | Learn how to enhance your existing Retrieval-Augmented Generation (RAG) pipelines by integrating John Snow Labs' optimized NLP capabilities with popular frameworks like LangChain and HayStack. This webinar shows that you can keep your current pipeline structure while dramatically improving its accuracy and scalability: accuracy is boosted via customizable embedding generation and smarter document splitting, and scalability (and speed) is improved by swapping in Spark NLP's highly optimized pipelines. Muhammet Santas demonstrates how these native integrations make it easy to transition to more efficient methods without overhauling your application's architecture. Whether your goal is to better protect data privacy (by processing data locally), increase NLP/LLM accuracy, or scale your RAG applications to millions of documents, this session provides the knowledge and tooling to achieve it - all while continuing to use the familiar LangChain or HayStack interfaces enhanced with John Snow Labs' software. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/John%20Snow%20Labs%E2%80%99%20Native%20Integrations%20with%20LangChain%20and%20HayStack.docx?d=w7bf9f24092eb44f4b72a5c43a27fda19&csf=1&web=1&e=yKL6Lt |
|  | Next-Gen Table Extraction from Visual Documents: Leveraging Multimodal AI | Alberto Andreotti - Data Scientist at John Snow Labs | 30/01/2024 | This webinar explores the latest multimodal AI techniques for extracting tabular data from visual documents like PDFs and images. It showcases novel methods implemented in John Snow Labs' Visual NLP library that significantly improve accuracy for information extraction and question answering from complex tables in documents. A key focus is on zero-shot table extraction models - where the AI can interpret and respond to table queries directly from images without any task-specific training. The session demonstrates how the system handles challenging scenarios such as multi-line cells, borderless or irregular table layouts, noisy document backgrounds, and multi-language content. Technical underpinnings are discussed, including how computer vision and OCR are combined to detect tables and cells, and how support for custom borders, unusual layouts, and international formats is achieved. This webinar is ideal for professionals who need to turn visually formatted data into actionable insights, and it offers a deep understanding of how cutting-edge models can be applied to improve data extraction efficiency from visual documents. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Next-Gen%20Table%20Extraction%20from%20Visual%20Documents%20Leveraging%20Multimodal%20AI.docx?d=w8a5b1c2b6ce2415daf5a0f6d27fee2c3&csf=1&web=1&e=jNvXQO |
|  | Building a RAG LLM Clinical Chatbot with John Snow Labs in Databricks | Amir Kermany - Technical Industry Lead for Healthcare & Life Sciences at Databricks; Veysel Kocaman - Head of Data Science at John Snow Labs | 2023-12-12 00:00:00 | In the era of powerful Large Language Models (LLMs) and chatbots, this webinar highlights the advantages of a Retrieval-Augmented Generation (RAG) approach for clinical QA chatbots. The presenters walk through constructing a clinical chatbot that uses John Snow Labs' healthcare-specific LLM and NLP models within the Databricks platform. The system works by leveraging LLMs to query a vectorized knowledge base of medical documents (populated by John Snow Labs' NLP at scale in a Databricks environment), thereby allowing the chatbot to provide accurate, source-backed answers to medical questions. The webinar features a user-friendly interface where clinicians can ask questions in natural language and get answers with cited sources, all without any sensitive data leaving the organization's cloud (no external API calls). Attendees see how this setup maintains data privacy and compliance while enabling near real-time updates to the knowledge base, illustrating a practical approach to deploying AI assistants in healthcare workflows. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Building%20a%20RAG%20LLM%20Clinical%20Chatbot%20with%20John%20Snow%20Labs%20in%20Databricks.docx?d=w8622842ac7454b88ad47f364dbd8c3bc&csf=1&web=1&e=8fRyCi |
|  | Introducing the Medical Research Chatbot | Dia Trambitas - Head of Product at John Snow Labs | 21/11/2023 | This webinar introduces the Medical Research Chatbot, a software platform designed to serve as an intelligent medical assistant for literature-backed information retrieval. Whether you're a clinician seeking evidence-based answers or a researcher querying proprietary documents, this chatbot provides trustworthy answers faster. The session outlines the chatbot's key features: users can ask medical questions in natural language and have a conversational experience (the bot remembers context and allows follow-up questions), each answer comes with cited sources for transparency, and users can build custom knowledge bases from their own documents for the bot to draw from. It also highlights privacy and access controls - content stays private to the organization, and role-based access with single sign-on can be managed for the knowledge bases. Attendees are encouraged to register and try the Medical Research Chatbot to see how it can transform healthcare research by bridging the gap between overwhelming medical literature and the need for fast, reliable answers. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Introducing%20the%20Medical%20Research%20Chatbot.docx?d=wf4b724899cc94057a7b18bdf0608b3ea&csf=1&web=1&e=e9wIqb |
|  | Extracting Social Determinants of Health from Free-Text Medical Records | Gursev Pirge - Researcher & Senior Data Scientist at John Snow Labs | 20/09/2023 | Social Determinants of Health (SDOH) are the non-medical factors (like housing, education, social support) that affect health outcomes. This webinar discusses how to automatically extract SDOH-related information from free-text medical notes using NLP. It explains how creating a profile of SDOH factors for a patient can help healthcare providers target interventions and fill gaps in standard assessments. The session notes that U.S. healthcare systems are increasingly interested in capturing SDOH, and recent advances in electronic health records and NLP present a unique opportunity to document SDOH from clinical text. The speakers describe how John Snow Labs' Healthcare NLP library - the most widely used in healthcare - provides a host of pre-trained models that can identify various SDOH indicators (e.g., housing instability, social support networks, employment status) from unstructured notes. Real examples of SDOH model outputs and the studies behind them are presented, showing attendees how these tools can systematically surface social risk factors to improve patient care. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Extracting%20Social%20Determinants%20of%20Health%20from%20Free-Text%20Medical%20Records.docx?d=w80bdbd799b3a4149b7609171dd5cc65d&csf=1&web=1&e=jmfA6U |
|  | From GPT-4 to Llama-2: Supercharging State-of-the-Art Embeddings for Vector Databases with Spark NLP | Maziyar Panahi - Principal AI/ML Engineer and Senior Team Lead at John Snow Labs | 23/08/2023 | Large Language Models (LLMs) like GPT-4, Llama-2, and Falcon can suffer from hallucinations (making up information) if not grounded in external knowledge. This webinar shows how to mitigate that by using Retrieval-Augmented QA, feeding relevant data from your own dataset into the LLM to make responses more factual. It also addresses how RAG can keep LLMs up-to-date with recent or private data that the base models don't know. A major focus is on the challenge of vectorizing huge volumes of text to populate vector databases for RAG - most NLP libraries aren't designed to process millions of documents efficiently with modern embedding models. The session demonstrates how Spark NLP 5.0 tackles this: offering new state-of-the-art embedding models (like INSTRUCTOR and E5), optimizations like ONNX for faster CPU inference, and native cloud integrations to dramatically boost throughput. Attendees learn strategies to speed up embedding generation and extend LLM knowledge using their proprietary data, overcoming common limitations of LLMs (like stale knowledge and inability to use internal documents) while maintaining scalability. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/From%20GPT4%20to%20Llama-2%20Supercharging%20State-of-the-Art%20Embeddings%20for%20Vector%20Databases%20with%20Spark%20NLP.docx?d=w4490a42ff05b44a5adacb15b5b18226c&csf=1&web=1&e=XavpeD |
|  | Contract Understanding with Legal NLP: building a Paralegal Service with AI | Jose Juan "Juan" Martinez - Senior Data Scientist at John Snow Labs | 21/06/2023 | This webinar demonstrates how Legal NLP techniques can automate the understanding and review of legal documents, essentially building an AI-powered "paralegal" service. It first covers how state-of-the-art NLP models can perform tasks like legal document classification, entity extraction (NER) for legal terms, relation extraction, and question answering on contract text. The session then introduces John Snow Labs Paralegal, an innovative product for reviewing NDA (Non-Disclosure Agreement) contracts. With this service, a user can simply email a DOCX version of an NDA to a designated address and receive a detailed AI-generated report identifying potential issues and subtle nuances in the agreement - effectively getting expert-level feedback in moments. The speakers explain how the system leverages the expertise of seasoned lawyers encoded in the AI to flag concerns in the NDA. By eliminating tedious manual review, this AI Paralegal accelerates contract analysis while maintaining thoroughness, showcasing the future of legal document handling with AI assistance. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Contract%20Understanding%20with%20Legal%20NLP%20building%20a%20Paralegal%20Service%20with%20AI.docx?d=wc47a6f7e2d67461fa35e0bd57d76d82d&csf=1&web=1&e=YXgAWy |
|  | Deliver Safe, Fair & Robust Language Models with the NLPTest Library | Luca Martial - Senior Data Scientist at John Snow Labs | 24/05/2023 | As organizations deploy more NLP and LLM models, there is a growing need for rigorous testing to ensure models are unbiased, robust, and accurate. In this webinar, Luca Martial introduces the NLP Test Library, an open-source framework by John Snow Labs for testing NLP/LLM models across a variety of tasks (question answering, summarization, NER, text classification, etc.). The library (available for free and installable in one line) allows users to generate extensive test cases for models from different libraries (Spark NLP, HuggingFace, spaCy, OpenAI, etc.) and run them to evaluate performance on criteria like fairness and robustness. Uniquely, it also enables augmenting training data based on test outcomes to iteratively improve model performance. The webinar shows how this tool can be used to catch biases or weaknesses in models before deployment and even help fix them by suggesting new training examples. Attendees learn how to easily incorporate the NLPTest Library into their ML workflow to deliver more reliable and responsible AI systems. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Deliver%20Safe,%20Fair%20%26%20Robust%20Language%20Models%20with%20the%20NLPTest%20Library.docx?d=w3e89ef43df1a471a92171d99f45fdcdb&csf=1&web=1&e=cWzjfn |
|  | Automated Summarization of Clinical Notes | Veysel Kocaman - Lead Data Scientist and ML Engineer at John Snow Labs | 26/04/2023 | In this webinar, Veysel Kocaman tackles the challenge of summarizing lengthy clinical notes into concise, relevant summaries. He begins by discussing why summarization is important in healthcare and reviewing various techniques from classic approaches to cutting-edge Large Language Models (LLMs), including both extractive and abstractive summarization methods. The talk then introduces a new clinical text summarization module in Spark NLP for Healthcare, which is built on a state-of-the-art LLM architecture and fine-tuned specifically for the clinical domain. This specialized model can produce high-accuracy summaries of patient notes, preserving critical information. Veysel also conducts a hands-on session with example notebooks, demonstrating how to use these summarization models on real clinical text and showcasing use cases and live results. Attendees leave with an understanding of the latest tools available for clinical note summarization and practical knowledge on implementing them to improve clinical workflows. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Automated%20Summarization%20of%20Clinical%20Notes.docx?d=w65fc1cf209c1473aae1b655ed13e4492&csf=1&web=1&e=3A1VgF |
|  | Zero-Shot Visual Question Answering | Alberto Andreotti - Senior Data Scientist at John Snow Labs | 2023-08-03 00:00:00 | Visual Question Answering (VQA) is emerging as a powerful technique to extract information from documents by asking natural language questions about their content. This webinar explores "OCR-free" VQA models that achieve better accuracy than ever on tasks like extracting information from forms, reports, receipts, and other documents - all without requiring any task-specific training or tuning. Alberto Andreotti discusses common use cases for visual QA and describes how John Snow Labs' Visual NLP library enables building practical VQA pipelines with just a few lines of code. Best practices are shared for deploying these models in real-world scenarios, including how to handle documents of varying layouts and quality. By the end of the session, attendees understand how zero-shot VQA models can be applied to their own document workflows, allowing them to ask questions of scanned documents and get answers immediately, drastically reducing the need for manual data entry or rule-based extraction from forms. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Zero-Shot%20Visual%20Question%20Answering.docx?d=w523ab001425f484fa2382647308d2b17&csf=1&web=1&e=nGK94Z |
|  | State-Of-The-Art Medical Data De-identification and Obfuscation | Jiri Dobes - Head of Solutions at John Snow Labs; Veysel Kocaman - Head of Data Science at John Snow Labs | 23/02/2023 | This webinar covers how to automatically de-identify protected health information (PHI) in medical text with accuracy on par with human experts. It explains that modern NLP techniques can remove patient identifiers from unstructured notes and structured data fields with extremely high accuracy. The speakers highlight that John Snow Labs' Healthcare NLP library has recently achieved new state-of-the-art accuracy on standard PHI de-identification benchmarks - outperforming the major cloud providers' medical NLP services. They then introduce this de-identification solution in detail, comparing its accuracy, speed, and scalability to human annotators and to cloud APIs. The webinar also discusses practical deployment considerations, such as handling multiple languages, applying data obfuscation techniques (like realistic name or date substitution), and recommended configurations for industrial-strength use. Attendees will learn what's required to meet regulatory standards (like HIPAA's Safe Harbor) for de-identification and see how this solution makes it feasible to automatically anonymize large datasets without sacrificing data utility. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/State-Of-The-Art%20Medical%20Data%20De-identification%20and%20Obfuscation.docx?d=w1c6bd7ea646945928dcbc2ab2934b4d5&csf=1&web=1&e=HgJ3Qc |
|  | Combining Prompt Engineering, Programmatic Labelling, and Model Tuning in the No-Code NLP Lab | Dia Trambitas - Lead Product Developer of the NLP Lab at John Snow Labs | 2023-01-02 00:00:00 | This webinar presents the NLP Lab, a no-code platform by John Snow Labs, as a solution for domain experts to fine-tune NLP models for their specific needs without writing code. It addresses the scenario where pre-trained models don't cover every information extraction need, and shows how users can easily improve models by combining three approaches: (1) Programmatic labeling - writing custom rules to automatically label entities in text; (2) Prompt engineering - using natural language prompts to guide the model to extract custom entities or relations; and (3) Transfer learning - training or tuning models on annotated data when available. The session demonstrates via the NLP Lab interface how to quickly test pre-trained models on one's own documents, apply programmatic labels and prompts to cover gaps, and then train improved models - all in an end-to-end workflow. By the end, attendees see how the NLP Lab makes it straightforward to adapt NLP models to their unique tasks, drastically reducing the time and expertise needed compared to traditional model development. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Combining%20Prompt%20Engineering,%20Programmatic%20Labelling,%20and%20Model%20Tuning%20in%20the%20No-Code%20NLP%20Lab.docx?d=wc07aee1a9c634e0fac2338a54cf57e36&csf=1&web=1&e=hf63Za |
|  | NLP for Oncology: Extracting Staging, Histology, Tumor, Biomarker, and Treatment Facts from Clinical Notes | Mauro Nievas Offidani - Medical Doctor & Data Scientist, Healthcare NLP Team at John Snow Labs | 2022-06-12 00:00:00 | Oncology research and care generate vast amounts of unstructured text (pathology reports, clinical notes), and this webinar shows how to leverage Spark NLP for Healthcare to extract critical cancer information from such texts. It begins by noting the immense burden of cancer (nearly 10 million deaths worldwide in 2020) and the efforts in prevention, screening, and treatment research. In this context, NLP can greatly aid by quickly pulling out relevant facts from oncology documents. The session then walks through how to use various model types - Named Entity Recognition to find tumor characteristics, staging, biomarkers, and treatments; assertion status detection to determine presence/absence; relation extraction to connect findings; and entity resolution to map to standard terminologies - specifically tuned for oncology data. The speaker uses example Python notebooks to demonstrate applying these models on sample oncology notes. Attendees learn how these NLP techniques can automate the abstraction of key cancer data (like staging or molecular marker status) from clinical text, supporting tasks like cohort building or treatment outcome tracking. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/NLP%20for%20Oncology%20Extracting%20Staging,%20Histology,%20Tumor,%20Biomarker,%20and%20Treatment%20Facts%20from%20Clinical%20Notes.docx?d=wffd9c5ec51d643048d295f3b2b09d147&csf=1&web=1&e=KdMGqT |
|  | Zero-Shot Learning of Healthcare NLP Models | Hasham Ul Haq - Data Scientist at John Snow Labs; AI Scholar at PI School of AI | 2022-02-11 00:00:00 | Zero-Shot Learning (ZSL) is a paradigm allowing models to handle tasks without direct training on those tasks. This webinar highlights how John Snow Labs applied ZSL to two major NLP tasks in healthcare: Named Entity Recognition (NER) and Relation Extraction. Hasham Ul Haq explains the motivation - reducing the need for large labeled datasets in specialized domains by using models that can generalize from prompts or descriptions of the task. The session demonstrates how Spark NLP for Healthcare includes ZSL models for NER and RE: users can input a description of the entities or relation they want to detect, and the model will identify them in text without having been explicitly trained on that specific entity type or relation. Performance results are shared, showing these ZSL models achieve strong results on real data and substantially cut down the manual annotation requirements. Attendees will see how ZSL techniques can accelerate NLP projects in healthcare by enabling immediate, out-of-the-box recognition of new entity types or relationships, thus bridging the gap until annotated data can be obtained. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Zero-Shot%20Learning%20of%20Healthcare%20NLP%20Models.docx?d=w1678c3e9a69b486884183dcba556c8fa&csf=1&web=1&e=fDyutY |
|  | Automated Text Generation & Data-Augmentation for Medicine, Finance, Law, and E-Commerce | Christian Kasim Loan - Lead Data Scientist & Scala Expert at John Snow Labs | 2022-07-09 00:00:00 | This webinar teaches how to leverage large Transformer-based text generation models to improve NLP classifiers via data augmentation in domains like Medicine, Finance, Law, and E-Commerce. Christian Kasim Loan demonstrates using human-level text generation capabilities of models (such as GPT-style Transformers) to create additional training data and improve model accuracy in classification tasks. The session also explores next-generation creative writing applications - for example, automating marketing text generation for e-commerce or generating plausible clinical trial descriptions - using these models. A crucial portion of the talk is devoted to intuitively explaining the roles of generation parameters like temperature, Top-K sampling, and Top-P (nucleus) sampling, and how they influence the diversity and creativity of the generated text. By adjusting these parameters, users can control the randomness vs. coherence of outputs. All generation and augmentation processes are shown to scale to industry-level GPU or CPU clusters via Spark. Attendees leave understanding how to use text generation to augment datasets and build creative applications, as well as how to tune generation settings for their needs. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Automated%20Text%20Generation%20%26%20Data-Augmentation%20for%20Medicine,%20Finance,%20Law,%20and%20E-Commerce.docx?d=wc63a8a4c15da456aaef9a959fb629bbb&csf=1&web=1&e=aseZnE |
|  | Text classification and named entity recognition with BertForTokenClassification & BertForSequenceClassification | Luca Martial - Data Scientist at John Snow Labs | 27/07/2022 | Recognizing entities in text is a fundamental step in understanding unstructured documents, and classifying documents helps organize large corpora. In this webinar, Luca Martial discusses how Spark NLP implements state-of-the-art BERT-based models for token classification (NER) and sequence classification. He covers the background and motivation behind using BERT (a Transformer model) for these tasks and provides practical code examples of how to utilize  BertForTokenClassification and BertForSequenceClassification within Spark NLP. The webinar also introduces some of the pre-trained BERT models available, including those in Spark NLP's licensed Healthcare library, which can be directly used or fine-tuned for specific needs. Attendees learn how these models can achieve superior accuracy in entity recognition and document classification compared to previous approaches, and how to integrate them into their NLP pipelines. The session offers insights into fine-tuning these models on custom data and highlights real-world use cases in healthcare for tasks like medical named entity recognition and document triage using BERT. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Text%20classification%20and%20named%20entity%20recognition%20with%20BertForTokenClassification%20%26%20BertForSequenceClassification.docx?d=wc00f4fda1ab943cdbeb08cb316b6a841&csf=1&web=1&e=itAube |
|  | Zero Shot Learning for Semantic Relation Extraction from Unstructured Text | Muhammet Santas - Data Scientist (Healthcare NLP Team) at John Snow Labs | 22/06/2022 | Relation Extraction is critical for many NLP applications (especially in healthcare) but training such models usually requires expensive manual labeling of text by experts. This webinar introduces a Zero-Shot Learning approach for semantic relation extraction that eliminates the need for labeled training data. Muhammet Santas explains how, using Spark NLP, one can train or configure relation extraction models without any annotated relations by leveraging zero-shot techniques. The presentation describes how the model can understand what relation to extract simply from a description of that relation (for example, "treats(patient, medication)" or "association between symptom and disease") and then identify instances of it in text. This method has been recently applied in NLP to allow extraction of new kinds of relationships on the fly. Attendees will see how implementing zero-shot relation extraction in unstructured medical texts can drastically reduce the time to develop new relation extractors, as the model does not require a specialized training set for each relation type. The webinar provides guidance on using this approach in Spark NLP and shares any performance considerations, positioning zero-shot RE as a promising solution where labeled data is scarce. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Zero-Shot%20Learning%20of%20Healthcare%20NLP%20Models.docx?d=w1678c3e9a69b486884183dcba556c8fa&csf=1&web=1&e=2fLJ4g |
|  | Building Real-World Healthcare AI Projects from Concept to Production | Juan Martinez - Senior Data Scientist at John Snow Labs; Ken Puffer - Chief Technology Officer for Healthcare Solutions at ePlus | 25/05/2022 | In this webinar, experts from John Snow Labs and ePlus share lessons learned from successfully building and deploying real-world healthcare AI projects. They discuss concrete case studies: for example, how they improved patient flow forecasting at Kaiser Permanente, implemented a real-time clinical decision support system in Psychiatry and Oncology at Mount Sinai, and deployed an automated de-identification solution that processed 700 million patient notes at Providence Health. For each project, they outline the problem, the approach taken, and key learnings on moving from proof-of-concept to production deployment. After sharing these experiences, the webinar showcases a live demo of the recently launched AI Workflow Accelerator Bundle for Healthcare. This bundle is a turnkey solution combining GPU-accelerated NVIDIA hardware, John Snow Labs software (including Spark NLP for Healthcare with 2,300+ pre-trained models/datasets and Spark OCR for handling medical images), and ePlus implementation services. It provides everything needed for an enterprise to jumpstart AI projects: from a vast repository of healthcare-specific models to secure, air-gapped infrastructure for high-compliance environments. The demo highlights capabilities such as pre-loaded healthcare datasets, NLP and OCR pipelines, and built-in security controls, as well as benchmark results showing optimization on the NVIDIA hardware. Viewers come away with practical insight into how large healthcare AI projects are executed and how integrated solutions can accelerate their AI initiatives. | NAN |  |
|  | Deeper Clinical Document Understanding Using Relation Extraction | Hasham Ul Haq - Data Scientist at John Snow Labs | 16/03/2022 | This webinar dives into relation extraction as a means to achieve richer understanding of clinical texts. While identifying individual medical entities (like medications, conditions, procedures) is important, understanding how those entities relate to each other provides critical context (e.g., which medication is prescribed for which condition). The session explains that Spark NLP for Healthcare includes state-of-the-art deep learning models (often BERT-based) to semantically relate entities in unstructured clinical text. Hasham Ul Haq outlines the background and motivation for focusing on relations, describes techniques for extracting relations (such as between problems and treatments, or lab tests and results), and shares real-world use cases where relation extraction adds value (like linking diagnoses to labs in a note). He also touches on implementation details and how these models were trained to achieve peer-reviewed benchmark results. Practical code examples are given to demonstrate how to use Spark NLP's relation extraction models in a pipeline. By the end, attendees understand the significance of moving beyond entity recognition to relation extraction for tasks like building clinical knowledge graphs or improved clinical decision support, and see how to implement these advanced models in their own projects. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Deeper%20Clinical%20Document%20Understanding%20Using%20Relation%20Extractiony.docx?d=w2f766b4e59ab497ea1e19e99db967650&csf=1&web=1&e=tDjLwS |
|  | Rule-Based and Pattern Matching for Entity Recognition in Spark NLP | Danilo Burbano - Software and Machine Learning Engineer at John Snow Labs | 16/02/2022 | This webinar covers how to use rule-based approaches in Spark NLP to recognize entities in text when machine learning models might not be available or sufficient. Danilo Burbano presents two Spark NLP components for pattern matching: the Entity Ruler (available in open-source Spark NLP) and the Contextual Parser (available in Spark NLP for Healthcare). He explains how these allow users to define patterns (like regex or token patterns) to identify custom entities in a scalable way across large document collections. Various use cases are discussed, such as extracting specific lab test names or identifying template phrases in social media text, which can be effectively handled by rule-based methods. The session provides examples of how to write and incorporate these rules, and enumerates the scenarios where rule-based extraction is advantageous (e.g., when precision on known patterns is needed, or training data is too scarce or expensive to obtain). Attendees learn best practices for tuning the available parameters of these annotators and how to decide when a rule-based approach is appropriate. After this webinar, they will know how to implement and combine these pattern matching annotators to boost their information extraction tasks and how to maintain these rulesets over time. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Rule-Based%20and%20Pattern%20Matching%20for%20Entity%20Recognition%20in%20Spark%20NLP.docx?d=waaada5eb97d34d03bfcc221227f433a5&csf=1&web=1&e=3gaDXP |
|  | Automating Clinical Trial Master File Migration & Information Extraction | Jiri Dobes - Head of Solutions at John Snow Labs | 2022-12-01 00:00:00 | Pharmaceutical companies conducting clinical trials often need to migrate millions of trial-related documents (the Trial Master File) to new systems (e.g., after acquiring a drug/trial), which traditionally requires reading and re-indexing each document manually. This webinar presents an NLP-based solution to automate this Trial Master File migration process. It describes how John Snow Labs' system can classify and extract required metadata from these documents with greatly reduced manual effort - achieving about an 80% reduction in labor and timeline in a major real-world project. The solution uses Spark NLP for Healthcare in a human-in-the-loop setup: documents are automatically read and classified into the appropriate categories, key fields are extracted, and humans validate critical pieces. The session highlights that this approach is end-to-end, secure (deployed in an isolated environment with GxP and GAMP5 validation), and fast. They share lessons learned from a deployment at Novartis where the entire trial master file was processed with this approach. Attendees will learn how NLP can accelerate large-scale document migration in pharma by automatically labeling documents and pulling out needed information (like document type, dates, patient IDs, etc.), turning a tedious manual project into a largely automated pipeline while maintaining compliance and accuracy. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Automating%20Clinical%20Trial%20Master%20File%20Migration%20%26%20Information%20Extraction.docx?d=w44672fe516cf4630ba92f4c217de960c&csf=1&web=1&e=KL5ijk |
|  | Enterprise-Scale Data Labeling & Automated Model Training with the Free Annotation Lab | Nabin Khadka - Lead Engineer for the Annotation Lab at John Snow Labs | 15/12/2021 | This webinar introduces attendees to John Snow Labs' Annotation Lab, a free data labeling and model training platform, and how it facilitates large-scale NLP projects. It begins by describing the complexities of annotation at enterprise scale: multiple projects, large annotation teams, ensuring high inter-annotator agreement, and managing tens of thousands of documents efficiently. Nabin Khadka then demonstrates how the Annotation Lab addresses these challenges with features for project management (setting up projects, guidelines, roles), real-time monitoring of annotators' performance, and customizable workflows (e.g., review/approval steps) to guarantee quality. A highlight is how the Annotation Lab integrates automated model training into the labeling process: it can train models on the annotated data continuously and even pre-annotate new documents to speed up the process (a human-in-the-loop approach where the model assists annotators by providing initial suggestions that they correct, achieving up to 5x faster labeling). The webinar showcases how to use pre-trained models to pre-label data, how to correct and improve those labels, and then one-click train a new model on the result - all within the UI. By the end, attendees see how a three-year deployed enterprise tool can drastically improve productivity in creating high-quality datasets and even building better models simultaneously, all without needing the users to write code. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Enterprise-Scale%20Data%20Labeling%20%26%20Automated%20Model%20Training%20with%20the%20Free%20Annotation%20Lab.docx?d=w656e6ca5b8114fbfaaa539e5e558b5f9&csf=1&web=1&e=wH0ezW |
|  | Creating a Clinical Knowledge Graph with Spark NLP and neo4j | Ali Emre Varol - Data Scientist at John Snow Labs | 17/11/2021 | This webinar shows how to construct a clinical knowledge graph by combining natural language processing and graph database technology. A knowledge graph represents a network of medical entities (e.g., diseases, drugs, symptoms) and their relationships, enabling advanced querying and reasoning. The speaker describes a project where Spark NLP was used to extract entities and relations from unstructured clinical text, and those were then ingested into a Neo4j graph database. The result is a comprehensive, semantic representation of medical knowledge that can be queried to answer complex clinical questions. For instance, they demonstrate how one could query the graph for patients who meet a complex set of conditions (like "stage 4 lung cancer patients with no history of smoking") or find connections between clinical concepts across documents. By integrating Spark NLP's ability to identify and normalize medical concepts with Neo4j's graph queries, the marriage of NLP and graph technology allows deeper insights and Q&A on medical data. Attendees will see a concrete example of building such a graph - from extracting concepts with Spark NLP models (for example, extracting drug-disease relationships) to populating Neo4j - and how this approach can be used for tasks like clinical decision support, literature analysis, or patient cohort discovery. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Creating%20a%20Clinical%20Knowledge%20Graph%20with%20Spark%20NLP%20and%20Neo4j.docx?d=wb043f67e27ab4a479103c1f2eaf7dacc&csf=1&web=1&e=qjEmPu |
|  | 1 Line of Code to Use 200+ State-of-the-Art Clinical & Biomedical NLP Models | Christian Kasim Loan - Data Scientist and Spark/Scala ML Engineer | 16/09/2021 | John Snow Labs' new NLU library allows users to tap into hundreds of pre-trained NLP models for healthcare and life sciences with just a single line of code. In this webinar, Christian Kasim Loan (the creator of NLU) walks through how this library provides simple access to a wide range of models: for example, performing named entity recognition for various medical domains, resolving entities to codes (ICD-10, SNOMED, RxNorm, etc.), extracting relations like temporal events and adverse drug effects, de-identifying PHI, and more - all by specifying a pre-trained pipeline with one command. He highlights that the NLU library wraps the powerful Spark NLP models (which include 350+ pretrained models, 100+ embeddings, covering 200+ languages) in an extremely user-friendly API. The session includes live coding where he shows how to get predictions from multiple models (e.g., identifying diseases, drugs, anatomy terms in text) by simply referencing them by name. The webinar also showcases new features like an interactive Streamlit visualization app that comes with NLU, enabling users to test models and see outputs and embeddings visually without coding. Attendees learn how NLU drastically lowers the barrier to using state-of-the-art clinical NLP - turning tasks that would normally require complex configuration into one-liners - and how they can leverage it to become "a data science superhero" by rapidly applying top-performing models to their own text data. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/1%20Line%20of%20Code%20to%20Use%20200+%20State-of-the-Art%20Clinical%20%26%20Biomedical%20NLP%20Models.docx?d=w491a53f182354f4a9aec8d026540d5a2&csf=1&web=1&e=H9dwWJ |
|  | Accurate Table Extraction from Documents & Images with Spark OCR | Mykola Melnyk - Senior Scala/Python/Spark Engineer; Lead Developer of Spark OCR at John Snow Labs | 2021-11-08 00:00:00 | Extracting tabular data from documents is challenging, especially when dealing with scanned images or PDFs where table structures vary greatly. In this webinar, Mykola Melnyk explains how Spark OCR provides an end-to-end solution for table extraction that achieves state-of-the-art accuracy on benchmarks like ICDAR 2013 and TableBank. The solution involves multiple steps: it uses computer vision models to detect the presence and structure of tables in a page (identifying table boundaries and cell layouts) and then applies OCR models to extract text and numeric data from each cell. The approach handles wide variations in table appearance - different fonts, border styles, even purely image-based tables where text isn't electronically searchable. By combining deep learning for table detection with high-accuracy OCR, Spark OCR can convert complex tables in forms, financial statements, clinical reports, etc., into structured data automatically. The webinar includes examples of tables with difficult layouts and demonstrates how the pipeline correctly identifies the rows/columns and outputs a structured representation (for instance, CSV or DataFrame format). Attendees will see how to integrate Spark OCR's table extraction into their workflows, enabling large-scale processing of documents (or images) to accurately capture tabular information that would otherwise require manual data entry. | YouTube Video | https://johnsnowlabs-my.sharepoint.com/:w:/r/personal/omer_johnsnowlabs_com/Documents/Product%20%26%20POC%20Documentation%20-%20To%20review/Webinars/Accurate%20Table%20Extraction%20from%20Documents%20%26%20Images%20with%20Spark%20OCR.docx?d=w2e5c698b43f54379878294cef64ae061&csf=1&web=1&e=p5gOKH |
|  | Speed Optimization & Benchmarks in Spark NLP 3: Making the Most of Modern Hardware | Maziyar Panahi - Senior Data Scientist and Spark NLP Lead at John Snow Labs | 16/06/2021 | Spark NLP 3.0 introduced significant optimizations to take advantage of modern CPUs and GPUs, and this webinar shows how to scale NLP pipelines for enterprise workloads. Maziyar Panahi first provides an overview of Spark NLP's scope: it's the most widely used enterprise NLP library, with support for multiple languages and a highly active community, implementing core NLP tasks and many state-of-the-art transformers under the hood. The talk then focuses on practical tips for scaling and optimizing Spark NLP in different environments. Topics include: how to efficiently distribute NLP workloads on a YARN or Kubernetes cluster, how to leverage GPU acceleration in Spark NLP (for example, using the latest Databricks runtimes with GPU support) to dramatically speed up inference, and how to handle large datasets and long pipelines in memory-constrained scenarios. The webinar shares benchmarks comparing Spark NLP 3's performance on CPU vs GPU, and outlines the improvements in Spark NLP 3 that yield faster processing (such as optimized transformers, better memory management, and compatibility with Spark 3.x enhancements). Attendees get a "tips and tricks" guide for squeezing maximum performance out of Spark NLP - from configuring cluster resources properly to using new pipeline features - ensuring that they can process billions of text records with state-of-the-art models in a reasonable time frame. | YouTube Video |  |
|  | Visual Document Understanding with Multi-Modal Image & Text Mining in Spark OCR 3 | Mykola Melnyk - Senior Scala/Python/Spark Engineer at John Snow Labs | 2021-12-05 00:00:00 | This webinar explores multi-modal document understanding, combining vision and NLP to analyze documents that have both textual and visual elements. Mykola Melnyk introduces the concept that many real-world documents (lab results, clinical forms, invoices) contain important information encoded in their layout or images, which pure text NLP would miss. He presents Spark OCR's implementation of the LayoutLM model - a transformer that takes into account both text and layout position - which has been integrated to achieve new state-of-the-art accuracy on tasks like form understanding (improving accuracy from 70.7 to 79.3), receipt understanding (94.0 to 95.2), and document image classification (93.1 to 94.4). The session demonstrates how Spark OCR 3 can process documents by extracting text with OCR and simultaneously analyzing the layout (coordinates of text, formatting) to produce richer representations. Use cases include extracting key-value pairs from forms, understanding structured PDFs where location matters (like lab report tables or checkboxes), and classifying documents not just by words but by visual cues. The webinar shows example improvements - e.g., correctly parsing complex forms that older OCR systems would scramble - and provides guidance on how to use these multi-modal models in practice. Attendees learn how multi-modal learning can significantly boost information extraction from documents by utilizing spatial information, and how Spark OCR 3 makes this accessible for healthcare and other industries dealing with scanned or structured documents. | YouTube Video |  |
|  | Using & Expanding the NLP Models Hub | Dia Trambitas - Head of Product at John Snow Labs | 2021-10-03 00:00:00 | This webinar provides an overview of John Snow Labs' NLP Models Hub and how it differs from other model repositories, as well as guidance on how users can contribute models to it. Dia Trambitas explains that, unlike generic hubs (TensorFlow Hub, Hugging Face, etc.), the JSL Models Hub emphasizes production-ready, high-quality models for specific tasks rather than a sheer quantity of models. It offers an easy interface to find, understand, and reuse pre-trained models (including all of Spark NLP's official models and community-contributed ones) with extensive documentation on accuracy, datasets, and intended use. The session then delves into the contribution process: community members can submit their own trained models to the hub, but there is a higher bar for acceptance which includes passing automated tests, providing documentation and metadata, and ensuring performance metrics are transparent. This ensures that models on the hub maintain a high standard of quality and reliability. The webinar encourages users to leverage the hub to speed up their projects (by picking from the curated models instead of training from scratch) and also to give back by contributing any novel models they develop. Attendees learn how to access the hub through the UI or API, how to load models with one line of code in NLU or Spark NLP, and how to prepare a model for submission if they want to expand the hub's offerings - effectively creating a virtuous cycle of community-driven improvements. | YouTube Video |  |
|  | State-of-the-art Natural Language Processing for 200+ Languages with 1 Line of code | Dia Trambitas - Head of Product at John Snow Labs | 18/02/2021 | John Snow Labs' NLP library has massively expanded multi-lingual support, and this webinar highlights how developers can tap into NLP for over 200 languages using just one line of code via the NLU library. The talk begins by noting that Spark NLP has delivered 80+ releases, making it the most widely used NLP library in enterprises and providing state-of-the-art models at scale for a variety of tasks. Recent releases have focused on extending language coverage to over 200 languages - including not only Latin-alphabet languages but also those with different scripts (Chinese, Japanese, Arabic, etc.). Dia Trambitas demonstrates features like automatic language detection (supporting up to 375 languages) and how NLU can seamlessly apply tasks like translation, NER, lemmatization, or sentiment analysis in many languages by simply specifying the language in the pipeline name. She shows examples where, in one line, you can detect the language of text and then apply a corresponding model (e.g., identifying healthcare entities in Spanish, or doing sentiment analysis in Arabic). The session also discusses how the hub curates models for low-resource languages and ensures performance. Attendees walk away with an understanding that advanced NLP is no longer limited to English or a few major languages - with John Snow Labs, one can easily incorporate hundreds of languages, dramatically broadening the reach of AI applications globally, all with minimal code and without needing to train models from scratch for each language. | YouTube Video |  |
|  | Automated Drug Adverse Event Detection from Unstructured Text | Julio Bonis - Data Scientist (Healthcare NLP) at John Snow Labs; MD (Medical Doctor) | 13/01/2021 | Adverse Drug Events (ADEs) are a major patient safety concern, and monitoring them in clinical text is crucial for pharmacovigilance. In this webinar, Julio Bonis introduces new deep learning models that automatically detect when an unstructured text (like a doctor's note or patient report) describes an adverse drug event, and extract the key details of that event. One model acts as a document classifier to flag if a given passage contains an ADE, and another performs NER to pull out the specific drug and event terms from the text. Using real examples from clinical narratives and even conversational texts, he demonstrates how these models (available in Spark NLP for Healthcare) can identify, for instance, if a paragraph mentions a patient's adverse reaction to a medication and highlight phrases like the drug name and the adverse outcome. These models are built to be state-of-the-art, leveraging transformers and are fine-tuned on biomedical corpora, achieving high accuracy. The session also emphasizes the importance of such tools: they help pharma companies and healthcare providers detect potential safety signals faster and with far less manual effort. Attendees learn how to apply these ADE detection models to their own text data - for example, scanning through electronic health records or patient forums - and how this fits into an overall pharmacovigilance pipeline (with the models able to feed into databases or trigger alerts for further review). | YouTube Video |  |
|  | John Snow Labs NLU: Become a Data Science Superhero with One Line of Python code | Christian Kasim Loan - Lead Developer of NLU at John Snow Labs | 2020-12-11 00:00:00 | This webinar unveils the newly released NLU library (Natural Language Understanding library) by John Snow Labs, which wraps the complexity of NLP pipelines into a simple interface. Christian Kasim Loan invites data scientists to "become a superhero" by showing how tasks that used to require extensive coding can now be done with one-liners. He demonstrates how with one line of Python code, users can leverage over 350 pre-trained NLP models, 100+ word embeddings, 50+ sentence embeddings, and 50+ classifiers across 46 languages. These include models for NER (covering medical entities, drugs, diseases, etc.), POS tagging, emotion detection, sarcasm detection, question answering, and more - all accessible by simply specifying what you want (e.g., nlu.load("emotion").predict(text) ). The session includes live walkthroughs where he uses NLU to solve real tasks: generating T-SNE visualizations of different embeddings with zero code, achieving top-tier text classification results on a Kaggle dataset with one line, and performing complex pipelines (like de-identification or entity resolution) by just loading the pre-configured pipeline name. The emphasis is on ease of use - making advanced NLP accessible to those who aren't NLP experts - and on the breadth of functionality (covering a wide variety of NLP needs out-of-the-box). The speaker highlights that NLU is built on Spark NLP's robust engine, so it inherits high accuracy and scalability, but abstracts away all tuning and pipeline assembly. Attendees are encouraged to incorporate NLU in their projects to drastically cut down development time and focus on insights rather than model maintenance. | YouTube Video |  |
|  | Answering natural language questions | Prabod Rathnayaka - Graduate Research Assistant and PhD Student at La Trobe University (collaborator with John Snow Labs) | 19/08/2020 | This webinar showcases a system for translating natural language questions into SQL queries to facilitate querying clinical databases via plain English questions. It begins by explaining the value: enabling clinicians or researchers to ask questions like "How many patients over 60 with diabetes have A1C > 8?" in natural language and get answers directly from the database, rather than manually crafting SQL. The solution presented uses advanced deep learning and transfer learning techniques to convert English questions into the corresponding SQL (covering SELECT, FROM, WHERE clauses appropriately). Prabod Rathnayaka describes a case study in which this approach was used to answer clinical questions by training domain-specific models on a Q&A dataset and by incorporating reference data to help the model understand medical context. The resulting system is part of Spark NLP Enterprise and is trainable and scalable, meaning organizations can adapt it to their own database schema and deploy it in-house. The webinar also emphasizes the practicality and production-readiness: it's a trainable, scalable solution that can be integrated with existing clinical data warehouses (with no data leaving the secure environment). Live notebook examples illustrate how a user question gets parsed and turned into a SQL query that yields the correct result. Attendees learn about the latest research behind the scenes (like seq2seq models for text-to-SQL) and see how this research has been engineered into a real product that can greatly streamline how healthcare professionals retrieve information, effectively allowing them to use an AI "data analyst" to query data using natural language. | YouTube Video |  |
|  | Accurate de-identification, obfuscation, and editing of scanned medical documents and images | Dr. Alina Petukhova - Data Scientist at John Snow Labs | 19/08/2020 | This webinar addresses the problem of de-identifying scanned medical documents and images, which contain Protected Health Information (PHI) that must be removed for privacy. Dr. Alina Petukhova describes a complete software system John Snow Labs developed to handle this challenge in real-world hospital settings. She outlines the difficulties: PHI can appear anywhere in free text (so it can't be removed by simple rules), and PHI can be "burned into" images like scanned PDFs or DICOM files where it isn't in text form. The presented solution uses Spark OCR to extract text from both digital text and scanned images/PDFs, then uses Spark NLP's healthcare de-identification models to detect PHI in that text, and finally either deletes or obfuscates that PHI. Additionally, Spark OCR can take the de-identified text and render a new PDF or DICOM image with the PHI removed or masked - essentially editing the original document or image to produce a sanitized version. All of this occurs within a secure local environment (no data is sent to external services) to meet privacy requirements. The session shows an example pipeline: a scanned pathology report PDF is processed and a new PDF is output with patient names and identifiers blacked out, while preserving all other content and structure. It emphasizes lessons learned from deploying this system in production over three years - covering OCR accuracy, edge cases like handwritten text, and performance on large archives. Attendees see how a combination of OCR and NLP can fully anonymize both the text and image content of medical documents, enabling data sharing and secondary use of medical images and scans that were previously hard to de-identify. | YouTube Video |  |
|  | Hardening a Cleanroom AI Platform to allow model training & inference on Protected Health Information | Ali Naqvi - Lead Product Manager of the AI Platform at John Snow Labs | 22/07/2020 | High-compliance industries like healthcare often require creating an "AI cleanroom" - an isolated, secure environment where teams can develop models on sensitive data (like PHI) without risk of data leakage. In this webinar, Ali Naqvi describes the architecture of such a Cleanroom AI Platform that John Snow Labs has built and used for Fortune 500 clients over several years. The platform allows data scientists to log into a hardened environment and perform the entire AI lifecycle (data exploration, model training, evaluation, deployment) inside it, with no data ever leaving. The webinar enumerates hundreds of security features and DevOps/SecOps measures required: multi-factor authentication, end-to-end encryption, strict role-based access control, disabled external network access, point-to-point encryption, continuous vulnerability scanning, and more. It then discusses how using a Kubernetes-based architecture ensures that while everything is locked down, the team doesn't lose benefits like elasticity, scalability, and ease of deployment - essentially, how to achieve "Cleanroom AI" without sacrificing the advantages of cloud computing (like auto-scaling and managed services). Ali explains how the platform supports elasticity (so that it can spin up resources as needed within the cleanroom), but every component - from storage to model registry - is contained and monitored. This platform has been actively used for 3+ years, so the talk includes real-world learnings on balancing usability with security. Attendees will understand what it takes to implement a similar secure AI environment, from governance policies to technical stack (Kubernetes, Terraform, etc.), and why such a platform allows high-compliance organizations to still benefit from AI on their sensitive data. | YouTube Video |  |
|  | Maximizing Text Recognition Accuracy with Image Transformers in Spark OCR | Mykola Melnyk - Lead Developer of Spark OCR at John Snow Labs | 24/06/2020 | Achieving high accuracy in Optical Character Recognition (OCR) often requires pre-processing images to reduce noise and improve text clarity. In this webinar, Mykola Melnyk describes how Spark OCR uses a series of image preprocessing transformers to maximize OCR accuracy on documents. He covers common issues that degrade OCR performance - such as noise (e.g., scanner speckles), skewed or rotated documents, watermarks or stamps, suboptimal scaling, and low contrast - and shows how Spark OCR provides out-of-the-box tools to fix each of these before text extraction. The transformers include noise reduction filters, skew correction algorithms, object removal (to eliminate lines or marks), automated scaling and resolution enhancement, binarization and morphology operations (erosion/dilation) to clarify text, etc. By building custom pipelines of these image transformers, users can effectively clean up even very noisy scans, resulting in dramatically improved OCR results. The session shares real use cases from healthcare and finance where applying these transformations solved issues like faint text on dark backgrounds or handwriting over forms. Benchmarks are provided to quantify accuracy improvements on public datasets when using these pre-processing steps. Attendees learn how to assemble an OCR pipeline that first applies the needed image transformations (which can be chosen and tuned based on the document's characteristics) and then performs text extraction, leading to state-of-the-art OCR accuracy even on challenging documents. Example code and notebook results are shown so they can replicate this in their Spark OCR workflows. | YouTube Video |  |
|  | Best Practices & Tools for Accurate Document Annotation and Data Abstraction | Dia Trambitas - Head of Product at John Snow Labs | 27/05/2020 | Creating high-quality labeled datasets is often the hardest part of NLP projects, and this webinar covers strategies and tools to do it effectively. Dia Trambitas shares best practices for document annotation gleaned from John Snow Labs' experience with projects in healthcare, finance, and other domains. Key points include setting up an annotation team with domain experts and well-defined guidelines, establishing QA workflows to ensure label consistency (like double annotation and adjudication to measure inter-annotator agreement), and using metrics to track annotator performance. The webinar then highlights how technology can support these best practices - specifically, how the John Snow Labs Annotation Lab (a free tool) helps implement them. She demonstrates features like configurable annotation projects, real-time quality monitoring (seeing disagreements and corrections), and productivity boosters (like pre-annotations by models or automated consistency checks) that the tool offers to eliminate common errors and speed up the process. The talk references scenarios such as sentiment analysis or NER projects where following these best practices and using the right tooling cut the project time in half while improving output quality. Attendees are given concrete advice on managing annotation projects at scale - for example, how to break tasks into smaller units, how to do consensus building among annotators - and they see how modern annotation platforms (like the Annotation Lab) incorporate these principles (with features for team management, workflow definitions, and even one-click model training on the labeled data). The session encourages investing time in planning the annotation process and leveraging such tools to avoid common pitfalls and to produce datasets that truly enable robust, unbiased models. | YouTube Video |  |
|  | Automated Mapping of Clinical Entities from Natural Language Text to Medical Terminologies | Andrés Fernández - Machine Learning Engineer and Data Scientist at John Snow Labs | 29/04/2020 | This webinar addresses the challenge of entity normalization in clinical text - mapping various ways of saying the same concept to a standard code in a medical terminology (like SNOMED CT, RxNorm, or ICD-10). Andrés Fernández begins by illustrating the problem: in clinical notes, a condition can be described in many ways ("renal insufficiency" vs "decreased kidney function" vs "renal failure"), and if these are not normalized to the same concept, an algorithm might treat them as unrelated, severely affecting downstream predictions. The talk then explains how Spark NLP for Healthcare provides trainable, deep learning-based entity resolution models to tackle this, as well as a set of pre-trained models for the most common medical terminologies. The session details how these models work: given an extracted entity (like a disease mention), the model finds the best matching standard concept (e.g., a specific SNOMED code) even if the wording in text isn't an exact match. It leverages context and embeddings to handle synonyms, spelling variants, and concept overlaps. Pre-trained models for major terminologies are discussed (covering thousands of codes each), and how they can be fine-tuned to a hospital's custom terminology if needed. Attendees see examples - e.g., mapping drug names to RxNorm, or procedure descriptions to CPT codes - and the improvement in analytics when text is normalized (e.g., grouping all synonyms under one code improved a predictive model's performance significantly). The webinar conveys that accurate entity mapping is a key requirement for healthcare NLP, and shows that with John Snow Labs' library, much of this can be achieved out-of-the-box or with minimal tuning, allowing applications like cohort selection or billing code assignment to be automated with high accuracy. | YouTube Video |  |
|  | AI Model Governance in a High-Compliance Industry | Ali Naqvi - Lead Product Manager of the AI Platform at John Snow Labs | 2020-08-04 00:00:00 | This webinar discusses best practices for AI model governance in industries like healthcare and finance where regulatory compliance and accountability are paramount. Ali Naqvi outlines the elements of model governance: versioning every model and dataset, ensuring reproducibility of training runs, tracking experiments and results, implementing automated CI/CD for model deployment, and monitoring models in production. He then layers on additional requirements when working with sensitive data (e.g., PHI): strong identity and access management, role-based access control for who can see/modify models, formal approval workflows for releasing models into production, and maintaining a full audit trail of model lineage and usage. The webinar then demonstrates how John Snow Labs' Healthcare AI Platform addresses these needs. For instance, it integrates tools like MLflow for experiment tracking (with extended metadata for compliance), has a built-in model registry with access controls, and provides validation reports needed for regulatory review. The platform also automates a lot of the checks (e.g., ensuring de-identification before data is used for training, verifying models meet bias and robustness criteria from the Responsible AI toolkit). Attendees see what a fully governed model lifecycle looks like: from an idea to a model being trained, evaluated, approved by a responsible officer, deployed in a container, and continuously monitored - all steps logged and reproducible. The takeaway is that while model governance can seem burdensome, with the right platform and practices it becomes an enabler for safe innovation. Companies can confidently develop and deploy AI in high-compliance settings by following these practices, turning governance into a competitive advantage rather than a bottleneck. | YouTube Video |  |
|  | Accurate De-Identification of Structured & Unstructured Medical Data at Scale | Julio Bonis - Data Scientist (Healthcare NLP) at John Snow Labs | 18/03/2020 | This webinar summarizes how to automatically de-identify patient data - both structured databases and unstructured text - with high accuracy and scalability. Julio Bonis begins by reviewing HIPAA's requirements for de-identification (e.g., removing 18 identifiers) and the typical use cases for de-id in healthcare (research data sharing, analytics, etc.). The talk explains that John Snow Labs' solution uses Spark NLP for Healthcare's pretrained models to identify PHI in text (names, dates, addresses, contact info, etc.) and also includes methods for structured data (like detecting MRNs or phone numbers in tables). The identified PHI can then be either masked, removed, or obfuscated (replaced with realistic fictitious values) depending on requirements. The webinar highlights that the solution scales to very large datasets - millions of notes or rows - by leveraging Apache Spark's distributed processing, so entire enterprise data lakes can be de-identified efficiently. Case studies are shared where hospitals de-identified years of notes within hours using this approach, attaining over 98% accuracy in PHI removal. The session also covers how the de-identification can be customized (e.g., preserving certain medical terms while removing context around them, or handling uncommon identifiers like device IDs). Attendees leave with an understanding of the state-of-the-art in automated medical data de-identification: it's possible to reliably anonymize text in multiple languages, as well as structured EHR data, in a way that meets regulatory standards and retains analytic value. This opens the door for more secondary use of healthcare data, as privacy concerns can be mitigated with advanced NLP and careful governance. | YouTube Video |  |
|  | State-of-the-art named entity recognition with BERT | Veysel Kocaman - Senior Data Scientist & ML Engineer at John Snow Labs | 26/02/2020 | This webinar walks through how to train a custom Named Entity Recognition (NER) model using BERT embeddings in Spark NLP, thereby leveraging transfer learning to drastically reduce the required training data while achieving state-of-the-art results. Veysel Kocaman explains that deep neural networks like BERT have revolutionized NLP by enabling high accuracy on small datasets via pre-trained contextual embeddings. He then demonstrates a step-by-step example: starting with a dataset of clinical notes annotated for a certain entity (e.g., medication names), he shows how to configure Spark NLP's BertForTokenClassification with a pretrained BERT (e.g., BioBERT or ClinicalBERT) and fine-tune it on the annotated data. The model quickly learns to tag the entities with performance close to or exceeding older models that required much more data. The session covers practical tips, like using the right pre-trained BERT for your domain (choosing a biomedical BERT for medical text), setting up GPUs for faster training, and monitoring training metrics. It also addresses the advantage of using such a model at inference time - BERT-based NER can capture context, so it's less likely to mislabel ambiguous terms compared to dictionary or CRF-based approaches. After fine-tuning, Veysel evaluates the model on test data and shows it outperforms previous benchmarks. The key message is that training custom NER models no longer needs tens of thousands of examples; with transfer learning (BERT) in Spark NLP, even a few hundred examples can be enough to get a robust model for domain-specific entity extraction. Attendees are encouraged to apply this to their own projects - bring a small annotated set, pick a pre-trained transformer, and get a high-quality NER model in a short time using the Spark NLP framework. | YouTube Video |  |
|  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |