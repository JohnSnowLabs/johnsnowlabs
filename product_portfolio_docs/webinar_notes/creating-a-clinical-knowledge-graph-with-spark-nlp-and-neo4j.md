# Creating a Clinical Knowledge Graph with Spark NLP and Neo4j
Creating a Clinical Knowledge Graph with Spark NLP and Neo4j

<https://www.johnsnowlabs.com/watch-webinar-creating-a-clinical-knowledge-graph-with-spark-nlp-and-neo4j/>

<https://www.youtube.com/watch?v=pI9H7Y4h_Sw>

<img src="/media/image.jpg" title="Video titled: Creating a Clinical Knowledge Graph with Spark NLP and Neo4j - Webinar" style="width:6.3125in;height:3.65625in" />

The following is an extraction of the speech from the video transcript, followed by a detailed summary of the key concepts and steps discussed in the webinar.

### **Extracted Speech (Transcript)**

"hello everyone i'm emre i live in istanbul in turkey i'm a data scientist in john snow labs healthcare team we will talk about clinical knowledge graph by on how to create clinical knowledge graph by spark nlp and no4j here is the agenda i'll start explaining spark nlp at first and then we will continue with sparking out being healthcare hobbit works and the pillars of it uh next step will be our other main component to create a knowledge graph its name is neo4j it's a graph database and then i will jump into clinical knowledge graph site i mean what what should be the properties and features of the clinical knowledge graph and the points to be considered by the practitioners i will share some of my experiences about knowledge graphs and then here is the most important part of this talk live demo uh how we can create clinical knowledge graph by spark nlp and neo4j this will be hands-on part so spark nlp is an open source library released in 2017 and right now it has around 40k daily do wnloads our monthly download is about 1.2 million and totally we hit the 10 million already we support four languages python r java and scala the goal was to able to create a single unified nlp library that would require no other dependencies other than spark itself and it should also work on clusters by the way there was no other library that could support to run on spark clusters we also want to take advantage of the transfer learning and implementing the latest and greatest state-of-the-art algorithms so what are the modules of spark nlp we have public and enterprise versions public is totally free and the healthcare models are licensed one licensed one we also have another library which is called sparkle cr as you know mostly data entry starts from like pdfs or images when it comes to clinical texts so ehrs electronic healthcare records or medical records are usually go through sparkles here for that and i'm not for that but i'm not cover that today on the left hand side you see pu blic modules we are supporting more than 200 languages by using the same ner architecture which is another nice point uh to underline uh because we can switch one language to another easily as long as we have the relevant word and word embeddings and uh or word coverage to accomplish a certain task in lp we have some deep learning based emotion detection text classification algorithms or pre-trained models that can that you can just plug and play so instead of trying to build your own pipeline you can just download and use the protein pipelines and then just feed your data frame so you will end up with the latest like state-of-the-art resource using which were various word embeddings including glow and the the latest cool kids in nlp town bert elmo albert chancellor ford so we all support them and you can just use any model like a building block and like a plug-and-play on the right side you see clinical versions like public models we have four main clinical models we have more than th at but let's just cover four of them clinical ner extracting clinical entities uh and we have around more than 50 different ner models uh pertained uh clinical ner models which means like uh the protein on certain clinical nlp data sets that are being used in clinical nlp challenges like i2b2 or and 2c2 datasets uh and we named them like anatomy ner uh ph ner possologeniar gsl ner so and so forth to extract the mini meaningful chunk given the task we use these ner models and on the other hand uh clinical entity linking is uh assigning some snomed uh eric storm icd-10 uh i sedan and the uh going codes calls to these entities detector in er so uh the assertion is very important model in healthcare in the healthcare domain uh it's like if the clinical note is talking about the patient's father not the patients itself we need to know that information so that we can assign different features i mean maybe we will create different features accordingly or if it is not that we can just filter o ut those symptoms maybe for the identification uh be removed or be room i'm sorry we remove or mask the uh sensitive insensitive information uh i mean according to hipaa rules we need to hide or conceal some of the information and these are called as you know the sensitive information and we need to de-identify or obfuscate them obfuscate means like replacing with the fake names or entities so uh we will also have some we also have some protein models that you can plug and play and combine with the public models okay uh next slide we keep a spark nlp up to date and upgrade in every two weeks with releases we have released more than 75 times the main focus is here to have a single unified library for all nlp or nlu tasks and all you needs we are using is select actively and also on the right side you see some comparisons between the nlp libraries with hours like spacey and rtk core nlp and hugging phase so let me show you a sample output of the spark and alpine model uh spark nlp pipeli ne as you see we can extract ner's age entity gender rate entity clinical finding entity relative data entity and dosage of the drug and the frequency of the drug and as you see we can not just extracting these ners we can also map the the codes of this uh some entities like uh clinical finding and the assertion status here past snomed icd-10 and umls codes here and also you see some drug related codes eric storm ndc and we can calculate acc risk adjustment score inside i mean the these are the out of the box uh result of the spark nlp pipelines so let me just talk about the structure of the healthcare healthcare nlp pipelines uh first of all everything starts with ner because it is the meaning a minimum meaningful chunk of uh any clinical text the importance of ner might not be that much in other domain but in healthcare that's very important everything builds upon clinical ner models ner means as you know the name entity recognition and we have many others that i mean we have many ot hers that have nothing to do with nr but when it comes to extract some knowledge uh to get a sense of uh what's going on inside the document inside the clinical document we start with we start with clinical ner model and then use the other models uh like i mean the other models used out of nars as an as an input what are these downstream models these are clinical entity linking assertion status the identification and relation extraction for it for example uh assertions model assigns some status if the feather and sort rot is a problem entity that coming from ner and association uh starts to try to find if it's absent or present i mean given given the text and given the sentence that chunk lives in any art chunk lives in and the if if if we can give another example relation extraction models try to find relation between these entities okay this can be the temporal relation or the cause and effect like cause and effect relations okay so uh this is the why ner is very important and highly valuable in healthcare domain uh here is another example and i just want to mention uh mentioned this i mean it seems to me and it waiting and annotating the data and ner are the brain and heart of the nlp body and and they they manage uh every other tasks and subtasks uh recognition of name entities uh is basically the classification of tokens ner's tries to ner tries to locate and classify predefined categories such as persons locations organizations i mean hospitals medical centers measurements so and so forth uh we use ner to downstream the related tasks to answer real world questions like what which hospital or and department have been admitted by the patient which clinical tech and which clinical tests have been applied to this patient and what are the results what are the test results and which medication or procedure has been started and when relation extraction is another very important part of the nlp and we will we will mostly use this relation extraction to create knowledg e graphs uh and it i mean it is the task of predicting a semantic relationships uh from uh the text relationships usually usually occur be occur between nars uh i mean in er chunks and the core i mean it is the core component uh to build uh relational knowledge graphs uh i mean the the role of this relation extraction uh in nlp applications are question answering and summarizing and etc clinical nr plays a key role in clinical nlp tasks to extract information from healthcare reports you can use it for multiple purposes such as detecting temporal relation relationships between clinical events to drug drug interactions and the relation between medical problems to treatment or medication interactions and so on and so forth i will not go deeper into the importance of the relation extraction medical studies but it is it is it is not uh less important than the ners so uh putting the clinical facts on a timeline this is this is the very big challenge in nlp world and the uh i will i will shar e some of my ideas about this uh this task uh i mean the let me talk about a little bit this uh this issue the automatic extraction of of a patient's natural history from clinical texts or ehrs is a critical step it helps to build intelligent systems that can reason about clinical variables and support decision making uh any intelligence system should be able to extract medical concepts data expressions uh temporal relations and the the order of temporal i mean the the temporal ordering of medical events from the clinical text but uh this task is as i said before the challenge i mean it's very hard to tackle due to the domain specific nature of clinical data such as writing quality and the lack of structure and the presence and the presence of redundant information more generally i think that we can handle this task by combining some rule-based methods unified in output library like spark nlp and the power of knowledge graph to my mind this combination is the most appropriate and the q uickest way to put the clinical facts on a timeline so let me give you some brief introduction to neo4j as you see i'm relaxed neo4j uh as you see i mean they it consists so it's the neo4j i mean the graph databases consist of nodes and relationships and nodes and edges edges keep the relationship on it and the the connected nodes according to this relationship neo4j is a highly scalable native graph database and the core belief behind it connections between data are as important as the data itself this is very nice this is very important point the connections between data are as important as the data itself i'm pretty sure that using the connections between data will create a competitive advantage to produce actionable insights in healthcare so you see some uh some uh features and properties of the graph database and the as you see it's nodes and i mean it's nodes and edges i just keep the relationships on it and the and connect the notes and you you can traverse on the notes and the edges according to your query so you see another and i mean the other kind of uh features of the neo4j it provides acid tx and it's it can be and you can licen you can get license like my sequel mongodb and you can run on its hiroku so and so forth i mean you can get much more detailed information from the optional website of neo4j and cipher is a neo4js graphquery languages language uh it's it's it is a declarative pattern matching language and the declarative meaning you can you you just tell it what you want not how to get it uh this is and this is the same as uh sql uh as you see and also the i mean it's it's also designed for graphs okay see this is this is not sql but this is cipher query languages okay sql uh when we talk about the knowledge graphs or the number talk about the graph databases it's all about patterns i mean you i mean you you just traverse according to your patterns on the on the graph database okay and as you see i mean the there is a two notes here and one rela tionship and this is the actor acted in this movie okay and this is the example of the cipher query on the movie database i mean match actor the relationship kind type is acted in and the movie and you will return you will get the act name of the actor and the roles of the i mean the roles in the movie and title of the movie when we start talk about the knowledge graphs uh here is important uh distinction uh as you see these are not graphs these are charts okay uh i mean it's good to start using the right terminology because these are not graphs these are just charts graph database is different from that these are okay so the purpose of the clinical knowledge graph what should be we need to create data points which accurately represents the patient history rather than creating a patient history which contains a variety of data points this is not easy and because healthcare data are complex as i said before exist in multiple places the redundancy and start with an unstructured and that you can find very i mean inconsistent definitions in the same text so and so forth okay but the the aim of the knowledge graph is i mean represent the patients i mean accurately represent the patient's history and the so it should be a representation and structure and the met and method and it should organize the entire body of the clinical knowledge and also it should contain high relevancy in clinical data and it should be universally accessible so this is the illustration of one of my conceptual graph models and here is the tip of the day especially for clinical ones before creating a knowledge graph you should spend some time uh working on conceptual graph models this is my experience otherwise it is very easy to create graphs that are irrelevant to your purpose i mean it will be complete the mess otherwise because it is very easy to connect the nodes each other after creating the knowledge graph you should validate the graph by querying and cross checking with the raw data like an input and output analysis analysis okay and here is another example uh of the knowledge graph uh as you see we just feed this text to spark nlp and we get we create this knowledge graph okay it's like uh it has i mean like six echelons right here okay and it is not it is not easy but uh sparking yummy i mean you can create a clinical knowledge graph using spark and not neo4j and it's a good combination so uh we end up with the presentation and let me jump into the live demo uh first of all i have created a notebook for you and this is the the spark nlp i mean this is sparking up and neo4j notebook how we can create and show you the how we can create a knowledge graph clinical knowledge graph using spark and arkano4j first of all you will uh you can get uh spark nlp free like free trial right license from our website and you can just try uh i mean give a shot for this for this task i think first of all you will just upload your license keys like this and after that you will uh install some libraries our spark and rp library and i mean the the public version and the gsl unlicensed version pi spark 3.1.2 we are still using this version and also uh spiking up a display library if you want to display some visual visualizations uh i mean they are i mean using the output of the pipeline uh and then you will start the spark nlp gsl okay i'm using the 3.3.2 versions of the public one and the license and here is our pipeline i mean this is the relation extraction pipeline this is possibly generation extraction pipeline because uh we will feed the text about the drugs okay we have documenter this is document assembler and sentence detector uh we will apply a tokenizer and we will get the word embeddings and after that we will get a part of speech tags and after that we will apply a medical ner model and uh we will uh any we will apply any our converting converter i mean the to create i mean to merge the ner tags i mean to create any art chunks and we will apply dependency par ser and after that lastly we will use postal leisure relation extraction model to create the relation semantic relationship between the inert chunks so let me run it you can also reach this notebook from our website i'm in the github github repo under the work i mean under this certification workshops okay and this is our helper function and this is our text while these are running let me show you the uh and what is neo4j and how can you use it uh how can how can you i mean interact with the is spark and i mean how how you will interact with the spark and alpine neo4j at the same time okay first of all you will go to neo4j.com sandbox you will launch a free you can launch a free sandbox and you will get this you will get this page and after that you will just select the blank sandbox it means an empty graph database and you can create it in a minute it's very short and as you see it's ready and we have three days and we can extend it for 10 for additional uh seven days an d you will see some connection details here and we will use them okay so uh let me let me install some uh libraries to uh interact with the neo4j graph database i mean with these sandbox this one and this is the helper function another helpful function and the update data is another helpful function and this is the this is one of our main function and i will just talk about with this and you will see some i mean credentials here first of all uri here is the url okay you will just copy and paste all these all these stuffs from the right side to the left side you will just copy and paste here and here is the password and the username is neo4j and when we run this code snippet we will create a connection between the this notebook and the neo4j graph database so uh what is this function what what this function do first of all check the uh check our relation extraction results okay here you will see some columns here relation entity one and so on begin and end chunk one and two and the othe rs and you will see some confidence here so uh you can see that the chunk one has a relationship between the chunk tool in this manner okay and also chunk one is a duration chunk too is a drug i mean we will create a relationship between phyt amoxillin using this function add ners and relations okay and you will see some batch size here i mean it is for the efficiency and you can just uh walk on i mean you can just uh i mean elaborate on this uh part okay later and the you can here is the here is the our main function here to create this relationship first of all we will create chunk one as a as nodes okay and we will create chunk tool also as nodes and we will create a relationship between them i mean this will be the edge okay we are connecting node one to node two okay so let me let me run it it's ready and we can go down first of all i highly suggest you to drop all constraints and create your own constraints at the beginning of this uh task because uh otherwise it will be created it will be completely a mess uh i mean it will it can be a mess in a graph database site and you can just run this part and you can delete all the nodes drop all the nodes and you will create a constraint here constraint means i mean just uh just to ah assure about the uh each ner is created only once i mean they they are unique okay they will be unique with this part and i will fit relation df here this this the data frame to this function and it's done in just in just in four seconds okay and we will see these notes and edges if we if we try to visualize the graph database and let me run some queries on it these are the all the nodes and the relation relationship between them okay and here is the another another query i mean the node will be the node one will be the advil i mean advil related dosages duration so on and so forth okay as you see this patient used the advil uh i mean the 12 units sometimes 40 units for five days and one minute okay and you can just walk through the grap h database according to your cipher query this is the cipher query and you can just spend some time about this visually visualizations okay and this is another one it's another one another one so i'm so sure okay let me show you the the visualize the graph you will just hit here the visualization part is opening by the way while uh firing up uh let me just show you another example and i will not go through this example today but you can just reach out from our guitar people the first example is about the healthcare library and the second example is the public one the free one okay you can also use graph extraction here graph extraction annotator in sparking up it to create graphs like what like this the person john snow uh was born in england and john small lives in new york you can just find everything here like this okay you can just try this part uh by yourself and you will see this graph after running this code singapores let me just we just visualize the graph database and we can just finish this webinar right here as you see all the notes and the relationships between nodes has been created and you can just visualize them using neo4j thank you for listening we can go through the q and a part"

### **Detailed Summary of the Webinar**

The webinar, presented by Emre, a data scientist at John Snow Labs, focuses on **creating a Clinical Knowledge Graph (CKG) using the combination of Spark NLP and Neo4j**.

#### **I. Spark NLP: Overview and Healthcare Focus**

Spark NLP is an **open-source library released in 2017**. It is designed as a **single unified NLP library** that works on clusters without requiring external dependencies other than Spark itself. It supports four languages (Python, R, Java, and Scala) and incorporates state-of-the-art algorithms and transfer learning. The library is kept up-to-date with upgrades every two weeks and has over 75 releases.

**Modules and Versions:** Spark NLP offers both public (free) and enterprise/healthcare (licensed) versions. There is also a companion library, Spark OCR, used for processing clinical texts derived from images or PDFs (like EHRs or medical records).

**Pillars of Clinical NLP:** In healthcare, **Named Entity Recognition (NER)** is crucial because it extracts the **minimum meaningful chunk of clinical text**; everything else in the healthcare NLP pipelines builds upon it. NER models locate and classify predefined categories such as persons, locations, organizations, and measurements. The speaker describes NER, along with data annotation, as the "brain and heart of the NLP body".

The four main clinical models covered are:

1.  **Clinical NER:** Extracts clinical entities, with more than 50 different pre-trained models available (e.g., anatomy NER, posology NER), trained on clinical NLP datasets like i2b2 or n2c2.

2.  **Clinical Entity Linking:** Assigns standardized codes (like SNOMED, RxNorm, ICD-10, and UMLS) to the entities detected by NER.

3.  **Assertion Status:** Determines the context of an entity, such as whether a condition is absent or present, or whether a note refers to the patient or a relative (like the patient's father).

4.  **De-identification:** Handles sensitive information according to HIPAA rules by removing or masking it. This process often involves obfuscation, which means replacing sensitive data with fake names or entities.

**Relation Extraction (RE):** Relation extraction is the task of **predicting semantic relationships** between NER chunks. It is the **core component** used to build relational knowledge graphs. RE is vital for detecting relationships such as temporal ordering between clinical events, drug-drug interactions, and connections between medical problems and treatments.

**Challenge of Temporal Ordering:** The automatic extraction of a patient's natural history and the temporal ordering of medical events from clinical texts (EHRs) is a major challenge due to the complex, unstructured, redundant, and inconsistent nature of clinical data. The speaker suggests that the **most appropriate and quickest way** to address this challenge is by combining rule-based methods, a unified NLP library like Spark NLP, and the power of knowledge graphs.

#### **II. Neo4j: The Graph Database**

Neo4j is a **highly scalable native graph database** that organizes data into nodes and relationships (edges). Its central tenet is that the **connections between data are as important as the data itself**.

- **Cypher:** Neo4j uses **Cypher** as its graph query language. Cypher is a declarative pattern matching language designed specifically for graphs, allowing users to specify "what you want, not how to get it".

- **Graph Traversal:** Using graph databases and knowledge graphs is "all about patterns," which are used to traverse nodes and edges.

#### **III. Clinical Knowledge Graph (CKG)**

The goal of a CKG is to **accurately represent the patient's history** and organize the entire body of clinical knowledge.

- **Practitioner Advice:** The speaker emphasizes that before creating a knowledge graph, practitioners must invest time in developing **conceptual graph models** to ensure the resulting graph is relevant and not a "complete mess". After creation, the graph must be validated against the raw data through querying and cross-checking.

- A CKG must be a structured representation, contain high relevancy in clinical data, and be universally accessible.

#### **IV. Live Demo Implementation**

The live demo illustrated the process of creating a CKG using a notebook that integrates Spark NLP and Neo4j.

**Pipeline for Relation Extraction (Posology):** The specific pipeline used to process drug-related text included an eight-step sequence:

1.  Document Assembler and Sentence Detector

2.  Tokenizer

3.  Word Embeddings

4.  Part of Speech Tags

5.  Medical NER Model

6.  NER Converter (to create NER chunks)

7.  Dependency Parser

8.  **Posology Relation Extraction Model** (to determine semantic relationships between the chunks).

**Database Interaction:** The process involves connecting the notebook to a free **Neo4j Sandbox**. A specific function (add ners and relations) is used to iterate over the Relation Extraction results-which detail Chunk 1, the relationship, and Chunk 2 (e.g., Chunk 1 is a duration, Chunk 2 is a drug). This function then executes the creation of nodes (Chunk 1 and Chunk 2) and the relationship (edge) between them in the Neo4j database.

The speaker stressed the importance of managing the graph database by suggesting users **drop all constraints and create their own constraints** at the start of the task to ensure that each NER is created only once (unique).

Finally, the created nodes and relationships were visualized and traversed using Cypher queries, demonstrating how a patient's use of a drug like Advil is linked to specific dosages and durations.